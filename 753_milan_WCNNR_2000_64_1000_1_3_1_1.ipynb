{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# file name meaning\n",
    "\n",
    "eg. 100_cairo_WCNN_2000_64_1000_1_8_1_1.ipynb\n",
    "\n",
    "`[tag]_[dataset_name]_[method_name]_[data_length]_[batch_size]_[epochs]_[kernel_wide_base]_[kernel_number_base]_[net_deep_base]_[calculate_unit]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from tools import general\n",
    "import os\n",
    "from tools.configure.constants import DATASETS_CONSTANT, METHOD_PARAMETER_TEMPLATE, JUPYTER_TOKEN\n",
    "from tools.integration import train_val\n",
    "\n",
    "\n",
    "nb_name_file = general.ipy_nb_name(JUPYTER_TOKEN[\"token_lists\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num': '753',\n",
       " 'dataset_name': 'milan',\n",
       " 'method_name': 'WCNNR',\n",
       " 'data_lenght': 2000,\n",
       " 'batch_size': 64,\n",
       " 'nb_epochs': 1000,\n",
       " 'kernel_wide_base': 1,\n",
       " 'kernel_number_base': 3,\n",
       " 'net_deep_base': 1,\n",
       " 'calculation_unit': '1'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "theNotebook = nb_name_file.split('_')\n",
    "assert len(theNotebook) == 9 or len(theNotebook) == 10, 'The number of parameters should be 9 / 10'\n",
    "\n",
    "global title_param\n",
    "title_param = {\n",
    "    'num': theNotebook[0],\n",
    "    'dataset_name': theNotebook[1],\n",
    "    'method_name': theNotebook[2],\n",
    "    'data_lenght': int(theNotebook[3]),\n",
    "    'batch_size': int(theNotebook[4]),\n",
    "    'nb_epochs': int(theNotebook[5]),\n",
    "    'kernel_wide_base': int(theNotebook[6]),\n",
    "    'kernel_number_base': int(theNotebook[7]),\n",
    "    'net_deep_base': int(theNotebook[8]),\n",
    "    'calculation_unit': theNotebook[9] if len(theNotebook)==10 else '0',  # If not specified, the CPU is used to train the model\n",
    "}\n",
    "\n",
    "# assert title_param['dataset'] in ['cairo', 'milan', 'kyoto7', 'kyoto8', 'kyoto11'], 'Please correct the dataset name！'\n",
    "# assert title_param['model_name'] in ['WCNN','LSTM'], 'The method is wrong. Please correct it！'\n",
    "# assert title_param['optimizer'] in ['rms', 'adagrad'], 'The optimizer is wrong. Please correct it！'\n",
    "# assert title_param['calculation_unit'] in ['0', '1', '2'], 'Error in calculation unit selection, please correct！'\n",
    "\n",
    "display(title_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_config_cus = {\n",
    "\n",
    "        \"datasets_dir\": DATASETS_CONSTANT[\"base_dir\"],  # 这是公共数据集常量\n",
    "        \"archive_name\": DATASETS_CONSTANT[\"archive_name\"],\n",
    "        \"ksplit\": DATASETS_CONSTANT[\"ksplit\"],\n",
    "\n",
    "        'distance_int': None,\n",
    "    }\n",
    "\n",
    "dict_config_cus = general.Merge(title_param, dict_config_cus)\n",
    "\n",
    "from tools.configure.constants import WCNNR_CONSTANT as MODEL_DEFAULT_CONF\n",
    "\n",
    "dict_config_cus = general.Merge(MODEL_DEFAULT_CONF, dict_config_cus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU used: [66], final choose: 0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "calculation_unit = general.getAvailableId()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = calculation_unit\n",
    "\n",
    "if calculation_unit != \"-1\":\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    session = tf.Session(config=config)\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[origin](#origin)\n",
    "\n",
    "[C](#constrain)\n",
    "\n",
    "[CS_1](#constrain_1)\n",
    "\n",
    "[CS_2](#constrain_2)\n",
    "\n",
    "[CS_3](#constrain_3)\n",
    "\n",
    "[CS_4](#constrain_4)\n",
    "\n",
    "[CS_5](#constrain_5)\n",
    "\n",
    "[statics](#statics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='origin'>origin</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current dataset: milan\n",
      "../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1\n",
      "no_activities: 10\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_19 (Embedding)     (None, 2000, 64)          172544    \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 2000, 12)          780       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 2000, 12)          0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_19 (Glo (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 18)                234       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 12)                228       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 10)                130       \n",
      "=================================================================\n",
      "Total params: 173,916\n",
      "Trainable params: 173,916\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Create subdir directory: ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights...\n",
      "Begin training ...\n",
      "Epoch 1/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.8357 - acc: 0.4453 - val_loss: 1.4623 - val_acc: 0.5432\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.4335 - acc: 0.5502 - val_loss: 1.2270 - val_acc: 0.6205\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.3098 - acc: 0.5778 - val_loss: 1.1338 - val_acc: 0.6458\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.2475 - acc: 0.5926 - val_loss: 1.0905 - val_acc: 0.6726\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.2087 - acc: 0.6079 - val_loss: 1.0539 - val_acc: 0.6689\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.1974 - acc: 0.6124 - val_loss: 1.0290 - val_acc: 0.6749\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.1678 - acc: 0.6161 - val_loss: 1.0079 - val_acc: 0.6815\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.1370 - acc: 0.6231 - val_loss: 0.9837 - val_acc: 0.6875\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.1162 - acc: 0.6306 - val_loss: 0.9636 - val_acc: 0.6905\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.0881 - acc: 0.6313 - val_loss: 0.9436 - val_acc: 0.6912\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.0893 - acc: 0.6246 - val_loss: 0.9312 - val_acc: 0.6912\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.0614 - acc: 0.6458 - val_loss: 0.9247 - val_acc: 0.6853\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.0339 - acc: 0.6525 - val_loss: 0.9084 - val_acc: 0.6905\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.0474 - acc: 0.6376 - val_loss: 0.9039 - val_acc: 0.6935\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.0335 - acc: 0.6429 - val_loss: 0.8960 - val_acc: 0.6920\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.0213 - acc: 0.6440 - val_loss: 0.8849 - val_acc: 0.6964\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 1.0136 - acc: 0.6440 - val_loss: 0.8831 - val_acc: 0.6920\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.0066 - acc: 0.6503 - val_loss: 0.8708 - val_acc: 0.7009\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.9902 - acc: 0.6589 - val_loss: 0.8593 - val_acc: 0.6972\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.9985 - acc: 0.6510 - val_loss: 0.8532 - val_acc: 0.6979\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.9782 - acc: 0.6648 - val_loss: 0.8460 - val_acc: 0.7165\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.9664 - acc: 0.6600 - val_loss: 0.8381 - val_acc: 0.7240\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.9604 - acc: 0.6700 - val_loss: 0.8277 - val_acc: 0.7254\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.9611 - acc: 0.6756 - val_loss: 0.8173 - val_acc: 0.7307\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.9452 - acc: 0.6715 - val_loss: 0.8212 - val_acc: 0.7336\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.9396 - acc: 0.6778 - val_loss: 0.8114 - val_acc: 0.7381\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.9466 - acc: 0.6801 - val_loss: 0.8039 - val_acc: 0.7396\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.9241 - acc: 0.6823 - val_loss: 0.8005 - val_acc: 0.7396\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.9321 - acc: 0.6868 - val_loss: 0.7983 - val_acc: 0.7426\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.9251 - acc: 0.6860 - val_loss: 0.7944 - val_acc: 0.7463\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.9245 - acc: 0.6741 - val_loss: 0.7897 - val_acc: 0.7463\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.9277 - acc: 0.6894 - val_loss: 0.7892 - val_acc: 0.7463\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.9240 - acc: 0.6808 - val_loss: 0.7903 - val_acc: 0.7440\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.9036 - acc: 0.6856 - val_loss: 0.7887 - val_acc: 0.7411\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.9035 - acc: 0.6953 - val_loss: 0.7806 - val_acc: 0.7478\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.8947 - acc: 0.6964 - val_loss: 0.7767 - val_acc: 0.7507\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.9050 - acc: 0.6882 - val_loss: 0.7731 - val_acc: 0.7493\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.9102 - acc: 0.6987 - val_loss: 0.7727 - val_acc: 0.7522\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.8908 - acc: 0.6949 - val_loss: 0.7721 - val_acc: 0.7522\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.8951 - acc: 0.6979 - val_loss: 0.7690 - val_acc: 0.7500\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.9079 - acc: 0.6901 - val_loss: 0.7668 - val_acc: 0.7507\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8987 - acc: 0.6983 - val_loss: 0.7644 - val_acc: 0.7493\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8936 - acc: 0.6856 - val_loss: 0.7620 - val_acc: 0.7470\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8910 - acc: 0.6901 - val_loss: 0.7640 - val_acc: 0.7500\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8800 - acc: 0.7024 - val_loss: 0.7550 - val_acc: 0.7522\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8872 - acc: 0.6972 - val_loss: 0.7565 - val_acc: 0.7493\n",
      "Epoch 47/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8857 - acc: 0.6938 - val_loss: 0.7507 - val_acc: 0.7522\n",
      "Epoch 48/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8643 - acc: 0.7031 - val_loss: 0.7478 - val_acc: 0.7493\n",
      "Epoch 49/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8679 - acc: 0.6964 - val_loss: 0.7469 - val_acc: 0.7507\n",
      "Epoch 50/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8710 - acc: 0.7102 - val_loss: 0.7465 - val_acc: 0.7507\n",
      "Epoch 51/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8527 - acc: 0.7035 - val_loss: 0.7445 - val_acc: 0.7507\n",
      "Epoch 52/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8632 - acc: 0.7068 - val_loss: 0.7393 - val_acc: 0.7507\n",
      "Epoch 53/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8599 - acc: 0.7020 - val_loss: 0.7458 - val_acc: 0.7485\n",
      "Epoch 54/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8549 - acc: 0.7031 - val_loss: 0.7433 - val_acc: 0.7485\n",
      "Epoch 55/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8538 - acc: 0.7139 - val_loss: 0.7387 - val_acc: 0.7493\n",
      "Epoch 56/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8676 - acc: 0.7072 - val_loss: 0.7416 - val_acc: 0.7493\n",
      "Epoch 57/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8562 - acc: 0.7068 - val_loss: 0.7381 - val_acc: 0.7515\n",
      "Epoch 58/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.8594 - acc: 0.6964 - val_loss: 0.7355 - val_acc: 0.7515\n",
      "Epoch 59/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8599 - acc: 0.7080 - val_loss: 0.7389 - val_acc: 0.7485\n",
      "Epoch 60/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8549 - acc: 0.7028 - val_loss: 0.7359 - val_acc: 0.7507\n",
      "Epoch 61/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8518 - acc: 0.7031 - val_loss: 0.7352 - val_acc: 0.7478\n",
      "Epoch 62/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8520 - acc: 0.7028 - val_loss: 0.7345 - val_acc: 0.7485\n",
      "Epoch 63/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8527 - acc: 0.7061 - val_loss: 0.7330 - val_acc: 0.7470\n",
      "Epoch 64/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8315 - acc: 0.7232 - val_loss: 0.7301 - val_acc: 0.7485\n",
      "Epoch 65/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8510 - acc: 0.7054 - val_loss: 0.7293 - val_acc: 0.7485\n",
      "\n",
      "Epoch 00065: loss improved from inf to 0.85103, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-0-000065-0.851026-0.748512.hdf5\n",
      "Epoch 66/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8363 - acc: 0.7117 - val_loss: 0.7296 - val_acc: 0.7485\n",
      "Epoch 67/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8462 - acc: 0.7080 - val_loss: 0.7287 - val_acc: 0.7485\n",
      "Epoch 68/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8446 - acc: 0.7117 - val_loss: 0.7278 - val_acc: 0.7470\n",
      "Epoch 69/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8318 - acc: 0.7150 - val_loss: 0.7251 - val_acc: 0.7493\n",
      "\n",
      "Epoch 00069: loss improved from 0.85103 to 0.83182, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-0-000069-0.831825-0.749256.hdf5\n",
      "Epoch 70/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8358 - acc: 0.7113 - val_loss: 0.7269 - val_acc: 0.7485\n",
      "Epoch 71/1000\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.8466 - acc: 0.7169 - val_loss: 0.7205 - val_acc: 0.7515\n",
      "Epoch 72/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8192 - acc: 0.7128 - val_loss: 0.7210 - val_acc: 0.7507\n",
      "Epoch 73/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8222 - acc: 0.7173 - val_loss: 0.7185 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00073: loss improved from 0.83182 to 0.82225, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-0-000073-0.822245-0.750000.hdf5\n",
      "Epoch 74/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8268 - acc: 0.7169 - val_loss: 0.7222 - val_acc: 0.7493\n",
      "Epoch 75/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8255 - acc: 0.7180 - val_loss: 0.7187 - val_acc: 0.7500\n",
      "Epoch 76/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8369 - acc: 0.7061 - val_loss: 0.7207 - val_acc: 0.7493\n",
      "Epoch 77/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8318 - acc: 0.7165 - val_loss: 0.7137 - val_acc: 0.7530\n",
      "Epoch 78/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8151 - acc: 0.7143 - val_loss: 0.7148 - val_acc: 0.7522\n",
      "Epoch 79/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8280 - acc: 0.7176 - val_loss: 0.7140 - val_acc: 0.7507\n",
      "Epoch 80/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8239 - acc: 0.7124 - val_loss: 0.7109 - val_acc: 0.7530\n",
      "Epoch 81/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8166 - acc: 0.7150 - val_loss: 0.7087 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00081: loss improved from 0.82225 to 0.81658, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-0-000081-0.816580-0.752232.hdf5\n",
      "Epoch 82/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8276 - acc: 0.7121 - val_loss: 0.7104 - val_acc: 0.7500\n",
      "Epoch 83/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8294 - acc: 0.7087 - val_loss: 0.7084 - val_acc: 0.7515\n",
      "Epoch 84/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8088 - acc: 0.7139 - val_loss: 0.7061 - val_acc: 0.7507\n",
      "Epoch 85/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8354 - acc: 0.7035 - val_loss: 0.7077 - val_acc: 0.7507\n",
      "Epoch 86/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8128 - acc: 0.7117 - val_loss: 0.7046 - val_acc: 0.7545\n",
      "Epoch 87/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8121 - acc: 0.7240 - val_loss: 0.7072 - val_acc: 0.7507\n",
      "Epoch 88/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8283 - acc: 0.7165 - val_loss: 0.7037 - val_acc: 0.7522\n",
      "Epoch 89/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8227 - acc: 0.7106 - val_loss: 0.7022 - val_acc: 0.7530\n",
      "Epoch 90/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8200 - acc: 0.7072 - val_loss: 0.7012 - val_acc: 0.7530\n",
      "Epoch 91/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8132 - acc: 0.7128 - val_loss: 0.7012 - val_acc: 0.7515\n",
      "Epoch 92/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8050 - acc: 0.7158 - val_loss: 0.7026 - val_acc: 0.7522\n",
      "Epoch 93/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8104 - acc: 0.7135 - val_loss: 0.7020 - val_acc: 0.7537\n",
      "\n",
      "Epoch 00093: loss improved from 0.81658 to 0.81037, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-0-000093-0.810370-0.753720.hdf5\n",
      "Epoch 94/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8048 - acc: 0.7161 - val_loss: 0.7018 - val_acc: 0.7515\n",
      "Epoch 95/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8098 - acc: 0.7161 - val_loss: 0.7000 - val_acc: 0.7515\n",
      "Epoch 96/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8077 - acc: 0.7154 - val_loss: 0.7016 - val_acc: 0.7522\n",
      "Epoch 97/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8059 - acc: 0.7269 - val_loss: 0.6989 - val_acc: 0.7552\n",
      "\n",
      "Epoch 00097: loss improved from 0.81037 to 0.80590, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-0-000097-0.805900-0.755208.hdf5\n",
      "Epoch 98/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7963 - acc: 0.7217 - val_loss: 0.6995 - val_acc: 0.7545\n",
      "Epoch 99/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8091 - acc: 0.7206 - val_loss: 0.6984 - val_acc: 0.7507\n",
      "Epoch 100/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8034 - acc: 0.7199 - val_loss: 0.6968 - val_acc: 0.7567\n",
      "\n",
      "Epoch 00100: saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/0-000100-0.803427-0.756696.hdf5\n",
      "Epoch 101/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8156 - acc: 0.7128 - val_loss: 0.6951 - val_acc: 0.7567\n",
      "Epoch 102/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8079 - acc: 0.7173 - val_loss: 0.6967 - val_acc: 0.7560\n",
      "Epoch 103/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7819 - acc: 0.7210 - val_loss: 0.6991 - val_acc: 0.7560\n",
      "Epoch 104/1000\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.8122 - acc: 0.7161 - val_loss: 0.7008 - val_acc: 0.7507\n",
      "Epoch 105/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7911 - acc: 0.7184 - val_loss: 0.6972 - val_acc: 0.7552\n",
      "Epoch 106/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7971 - acc: 0.7240 - val_loss: 0.6936 - val_acc: 0.7560\n",
      "Epoch 107/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7940 - acc: 0.7221 - val_loss: 0.6908 - val_acc: 0.7574\n",
      "Epoch 108/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.7854 - acc: 0.7232 - val_loss: 0.6922 - val_acc: 0.7567\n",
      "Epoch 109/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8020 - acc: 0.7188 - val_loss: 0.6915 - val_acc: 0.7612\n",
      "Epoch 110/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7964 - acc: 0.7143 - val_loss: 0.6894 - val_acc: 0.7567\n",
      "Epoch 111/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7867 - acc: 0.7325 - val_loss: 0.6907 - val_acc: 0.7515\n",
      "Epoch 112/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7905 - acc: 0.7180 - val_loss: 0.6888 - val_acc: 0.7567\n",
      "Epoch 113/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7849 - acc: 0.7243 - val_loss: 0.6866 - val_acc: 0.7560\n",
      "Epoch 114/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7810 - acc: 0.7258 - val_loss: 0.6865 - val_acc: 0.7552\n",
      "Epoch 115/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7826 - acc: 0.7217 - val_loss: 0.6893 - val_acc: 0.7537\n",
      "Epoch 116/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7982 - acc: 0.7121 - val_loss: 0.6893 - val_acc: 0.7552\n",
      "Epoch 117/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7935 - acc: 0.7273 - val_loss: 0.6888 - val_acc: 0.7552\n",
      "Epoch 118/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7972 - acc: 0.7214 - val_loss: 0.6885 - val_acc: 0.7552\n",
      "Epoch 119/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7944 - acc: 0.7154 - val_loss: 0.6846 - val_acc: 0.7574\n",
      "Epoch 120/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.7725 - acc: 0.7295 - val_loss: 0.6825 - val_acc: 0.7626\n",
      "Epoch 121/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7871 - acc: 0.7202 - val_loss: 0.6879 - val_acc: 0.7552\n",
      "Epoch 122/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7873 - acc: 0.7262 - val_loss: 0.6849 - val_acc: 0.7604\n",
      "Epoch 123/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7916 - acc: 0.7258 - val_loss: 0.6876 - val_acc: 0.7530\n",
      "Epoch 124/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7854 - acc: 0.7214 - val_loss: 0.6808 - val_acc: 0.7664\n",
      "Epoch 125/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7850 - acc: 0.7277 - val_loss: 0.6824 - val_acc: 0.7589\n",
      "Epoch 126/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7857 - acc: 0.7217 - val_loss: 0.6827 - val_acc: 0.7567\n",
      "Epoch 127/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7904 - acc: 0.7195 - val_loss: 0.6845 - val_acc: 0.7619\n",
      "Epoch 128/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7768 - acc: 0.7191 - val_loss: 0.6851 - val_acc: 0.7567\n",
      "Epoch 129/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7736 - acc: 0.7292 - val_loss: 0.6847 - val_acc: 0.7574\n",
      "Epoch 130/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7954 - acc: 0.7169 - val_loss: 0.6778 - val_acc: 0.7574\n",
      "Epoch 131/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7932 - acc: 0.7292 - val_loss: 0.6816 - val_acc: 0.7612\n",
      "Epoch 132/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7930 - acc: 0.7254 - val_loss: 0.6748 - val_acc: 0.7619\n",
      "Epoch 133/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7774 - acc: 0.7236 - val_loss: 0.6802 - val_acc: 0.7626\n",
      "Epoch 134/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7903 - acc: 0.7243 - val_loss: 0.6800 - val_acc: 0.7634\n",
      "Epoch 135/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7870 - acc: 0.7169 - val_loss: 0.6764 - val_acc: 0.7656\n",
      "Epoch 136/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7643 - acc: 0.7284 - val_loss: 0.6814 - val_acc: 0.7612\n",
      "Epoch 137/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7726 - acc: 0.7277 - val_loss: 0.6798 - val_acc: 0.7649\n",
      "Epoch 138/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7752 - acc: 0.7262 - val_loss: 0.6746 - val_acc: 0.7649\n",
      "Epoch 139/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7773 - acc: 0.7284 - val_loss: 0.6750 - val_acc: 0.7664\n",
      "Epoch 140/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7664 - acc: 0.7217 - val_loss: 0.6784 - val_acc: 0.7649\n",
      "Epoch 141/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7707 - acc: 0.7344 - val_loss: 0.6780 - val_acc: 0.7656\n",
      "Epoch 142/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7763 - acc: 0.7254 - val_loss: 0.6770 - val_acc: 0.7604\n",
      "Epoch 143/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7797 - acc: 0.7307 - val_loss: 0.6763 - val_acc: 0.7641\n",
      "Epoch 144/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7609 - acc: 0.7247 - val_loss: 0.6762 - val_acc: 0.7641\n",
      "Epoch 145/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7683 - acc: 0.7258 - val_loss: 0.6769 - val_acc: 0.7589\n",
      "Epoch 146/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7613 - acc: 0.7299 - val_loss: 0.6783 - val_acc: 0.7574\n",
      "Epoch 147/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7606 - acc: 0.7344 - val_loss: 0.6758 - val_acc: 0.7582\n",
      "Epoch 148/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7785 - acc: 0.7161 - val_loss: 0.6772 - val_acc: 0.7574\n",
      "Epoch 149/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7873 - acc: 0.7124 - val_loss: 0.6744 - val_acc: 0.7574\n",
      "Epoch 150/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7743 - acc: 0.7240 - val_loss: 0.6785 - val_acc: 0.7589\n",
      "Epoch 151/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7705 - acc: 0.7243 - val_loss: 0.6768 - val_acc: 0.7574\n",
      "Epoch 152/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7692 - acc: 0.7318 - val_loss: 0.6743 - val_acc: 0.7604\n",
      "Epoch 153/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7641 - acc: 0.7333 - val_loss: 0.6745 - val_acc: 0.7582\n",
      "Epoch 154/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7664 - acc: 0.7221 - val_loss: 0.6766 - val_acc: 0.7567\n",
      "Epoch 155/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7654 - acc: 0.7299 - val_loss: 0.6751 - val_acc: 0.7574\n",
      "Epoch 156/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7781 - acc: 0.7292 - val_loss: 0.6752 - val_acc: 0.7560\n",
      "Epoch 157/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7621 - acc: 0.7336 - val_loss: 0.6727 - val_acc: 0.7574\n",
      "Epoch 158/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7645 - acc: 0.7340 - val_loss: 0.6713 - val_acc: 0.7641\n",
      "Epoch 159/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7598 - acc: 0.7266 - val_loss: 0.6729 - val_acc: 0.7626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7645 - acc: 0.7281 - val_loss: 0.6715 - val_acc: 0.7582\n",
      "Epoch 161/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7662 - acc: 0.7288 - val_loss: 0.6737 - val_acc: 0.7582\n",
      "Epoch 162/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7821 - acc: 0.7150 - val_loss: 0.6724 - val_acc: 0.7604\n",
      "Epoch 163/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7704 - acc: 0.7277 - val_loss: 0.6706 - val_acc: 0.7574\n",
      "Epoch 164/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7710 - acc: 0.7310 - val_loss: 0.6684 - val_acc: 0.7567\n",
      "Epoch 165/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7764 - acc: 0.7184 - val_loss: 0.6704 - val_acc: 0.7560\n",
      "\n",
      "Epoch 00165: loss improved from inf to 0.77637, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-0-000165-0.776371-0.755952.hdf5\n",
      "Epoch 166/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7563 - acc: 0.7254 - val_loss: 0.6725 - val_acc: 0.7552\n",
      "Epoch 167/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7586 - acc: 0.7396 - val_loss: 0.6680 - val_acc: 0.7597\n",
      "Epoch 168/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7622 - acc: 0.7258 - val_loss: 0.6644 - val_acc: 0.7619\n",
      "Epoch 169/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7651 - acc: 0.7251 - val_loss: 0.6688 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00169: loss improved from 0.77637 to 0.76512, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-0-000169-0.765117-0.757440.hdf5\n",
      "Epoch 170/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7563 - acc: 0.7362 - val_loss: 0.6663 - val_acc: 0.7597\n",
      "Epoch 171/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7590 - acc: 0.7254 - val_loss: 0.6681 - val_acc: 0.7560\n",
      "Epoch 172/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7655 - acc: 0.7247 - val_loss: 0.6655 - val_acc: 0.7567\n",
      "Epoch 173/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7652 - acc: 0.7258 - val_loss: 0.6654 - val_acc: 0.7604\n",
      "Epoch 174/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7599 - acc: 0.7281 - val_loss: 0.6684 - val_acc: 0.7560\n",
      "Epoch 175/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7636 - acc: 0.7310 - val_loss: 0.6677 - val_acc: 0.7545\n",
      "Epoch 176/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7500 - acc: 0.7288 - val_loss: 0.6685 - val_acc: 0.7567\n",
      "Epoch 177/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7467 - acc: 0.7433 - val_loss: 0.6659 - val_acc: 0.7567\n",
      "\n",
      "Epoch 00177: loss improved from 0.76512 to 0.74673, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-0-000177-0.746733-0.756696.hdf5\n",
      "Epoch 178/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7648 - acc: 0.7228 - val_loss: 0.6661 - val_acc: 0.7552\n",
      "Epoch 179/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7548 - acc: 0.7281 - val_loss: 0.6651 - val_acc: 0.7582\n",
      "Epoch 180/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7588 - acc: 0.7228 - val_loss: 0.6655 - val_acc: 0.7552\n",
      "Epoch 181/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7627 - acc: 0.7262 - val_loss: 0.6665 - val_acc: 0.7552\n",
      "Epoch 182/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7489 - acc: 0.7388 - val_loss: 0.6656 - val_acc: 0.7597\n",
      "Epoch 183/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7617 - acc: 0.7254 - val_loss: 0.6652 - val_acc: 0.7582\n",
      "Epoch 184/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7457 - acc: 0.7307 - val_loss: 0.6638 - val_acc: 0.7574\n",
      "Epoch 185/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.7571 - acc: 0.7318 - val_loss: 0.6633 - val_acc: 0.7589\n",
      "Epoch 186/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7554 - acc: 0.7295 - val_loss: 0.6628 - val_acc: 0.7589\n",
      "Epoch 187/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7570 - acc: 0.7221 - val_loss: 0.6604 - val_acc: 0.7589\n",
      "Epoch 188/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7550 - acc: 0.7333 - val_loss: 0.6564 - val_acc: 0.7582\n",
      "Epoch 189/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7496 - acc: 0.7336 - val_loss: 0.6615 - val_acc: 0.7537\n",
      "Epoch 190/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7461 - acc: 0.7281 - val_loss: 0.6653 - val_acc: 0.7545\n",
      "Epoch 191/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7550 - acc: 0.7228 - val_loss: 0.6631 - val_acc: 0.7552\n",
      "Epoch 192/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7611 - acc: 0.7310 - val_loss: 0.6588 - val_acc: 0.7626\n",
      "Epoch 193/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.7499 - acc: 0.7299 - val_loss: 0.6635 - val_acc: 0.7589\n",
      "Epoch 194/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7473 - acc: 0.7299 - val_loss: 0.6637 - val_acc: 0.7582\n",
      "Epoch 195/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7547 - acc: 0.7333 - val_loss: 0.6618 - val_acc: 0.7589\n",
      "Epoch 196/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7524 - acc: 0.7247 - val_loss: 0.6650 - val_acc: 0.7574\n",
      "Epoch 197/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7422 - acc: 0.7344 - val_loss: 0.6635 - val_acc: 0.7567\n",
      "\n",
      "Epoch 00197: loss improved from 0.74673 to 0.74215, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-0-000197-0.742152-0.756696.hdf5\n",
      "Epoch 198/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7462 - acc: 0.7247 - val_loss: 0.6603 - val_acc: 0.7612\n",
      "Epoch 199/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7444 - acc: 0.7340 - val_loss: 0.6615 - val_acc: 0.7626\n",
      "Epoch 200/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7393 - acc: 0.7392 - val_loss: 0.6587 - val_acc: 0.7626\n",
      "\n",
      "Epoch 00200: saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/0-000200-0.739323-0.762649.hdf5\n",
      "Epoch 201/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.7516 - acc: 0.7288 - val_loss: 0.6625 - val_acc: 0.7626\n",
      "Epoch 202/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7461 - acc: 0.7355 - val_loss: 0.6621 - val_acc: 0.7604\n",
      "Epoch 203/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7346 - acc: 0.7381 - val_loss: 0.6589 - val_acc: 0.7634\n",
      "Epoch 204/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7479 - acc: 0.7370 - val_loss: 0.6549 - val_acc: 0.7552\n",
      "Epoch 205/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7418 - acc: 0.7344 - val_loss: 0.6595 - val_acc: 0.7545\n",
      "Epoch 206/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7453 - acc: 0.7355 - val_loss: 0.6609 - val_acc: 0.7530\n",
      "Epoch 207/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7398 - acc: 0.7295 - val_loss: 0.6590 - val_acc: 0.7604\n",
      "Epoch 208/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7458 - acc: 0.7359 - val_loss: 0.6595 - val_acc: 0.7515\n",
      "Epoch 209/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7304 - acc: 0.7314 - val_loss: 0.6568 - val_acc: 0.7574\n",
      "Epoch 210/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7497 - acc: 0.7336 - val_loss: 0.6596 - val_acc: 0.7537\n",
      "Epoch 211/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7425 - acc: 0.7314 - val_loss: 0.6570 - val_acc: 0.7552\n",
      "Epoch 212/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7316 - acc: 0.7366 - val_loss: 0.6550 - val_acc: 0.7560\n",
      "Epoch 213/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7452 - acc: 0.7336 - val_loss: 0.6562 - val_acc: 0.7552\n",
      "Epoch 214/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7503 - acc: 0.7336 - val_loss: 0.6580 - val_acc: 0.7500\n",
      "Epoch 215/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7418 - acc: 0.7314 - val_loss: 0.6584 - val_acc: 0.7589\n",
      "Epoch 216/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7441 - acc: 0.7366 - val_loss: 0.6559 - val_acc: 0.7567\n",
      "Epoch 217/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7339 - acc: 0.7333 - val_loss: 0.6565 - val_acc: 0.7597\n",
      "Epoch 218/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7268 - acc: 0.7377 - val_loss: 0.6549 - val_acc: 0.7612\n",
      "Epoch 219/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7346 - acc: 0.7396 - val_loss: 0.6561 - val_acc: 0.7604\n",
      "Epoch 220/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7431 - acc: 0.7437 - val_loss: 0.6539 - val_acc: 0.7604\n",
      "Epoch 221/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7454 - acc: 0.7359 - val_loss: 0.6544 - val_acc: 0.7560\n",
      "Epoch 222/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7290 - acc: 0.7370 - val_loss: 0.6537 - val_acc: 0.7589\n",
      "Epoch 223/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7249 - acc: 0.7292 - val_loss: 0.6517 - val_acc: 0.7552\n",
      "Epoch 224/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7487 - acc: 0.7347 - val_loss: 0.6546 - val_acc: 0.7545\n",
      "Epoch 225/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7408 - acc: 0.7403 - val_loss: 0.6535 - val_acc: 0.7589\n",
      "Epoch 226/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7383 - acc: 0.7366 - val_loss: 0.6528 - val_acc: 0.7612\n",
      "Epoch 227/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7658 - acc: 0.7314 - val_loss: 0.6548 - val_acc: 0.7604\n",
      "Epoch 228/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7349 - acc: 0.7321 - val_loss: 0.6537 - val_acc: 0.7604\n",
      "Epoch 229/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7411 - acc: 0.7303 - val_loss: 0.6509 - val_acc: 0.7589\n",
      "Epoch 230/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7521 - acc: 0.7284 - val_loss: 0.6545 - val_acc: 0.7604\n",
      "Epoch 231/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7398 - acc: 0.7400 - val_loss: 0.6532 - val_acc: 0.7619\n",
      "Epoch 232/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7370 - acc: 0.7347 - val_loss: 0.6536 - val_acc: 0.7582\n",
      "Epoch 233/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7343 - acc: 0.7381 - val_loss: 0.6502 - val_acc: 0.7574\n",
      "Epoch 234/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7426 - acc: 0.7217 - val_loss: 0.6553 - val_acc: 0.7567\n",
      "Epoch 235/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7425 - acc: 0.7344 - val_loss: 0.6526 - val_acc: 0.7626\n",
      "Epoch 236/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7340 - acc: 0.7392 - val_loss: 0.6502 - val_acc: 0.7634\n",
      "Epoch 237/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7413 - acc: 0.7336 - val_loss: 0.6529 - val_acc: 0.7597\n",
      "Epoch 238/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7300 - acc: 0.7362 - val_loss: 0.6542 - val_acc: 0.7567\n",
      "Epoch 239/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7296 - acc: 0.7396 - val_loss: 0.6532 - val_acc: 0.7567\n",
      "Epoch 240/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7376 - acc: 0.7321 - val_loss: 0.6526 - val_acc: 0.7560\n",
      "Epoch 241/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7349 - acc: 0.7307 - val_loss: 0.6531 - val_acc: 0.7634\n",
      "Epoch 242/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7333 - acc: 0.7355 - val_loss: 0.6525 - val_acc: 0.7634\n",
      "Epoch 243/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7354 - acc: 0.7414 - val_loss: 0.6536 - val_acc: 0.7612\n",
      "\n",
      "Epoch 00243: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 244/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7351 - acc: 0.7418 - val_loss: 0.6487 - val_acc: 0.7634\n",
      "Epoch 245/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7206 - acc: 0.7455 - val_loss: 0.6522 - val_acc: 0.7612\n",
      "Epoch 246/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7074 - acc: 0.7426 - val_loss: 0.6493 - val_acc: 0.7626\n",
      "Epoch 247/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7306 - acc: 0.7407 - val_loss: 0.6520 - val_acc: 0.7619\n",
      "Epoch 248/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7228 - acc: 0.7433 - val_loss: 0.6490 - val_acc: 0.7641\n",
      "Epoch 249/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7304 - acc: 0.7463 - val_loss: 0.6518 - val_acc: 0.7626\n",
      "Epoch 250/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7199 - acc: 0.7403 - val_loss: 0.6518 - val_acc: 0.7619\n",
      "Epoch 251/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7302 - acc: 0.7403 - val_loss: 0.6444 - val_acc: 0.7619\n",
      "Epoch 252/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.7354 - acc: 0.7318 - val_loss: 0.6503 - val_acc: 0.7612\n",
      "Epoch 253/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7208 - acc: 0.7414 - val_loss: 0.6483 - val_acc: 0.7619\n",
      "Epoch 254/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7392 - acc: 0.7277 - val_loss: 0.6496 - val_acc: 0.7612\n",
      "Epoch 255/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7318 - acc: 0.7355 - val_loss: 0.6508 - val_acc: 0.7626\n",
      "Epoch 256/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7196 - acc: 0.7426 - val_loss: 0.6511 - val_acc: 0.7626\n",
      "Epoch 257/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7343 - acc: 0.7284 - val_loss: 0.6485 - val_acc: 0.7634\n",
      "Epoch 258/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7131 - acc: 0.7396 - val_loss: 0.6499 - val_acc: 0.7634\n",
      "Epoch 259/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7355 - acc: 0.7400 - val_loss: 0.6492 - val_acc: 0.7612\n",
      "Epoch 260/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7470 - acc: 0.7281 - val_loss: 0.6483 - val_acc: 0.7626\n",
      "Epoch 261/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7396 - acc: 0.7355 - val_loss: 0.6498 - val_acc: 0.7612\n",
      "Epoch 262/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7321 - acc: 0.7370 - val_loss: 0.6492 - val_acc: 0.7619\n",
      "Epoch 263/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7349 - acc: 0.7414 - val_loss: 0.6514 - val_acc: 0.7604\n",
      "Epoch 264/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7379 - acc: 0.7295 - val_loss: 0.6491 - val_acc: 0.7634\n",
      "Epoch 265/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7347 - acc: 0.7385 - val_loss: 0.6507 - val_acc: 0.7619\n",
      "\n",
      "Epoch 00265: loss improved from inf to 0.73470, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-0-000265-0.734695-0.761905.hdf5\n",
      "Epoch 266/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7290 - acc: 0.7392 - val_loss: 0.6480 - val_acc: 0.7634\n",
      "\n",
      "Epoch 00266: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 267/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7268 - acc: 0.7407 - val_loss: 0.6497 - val_acc: 0.7626\n",
      "Epoch 268/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7288 - acc: 0.7292 - val_loss: 0.6490 - val_acc: 0.7619\n",
      "Epoch 269/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7250 - acc: 0.7429 - val_loss: 0.6506 - val_acc: 0.7612\n",
      "\n",
      "Epoch 00269: loss improved from 0.73470 to 0.72498, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-0-000269-0.724985-0.761161.hdf5\n",
      "Epoch 270/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7441 - acc: 0.7347 - val_loss: 0.6459 - val_acc: 0.7612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7269 - acc: 0.7351 - val_loss: 0.6505 - val_acc: 0.7604\n",
      "Epoch 272/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7319 - acc: 0.7385 - val_loss: 0.6487 - val_acc: 0.7619\n",
      "Epoch 273/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7326 - acc: 0.7396 - val_loss: 0.6451 - val_acc: 0.7619\n",
      "Epoch 274/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7321 - acc: 0.7329 - val_loss: 0.6489 - val_acc: 0.7612\n",
      "Epoch 275/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7244 - acc: 0.7381 - val_loss: 0.6506 - val_acc: 0.7612\n",
      "Epoch 276/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7316 - acc: 0.7414 - val_loss: 0.6479 - val_acc: 0.7619\n",
      "Epoch 277/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7447 - acc: 0.7303 - val_loss: 0.6479 - val_acc: 0.7619\n",
      "Epoch 278/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7210 - acc: 0.7440 - val_loss: 0.6510 - val_acc: 0.7604\n",
      "Epoch 279/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7552 - acc: 0.7396 - val_loss: 0.6478 - val_acc: 0.7619\n",
      "Epoch 280/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7398 - acc: 0.7325 - val_loss: 0.6500 - val_acc: 0.7604\n",
      "Epoch 281/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7279 - acc: 0.7403 - val_loss: 0.6504 - val_acc: 0.7604\n",
      "Epoch 282/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7094 - acc: 0.7370 - val_loss: 0.6498 - val_acc: 0.7612\n",
      "Epoch 283/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7365 - acc: 0.7318 - val_loss: 0.6508 - val_acc: 0.7604\n",
      "Epoch 284/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7225 - acc: 0.7340 - val_loss: 0.6500 - val_acc: 0.7612\n",
      "Epoch 285/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7292 - acc: 0.7333 - val_loss: 0.6511 - val_acc: 0.7604\n",
      "Epoch 286/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7366 - acc: 0.7329 - val_loss: 0.6498 - val_acc: 0.7612\n",
      "\n",
      "Epoch 00286: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 287/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7430 - acc: 0.7303 - val_loss: 0.6494 - val_acc: 0.7612\n",
      "Epoch 288/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7318 - acc: 0.7448 - val_loss: 0.6504 - val_acc: 0.7612\n",
      "Epoch 289/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.7307 - acc: 0.7388 - val_loss: 0.6473 - val_acc: 0.7626\n",
      "Epoch 290/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7417 - acc: 0.7295 - val_loss: 0.6480 - val_acc: 0.7612\n",
      "Epoch 291/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7374 - acc: 0.7362 - val_loss: 0.6473 - val_acc: 0.7626\n",
      "Epoch 292/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7287 - acc: 0.7467 - val_loss: 0.6498 - val_acc: 0.7612\n",
      "Epoch 293/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7220 - acc: 0.7344 - val_loss: 0.6497 - val_acc: 0.7612\n",
      "\n",
      "Epoch 00293: loss improved from 0.72498 to 0.72202, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-0-000293-0.722017-0.761161.hdf5\n",
      "Epoch 294/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7193 - acc: 0.7381 - val_loss: 0.6484 - val_acc: 0.7619\n",
      "Epoch 295/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7142 - acc: 0.7448 - val_loss: 0.6506 - val_acc: 0.7604\n",
      "Epoch 296/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7423 - acc: 0.7329 - val_loss: 0.6494 - val_acc: 0.7619\n",
      "Epoch 297/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7353 - acc: 0.7351 - val_loss: 0.6509 - val_acc: 0.7604\n",
      "Epoch 298/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7414 - acc: 0.7426 - val_loss: 0.6496 - val_acc: 0.7612\n",
      "Epoch 299/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7213 - acc: 0.7403 - val_loss: 0.6493 - val_acc: 0.7612\n",
      "Epoch 300/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7278 - acc: 0.7329 - val_loss: 0.6497 - val_acc: 0.7612\n",
      "\n",
      "Epoch 00300: saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/0-000300-0.727806-0.761161.hdf5\n",
      "Epoch 301/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7333 - acc: 0.7403 - val_loss: 0.6501 - val_acc: 0.7612\n",
      "Epoch 302/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7279 - acc: 0.7340 - val_loss: 0.6490 - val_acc: 0.7619\n",
      "Epoch 303/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7406 - acc: 0.7318 - val_loss: 0.6505 - val_acc: 0.7604\n",
      "Epoch 304/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.7183 - acc: 0.7433 - val_loss: 0.6501 - val_acc: 0.7604\n",
      "Epoch 305/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.7332 - acc: 0.7407 - val_loss: 0.6478 - val_acc: 0.7619\n",
      "Epoch 306/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7225 - acc: 0.7418 - val_loss: 0.6491 - val_acc: 0.7612\n",
      "Epoch 307/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7383 - acc: 0.7396 - val_loss: 0.6471 - val_acc: 0.7626\n",
      "Epoch 308/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7195 - acc: 0.7385 - val_loss: 0.6490 - val_acc: 0.7619\n",
      "Epoch 309/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7205 - acc: 0.7440 - val_loss: 0.6506 - val_acc: 0.7604\n",
      "Epoch 310/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.7318 - acc: 0.7333 - val_loss: 0.6508 - val_acc: 0.7604\n",
      "Epoch 311/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7302 - acc: 0.7418 - val_loss: 0.6479 - val_acc: 0.7612\n",
      "Epoch 312/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7292 - acc: 0.7400 - val_loss: 0.6505 - val_acc: 0.7604\n",
      "Epoch 313/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.7315 - acc: 0.7344 - val_loss: 0.6484 - val_acc: 0.7619\n",
      "Epoch 314/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7302 - acc: 0.7374 - val_loss: 0.6469 - val_acc: 0.7619\n",
      "Epoch 315/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7274 - acc: 0.7437 - val_loss: 0.6496 - val_acc: 0.7619\n",
      "Epoch 316/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7316 - acc: 0.7355 - val_loss: 0.6509 - val_acc: 0.7604\n",
      "Epoch 317/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.7331 - acc: 0.7448 - val_loss: 0.6495 - val_acc: 0.7612\n",
      "Epoch 318/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7353 - acc: 0.7303 - val_loss: 0.6511 - val_acc: 0.7604\n",
      "Epoch 319/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7362 - acc: 0.7403 - val_loss: 0.6495 - val_acc: 0.7612\n",
      "Epoch 320/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7397 - acc: 0.7336 - val_loss: 0.6498 - val_acc: 0.7612\n",
      "Epoch 321/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.7412 - acc: 0.7333 - val_loss: 0.6511 - val_acc: 0.7604\n",
      "Epoch 322/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7481 - acc: 0.7295 - val_loss: 0.6496 - val_acc: 0.7612\n",
      "Epoch 323/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7306 - acc: 0.7437 - val_loss: 0.6489 - val_acc: 0.7619\n",
      "Epoch 324/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7374 - acc: 0.7392 - val_loss: 0.6501 - val_acc: 0.7612\n",
      "Epoch 325/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7150 - acc: 0.7437 - val_loss: 0.6483 - val_acc: 0.7612\n",
      "Epoch 326/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7255 - acc: 0.7366 - val_loss: 0.6501 - val_acc: 0.7612\n",
      "Epoch 327/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7257 - acc: 0.7411 - val_loss: 0.6494 - val_acc: 0.7619\n",
      "Epoch 328/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7265 - acc: 0.7347 - val_loss: 0.6474 - val_acc: 0.7619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7446 - acc: 0.7299 - val_loss: 0.6508 - val_acc: 0.7604\n",
      "Epoch 330/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7369 - acc: 0.7336 - val_loss: 0.6470 - val_acc: 0.7619\n",
      "Epoch 331/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7299 - acc: 0.7418 - val_loss: 0.6503 - val_acc: 0.7612\n",
      "Epoch 332/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7221 - acc: 0.7370 - val_loss: 0.6474 - val_acc: 0.7619\n",
      "Epoch 333/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7283 - acc: 0.7321 - val_loss: 0.6510 - val_acc: 0.7604\n",
      "Epoch 334/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7295 - acc: 0.7370 - val_loss: 0.6506 - val_acc: 0.7604\n",
      "Epoch 335/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7393 - acc: 0.7340 - val_loss: 0.6503 - val_acc: 0.7604\n",
      "Epoch 336/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7340 - acc: 0.7359 - val_loss: 0.6504 - val_acc: 0.7604\n",
      "Epoch 337/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7429 - acc: 0.7318 - val_loss: 0.6395 - val_acc: 0.7626\n",
      "Epoch 338/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7341 - acc: 0.7407 - val_loss: 0.6512 - val_acc: 0.7604\n",
      "Epoch 339/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7154 - acc: 0.7411 - val_loss: 0.6510 - val_acc: 0.7604\n",
      "Epoch 340/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.7235 - acc: 0.7474 - val_loss: 0.6485 - val_acc: 0.7619\n",
      "Epoch 341/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7326 - acc: 0.7288 - val_loss: 0.6491 - val_acc: 0.7612\n",
      "Epoch 342/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7322 - acc: 0.7414 - val_loss: 0.6500 - val_acc: 0.7604\n",
      "Epoch 343/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7335 - acc: 0.7351 - val_loss: 0.6492 - val_acc: 0.7612\n",
      "Epoch 344/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7311 - acc: 0.7362 - val_loss: 0.6445 - val_acc: 0.7619\n",
      "Epoch 345/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7358 - acc: 0.7333 - val_loss: 0.6459 - val_acc: 0.7612\n",
      "Epoch 346/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7412 - acc: 0.7314 - val_loss: 0.6462 - val_acc: 0.7626\n",
      "Epoch 347/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7350 - acc: 0.7407 - val_loss: 0.6483 - val_acc: 0.7612\n",
      "Epoch 348/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7337 - acc: 0.7318 - val_loss: 0.6479 - val_acc: 0.7626\n",
      "Epoch 349/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7279 - acc: 0.7351 - val_loss: 0.6504 - val_acc: 0.7604\n",
      "Epoch 350/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.7398 - acc: 0.7340 - val_loss: 0.6484 - val_acc: 0.7619\n",
      "Epoch 351/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7309 - acc: 0.7333 - val_loss: 0.6465 - val_acc: 0.7619\n",
      "Epoch 352/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7417 - acc: 0.7292 - val_loss: 0.6486 - val_acc: 0.7619\n",
      "Epoch 353/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7382 - acc: 0.7344 - val_loss: 0.6493 - val_acc: 0.7619\n",
      "Epoch 354/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7307 - acc: 0.7403 - val_loss: 0.6507 - val_acc: 0.7604\n",
      "Epoch 355/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7201 - acc: 0.7463 - val_loss: 0.6502 - val_acc: 0.7604\n",
      "Epoch 356/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7234 - acc: 0.7370 - val_loss: 0.6489 - val_acc: 0.7612\n",
      "Epoch 357/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7270 - acc: 0.7411 - val_loss: 0.6497 - val_acc: 0.7612\n",
      "Epoch 358/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7333 - acc: 0.7426 - val_loss: 0.6505 - val_acc: 0.7604\n",
      "Epoch 359/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7371 - acc: 0.7366 - val_loss: 0.6500 - val_acc: 0.7612\n",
      "Epoch 360/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7185 - acc: 0.7377 - val_loss: 0.6497 - val_acc: 0.7612\n",
      "Epoch 361/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7272 - acc: 0.7340 - val_loss: 0.6495 - val_acc: 0.7612\n",
      "Epoch 362/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.7470 - acc: 0.7240 - val_loss: 0.6472 - val_acc: 0.7619\n",
      "Epoch 363/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7476 - acc: 0.7247 - val_loss: 0.6496 - val_acc: 0.7612\n",
      "Epoch 364/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7440 - acc: 0.7266 - val_loss: 0.6502 - val_acc: 0.7604\n",
      "Epoch 365/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7215 - acc: 0.7329 - val_loss: 0.6486 - val_acc: 0.7612\n",
      "\n",
      "Epoch 00365: loss improved from inf to 0.72145, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-0-000365-0.721452-0.761161.hdf5\n",
      "Epoch 366/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7409 - acc: 0.7321 - val_loss: 0.6502 - val_acc: 0.7604\n",
      "Epoch 367/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7451 - acc: 0.7281 - val_loss: 0.6507 - val_acc: 0.7612\n",
      "Epoch 368/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7385 - acc: 0.7281 - val_loss: 0.6479 - val_acc: 0.7612\n",
      "Epoch 369/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7230 - acc: 0.7347 - val_loss: 0.6501 - val_acc: 0.7604\n",
      "Epoch 370/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7366 - acc: 0.7407 - val_loss: 0.6468 - val_acc: 0.7626\n",
      "Epoch 371/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7219 - acc: 0.7403 - val_loss: 0.6509 - val_acc: 0.7604\n",
      "Epoch 372/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7355 - acc: 0.7284 - val_loss: 0.6488 - val_acc: 0.7612\n",
      "Epoch 373/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7399 - acc: 0.7329 - val_loss: 0.6497 - val_acc: 0.7612\n",
      "Epoch 374/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7397 - acc: 0.7336 - val_loss: 0.6487 - val_acc: 0.7612\n",
      "Epoch 375/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7358 - acc: 0.7347 - val_loss: 0.6502 - val_acc: 0.7604\n",
      "Epoch 376/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7388 - acc: 0.7295 - val_loss: 0.6511 - val_acc: 0.7604\n",
      "Epoch 377/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7278 - acc: 0.7366 - val_loss: 0.6492 - val_acc: 0.7612\n",
      "Epoch 378/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7341 - acc: 0.7307 - val_loss: 0.6513 - val_acc: 0.7604\n",
      "Epoch 379/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7249 - acc: 0.7411 - val_loss: 0.6486 - val_acc: 0.7619\n",
      "Epoch 380/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7330 - acc: 0.7333 - val_loss: 0.6463 - val_acc: 0.7626\n",
      "Epoch 381/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7220 - acc: 0.7351 - val_loss: 0.6498 - val_acc: 0.7604\n",
      "Epoch 382/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7442 - acc: 0.7325 - val_loss: 0.6492 - val_acc: 0.7619\n",
      "Epoch 383/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7294 - acc: 0.7385 - val_loss: 0.6483 - val_acc: 0.7619\n",
      "Epoch 384/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7321 - acc: 0.7400 - val_loss: 0.6492 - val_acc: 0.7619\n",
      "Epoch 385/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7342 - acc: 0.7388 - val_loss: 0.6489 - val_acc: 0.7619\n",
      "Epoch 386/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7379 - acc: 0.7347 - val_loss: 0.6494 - val_acc: 0.7612\n",
      "Epoch 387/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7379 - acc: 0.7392 - val_loss: 0.6503 - val_acc: 0.7612\n",
      "Epoch 388/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7267 - acc: 0.7347 - val_loss: 0.6496 - val_acc: 0.7612\n",
      "Epoch 389/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7318 - acc: 0.7433 - val_loss: 0.6439 - val_acc: 0.7626\n",
      "Epoch 390/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7430 - acc: 0.7381 - val_loss: 0.6509 - val_acc: 0.7604\n",
      "Epoch 391/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7358 - acc: 0.7422 - val_loss: 0.6495 - val_acc: 0.7619\n",
      "Epoch 392/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7274 - acc: 0.7340 - val_loss: 0.6485 - val_acc: 0.7612\n",
      "Epoch 393/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7206 - acc: 0.7400 - val_loss: 0.6471 - val_acc: 0.7612\n",
      "\n",
      "Epoch 00393: loss improved from 0.72145 to 0.72058, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-0-000393-0.720578-0.761161.hdf5\n",
      "Epoch 394/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7411 - acc: 0.7321 - val_loss: 0.6495 - val_acc: 0.7612\n",
      "Epoch 395/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.7220 - acc: 0.7418 - val_loss: 0.6506 - val_acc: 0.7604\n",
      "Epoch 396/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7260 - acc: 0.7396 - val_loss: 0.6510 - val_acc: 0.7604\n",
      "Epoch 397/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7357 - acc: 0.7303 - val_loss: 0.6508 - val_acc: 0.7604\n",
      "Epoch 398/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7370 - acc: 0.7288 - val_loss: 0.6485 - val_acc: 0.7619\n",
      "Epoch 399/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7245 - acc: 0.7418 - val_loss: 0.6493 - val_acc: 0.7612\n",
      "Epoch 400/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7322 - acc: 0.7407 - val_loss: 0.6489 - val_acc: 0.7612\n",
      "\n",
      "Epoch 00400: saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/0-000400-0.732188-0.761161.hdf5\n",
      "Epoch 401/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7279 - acc: 0.7381 - val_loss: 0.6489 - val_acc: 0.7612\n",
      "Epoch 402/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7174 - acc: 0.7541 - val_loss: 0.6506 - val_acc: 0.7604\n",
      "Epoch 403/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7223 - acc: 0.7440 - val_loss: 0.6502 - val_acc: 0.7612\n",
      "Epoch 404/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7343 - acc: 0.7396 - val_loss: 0.6495 - val_acc: 0.7612\n",
      "Epoch 405/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7271 - acc: 0.7366 - val_loss: 0.6462 - val_acc: 0.7612\n",
      "Epoch 406/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7168 - acc: 0.7437 - val_loss: 0.6506 - val_acc: 0.7604\n",
      "Epoch 407/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7401 - acc: 0.7288 - val_loss: 0.6492 - val_acc: 0.7612\n",
      "Epoch 408/1000\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.7300 - acc: 0.7284 - val_loss: 0.6459 - val_acc: 0.7619\n",
      "Epoch 409/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7288 - acc: 0.7452 - val_loss: 0.6508 - val_acc: 0.7604\n",
      "Epoch 410/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7231 - acc: 0.7437 - val_loss: 0.6487 - val_acc: 0.7612\n",
      "Epoch 411/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7321 - acc: 0.7355 - val_loss: 0.6478 - val_acc: 0.7619\n",
      "Epoch 412/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7412 - acc: 0.7392 - val_loss: 0.6494 - val_acc: 0.7612\n",
      "Epoch 413/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7369 - acc: 0.7370 - val_loss: 0.6505 - val_acc: 0.7604\n",
      "Epoch 414/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7193 - acc: 0.7433 - val_loss: 0.6485 - val_acc: 0.7619\n",
      "Epoch 415/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7230 - acc: 0.7444 - val_loss: 0.6491 - val_acc: 0.7612\n",
      "Epoch 416/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7437 - acc: 0.7336 - val_loss: 0.6443 - val_acc: 0.7626\n",
      "Epoch 417/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7352 - acc: 0.7370 - val_loss: 0.6462 - val_acc: 0.7626\n",
      "Epoch 418/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7350 - acc: 0.7385 - val_loss: 0.6479 - val_acc: 0.7626\n",
      "Epoch 419/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7277 - acc: 0.7392 - val_loss: 0.6506 - val_acc: 0.7604\n",
      "Epoch 420/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7122 - acc: 0.7448 - val_loss: 0.6494 - val_acc: 0.7619\n",
      "Epoch 421/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7225 - acc: 0.7381 - val_loss: 0.6484 - val_acc: 0.7612\n",
      "Epoch 422/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7213 - acc: 0.7307 - val_loss: 0.6488 - val_acc: 0.7619\n",
      "Epoch 423/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7403 - acc: 0.7370 - val_loss: 0.6462 - val_acc: 0.7619\n",
      "Epoch 424/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7357 - acc: 0.7277 - val_loss: 0.6501 - val_acc: 0.7612\n",
      "Epoch 425/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7443 - acc: 0.7329 - val_loss: 0.6481 - val_acc: 0.7619\n",
      "Epoch 426/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7409 - acc: 0.7347 - val_loss: 0.6487 - val_acc: 0.7619\n",
      "Epoch 427/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7290 - acc: 0.7385 - val_loss: 0.6502 - val_acc: 0.7604\n",
      "Epoch 428/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7239 - acc: 0.7429 - val_loss: 0.6495 - val_acc: 0.7612\n",
      "Epoch 429/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7216 - acc: 0.7403 - val_loss: 0.6494 - val_acc: 0.7612\n",
      "Epoch 430/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7221 - acc: 0.7422 - val_loss: 0.6497 - val_acc: 0.7612\n",
      "Epoch 431/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7292 - acc: 0.7347 - val_loss: 0.6478 - val_acc: 0.7612\n",
      "Epoch 432/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7241 - acc: 0.7388 - val_loss: 0.6499 - val_acc: 0.7612\n",
      "Epoch 433/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7307 - acc: 0.7321 - val_loss: 0.6504 - val_acc: 0.7604\n",
      "Epoch 434/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7319 - acc: 0.7392 - val_loss: 0.6503 - val_acc: 0.7604\n",
      "Epoch 435/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7307 - acc: 0.7314 - val_loss: 0.6458 - val_acc: 0.7626\n",
      "Epoch 436/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7234 - acc: 0.7388 - val_loss: 0.6494 - val_acc: 0.7619\n",
      "Epoch 437/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7430 - acc: 0.7374 - val_loss: 0.6502 - val_acc: 0.7612\n",
      "Epoch 438/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7166 - acc: 0.7470 - val_loss: 0.6506 - val_acc: 0.7604\n",
      "Epoch 439/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7134 - acc: 0.7392 - val_loss: 0.6506 - val_acc: 0.7604\n",
      "Epoch 440/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7162 - acc: 0.7459 - val_loss: 0.6496 - val_acc: 0.7612\n",
      "Epoch 441/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7086 - acc: 0.7374 - val_loss: 0.6505 - val_acc: 0.7604\n",
      "Epoch 442/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7391 - acc: 0.7321 - val_loss: 0.6478 - val_acc: 0.7612\n",
      "Epoch 443/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7403 - acc: 0.7362 - val_loss: 0.6475 - val_acc: 0.7619\n",
      "Epoch 444/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7072 - acc: 0.7459 - val_loss: 0.6499 - val_acc: 0.7612\n",
      "Epoch 445/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7206 - acc: 0.7407 - val_loss: 0.6490 - val_acc: 0.7604\n",
      "Epoch 446/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7354 - acc: 0.7347 - val_loss: 0.6495 - val_acc: 0.7604\n",
      "Epoch 447/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7377 - acc: 0.7344 - val_loss: 0.6482 - val_acc: 0.7604\n",
      "Epoch 448/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7395 - acc: 0.7340 - val_loss: 0.6450 - val_acc: 0.7626\n",
      "Epoch 449/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7411 - acc: 0.7340 - val_loss: 0.6505 - val_acc: 0.7597\n",
      "Epoch 450/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7219 - acc: 0.7418 - val_loss: 0.6448 - val_acc: 0.7619\n",
      "Epoch 451/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7294 - acc: 0.7336 - val_loss: 0.6503 - val_acc: 0.7597\n",
      "Epoch 452/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7161 - acc: 0.7478 - val_loss: 0.6503 - val_acc: 0.7597\n",
      "Epoch 453/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7270 - acc: 0.7411 - val_loss: 0.6489 - val_acc: 0.7604\n",
      "Epoch 454/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7373 - acc: 0.7351 - val_loss: 0.6499 - val_acc: 0.7604\n",
      "Epoch 455/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7264 - acc: 0.7388 - val_loss: 0.6459 - val_acc: 0.7612\n",
      "Epoch 456/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7409 - acc: 0.7377 - val_loss: 0.6494 - val_acc: 0.7612\n",
      "Epoch 457/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7183 - acc: 0.7411 - val_loss: 0.6511 - val_acc: 0.7597\n",
      "Epoch 458/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7265 - acc: 0.7426 - val_loss: 0.6501 - val_acc: 0.7597\n",
      "Epoch 459/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7301 - acc: 0.7433 - val_loss: 0.6472 - val_acc: 0.7604\n",
      "Epoch 460/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7131 - acc: 0.7411 - val_loss: 0.6491 - val_acc: 0.7604\n",
      "Epoch 461/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7220 - acc: 0.7470 - val_loss: 0.6504 - val_acc: 0.7597\n",
      "Epoch 462/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7256 - acc: 0.7411 - val_loss: 0.6506 - val_acc: 0.7597\n",
      "Epoch 463/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7442 - acc: 0.7366 - val_loss: 0.6480 - val_acc: 0.7612\n",
      "Epoch 464/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7277 - acc: 0.7400 - val_loss: 0.6503 - val_acc: 0.7604\n",
      "Epoch 465/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7129 - acc: 0.7440 - val_loss: 0.6507 - val_acc: 0.7597\n",
      "\n",
      "Epoch 00465: loss improved from inf to 0.71294, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-0-000465-0.712940-0.759673.hdf5\n",
      "Epoch 466/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7229 - acc: 0.7400 - val_loss: 0.6495 - val_acc: 0.7604\n",
      "Epoch 467/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7428 - acc: 0.7299 - val_loss: 0.6496 - val_acc: 0.7604\n",
      "Epoch 468/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7458 - acc: 0.7355 - val_loss: 0.6502 - val_acc: 0.7604\n",
      "Epoch 469/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7281 - acc: 0.7362 - val_loss: 0.6465 - val_acc: 0.7604\n",
      "Epoch 470/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7269 - acc: 0.7414 - val_loss: 0.6497 - val_acc: 0.7604\n",
      "Epoch 471/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7253 - acc: 0.7433 - val_loss: 0.6493 - val_acc: 0.7604\n",
      "Epoch 472/1000\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.7258 - acc: 0.7459 - val_loss: 0.6509 - val_acc: 0.7597\n",
      "Epoch 473/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7227 - acc: 0.7407 - val_loss: 0.6483 - val_acc: 0.7612\n",
      "Epoch 474/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7318 - acc: 0.7310 - val_loss: 0.6481 - val_acc: 0.7604\n",
      "Epoch 475/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7351 - acc: 0.7385 - val_loss: 0.6503 - val_acc: 0.7604\n",
      "Epoch 476/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7256 - acc: 0.7385 - val_loss: 0.6510 - val_acc: 0.7597\n",
      "Epoch 477/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7294 - acc: 0.7347 - val_loss: 0.6475 - val_acc: 0.7612\n",
      "Epoch 478/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7238 - acc: 0.7459 - val_loss: 0.6504 - val_acc: 0.7597\n",
      "Epoch 479/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7182 - acc: 0.7370 - val_loss: 0.6508 - val_acc: 0.7597\n",
      "Epoch 480/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7342 - acc: 0.7288 - val_loss: 0.6496 - val_acc: 0.7604\n",
      "Epoch 481/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7266 - acc: 0.7355 - val_loss: 0.6487 - val_acc: 0.7612\n",
      "Epoch 482/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7231 - acc: 0.7396 - val_loss: 0.6507 - val_acc: 0.7597\n",
      "Epoch 483/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7253 - acc: 0.7444 - val_loss: 0.6493 - val_acc: 0.7612\n",
      "Epoch 484/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7277 - acc: 0.7400 - val_loss: 0.6490 - val_acc: 0.7612\n",
      "Epoch 485/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7248 - acc: 0.7329 - val_loss: 0.6497 - val_acc: 0.7604\n",
      "Epoch 486/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7276 - acc: 0.7385 - val_loss: 0.6481 - val_acc: 0.7612\n",
      "Epoch 487/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.7331 - acc: 0.7355 - val_loss: 0.6505 - val_acc: 0.7597\n",
      "Epoch 488/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7316 - acc: 0.7347 - val_loss: 0.6509 - val_acc: 0.7597\n",
      "Epoch 489/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7198 - acc: 0.7400 - val_loss: 0.6494 - val_acc: 0.7604\n",
      "Epoch 490/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7395 - acc: 0.7307 - val_loss: 0.6511 - val_acc: 0.7604\n",
      "Epoch 491/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7353 - acc: 0.7359 - val_loss: 0.6505 - val_acc: 0.7604\n",
      "Epoch 492/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7311 - acc: 0.7429 - val_loss: 0.6466 - val_acc: 0.7612\n",
      "Epoch 493/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7216 - acc: 0.7422 - val_loss: 0.6506 - val_acc: 0.7604\n",
      "Epoch 494/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7300 - acc: 0.7288 - val_loss: 0.6458 - val_acc: 0.7626\n",
      "Epoch 495/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7296 - acc: 0.7400 - val_loss: 0.6485 - val_acc: 0.7619\n",
      "Epoch 496/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7384 - acc: 0.7366 - val_loss: 0.6488 - val_acc: 0.7612\n",
      "Epoch 497/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7250 - acc: 0.7444 - val_loss: 0.6487 - val_acc: 0.7619\n",
      "Epoch 498/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7195 - acc: 0.7437 - val_loss: 0.6500 - val_acc: 0.7604\n",
      "Epoch 499/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7333 - acc: 0.7362 - val_loss: 0.6509 - val_acc: 0.7604\n",
      "Epoch 500/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7287 - acc: 0.7437 - val_loss: 0.6494 - val_acc: 0.7619\n",
      "\n",
      "Epoch 00500: saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/0-000500-0.728737-0.761905.hdf5\n",
      "Epoch 501/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7193 - acc: 0.7426 - val_loss: 0.6471 - val_acc: 0.7612\n",
      "Epoch 502/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7379 - acc: 0.7292 - val_loss: 0.6461 - val_acc: 0.7634\n",
      "Epoch 503/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7326 - acc: 0.7400 - val_loss: 0.6482 - val_acc: 0.7619\n",
      "Epoch 504/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7410 - acc: 0.7355 - val_loss: 0.6489 - val_acc: 0.7612\n",
      "Epoch 505/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7295 - acc: 0.7370 - val_loss: 0.6479 - val_acc: 0.7626\n",
      "Epoch 506/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7224 - acc: 0.7396 - val_loss: 0.6506 - val_acc: 0.7604\n",
      "Epoch 507/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7246 - acc: 0.7374 - val_loss: 0.6506 - val_acc: 0.7597\n",
      "Epoch 508/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7202 - acc: 0.7407 - val_loss: 0.6505 - val_acc: 0.7597\n",
      "Epoch 509/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7257 - acc: 0.7400 - val_loss: 0.6482 - val_acc: 0.7612\n",
      "Epoch 510/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7169 - acc: 0.7377 - val_loss: 0.6501 - val_acc: 0.7597\n",
      "Epoch 511/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7239 - acc: 0.7392 - val_loss: 0.6497 - val_acc: 0.7604\n",
      "Epoch 512/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7275 - acc: 0.7403 - val_loss: 0.6482 - val_acc: 0.7604\n",
      "Epoch 513/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7240 - acc: 0.7355 - val_loss: 0.6479 - val_acc: 0.7612\n",
      "Epoch 514/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7280 - acc: 0.7392 - val_loss: 0.6453 - val_acc: 0.7626\n",
      "Epoch 515/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7295 - acc: 0.7388 - val_loss: 0.6489 - val_acc: 0.7604\n",
      "Epoch 516/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7240 - acc: 0.7414 - val_loss: 0.6504 - val_acc: 0.7597\n",
      "Epoch 517/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7353 - acc: 0.7362 - val_loss: 0.6503 - val_acc: 0.7597\n",
      "Epoch 518/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7338 - acc: 0.7374 - val_loss: 0.6482 - val_acc: 0.7612\n",
      "Epoch 519/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7283 - acc: 0.7418 - val_loss: 0.6505 - val_acc: 0.7597\n",
      "Epoch 520/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7215 - acc: 0.7481 - val_loss: 0.6483 - val_acc: 0.7612\n",
      "Epoch 521/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7252 - acc: 0.7426 - val_loss: 0.6497 - val_acc: 0.7604\n",
      "Epoch 522/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7299 - acc: 0.7377 - val_loss: 0.6506 - val_acc: 0.7597\n",
      "Epoch 523/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7244 - acc: 0.7440 - val_loss: 0.6500 - val_acc: 0.7604\n",
      "Epoch 524/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7287 - acc: 0.7336 - val_loss: 0.6503 - val_acc: 0.7597\n",
      "Epoch 525/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7342 - acc: 0.7340 - val_loss: 0.6481 - val_acc: 0.7612\n",
      "Epoch 526/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.7273 - acc: 0.7396 - val_loss: 0.6507 - val_acc: 0.7597\n",
      "Epoch 527/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7167 - acc: 0.7440 - val_loss: 0.6479 - val_acc: 0.7604\n",
      "Epoch 528/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7273 - acc: 0.7370 - val_loss: 0.6506 - val_acc: 0.7597\n",
      "Epoch 529/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7318 - acc: 0.7388 - val_loss: 0.6491 - val_acc: 0.7604\n",
      "Epoch 530/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7279 - acc: 0.7362 - val_loss: 0.6497 - val_acc: 0.7604\n",
      "Epoch 531/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7198 - acc: 0.7388 - val_loss: 0.6494 - val_acc: 0.7612\n",
      "Epoch 532/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7144 - acc: 0.7463 - val_loss: 0.6474 - val_acc: 0.7612\n",
      "Epoch 533/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7389 - acc: 0.7433 - val_loss: 0.6492 - val_acc: 0.7604\n",
      "Epoch 534/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7416 - acc: 0.7411 - val_loss: 0.6504 - val_acc: 0.7597\n",
      "Epoch 535/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7217 - acc: 0.7414 - val_loss: 0.6477 - val_acc: 0.7604\n",
      "Epoch 536/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7360 - acc: 0.7281 - val_loss: 0.6489 - val_acc: 0.7604\n",
      "Epoch 537/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7305 - acc: 0.7351 - val_loss: 0.6504 - val_acc: 0.7597\n",
      "Epoch 538/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7450 - acc: 0.7385 - val_loss: 0.6480 - val_acc: 0.7612\n",
      "Epoch 539/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7190 - acc: 0.7385 - val_loss: 0.6509 - val_acc: 0.7604\n",
      "Epoch 540/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7527 - acc: 0.7366 - val_loss: 0.6500 - val_acc: 0.7604\n",
      "Epoch 541/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7324 - acc: 0.7347 - val_loss: 0.6495 - val_acc: 0.7612\n",
      "Epoch 542/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7302 - acc: 0.7440 - val_loss: 0.6460 - val_acc: 0.7612\n",
      "Epoch 543/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7362 - acc: 0.7407 - val_loss: 0.6501 - val_acc: 0.7612\n",
      "Epoch 544/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7345 - acc: 0.7396 - val_loss: 0.6449 - val_acc: 0.7619\n",
      "Epoch 545/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7294 - acc: 0.7295 - val_loss: 0.6487 - val_acc: 0.7604\n",
      "Epoch 546/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7387 - acc: 0.7307 - val_loss: 0.6484 - val_acc: 0.7612\n",
      "Epoch 547/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7394 - acc: 0.7281 - val_loss: 0.6496 - val_acc: 0.7604\n",
      "Epoch 548/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7363 - acc: 0.7366 - val_loss: 0.6485 - val_acc: 0.7604\n",
      "Epoch 549/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7338 - acc: 0.7392 - val_loss: 0.6493 - val_acc: 0.7612\n",
      "Epoch 550/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7354 - acc: 0.7325 - val_loss: 0.6493 - val_acc: 0.7612\n",
      "Epoch 551/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7239 - acc: 0.7455 - val_loss: 0.6441 - val_acc: 0.7612\n",
      "Epoch 552/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7368 - acc: 0.7243 - val_loss: 0.6449 - val_acc: 0.7604\n",
      "Epoch 553/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7324 - acc: 0.7385 - val_loss: 0.6501 - val_acc: 0.7597\n",
      "Epoch 554/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7216 - acc: 0.7374 - val_loss: 0.6507 - val_acc: 0.7597\n",
      "Epoch 555/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7267 - acc: 0.7396 - val_loss: 0.6501 - val_acc: 0.7604\n",
      "Epoch 556/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7314 - acc: 0.7340 - val_loss: 0.6489 - val_acc: 0.7604\n",
      "Epoch 557/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7258 - acc: 0.7411 - val_loss: 0.6486 - val_acc: 0.7604\n",
      "Epoch 558/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7276 - acc: 0.7414 - val_loss: 0.6499 - val_acc: 0.7604\n",
      "Epoch 559/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7316 - acc: 0.7344 - val_loss: 0.6459 - val_acc: 0.7626\n",
      "Epoch 560/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7281 - acc: 0.7444 - val_loss: 0.6506 - val_acc: 0.7597\n",
      "Epoch 561/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7256 - acc: 0.7388 - val_loss: 0.6444 - val_acc: 0.7612\n",
      "Epoch 562/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7198 - acc: 0.7359 - val_loss: 0.6471 - val_acc: 0.7604\n",
      "Epoch 563/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7375 - acc: 0.7321 - val_loss: 0.6482 - val_acc: 0.7619\n",
      "Epoch 564/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7212 - acc: 0.7429 - val_loss: 0.6506 - val_acc: 0.7597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 565/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7328 - acc: 0.7455 - val_loss: 0.6482 - val_acc: 0.7612\n",
      "\n",
      "Epoch 00565: loss improved from inf to 0.73280, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-0-000565-0.732795-0.761161.hdf5\n",
      "Epoch 566/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7331 - acc: 0.7381 - val_loss: 0.6451 - val_acc: 0.7626\n",
      "Epoch 567/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7280 - acc: 0.7426 - val_loss: 0.6499 - val_acc: 0.7604\n",
      "Epoch 568/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7329 - acc: 0.7422 - val_loss: 0.6465 - val_acc: 0.7604\n",
      "Epoch 569/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7347 - acc: 0.7370 - val_loss: 0.6496 - val_acc: 0.7604\n",
      "Epoch 570/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7300 - acc: 0.7366 - val_loss: 0.6507 - val_acc: 0.7597\n",
      "Epoch 571/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7375 - acc: 0.7351 - val_loss: 0.6494 - val_acc: 0.7604\n",
      "Epoch 572/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7337 - acc: 0.7236 - val_loss: 0.6501 - val_acc: 0.7597\n",
      "Epoch 573/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7350 - acc: 0.7414 - val_loss: 0.6498 - val_acc: 0.7604\n",
      "Epoch 574/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7270 - acc: 0.7407 - val_loss: 0.6496 - val_acc: 0.7604\n",
      "Epoch 575/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7287 - acc: 0.7362 - val_loss: 0.6422 - val_acc: 0.7619\n",
      "Epoch 576/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7255 - acc: 0.7418 - val_loss: 0.6477 - val_acc: 0.7612\n",
      "Epoch 577/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7347 - acc: 0.7374 - val_loss: 0.6468 - val_acc: 0.7612\n",
      "Epoch 578/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7295 - acc: 0.7429 - val_loss: 0.6506 - val_acc: 0.7597\n",
      "Epoch 579/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7439 - acc: 0.7351 - val_loss: 0.6503 - val_acc: 0.7604\n",
      "Epoch 580/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7329 - acc: 0.7374 - val_loss: 0.6417 - val_acc: 0.7626\n",
      "Epoch 581/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7251 - acc: 0.7303 - val_loss: 0.6486 - val_acc: 0.7612\n",
      "\n",
      "Epoch 00581: loss improved from 0.73280 to 0.72514, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-0-000581-0.725142-0.761161.hdf5\n",
      "Epoch 582/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7356 - acc: 0.7329 - val_loss: 0.6498 - val_acc: 0.7604\n",
      "Epoch 583/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7262 - acc: 0.7374 - val_loss: 0.6506 - val_acc: 0.7597\n",
      "Epoch 584/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7435 - acc: 0.7307 - val_loss: 0.6481 - val_acc: 0.7604\n",
      "Epoch 585/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7254 - acc: 0.7385 - val_loss: 0.6491 - val_acc: 0.7604\n",
      "Epoch 586/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7370 - acc: 0.7303 - val_loss: 0.6460 - val_acc: 0.7612\n",
      "Epoch 587/1000\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.7196 - acc: 0.7467 - val_loss: 0.6498 - val_acc: 0.7604\n",
      "Epoch 588/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7241 - acc: 0.7374 - val_loss: 0.6432 - val_acc: 0.7619\n",
      "Epoch 589/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7347 - acc: 0.7418 - val_loss: 0.6485 - val_acc: 0.7612\n",
      "Epoch 590/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7405 - acc: 0.7303 - val_loss: 0.6497 - val_acc: 0.7604\n",
      "Epoch 591/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7206 - acc: 0.7351 - val_loss: 0.6503 - val_acc: 0.7597\n",
      "Epoch 592/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7329 - acc: 0.7359 - val_loss: 0.6496 - val_acc: 0.7604\n",
      "Epoch 593/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7350 - acc: 0.7359 - val_loss: 0.6473 - val_acc: 0.7612\n",
      "Epoch 594/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7156 - acc: 0.7385 - val_loss: 0.6504 - val_acc: 0.7597\n",
      "Epoch 595/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7175 - acc: 0.7400 - val_loss: 0.6505 - val_acc: 0.7597\n",
      "Epoch 596/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7511 - acc: 0.7295 - val_loss: 0.6496 - val_acc: 0.7604\n",
      "Epoch 597/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7435 - acc: 0.7210 - val_loss: 0.6497 - val_acc: 0.7597\n",
      "Epoch 598/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7270 - acc: 0.7474 - val_loss: 0.6509 - val_acc: 0.7597\n",
      "Epoch 599/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7189 - acc: 0.7403 - val_loss: 0.6471 - val_acc: 0.7612\n",
      "Epoch 600/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7337 - acc: 0.7429 - val_loss: 0.6471 - val_acc: 0.7619\n",
      "\n",
      "Epoch 00600: saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/0-000600-0.733716-0.761905.hdf5\n",
      "Epoch 601/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7369 - acc: 0.7295 - val_loss: 0.6495 - val_acc: 0.7604\n",
      "Epoch 602/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7323 - acc: 0.7396 - val_loss: 0.6501 - val_acc: 0.7597\n",
      "Epoch 603/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7303 - acc: 0.7448 - val_loss: 0.6467 - val_acc: 0.7612\n",
      "Epoch 604/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7203 - acc: 0.7370 - val_loss: 0.6464 - val_acc: 0.7612\n",
      "Epoch 605/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7277 - acc: 0.7422 - val_loss: 0.6494 - val_acc: 0.7604\n",
      "Epoch 606/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7138 - acc: 0.7347 - val_loss: 0.6486 - val_acc: 0.7612\n",
      "Epoch 607/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7108 - acc: 0.7437 - val_loss: 0.6493 - val_acc: 0.7604\n",
      "Epoch 608/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7383 - acc: 0.7362 - val_loss: 0.6497 - val_acc: 0.7604\n",
      "Epoch 609/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7259 - acc: 0.7321 - val_loss: 0.6488 - val_acc: 0.7604\n",
      "Epoch 610/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7251 - acc: 0.7414 - val_loss: 0.6490 - val_acc: 0.7612\n",
      "Epoch 611/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7195 - acc: 0.7418 - val_loss: 0.6501 - val_acc: 0.7597\n",
      "Epoch 612/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7212 - acc: 0.7411 - val_loss: 0.6495 - val_acc: 0.7604\n",
      "Epoch 613/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7216 - acc: 0.7429 - val_loss: 0.6504 - val_acc: 0.7597\n",
      "Epoch 614/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7305 - acc: 0.7381 - val_loss: 0.6501 - val_acc: 0.7604\n",
      "Epoch 615/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7356 - acc: 0.7374 - val_loss: 0.6480 - val_acc: 0.7612\n",
      "Epoch 616/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7332 - acc: 0.7303 - val_loss: 0.6490 - val_acc: 0.7604\n",
      "Epoch 617/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7312 - acc: 0.7366 - val_loss: 0.6491 - val_acc: 0.7612\n",
      "Epoch 618/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7419 - acc: 0.7381 - val_loss: 0.6505 - val_acc: 0.7597\n",
      "Epoch 619/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7320 - acc: 0.7340 - val_loss: 0.6500 - val_acc: 0.7604\n",
      "Epoch 620/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7437 - acc: 0.7288 - val_loss: 0.6479 - val_acc: 0.7612\n",
      "Epoch 621/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7267 - acc: 0.7347 - val_loss: 0.6498 - val_acc: 0.7604\n",
      "Epoch 622/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7278 - acc: 0.7414 - val_loss: 0.6463 - val_acc: 0.7604\n",
      "Epoch 623/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7339 - acc: 0.7329 - val_loss: 0.6495 - val_acc: 0.7604\n",
      "Epoch 624/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7190 - acc: 0.7396 - val_loss: 0.6504 - val_acc: 0.7597\n",
      "Epoch 625/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7381 - acc: 0.7344 - val_loss: 0.6484 - val_acc: 0.7612\n",
      "Epoch 626/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7334 - acc: 0.7467 - val_loss: 0.6509 - val_acc: 0.7597\n",
      "Epoch 627/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7340 - acc: 0.7336 - val_loss: 0.6500 - val_acc: 0.7604\n",
      "Epoch 628/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7393 - acc: 0.7318 - val_loss: 0.6505 - val_acc: 0.7597\n",
      "Epoch 629/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7362 - acc: 0.7359 - val_loss: 0.6509 - val_acc: 0.7597\n",
      "Epoch 630/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7139 - acc: 0.7470 - val_loss: 0.6498 - val_acc: 0.7597\n",
      "Epoch 631/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7207 - acc: 0.7381 - val_loss: 0.6492 - val_acc: 0.7604\n",
      "Epoch 632/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7237 - acc: 0.7310 - val_loss: 0.6508 - val_acc: 0.7597\n",
      "Epoch 633/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7273 - acc: 0.7359 - val_loss: 0.6486 - val_acc: 0.7604\n",
      "Epoch 634/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7256 - acc: 0.7325 - val_loss: 0.6509 - val_acc: 0.7597\n",
      "Epoch 635/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7359 - acc: 0.7333 - val_loss: 0.6492 - val_acc: 0.7612\n",
      "Epoch 636/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7181 - acc: 0.7321 - val_loss: 0.6486 - val_acc: 0.7612\n",
      "Epoch 637/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7422 - acc: 0.7370 - val_loss: 0.6478 - val_acc: 0.7604\n",
      "Epoch 638/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7236 - acc: 0.7474 - val_loss: 0.6483 - val_acc: 0.7612\n",
      "Epoch 639/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7256 - acc: 0.7351 - val_loss: 0.6475 - val_acc: 0.7619\n",
      "Epoch 640/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7382 - acc: 0.7347 - val_loss: 0.6501 - val_acc: 0.7604\n",
      "Epoch 641/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.7271 - acc: 0.7448 - val_loss: 0.6495 - val_acc: 0.7604\n",
      "Epoch 642/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7360 - acc: 0.7307 - val_loss: 0.6488 - val_acc: 0.7604\n",
      "Epoch 643/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7404 - acc: 0.7340 - val_loss: 0.6503 - val_acc: 0.7597\n",
      "Epoch 644/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7265 - acc: 0.7355 - val_loss: 0.6494 - val_acc: 0.7604\n",
      "Epoch 00644: early stopping\n",
      "ModelCheckpoint 已经保存到 ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/0-final.hdf5\n",
      "Create subdir directory: ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/log...\n",
      "save in: ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/log/20220201_2000_64_1_3_1.csv\n",
      "time: 0:09:51 s\n",
      "time: 591.0 s\n",
      "average 0.591000 s\n",
      "0 epoch finished\n",
      "--------------------   best   --------------------\n",
      "no_activities: 10\n",
      "\n",
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1349/1349 [==============================] - 1s 426us/step\n",
      "0-milan:\tacc: 76.13%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 0, 0, 0, 9, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 7, 0, 0, 0, 0, 7, 7, 7, 7, 7, 7, 7, 9, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 7, 0, 9, 9, 0, 9, 7, 7, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 0, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 0, 9, 0, 9, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 0, 7, 9, 9, 9, 0, 7, 9, 0, 9, 9, 9, 0, 9, 9, 7, 0, 7, 7, 7, 0, 7, 7, 0, 7, 7, 0, 7, 0, 7, 9, 7, 7, 7, 7, 0, 7, 7, 7, 7, 4, 7, 7, 7, 7, 0, 7, 7, 7, 7, 0, 7, 7, 7, 7, 0, 7, 0, 0, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 4, 0, 7, 7, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 4, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 0, 7, 7, 7, 7, 7, 7, 9, 7, 7, 0, 7, 0, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 7, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 5, 5, 9, 0, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 0, 9, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 7, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 0, 9, 0, 0, 7, 0, 0, 7, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 9, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 7, 4, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 5, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 4, 4, 0, 4, 4, 4, 0, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 0, 0, 4, 4, 0, 0, 4, 4, 0, 0, 4, 0, 4, 4, 0, 4, 0, 4, 4, 0, 4, 4, 4, 4, 0, 4, 4, 0, 4, 4, 0, 4, 0, 4, 4, 0, 4, 4, 4, 4, 4, 4, 0, 4, 4, 0, 7, 4, 0, 4, 4, 4, 4, 4, 4, 4, 0, 7, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.750000  0.914928  0.824295       623\n",
      "         Work   0.666667  0.307692  0.421053        26\n",
      "Take_medicine   0.000000  0.000000  0.000000        20\n",
      "        Sleep   0.000000  0.000000  0.000000        32\n",
      "        Relax   0.808989  0.503497  0.620690       143\n",
      "   Leave_Home   0.954545  0.887324  0.919708        71\n",
      "          Eat   0.000000  0.000000  0.000000         7\n",
      "         Cook   0.717073  0.794595  0.753846       185\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        30\n",
      "      Bathing   0.769585  0.787736  0.778555       212\n",
      "\n",
      "     accuracy                       0.761305      1349\n",
      "    macro avg   0.466686  0.419577  0.431815      1349\n",
      " weighted avg   0.714494  0.761305  0.728730      1349\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  30   0   0   0   0   0]\n",
      " [  0   8   0   0   1   1   0  16   0   0]\n",
      " [  0   0   0   0   0   3   0   4   0   0]\n",
      " [  0   0   0   0   0  20   0   0   0   0]\n",
      " [  0   0   0   0 167   6   0  39   0   0]\n",
      " [  0   0   0   0   2 147   0  33   3   0]\n",
      " [  0   0   0   0   2   2  63   4   0   0]\n",
      " [  0   0   0   0  12  24   3 570  14   0]\n",
      " [  0   4   0   0   0   2   0  65  72   0]\n",
      " [  0   0   0   0   3   0   0  29   0   0]]\n",
      "--------------------   final   --------------------\n",
      "no_activities: 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1349/1349 [==============================] - 1s 428us/step\n",
      "0-milan:\tacc: 76.06%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 0, 0, 0, 9, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 7, 0, 0, 0, 0, 7, 7, 7, 7, 7, 7, 7, 9, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 7, 0, 9, 9, 0, 9, 7, 7, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 0, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 9, 0, 9, 0, 9, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 0, 7, 9, 9, 9, 0, 7, 9, 0, 9, 9, 9, 0, 9, 9, 7, 0, 7, 7, 7, 0, 7, 7, 0, 7, 7, 0, 7, 0, 7, 9, 7, 7, 7, 7, 0, 7, 7, 7, 7, 4, 7, 7, 7, 7, 0, 7, 7, 7, 7, 0, 7, 7, 7, 7, 0, 7, 0, 0, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 4, 0, 7, 7, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 4, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 0, 7, 7, 7, 7, 7, 7, 9, 7, 7, 0, 7, 0, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 7, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 5, 5, 9, 0, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 0, 9, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 7, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 0, 9, 0, 0, 7, 0, 0, 7, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 9, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 7, 4, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 5, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 4, 4, 0, 4, 4, 4, 0, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 4, 4, 0, 0, 4, 4, 0, 0, 4, 4, 0, 0, 4, 0, 4, 4, 0, 4, 0, 4, 4, 0, 4, 4, 4, 4, 0, 4, 4, 0, 4, 4, 0, 4, 0, 4, 4, 0, 4, 4, 4, 4, 4, 4, 0, 4, 4, 0, 7, 4, 0, 4, 4, 4, 4, 4, 4, 4, 0, 7, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.749014  0.914928  0.823699       623\n",
      "         Work   0.666667  0.307692  0.421053        26\n",
      "Take_medicine   0.000000  0.000000  0.000000        20\n",
      "        Sleep   0.000000  0.000000  0.000000        32\n",
      "        Relax   0.806818  0.496503  0.614719       143\n",
      "   Leave_Home   0.954545  0.887324  0.919708        71\n",
      "          Eat   0.000000  0.000000  0.000000         7\n",
      "         Cook   0.717073  0.794595  0.753846       185\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        30\n",
      "      Bathing   0.769585  0.787736  0.778555       212\n",
      "\n",
      "     accuracy                       0.760563      1349\n",
      "    macro avg   0.466370  0.418878  0.431158      1349\n",
      " weighted avg   0.713809  0.760563  0.727822      1349\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  30   0   0   0   0   0]\n",
      " [  0   8   0   0   1   1   0  16   0   0]\n",
      " [  0   0   0   0   0   3   0   4   0   0]\n",
      " [  0   0   0   0   0  20   0   0   0   0]\n",
      " [  0   0   0   0 167   6   0  39   0   0]\n",
      " [  0   0   0   0   2 147   0  33   3   0]\n",
      " [  0   0   0   0   2   2  63   4   0   0]\n",
      " [  0   0   0   0  12  24   3 570  14   0]\n",
      " [  0   4   0   0   0   2   0  66  71   0]\n",
      " [  0   0   0   0   3   0   0  29   0   0]]\n",
      "no_activities: 10\n",
      "\n",
      "Begin training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.7529 - acc: 0.4896 - val_loss: 1.3821 - val_acc: 0.5804\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 1.4200 - acc: 0.5647 - val_loss: 1.2279 - val_acc: 0.6272\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 1.3048 - acc: 0.5975 - val_loss: 1.1422 - val_acc: 0.6548\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 1.2456 - acc: 0.6142 - val_loss: 1.0968 - val_acc: 0.6600\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 1.1778 - acc: 0.6224 - val_loss: 1.0446 - val_acc: 0.6726\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 1.1620 - acc: 0.6440 - val_loss: 1.0171 - val_acc: 0.7024\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 1.1188 - acc: 0.6533 - val_loss: 0.9904 - val_acc: 0.7001\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 1.0849 - acc: 0.6566 - val_loss: 0.9617 - val_acc: 0.7054\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 1.0664 - acc: 0.6622 - val_loss: 0.9416 - val_acc: 0.7061\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 1.0530 - acc: 0.6644 - val_loss: 0.9169 - val_acc: 0.7076\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 1.0321 - acc: 0.6667 - val_loss: 0.9008 - val_acc: 0.7083\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 1.0209 - acc: 0.6693 - val_loss: 0.8906 - val_acc: 0.7068\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.9812 - acc: 0.6804 - val_loss: 0.8718 - val_acc: 0.7076\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.9850 - acc: 0.6700 - val_loss: 0.8641 - val_acc: 0.7076\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.9818 - acc: 0.6674 - val_loss: 0.8522 - val_acc: 0.7113\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.9609 - acc: 0.6786 - val_loss: 0.8438 - val_acc: 0.7068\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.9612 - acc: 0.6760 - val_loss: 0.8378 - val_acc: 0.7083\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.9580 - acc: 0.6730 - val_loss: 0.8294 - val_acc: 0.7106\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.9470 - acc: 0.6815 - val_loss: 0.8238 - val_acc: 0.7091\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.9242 - acc: 0.6864 - val_loss: 0.8166 - val_acc: 0.7128\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.9226 - acc: 0.6804 - val_loss: 0.8111 - val_acc: 0.7173\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.9280 - acc: 0.6845 - val_loss: 0.8099 - val_acc: 0.7225\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.9113 - acc: 0.6834 - val_loss: 0.8056 - val_acc: 0.7277\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.9103 - acc: 0.6994 - val_loss: 0.8033 - val_acc: 0.7344\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.9048 - acc: 0.7016 - val_loss: 0.7972 - val_acc: 0.7359\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8876 - acc: 0.7057 - val_loss: 0.7904 - val_acc: 0.7388\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8826 - acc: 0.7102 - val_loss: 0.7882 - val_acc: 0.7381\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8908 - acc: 0.6987 - val_loss: 0.7901 - val_acc: 0.7381\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8880 - acc: 0.6968 - val_loss: 0.7846 - val_acc: 0.7403\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8755 - acc: 0.7013 - val_loss: 0.7854 - val_acc: 0.7344\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8759 - acc: 0.7013 - val_loss: 0.7797 - val_acc: 0.7388\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8706 - acc: 0.7102 - val_loss: 0.7775 - val_acc: 0.7366\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8703 - acc: 0.7106 - val_loss: 0.7716 - val_acc: 0.7411\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8664 - acc: 0.7042 - val_loss: 0.7711 - val_acc: 0.7426\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.8695 - acc: 0.7035 - val_loss: 0.7711 - val_acc: 0.7448\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.8548 - acc: 0.7150 - val_loss: 0.7699 - val_acc: 0.7388\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.8567 - acc: 0.7046 - val_loss: 0.7651 - val_acc: 0.7381\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.8620 - acc: 0.6990 - val_loss: 0.7634 - val_acc: 0.7433\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8510 - acc: 0.7147 - val_loss: 0.7653 - val_acc: 0.7448\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.8617 - acc: 0.7065 - val_loss: 0.7645 - val_acc: 0.7411\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.8414 - acc: 0.7113 - val_loss: 0.7612 - val_acc: 0.7426\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8597 - acc: 0.7050 - val_loss: 0.7596 - val_acc: 0.7426\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.8485 - acc: 0.7135 - val_loss: 0.7597 - val_acc: 0.7515\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8321 - acc: 0.7113 - val_loss: 0.7585 - val_acc: 0.7455\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.8361 - acc: 0.7165 - val_loss: 0.7560 - val_acc: 0.7485\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8280 - acc: 0.7132 - val_loss: 0.7547 - val_acc: 0.7440\n",
      "Epoch 47/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.8235 - acc: 0.7247 - val_loss: 0.7515 - val_acc: 0.7500\n",
      "Epoch 48/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8483 - acc: 0.7121 - val_loss: 0.7508 - val_acc: 0.7507\n",
      "Epoch 49/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8286 - acc: 0.7169 - val_loss: 0.7508 - val_acc: 0.7493\n",
      "Epoch 50/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8353 - acc: 0.7150 - val_loss: 0.7478 - val_acc: 0.7478\n",
      "Epoch 51/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8340 - acc: 0.7214 - val_loss: 0.7488 - val_acc: 0.7485\n",
      "Epoch 52/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8256 - acc: 0.7169 - val_loss: 0.7423 - val_acc: 0.7522\n",
      "Epoch 53/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8197 - acc: 0.7180 - val_loss: 0.7429 - val_acc: 0.7478\n",
      "Epoch 54/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8211 - acc: 0.7191 - val_loss: 0.7463 - val_acc: 0.7470\n",
      "Epoch 55/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8180 - acc: 0.7214 - val_loss: 0.7442 - val_acc: 0.7463\n",
      "Epoch 56/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8055 - acc: 0.7262 - val_loss: 0.7435 - val_acc: 0.7485\n",
      "Epoch 57/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8239 - acc: 0.7221 - val_loss: 0.7419 - val_acc: 0.7463\n",
      "Epoch 58/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8270 - acc: 0.7195 - val_loss: 0.7383 - val_acc: 0.7493\n",
      "Epoch 59/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8008 - acc: 0.7225 - val_loss: 0.7399 - val_acc: 0.7507\n",
      "Epoch 60/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8250 - acc: 0.7184 - val_loss: 0.7396 - val_acc: 0.7478\n",
      "Epoch 61/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.8102 - acc: 0.7243 - val_loss: 0.7370 - val_acc: 0.7500\n",
      "Epoch 62/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8063 - acc: 0.7180 - val_loss: 0.7370 - val_acc: 0.7507\n",
      "Epoch 63/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8118 - acc: 0.7202 - val_loss: 0.7371 - val_acc: 0.7493\n",
      "Epoch 64/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8050 - acc: 0.7228 - val_loss: 0.7352 - val_acc: 0.7522\n",
      "Epoch 65/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8104 - acc: 0.7225 - val_loss: 0.7346 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00065: loss improved from inf to 0.81038, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-1-000065-0.810385-0.750000.hdf5\n",
      "Epoch 66/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8201 - acc: 0.7206 - val_loss: 0.7362 - val_acc: 0.7485\n",
      "Epoch 67/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8032 - acc: 0.7225 - val_loss: 0.7355 - val_acc: 0.7515\n",
      "Epoch 68/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8137 - acc: 0.7247 - val_loss: 0.7310 - val_acc: 0.7515\n",
      "Epoch 69/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7951 - acc: 0.7292 - val_loss: 0.7354 - val_acc: 0.7507\n",
      "\n",
      "Epoch 00069: loss improved from 0.81038 to 0.79509, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-1-000069-0.795088-0.750744.hdf5\n",
      "Epoch 70/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8025 - acc: 0.7284 - val_loss: 0.7336 - val_acc: 0.7515\n",
      "Epoch 71/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8140 - acc: 0.7236 - val_loss: 0.7276 - val_acc: 0.7493\n",
      "Epoch 72/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7965 - acc: 0.7277 - val_loss: 0.7330 - val_acc: 0.7500\n",
      "Epoch 73/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8151 - acc: 0.7221 - val_loss: 0.7322 - val_acc: 0.7515\n",
      "Epoch 74/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7962 - acc: 0.7210 - val_loss: 0.7309 - val_acc: 0.7522\n",
      "Epoch 75/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7946 - acc: 0.7206 - val_loss: 0.7274 - val_acc: 0.7507\n",
      "Epoch 76/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7994 - acc: 0.7314 - val_loss: 0.7272 - val_acc: 0.7485\n",
      "Epoch 77/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7962 - acc: 0.7232 - val_loss: 0.7257 - val_acc: 0.7530\n",
      "Epoch 78/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7940 - acc: 0.7228 - val_loss: 0.7278 - val_acc: 0.7493\n",
      "Epoch 79/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7921 - acc: 0.7240 - val_loss: 0.7267 - val_acc: 0.7470\n",
      "Epoch 80/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7910 - acc: 0.7214 - val_loss: 0.7231 - val_acc: 0.7507\n",
      "Epoch 81/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8107 - acc: 0.7161 - val_loss: 0.7276 - val_acc: 0.7485\n",
      "Epoch 82/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.8042 - acc: 0.7188 - val_loss: 0.7254 - val_acc: 0.7515\n",
      "Epoch 83/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7943 - acc: 0.7307 - val_loss: 0.7239 - val_acc: 0.7515\n",
      "Epoch 84/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7760 - acc: 0.7307 - val_loss: 0.7254 - val_acc: 0.7493\n",
      "Epoch 85/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7981 - acc: 0.7165 - val_loss: 0.7240 - val_acc: 0.7470\n",
      "Epoch 86/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7936 - acc: 0.7143 - val_loss: 0.7245 - val_acc: 0.7500\n",
      "Epoch 87/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7853 - acc: 0.7299 - val_loss: 0.7208 - val_acc: 0.7493\n",
      "Epoch 88/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7708 - acc: 0.7310 - val_loss: 0.7226 - val_acc: 0.7485\n",
      "Epoch 89/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7842 - acc: 0.7292 - val_loss: 0.7217 - val_acc: 0.7485\n",
      "\n",
      "Epoch 00089: loss improved from 0.79509 to 0.78419, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-1-000089-0.784188-0.748512.hdf5\n",
      "Epoch 90/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7883 - acc: 0.7188 - val_loss: 0.7213 - val_acc: 0.7493\n",
      "Epoch 91/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7736 - acc: 0.7277 - val_loss: 0.7230 - val_acc: 0.7493\n",
      "Epoch 92/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7895 - acc: 0.7333 - val_loss: 0.7214 - val_acc: 0.7485\n",
      "Epoch 93/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7892 - acc: 0.7254 - val_loss: 0.7225 - val_acc: 0.7485\n",
      "Epoch 94/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7801 - acc: 0.7195 - val_loss: 0.7214 - val_acc: 0.7485\n",
      "Epoch 95/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7667 - acc: 0.7310 - val_loss: 0.7210 - val_acc: 0.7470\n",
      "Epoch 96/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7997 - acc: 0.7206 - val_loss: 0.7204 - val_acc: 0.7470\n",
      "Epoch 97/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7724 - acc: 0.7295 - val_loss: 0.7199 - val_acc: 0.7493\n",
      "\n",
      "Epoch 00097: loss improved from 0.78419 to 0.77239, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-1-000097-0.772387-0.749256.hdf5\n",
      "Epoch 98/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7706 - acc: 0.7299 - val_loss: 0.7194 - val_acc: 0.7500\n",
      "Epoch 99/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7760 - acc: 0.7362 - val_loss: 0.7180 - val_acc: 0.7500\n",
      "Epoch 100/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7751 - acc: 0.7273 - val_loss: 0.7187 - val_acc: 0.7478\n",
      "\n",
      "Epoch 00100: saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/1-000100-0.775084-0.747768.hdf5\n",
      "Epoch 101/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7779 - acc: 0.7232 - val_loss: 0.7194 - val_acc: 0.7485\n",
      "Epoch 102/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7848 - acc: 0.7310 - val_loss: 0.7183 - val_acc: 0.7493\n",
      "Epoch 103/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7745 - acc: 0.7254 - val_loss: 0.7191 - val_acc: 0.7478\n",
      "Epoch 104/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7829 - acc: 0.7344 - val_loss: 0.7163 - val_acc: 0.7530\n",
      "Epoch 105/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7644 - acc: 0.7321 - val_loss: 0.7156 - val_acc: 0.7478\n",
      "Epoch 106/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7783 - acc: 0.7273 - val_loss: 0.7170 - val_acc: 0.7500\n",
      "Epoch 107/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7814 - acc: 0.7214 - val_loss: 0.7176 - val_acc: 0.7493\n",
      "Epoch 108/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7636 - acc: 0.7269 - val_loss: 0.7155 - val_acc: 0.7485\n",
      "Epoch 109/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7703 - acc: 0.7325 - val_loss: 0.7151 - val_acc: 0.7515\n",
      "Epoch 110/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7685 - acc: 0.7318 - val_loss: 0.7162 - val_acc: 0.7485\n",
      "Epoch 111/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.7720 - acc: 0.7321 - val_loss: 0.7163 - val_acc: 0.7493\n",
      "Epoch 112/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7781 - acc: 0.7303 - val_loss: 0.7157 - val_acc: 0.7507\n",
      "Epoch 113/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7690 - acc: 0.7269 - val_loss: 0.7138 - val_acc: 0.7515\n",
      "Epoch 114/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7693 - acc: 0.7321 - val_loss: 0.7158 - val_acc: 0.7515\n",
      "Epoch 115/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7663 - acc: 0.7344 - val_loss: 0.7138 - val_acc: 0.7537\n",
      "Epoch 116/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.7524 - acc: 0.7385 - val_loss: 0.7151 - val_acc: 0.7522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7698 - acc: 0.7344 - val_loss: 0.7116 - val_acc: 0.7567\n",
      "Epoch 118/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7634 - acc: 0.7333 - val_loss: 0.7121 - val_acc: 0.7545\n",
      "Epoch 119/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7627 - acc: 0.7329 - val_loss: 0.7108 - val_acc: 0.7574\n",
      "Epoch 120/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7663 - acc: 0.7318 - val_loss: 0.7118 - val_acc: 0.7582\n",
      "Epoch 121/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.7627 - acc: 0.7355 - val_loss: 0.7113 - val_acc: 0.7574\n",
      "Epoch 122/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7713 - acc: 0.7321 - val_loss: 0.7133 - val_acc: 0.7560\n",
      "Epoch 123/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7541 - acc: 0.7321 - val_loss: 0.7104 - val_acc: 0.7560\n",
      "Epoch 124/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7649 - acc: 0.7310 - val_loss: 0.7111 - val_acc: 0.7567\n",
      "Epoch 125/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7679 - acc: 0.7355 - val_loss: 0.7089 - val_acc: 0.7582\n",
      "Epoch 126/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7649 - acc: 0.7254 - val_loss: 0.7095 - val_acc: 0.7597\n",
      "Epoch 127/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7611 - acc: 0.7362 - val_loss: 0.7106 - val_acc: 0.7597\n",
      "Epoch 128/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7617 - acc: 0.7351 - val_loss: 0.7090 - val_acc: 0.7604\n",
      "Epoch 129/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7604 - acc: 0.7355 - val_loss: 0.7104 - val_acc: 0.7574\n",
      "Epoch 130/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7630 - acc: 0.7340 - val_loss: 0.7082 - val_acc: 0.7589\n",
      "Epoch 131/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7642 - acc: 0.7292 - val_loss: 0.7109 - val_acc: 0.7574\n",
      "Epoch 132/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7483 - acc: 0.7403 - val_loss: 0.7096 - val_acc: 0.7567\n",
      "Epoch 133/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7509 - acc: 0.7362 - val_loss: 0.7099 - val_acc: 0.7589\n",
      "Epoch 134/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7544 - acc: 0.7366 - val_loss: 0.7104 - val_acc: 0.7552\n",
      "Epoch 135/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7547 - acc: 0.7381 - val_loss: 0.7063 - val_acc: 0.7589\n",
      "Epoch 136/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7714 - acc: 0.7258 - val_loss: 0.7060 - val_acc: 0.7567\n",
      "Epoch 137/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7459 - acc: 0.7411 - val_loss: 0.7020 - val_acc: 0.7552\n",
      "Epoch 138/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7646 - acc: 0.7396 - val_loss: 0.7090 - val_acc: 0.7560\n",
      "Epoch 139/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7674 - acc: 0.7299 - val_loss: 0.7075 - val_acc: 0.7567\n",
      "Epoch 140/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7669 - acc: 0.7392 - val_loss: 0.7069 - val_acc: 0.7582\n",
      "Epoch 141/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7466 - acc: 0.7440 - val_loss: 0.7083 - val_acc: 0.7574\n",
      "Epoch 142/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7552 - acc: 0.7374 - val_loss: 0.7089 - val_acc: 0.7560\n",
      "Epoch 143/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7620 - acc: 0.7292 - val_loss: 0.7079 - val_acc: 0.7574\n",
      "Epoch 144/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7561 - acc: 0.7377 - val_loss: 0.7094 - val_acc: 0.7567\n",
      "Epoch 145/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7533 - acc: 0.7228 - val_loss: 0.7077 - val_acc: 0.7522\n",
      "Epoch 146/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7537 - acc: 0.7426 - val_loss: 0.7071 - val_acc: 0.7552\n",
      "Epoch 147/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7546 - acc: 0.7388 - val_loss: 0.7056 - val_acc: 0.7589\n",
      "Epoch 148/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7595 - acc: 0.7355 - val_loss: 0.7071 - val_acc: 0.7604\n",
      "Epoch 149/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7383 - acc: 0.7470 - val_loss: 0.7068 - val_acc: 0.7567\n",
      "Epoch 150/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.7536 - acc: 0.7359 - val_loss: 0.7068 - val_acc: 0.7567\n",
      "Epoch 151/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7345 - acc: 0.7433 - val_loss: 0.7049 - val_acc: 0.7582\n",
      "Epoch 152/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7625 - acc: 0.7392 - val_loss: 0.7066 - val_acc: 0.7567\n",
      "Epoch 153/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.7487 - acc: 0.7366 - val_loss: 0.7055 - val_acc: 0.7560\n",
      "Epoch 154/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7620 - acc: 0.7437 - val_loss: 0.7061 - val_acc: 0.7574\n",
      "Epoch 155/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.7448 - acc: 0.7448 - val_loss: 0.7052 - val_acc: 0.7597\n",
      "Epoch 156/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7576 - acc: 0.7452 - val_loss: 0.7053 - val_acc: 0.7574\n",
      "Epoch 157/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7501 - acc: 0.7366 - val_loss: 0.7034 - val_acc: 0.7574\n",
      "Epoch 158/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7545 - acc: 0.7347 - val_loss: 0.7061 - val_acc: 0.7582\n",
      "Epoch 159/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7497 - acc: 0.7414 - val_loss: 0.7042 - val_acc: 0.7582\n",
      "Epoch 160/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7437 - acc: 0.7366 - val_loss: 0.7029 - val_acc: 0.7612\n",
      "Epoch 161/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7507 - acc: 0.7418 - val_loss: 0.7023 - val_acc: 0.7560\n",
      "Epoch 162/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7479 - acc: 0.7303 - val_loss: 0.7022 - val_acc: 0.7582\n",
      "Epoch 163/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7522 - acc: 0.7396 - val_loss: 0.7018 - val_acc: 0.7574\n",
      "Epoch 164/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7456 - acc: 0.7359 - val_loss: 0.7031 - val_acc: 0.7597\n",
      "Epoch 165/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7419 - acc: 0.7325 - val_loss: 0.7057 - val_acc: 0.7589\n",
      "\n",
      "Epoch 00165: loss improved from inf to 0.74191, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-1-000165-0.741911-0.758929.hdf5\n",
      "Epoch 166/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7426 - acc: 0.7411 - val_loss: 0.7040 - val_acc: 0.7582\n",
      "Epoch 167/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7550 - acc: 0.7388 - val_loss: 0.7023 - val_acc: 0.7574\n",
      "Epoch 168/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7378 - acc: 0.7381 - val_loss: 0.7024 - val_acc: 0.7604\n",
      "Epoch 169/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7431 - acc: 0.7407 - val_loss: 0.6996 - val_acc: 0.7589\n",
      "Epoch 170/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7476 - acc: 0.7374 - val_loss: 0.7021 - val_acc: 0.7582\n",
      "Epoch 171/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7377 - acc: 0.7426 - val_loss: 0.6993 - val_acc: 0.7567\n",
      "\n",
      "Epoch 00171: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 172/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7437 - acc: 0.7340 - val_loss: 0.6996 - val_acc: 0.7567\n",
      "Epoch 173/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7271 - acc: 0.7493 - val_loss: 0.7013 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00173: loss improved from 0.74191 to 0.72710, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-1-000173-0.727100-0.757440.hdf5\n",
      "Epoch 174/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7344 - acc: 0.7429 - val_loss: 0.7002 - val_acc: 0.7582\n",
      "Epoch 175/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7497 - acc: 0.7381 - val_loss: 0.7009 - val_acc: 0.7574\n",
      "Epoch 176/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7555 - acc: 0.7359 - val_loss: 0.7013 - val_acc: 0.7567\n",
      "Epoch 177/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7484 - acc: 0.7422 - val_loss: 0.6993 - val_acc: 0.7582\n",
      "Epoch 178/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7477 - acc: 0.7455 - val_loss: 0.6976 - val_acc: 0.7582\n",
      "Epoch 179/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7462 - acc: 0.7314 - val_loss: 0.6945 - val_acc: 0.7597\n",
      "Epoch 180/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7403 - acc: 0.7374 - val_loss: 0.6994 - val_acc: 0.7597\n",
      "Epoch 181/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7439 - acc: 0.7336 - val_loss: 0.7018 - val_acc: 0.7560\n",
      "Epoch 182/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7363 - acc: 0.7489 - val_loss: 0.6985 - val_acc: 0.7574\n",
      "Epoch 183/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7552 - acc: 0.7403 - val_loss: 0.7009 - val_acc: 0.7597\n",
      "Epoch 184/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7522 - acc: 0.7392 - val_loss: 0.6995 - val_acc: 0.7597\n",
      "Epoch 185/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7296 - acc: 0.7515 - val_loss: 0.7010 - val_acc: 0.7582\n",
      "Epoch 186/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7477 - acc: 0.7362 - val_loss: 0.7002 - val_acc: 0.7589\n",
      "Epoch 187/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7284 - acc: 0.7485 - val_loss: 0.6996 - val_acc: 0.7574\n",
      "Epoch 188/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7422 - acc: 0.7396 - val_loss: 0.7020 - val_acc: 0.7560\n",
      "Epoch 189/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7451 - acc: 0.7433 - val_loss: 0.6993 - val_acc: 0.7574\n",
      "Epoch 190/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7420 - acc: 0.7422 - val_loss: 0.6999 - val_acc: 0.7589\n",
      "Epoch 191/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7418 - acc: 0.7455 - val_loss: 0.7009 - val_acc: 0.7560\n",
      "Epoch 192/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7470 - acc: 0.7396 - val_loss: 0.6983 - val_acc: 0.7589\n",
      "Epoch 193/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7410 - acc: 0.7366 - val_loss: 0.6999 - val_acc: 0.7597\n",
      "\n",
      "Epoch 00193: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 194/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7282 - acc: 0.7414 - val_loss: 0.6988 - val_acc: 0.7604\n",
      "Epoch 195/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7338 - acc: 0.7407 - val_loss: 0.6971 - val_acc: 0.7589\n",
      "Epoch 196/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7530 - acc: 0.7336 - val_loss: 0.7011 - val_acc: 0.7589\n",
      "Epoch 197/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7377 - acc: 0.7467 - val_loss: 0.6983 - val_acc: 0.7604\n",
      "Epoch 198/1000\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.7507 - acc: 0.7388 - val_loss: 0.6983 - val_acc: 0.7597\n",
      "Epoch 199/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7288 - acc: 0.7552 - val_loss: 0.7009 - val_acc: 0.7589\n",
      "Epoch 200/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7371 - acc: 0.7418 - val_loss: 0.7012 - val_acc: 0.7582\n",
      "\n",
      "Epoch 00200: saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/1-000200-0.737063-0.758185.hdf5\n",
      "Epoch 201/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7348 - acc: 0.7366 - val_loss: 0.7017 - val_acc: 0.7574\n",
      "Epoch 202/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7327 - acc: 0.7440 - val_loss: 0.7006 - val_acc: 0.7589\n",
      "Epoch 203/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7544 - acc: 0.7292 - val_loss: 0.7013 - val_acc: 0.7582\n",
      "Epoch 204/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7412 - acc: 0.7340 - val_loss: 0.6982 - val_acc: 0.7589\n",
      "Epoch 205/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7302 - acc: 0.7474 - val_loss: 0.7010 - val_acc: 0.7582\n",
      "Epoch 206/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7334 - acc: 0.7485 - val_loss: 0.7006 - val_acc: 0.7582\n",
      "Epoch 207/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7507 - acc: 0.7318 - val_loss: 0.6983 - val_acc: 0.7574\n",
      "Epoch 208/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7407 - acc: 0.7429 - val_loss: 0.7012 - val_acc: 0.7567\n",
      "Epoch 209/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7424 - acc: 0.7370 - val_loss: 0.7012 - val_acc: 0.7574\n",
      "Epoch 210/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7361 - acc: 0.7418 - val_loss: 0.6989 - val_acc: 0.7597\n",
      "Epoch 211/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7395 - acc: 0.7556 - val_loss: 0.7015 - val_acc: 0.7574\n",
      "Epoch 212/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7353 - acc: 0.7407 - val_loss: 0.6989 - val_acc: 0.7582\n",
      "Epoch 213/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7446 - acc: 0.7437 - val_loss: 0.6976 - val_acc: 0.7597\n",
      "\n",
      "Epoch 00213: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 214/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7406 - acc: 0.7388 - val_loss: 0.7013 - val_acc: 0.7574\n",
      "Epoch 215/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7301 - acc: 0.7414 - val_loss: 0.6975 - val_acc: 0.7589\n",
      "Epoch 216/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7422 - acc: 0.7478 - val_loss: 0.6978 - val_acc: 0.7589\n",
      "Epoch 217/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7300 - acc: 0.7478 - val_loss: 0.6994 - val_acc: 0.7589\n",
      "Epoch 218/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.7449 - acc: 0.7370 - val_loss: 0.6992 - val_acc: 0.7582\n",
      "Epoch 219/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7491 - acc: 0.7336 - val_loss: 0.7006 - val_acc: 0.7582\n",
      "Epoch 220/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.7383 - acc: 0.7448 - val_loss: 0.7006 - val_acc: 0.7582\n",
      "Epoch 221/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7431 - acc: 0.7440 - val_loss: 0.7015 - val_acc: 0.7574\n",
      "Epoch 222/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7393 - acc: 0.7493 - val_loss: 0.6994 - val_acc: 0.7582\n",
      "Epoch 223/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.7355 - acc: 0.7467 - val_loss: 0.6991 - val_acc: 0.7582\n",
      "Epoch 224/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7295 - acc: 0.7403 - val_loss: 0.7017 - val_acc: 0.7574\n",
      "Epoch 225/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7354 - acc: 0.7377 - val_loss: 0.6996 - val_acc: 0.7589\n",
      "Epoch 226/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7245 - acc: 0.7448 - val_loss: 0.7006 - val_acc: 0.7589\n",
      "Epoch 227/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7476 - acc: 0.7381 - val_loss: 0.7008 - val_acc: 0.7582\n",
      "Epoch 228/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7474 - acc: 0.7392 - val_loss: 0.6971 - val_acc: 0.7589\n",
      "Epoch 229/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7401 - acc: 0.7426 - val_loss: 0.7016 - val_acc: 0.7574\n",
      "Epoch 230/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7380 - acc: 0.7407 - val_loss: 0.6996 - val_acc: 0.7582\n",
      "Epoch 231/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7335 - acc: 0.7403 - val_loss: 0.7012 - val_acc: 0.7574\n",
      "Epoch 232/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7455 - acc: 0.7400 - val_loss: 0.7017 - val_acc: 0.7567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7307 - acc: 0.7403 - val_loss: 0.6995 - val_acc: 0.7574\n",
      "Epoch 234/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7432 - acc: 0.7437 - val_loss: 0.6987 - val_acc: 0.7574\n",
      "Epoch 235/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7419 - acc: 0.7407 - val_loss: 0.7011 - val_acc: 0.7574\n",
      "Epoch 236/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7291 - acc: 0.7437 - val_loss: 0.7009 - val_acc: 0.7574\n",
      "Epoch 237/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7442 - acc: 0.7344 - val_loss: 0.7011 - val_acc: 0.7567\n",
      "Epoch 238/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7406 - acc: 0.7359 - val_loss: 0.7010 - val_acc: 0.7567\n",
      "Epoch 239/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7632 - acc: 0.7310 - val_loss: 0.7014 - val_acc: 0.7567\n",
      "Epoch 240/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7249 - acc: 0.7556 - val_loss: 0.7007 - val_acc: 0.7567\n",
      "Epoch 241/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7370 - acc: 0.7504 - val_loss: 0.7016 - val_acc: 0.7567\n",
      "Epoch 242/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7375 - acc: 0.7448 - val_loss: 0.7009 - val_acc: 0.7574\n",
      "Epoch 243/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7269 - acc: 0.7452 - val_loss: 0.7014 - val_acc: 0.7574\n",
      "Epoch 244/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7435 - acc: 0.7400 - val_loss: 0.7010 - val_acc: 0.7567\n",
      "Epoch 245/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7473 - acc: 0.7381 - val_loss: 0.6964 - val_acc: 0.7574\n",
      "Epoch 246/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.7689 - acc: 0.7329 - val_loss: 0.6999 - val_acc: 0.7574\n",
      "Epoch 247/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7469 - acc: 0.7362 - val_loss: 0.7012 - val_acc: 0.7574\n",
      "Epoch 248/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7485 - acc: 0.7448 - val_loss: 0.7015 - val_acc: 0.7567\n",
      "Epoch 249/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7423 - acc: 0.7392 - val_loss: 0.7014 - val_acc: 0.7567\n",
      "Epoch 250/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7487 - acc: 0.7277 - val_loss: 0.7006 - val_acc: 0.7574\n",
      "Epoch 251/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7322 - acc: 0.7467 - val_loss: 0.7012 - val_acc: 0.7574\n",
      "Epoch 252/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7362 - acc: 0.7426 - val_loss: 0.7013 - val_acc: 0.7567\n",
      "Epoch 253/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7470 - acc: 0.7411 - val_loss: 0.7007 - val_acc: 0.7574\n",
      "Epoch 254/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7401 - acc: 0.7407 - val_loss: 0.7014 - val_acc: 0.7567\n",
      "Epoch 255/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7468 - acc: 0.7351 - val_loss: 0.6989 - val_acc: 0.7582\n",
      "Epoch 256/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7402 - acc: 0.7414 - val_loss: 0.7011 - val_acc: 0.7574\n",
      "Epoch 257/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7494 - acc: 0.7418 - val_loss: 0.7013 - val_acc: 0.7567\n",
      "Epoch 258/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7434 - acc: 0.7448 - val_loss: 0.7012 - val_acc: 0.7567\n",
      "Epoch 259/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7380 - acc: 0.7347 - val_loss: 0.7014 - val_acc: 0.7567\n",
      "Epoch 260/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7301 - acc: 0.7530 - val_loss: 0.6987 - val_acc: 0.7589\n",
      "Epoch 261/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7453 - acc: 0.7385 - val_loss: 0.7017 - val_acc: 0.7567\n",
      "Epoch 262/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7683 - acc: 0.7295 - val_loss: 0.6982 - val_acc: 0.7582\n",
      "Epoch 263/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7509 - acc: 0.7407 - val_loss: 0.6989 - val_acc: 0.7574\n",
      "Epoch 264/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7473 - acc: 0.7366 - val_loss: 0.7010 - val_acc: 0.7567\n",
      "Epoch 265/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7349 - acc: 0.7396 - val_loss: 0.7003 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00265: loss improved from inf to 0.73490, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-1-000265-0.734896-0.757440.hdf5\n",
      "Epoch 266/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7479 - acc: 0.7459 - val_loss: 0.7007 - val_acc: 0.7574\n",
      "Epoch 267/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7304 - acc: 0.7414 - val_loss: 0.7002 - val_acc: 0.7574\n",
      "Epoch 268/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7286 - acc: 0.7470 - val_loss: 0.7016 - val_acc: 0.7567\n",
      "Epoch 269/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7416 - acc: 0.7455 - val_loss: 0.7014 - val_acc: 0.7567\n",
      "Epoch 270/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7462 - acc: 0.7381 - val_loss: 0.7014 - val_acc: 0.7567\n",
      "Epoch 271/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7321 - acc: 0.7496 - val_loss: 0.7001 - val_acc: 0.7574\n",
      "Epoch 272/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7502 - acc: 0.7388 - val_loss: 0.7017 - val_acc: 0.7567\n",
      "Epoch 273/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7414 - acc: 0.7411 - val_loss: 0.6990 - val_acc: 0.7582\n",
      "Epoch 274/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7373 - acc: 0.7444 - val_loss: 0.6980 - val_acc: 0.7582\n",
      "Epoch 275/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7346 - acc: 0.7403 - val_loss: 0.6995 - val_acc: 0.7574\n",
      "Epoch 276/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7299 - acc: 0.7455 - val_loss: 0.7007 - val_acc: 0.7574\n",
      "Epoch 277/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7539 - acc: 0.7362 - val_loss: 0.6978 - val_acc: 0.7582\n",
      "Epoch 278/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7305 - acc: 0.7452 - val_loss: 0.6984 - val_acc: 0.7582\n",
      "Epoch 279/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7453 - acc: 0.7474 - val_loss: 0.7016 - val_acc: 0.7567\n",
      "Epoch 280/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7327 - acc: 0.7429 - val_loss: 0.7012 - val_acc: 0.7567\n",
      "Epoch 281/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7340 - acc: 0.7385 - val_loss: 0.6996 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00281: loss improved from 0.73490 to 0.73402, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-1-000281-0.734024-0.757440.hdf5\n",
      "Epoch 282/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7411 - acc: 0.7452 - val_loss: 0.6985 - val_acc: 0.7574\n",
      "Epoch 283/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7345 - acc: 0.7496 - val_loss: 0.7005 - val_acc: 0.7574\n",
      "Epoch 284/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7474 - acc: 0.7403 - val_loss: 0.7009 - val_acc: 0.7567\n",
      "Epoch 285/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7409 - acc: 0.7355 - val_loss: 0.7007 - val_acc: 0.7574\n",
      "Epoch 286/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7330 - acc: 0.7474 - val_loss: 0.7002 - val_acc: 0.7574\n",
      "Epoch 287/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7519 - acc: 0.7325 - val_loss: 0.7016 - val_acc: 0.7567\n",
      "Epoch 288/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7434 - acc: 0.7366 - val_loss: 0.6985 - val_acc: 0.7574\n",
      "Epoch 289/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7535 - acc: 0.7437 - val_loss: 0.7009 - val_acc: 0.7567\n",
      "Epoch 290/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7348 - acc: 0.7437 - val_loss: 0.6984 - val_acc: 0.7589\n",
      "Epoch 291/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7294 - acc: 0.7426 - val_loss: 0.6988 - val_acc: 0.7582\n",
      "Epoch 292/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7392 - acc: 0.7418 - val_loss: 0.7015 - val_acc: 0.7567\n",
      "Epoch 293/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7496 - acc: 0.7340 - val_loss: 0.6999 - val_acc: 0.7574\n",
      "Epoch 294/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7389 - acc: 0.7396 - val_loss: 0.7007 - val_acc: 0.7574\n",
      "Epoch 295/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7347 - acc: 0.7485 - val_loss: 0.7008 - val_acc: 0.7574\n",
      "Epoch 296/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.7394 - acc: 0.7463 - val_loss: 0.7013 - val_acc: 0.7574\n",
      "Epoch 297/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7623 - acc: 0.7262 - val_loss: 0.6976 - val_acc: 0.7589\n",
      "Epoch 298/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7289 - acc: 0.7437 - val_loss: 0.6995 - val_acc: 0.7582\n",
      "Epoch 299/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7430 - acc: 0.7463 - val_loss: 0.6991 - val_acc: 0.7582\n",
      "Epoch 300/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7524 - acc: 0.7333 - val_loss: 0.7010 - val_acc: 0.7567\n",
      "\n",
      "Epoch 00300: saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/1-000300-0.752437-0.756696.hdf5\n",
      "Epoch 301/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7375 - acc: 0.7459 - val_loss: 0.6968 - val_acc: 0.7574\n",
      "Epoch 302/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7394 - acc: 0.7362 - val_loss: 0.6984 - val_acc: 0.7574\n",
      "Epoch 303/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7341 - acc: 0.7381 - val_loss: 0.6993 - val_acc: 0.7574\n",
      "Epoch 304/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7410 - acc: 0.7444 - val_loss: 0.7004 - val_acc: 0.7574\n",
      "Epoch 305/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7217 - acc: 0.7515 - val_loss: 0.6997 - val_acc: 0.7582\n",
      "Epoch 306/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7471 - acc: 0.7362 - val_loss: 0.7005 - val_acc: 0.7574\n",
      "Epoch 307/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7459 - acc: 0.7407 - val_loss: 0.6978 - val_acc: 0.7574\n",
      "Epoch 308/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7313 - acc: 0.7370 - val_loss: 0.7008 - val_acc: 0.7574\n",
      "Epoch 309/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7386 - acc: 0.7448 - val_loss: 0.6993 - val_acc: 0.7582\n",
      "Epoch 310/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7396 - acc: 0.7403 - val_loss: 0.7010 - val_acc: 0.7574\n",
      "Epoch 311/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.7374 - acc: 0.7414 - val_loss: 0.7007 - val_acc: 0.7567\n",
      "Epoch 312/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7381 - acc: 0.7429 - val_loss: 0.7005 - val_acc: 0.7567\n",
      "Epoch 313/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7427 - acc: 0.7370 - val_loss: 0.6990 - val_acc: 0.7574\n",
      "Epoch 314/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7357 - acc: 0.7392 - val_loss: 0.7018 - val_acc: 0.7567\n",
      "Epoch 315/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7261 - acc: 0.7507 - val_loss: 0.7017 - val_acc: 0.7567\n",
      "Epoch 316/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7644 - acc: 0.7362 - val_loss: 0.7012 - val_acc: 0.7567\n",
      "Epoch 317/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7342 - acc: 0.7314 - val_loss: 0.7005 - val_acc: 0.7567\n",
      "Epoch 318/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7367 - acc: 0.7381 - val_loss: 0.7003 - val_acc: 0.7574\n",
      "Epoch 319/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7544 - acc: 0.7403 - val_loss: 0.7004 - val_acc: 0.7574\n",
      "Epoch 320/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7395 - acc: 0.7463 - val_loss: 0.6975 - val_acc: 0.7589\n",
      "Epoch 321/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7355 - acc: 0.7433 - val_loss: 0.7003 - val_acc: 0.7567\n",
      "Epoch 322/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7543 - acc: 0.7333 - val_loss: 0.6993 - val_acc: 0.7582\n",
      "Epoch 323/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7456 - acc: 0.7295 - val_loss: 0.7009 - val_acc: 0.7574\n",
      "Epoch 324/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7274 - acc: 0.7504 - val_loss: 0.7007 - val_acc: 0.7574\n",
      "Epoch 325/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7410 - acc: 0.7340 - val_loss: 0.6977 - val_acc: 0.7574\n",
      "Epoch 326/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7294 - acc: 0.7455 - val_loss: 0.7005 - val_acc: 0.7574\n",
      "Epoch 327/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7432 - acc: 0.7407 - val_loss: 0.7010 - val_acc: 0.7567\n",
      "Epoch 328/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7542 - acc: 0.7355 - val_loss: 0.6959 - val_acc: 0.7574\n",
      "Epoch 329/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7291 - acc: 0.7504 - val_loss: 0.6997 - val_acc: 0.7574\n",
      "Epoch 330/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7222 - acc: 0.7511 - val_loss: 0.6994 - val_acc: 0.7574\n",
      "Epoch 331/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7319 - acc: 0.7448 - val_loss: 0.6999 - val_acc: 0.7574\n",
      "Epoch 332/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7429 - acc: 0.7452 - val_loss: 0.7008 - val_acc: 0.7574\n",
      "Epoch 333/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7365 - acc: 0.7347 - val_loss: 0.7002 - val_acc: 0.7582\n",
      "Epoch 334/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7372 - acc: 0.7452 - val_loss: 0.6982 - val_acc: 0.7582\n",
      "Epoch 335/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7350 - acc: 0.7321 - val_loss: 0.7017 - val_acc: 0.7567\n",
      "Epoch 336/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7474 - acc: 0.7418 - val_loss: 0.7006 - val_acc: 0.7574\n",
      "Epoch 337/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7367 - acc: 0.7444 - val_loss: 0.6988 - val_acc: 0.7574\n",
      "Epoch 338/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7349 - acc: 0.7448 - val_loss: 0.6989 - val_acc: 0.7574\n",
      "Epoch 339/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7299 - acc: 0.7459 - val_loss: 0.7003 - val_acc: 0.7567\n",
      "Epoch 340/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7398 - acc: 0.7411 - val_loss: 0.6970 - val_acc: 0.7582\n",
      "Epoch 341/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7414 - acc: 0.7444 - val_loss: 0.6994 - val_acc: 0.7582\n",
      "Epoch 342/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7364 - acc: 0.7481 - val_loss: 0.7000 - val_acc: 0.7574\n",
      "Epoch 343/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.7350 - acc: 0.7381 - val_loss: 0.6982 - val_acc: 0.7589\n",
      "Epoch 344/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7414 - acc: 0.7407 - val_loss: 0.6947 - val_acc: 0.7589\n",
      "Epoch 345/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7269 - acc: 0.7455 - val_loss: 0.7003 - val_acc: 0.7574\n",
      "Epoch 346/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7463 - acc: 0.7351 - val_loss: 0.7011 - val_acc: 0.7574\n",
      "Epoch 347/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7416 - acc: 0.7422 - val_loss: 0.6989 - val_acc: 0.7582\n",
      "Epoch 348/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7309 - acc: 0.7444 - val_loss: 0.7013 - val_acc: 0.7574\n",
      "Epoch 349/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7363 - acc: 0.7470 - val_loss: 0.7010 - val_acc: 0.7567\n",
      "Epoch 350/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7341 - acc: 0.7318 - val_loss: 0.7001 - val_acc: 0.7574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 351/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7491 - acc: 0.7336 - val_loss: 0.6997 - val_acc: 0.7574\n",
      "Epoch 352/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7420 - acc: 0.7381 - val_loss: 0.7015 - val_acc: 0.7567\n",
      "Epoch 353/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7340 - acc: 0.7437 - val_loss: 0.7013 - val_acc: 0.7567\n",
      "Epoch 354/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7375 - acc: 0.7400 - val_loss: 0.7007 - val_acc: 0.7567\n",
      "Epoch 355/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7234 - acc: 0.7444 - val_loss: 0.7016 - val_acc: 0.7567\n",
      "Epoch 356/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7553 - acc: 0.7355 - val_loss: 0.7004 - val_acc: 0.7582\n",
      "Epoch 357/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7490 - acc: 0.7481 - val_loss: 0.7017 - val_acc: 0.7567\n",
      "Epoch 358/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7307 - acc: 0.7437 - val_loss: 0.6975 - val_acc: 0.7582\n",
      "Epoch 359/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7325 - acc: 0.7433 - val_loss: 0.7007 - val_acc: 0.7574\n",
      "Epoch 360/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7598 - acc: 0.7422 - val_loss: 0.7012 - val_acc: 0.7567\n",
      "Epoch 361/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7362 - acc: 0.7452 - val_loss: 0.6989 - val_acc: 0.7582\n",
      "Epoch 362/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7290 - acc: 0.7478 - val_loss: 0.7006 - val_acc: 0.7574\n",
      "Epoch 363/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7400 - acc: 0.7366 - val_loss: 0.7005 - val_acc: 0.7567\n",
      "Epoch 364/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7311 - acc: 0.7489 - val_loss: 0.7006 - val_acc: 0.7574\n",
      "Epoch 365/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7468 - acc: 0.7407 - val_loss: 0.7014 - val_acc: 0.7567\n",
      "\n",
      "Epoch 00365: loss improved from inf to 0.74675, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-1-000365-0.746754-0.756696.hdf5\n",
      "Epoch 366/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7381 - acc: 0.7377 - val_loss: 0.7014 - val_acc: 0.7567\n",
      "Epoch 367/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7362 - acc: 0.7459 - val_loss: 0.6994 - val_acc: 0.7582\n",
      "Epoch 368/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7568 - acc: 0.7403 - val_loss: 0.7012 - val_acc: 0.7567\n",
      "Epoch 369/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7485 - acc: 0.7344 - val_loss: 0.7006 - val_acc: 0.7574\n",
      "Epoch 370/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7411 - acc: 0.7374 - val_loss: 0.6975 - val_acc: 0.7582\n",
      "Epoch 371/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7463 - acc: 0.7362 - val_loss: 0.7015 - val_acc: 0.7567\n",
      "Epoch 372/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7509 - acc: 0.7400 - val_loss: 0.7000 - val_acc: 0.7574\n",
      "Epoch 373/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7406 - acc: 0.7392 - val_loss: 0.6989 - val_acc: 0.7589\n",
      "\n",
      "Epoch 00373: loss improved from 0.74675 to 0.74056, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-1-000373-0.740561-0.758929.hdf5\n",
      "Epoch 374/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7425 - acc: 0.7440 - val_loss: 0.7007 - val_acc: 0.7574\n",
      "Epoch 375/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7282 - acc: 0.7485 - val_loss: 0.6997 - val_acc: 0.7574\n",
      "Epoch 376/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7492 - acc: 0.7374 - val_loss: 0.7016 - val_acc: 0.7567\n",
      "Epoch 377/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7318 - acc: 0.7422 - val_loss: 0.6998 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00377: loss improved from 0.74056 to 0.73176, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-1-000377-0.731760-0.757440.hdf5\n",
      "Epoch 378/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7363 - acc: 0.7388 - val_loss: 0.6999 - val_acc: 0.7574\n",
      "Epoch 379/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7466 - acc: 0.7411 - val_loss: 0.6983 - val_acc: 0.7574\n",
      "Epoch 380/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7308 - acc: 0.7440 - val_loss: 0.6974 - val_acc: 0.7582\n",
      "Epoch 381/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7417 - acc: 0.7414 - val_loss: 0.7011 - val_acc: 0.7567\n",
      "Epoch 382/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7539 - acc: 0.7400 - val_loss: 0.6988 - val_acc: 0.7574\n",
      "Epoch 383/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.7406 - acc: 0.7403 - val_loss: 0.6984 - val_acc: 0.7574\n",
      "Epoch 384/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7306 - acc: 0.7426 - val_loss: 0.6995 - val_acc: 0.7582\n",
      "Epoch 385/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7518 - acc: 0.7336 - val_loss: 0.7018 - val_acc: 0.7567\n",
      "Epoch 386/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7394 - acc: 0.7422 - val_loss: 0.7003 - val_acc: 0.7574\n",
      "Epoch 387/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.7304 - acc: 0.7455 - val_loss: 0.7002 - val_acc: 0.7574\n",
      "Epoch 388/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7510 - acc: 0.7437 - val_loss: 0.7000 - val_acc: 0.7574\n",
      "Epoch 389/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7416 - acc: 0.7437 - val_loss: 0.7013 - val_acc: 0.7574\n",
      "Epoch 390/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7380 - acc: 0.7411 - val_loss: 0.7001 - val_acc: 0.7574\n",
      "Epoch 391/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7283 - acc: 0.7459 - val_loss: 0.7005 - val_acc: 0.7574\n",
      "Epoch 392/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7420 - acc: 0.7455 - val_loss: 0.6996 - val_acc: 0.7574\n",
      "Epoch 393/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7422 - acc: 0.7385 - val_loss: 0.6971 - val_acc: 0.7582\n",
      "Epoch 394/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7350 - acc: 0.7407 - val_loss: 0.6991 - val_acc: 0.7582\n",
      "Epoch 395/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7383 - acc: 0.7455 - val_loss: 0.6994 - val_acc: 0.7574\n",
      "Epoch 396/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7487 - acc: 0.7336 - val_loss: 0.6983 - val_acc: 0.7574\n",
      "Epoch 397/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7388 - acc: 0.7452 - val_loss: 0.6981 - val_acc: 0.7574\n",
      "Epoch 398/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7337 - acc: 0.7396 - val_loss: 0.6951 - val_acc: 0.7589\n",
      "Epoch 399/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7510 - acc: 0.7362 - val_loss: 0.7008 - val_acc: 0.7567\n",
      "Epoch 400/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.7605 - acc: 0.7347 - val_loss: 0.6993 - val_acc: 0.7582\n",
      "\n",
      "Epoch 00400: saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/1-000400-0.760549-0.758185.hdf5\n",
      "Epoch 401/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7456 - acc: 0.7455 - val_loss: 0.6983 - val_acc: 0.7574\n",
      "Epoch 402/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7276 - acc: 0.7414 - val_loss: 0.7013 - val_acc: 0.7567\n",
      "Epoch 403/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7308 - acc: 0.7433 - val_loss: 0.6961 - val_acc: 0.7589\n",
      "Epoch 404/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7460 - acc: 0.7452 - val_loss: 0.6989 - val_acc: 0.7582\n",
      "Epoch 405/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.7294 - acc: 0.7463 - val_loss: 0.6997 - val_acc: 0.7567\n",
      "Epoch 406/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7294 - acc: 0.7459 - val_loss: 0.6991 - val_acc: 0.7582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7348 - acc: 0.7444 - val_loss: 0.7001 - val_acc: 0.7574\n",
      "Epoch 408/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7400 - acc: 0.7429 - val_loss: 0.7018 - val_acc: 0.7567\n",
      "Epoch 409/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.7424 - acc: 0.7318 - val_loss: 0.7008 - val_acc: 0.7574\n",
      "Epoch 410/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7343 - acc: 0.7411 - val_loss: 0.6997 - val_acc: 0.7582\n",
      "Epoch 411/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7550 - acc: 0.7325 - val_loss: 0.6996 - val_acc: 0.7574\n",
      "Epoch 412/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7307 - acc: 0.7407 - val_loss: 0.7011 - val_acc: 0.7574\n",
      "Epoch 413/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7390 - acc: 0.7455 - val_loss: 0.7009 - val_acc: 0.7574\n",
      "Epoch 414/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7500 - acc: 0.7325 - val_loss: 0.6971 - val_acc: 0.7589\n",
      "Epoch 415/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7390 - acc: 0.7344 - val_loss: 0.7014 - val_acc: 0.7567\n",
      "Epoch 416/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7313 - acc: 0.7433 - val_loss: 0.7005 - val_acc: 0.7574\n",
      "Epoch 417/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7308 - acc: 0.7455 - val_loss: 0.7004 - val_acc: 0.7567\n",
      "Epoch 418/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7451 - acc: 0.7374 - val_loss: 0.6973 - val_acc: 0.7574\n",
      "Epoch 419/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7362 - acc: 0.7392 - val_loss: 0.6994 - val_acc: 0.7574\n",
      "Epoch 420/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7431 - acc: 0.7411 - val_loss: 0.6997 - val_acc: 0.7574\n",
      "Epoch 421/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7376 - acc: 0.7355 - val_loss: 0.7014 - val_acc: 0.7567\n",
      "Epoch 422/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7352 - acc: 0.7455 - val_loss: 0.6977 - val_acc: 0.7582\n",
      "Epoch 423/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7430 - acc: 0.7400 - val_loss: 0.6988 - val_acc: 0.7582\n",
      "Epoch 424/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7343 - acc: 0.7374 - val_loss: 0.7017 - val_acc: 0.7567\n",
      "Epoch 425/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7465 - acc: 0.7455 - val_loss: 0.7009 - val_acc: 0.7567\n",
      "Epoch 426/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7434 - acc: 0.7403 - val_loss: 0.7013 - val_acc: 0.7567\n",
      "Epoch 427/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7401 - acc: 0.7377 - val_loss: 0.7003 - val_acc: 0.7574\n",
      "Epoch 428/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7263 - acc: 0.7493 - val_loss: 0.6989 - val_acc: 0.7589\n",
      "Epoch 429/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7297 - acc: 0.7414 - val_loss: 0.6977 - val_acc: 0.7582\n",
      "Epoch 430/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7469 - acc: 0.7388 - val_loss: 0.7017 - val_acc: 0.7567\n",
      "Epoch 431/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7370 - acc: 0.7474 - val_loss: 0.6986 - val_acc: 0.7582\n",
      "Epoch 432/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7465 - acc: 0.7467 - val_loss: 0.7012 - val_acc: 0.7567\n",
      "Epoch 433/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7336 - acc: 0.7429 - val_loss: 0.7001 - val_acc: 0.7574\n",
      "Epoch 434/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7403 - acc: 0.7433 - val_loss: 0.6984 - val_acc: 0.7574\n",
      "Epoch 435/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7280 - acc: 0.7463 - val_loss: 0.7002 - val_acc: 0.7574\n",
      "Epoch 436/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7401 - acc: 0.7429 - val_loss: 0.6989 - val_acc: 0.7574\n",
      "Epoch 437/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7454 - acc: 0.7414 - val_loss: 0.6999 - val_acc: 0.7574\n",
      "Epoch 438/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7428 - acc: 0.7359 - val_loss: 0.6979 - val_acc: 0.7574\n",
      "Epoch 439/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7399 - acc: 0.7422 - val_loss: 0.7002 - val_acc: 0.7574\n",
      "Epoch 440/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7489 - acc: 0.7351 - val_loss: 0.7000 - val_acc: 0.7574\n",
      "Epoch 441/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7318 - acc: 0.7422 - val_loss: 0.6982 - val_acc: 0.7574\n",
      "Epoch 442/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7474 - acc: 0.7388 - val_loss: 0.6999 - val_acc: 0.7574\n",
      "Epoch 443/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7196 - acc: 0.7526 - val_loss: 0.7000 - val_acc: 0.7582\n",
      "Epoch 444/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7403 - acc: 0.7418 - val_loss: 0.6996 - val_acc: 0.7574\n",
      "Epoch 445/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7444 - acc: 0.7370 - val_loss: 0.7001 - val_acc: 0.7574\n",
      "Epoch 446/1000\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.7363 - acc: 0.7418 - val_loss: 0.7005 - val_acc: 0.7574\n",
      "Epoch 447/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7364 - acc: 0.7385 - val_loss: 0.7010 - val_acc: 0.7567\n",
      "Epoch 448/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7356 - acc: 0.7403 - val_loss: 0.7003 - val_acc: 0.7574\n",
      "Epoch 449/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7255 - acc: 0.7500 - val_loss: 0.6997 - val_acc: 0.7574\n",
      "Epoch 450/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7450 - acc: 0.7448 - val_loss: 0.7000 - val_acc: 0.7574\n",
      "Epoch 451/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7470 - acc: 0.7407 - val_loss: 0.6967 - val_acc: 0.7582\n",
      "Epoch 452/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7374 - acc: 0.7522 - val_loss: 0.7001 - val_acc: 0.7589\n",
      "Epoch 453/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7385 - acc: 0.7455 - val_loss: 0.7013 - val_acc: 0.7574\n",
      "Epoch 454/1000\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.7430 - acc: 0.7418 - val_loss: 0.7011 - val_acc: 0.7567\n",
      "Epoch 455/1000\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.7238 - acc: 0.7433 - val_loss: 0.7016 - val_acc: 0.7567\n",
      "Epoch 456/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7361 - acc: 0.7433 - val_loss: 0.6993 - val_acc: 0.7574\n",
      "Epoch 457/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7450 - acc: 0.7362 - val_loss: 0.6974 - val_acc: 0.7582\n",
      "Epoch 458/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7534 - acc: 0.7422 - val_loss: 0.7007 - val_acc: 0.7567\n",
      "Epoch 459/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7425 - acc: 0.7411 - val_loss: 0.7014 - val_acc: 0.7567\n",
      "Epoch 460/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7396 - acc: 0.7392 - val_loss: 0.7015 - val_acc: 0.7567\n",
      "Epoch 461/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7409 - acc: 0.7407 - val_loss: 0.6978 - val_acc: 0.7597\n",
      "Epoch 462/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7602 - acc: 0.7400 - val_loss: 0.7002 - val_acc: 0.7582\n",
      "Epoch 463/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7431 - acc: 0.7407 - val_loss: 0.6997 - val_acc: 0.7582\n",
      "Epoch 464/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7423 - acc: 0.7429 - val_loss: 0.6996 - val_acc: 0.7574\n",
      "Epoch 465/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7435 - acc: 0.7370 - val_loss: 0.6999 - val_acc: 0.7582\n",
      "\n",
      "Epoch 00465: loss improved from inf to 0.74350, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-1-000465-0.743495-0.758185.hdf5\n",
      "Epoch 466/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7315 - acc: 0.7429 - val_loss: 0.7002 - val_acc: 0.7582\n",
      "Epoch 467/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7331 - acc: 0.7459 - val_loss: 0.7011 - val_acc: 0.7574\n",
      "Epoch 468/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7396 - acc: 0.7418 - val_loss: 0.7001 - val_acc: 0.7582\n",
      "Epoch 469/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7321 - acc: 0.7437 - val_loss: 0.7010 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00469: loss improved from 0.74350 to 0.73209, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-1-000469-0.732094-0.757440.hdf5\n",
      "Epoch 470/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7359 - acc: 0.7433 - val_loss: 0.6974 - val_acc: 0.7589\n",
      "Epoch 471/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7436 - acc: 0.7381 - val_loss: 0.7000 - val_acc: 0.7582\n",
      "Epoch 472/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7416 - acc: 0.7433 - val_loss: 0.6997 - val_acc: 0.7582\n",
      "Epoch 473/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7379 - acc: 0.7448 - val_loss: 0.7007 - val_acc: 0.7574\n",
      "Epoch 474/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7351 - acc: 0.7507 - val_loss: 0.7001 - val_acc: 0.7582\n",
      "Epoch 475/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7337 - acc: 0.7429 - val_loss: 0.6986 - val_acc: 0.7589\n",
      "Epoch 476/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7432 - acc: 0.7459 - val_loss: 0.7001 - val_acc: 0.7582\n",
      "Epoch 477/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7472 - acc: 0.7411 - val_loss: 0.7013 - val_acc: 0.7574\n",
      "Epoch 478/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7367 - acc: 0.7515 - val_loss: 0.7005 - val_acc: 0.7582\n",
      "Epoch 479/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7420 - acc: 0.7370 - val_loss: 0.6995 - val_acc: 0.7582\n",
      "Epoch 480/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7428 - acc: 0.7478 - val_loss: 0.7005 - val_acc: 0.7574\n",
      "Epoch 481/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7507 - acc: 0.7374 - val_loss: 0.6958 - val_acc: 0.7582\n",
      "Epoch 482/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7282 - acc: 0.7448 - val_loss: 0.7006 - val_acc: 0.7582\n",
      "Epoch 483/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7421 - acc: 0.7407 - val_loss: 0.7019 - val_acc: 0.7574\n",
      "Epoch 484/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7474 - acc: 0.7418 - val_loss: 0.6960 - val_acc: 0.7589\n",
      "Epoch 485/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7316 - acc: 0.7433 - val_loss: 0.7014 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00485: loss improved from 0.73209 to 0.73163, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-1-000485-0.731629-0.757440.hdf5\n",
      "Epoch 486/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7447 - acc: 0.7374 - val_loss: 0.7017 - val_acc: 0.7574\n",
      "Epoch 487/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7384 - acc: 0.7414 - val_loss: 0.6987 - val_acc: 0.7582\n",
      "Epoch 488/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7419 - acc: 0.7381 - val_loss: 0.6982 - val_acc: 0.7589\n",
      "Epoch 489/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7366 - acc: 0.7422 - val_loss: 0.7015 - val_acc: 0.7574\n",
      "Epoch 490/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7389 - acc: 0.7403 - val_loss: 0.6983 - val_acc: 0.7582\n",
      "Epoch 491/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7463 - acc: 0.7381 - val_loss: 0.7013 - val_acc: 0.7574\n",
      "Epoch 492/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7367 - acc: 0.7411 - val_loss: 0.7004 - val_acc: 0.7582\n",
      "Epoch 493/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7278 - acc: 0.7459 - val_loss: 0.7008 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00493: loss improved from 0.73163 to 0.72784, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-1-000493-0.727839-0.757440.hdf5\n",
      "Epoch 494/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7327 - acc: 0.7467 - val_loss: 0.6967 - val_acc: 0.7589\n",
      "Epoch 495/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7446 - acc: 0.7437 - val_loss: 0.7015 - val_acc: 0.7574\n",
      "Epoch 496/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7330 - acc: 0.7448 - val_loss: 0.6999 - val_acc: 0.7582\n",
      "Epoch 497/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7336 - acc: 0.7344 - val_loss: 0.7011 - val_acc: 0.7574\n",
      "Epoch 498/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7439 - acc: 0.7411 - val_loss: 0.7000 - val_acc: 0.7582\n",
      "Epoch 499/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7411 - acc: 0.7392 - val_loss: 0.7010 - val_acc: 0.7574\n",
      "Epoch 500/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7416 - acc: 0.7344 - val_loss: 0.7011 - val_acc: 0.7582\n",
      "\n",
      "Epoch 00500: saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/1-000500-0.741640-0.758185.hdf5\n",
      "Epoch 501/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7453 - acc: 0.7440 - val_loss: 0.6978 - val_acc: 0.7589\n",
      "Epoch 502/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7441 - acc: 0.7377 - val_loss: 0.7015 - val_acc: 0.7574\n",
      "Epoch 503/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7396 - acc: 0.7366 - val_loss: 0.6982 - val_acc: 0.7589\n",
      "Epoch 504/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7334 - acc: 0.7467 - val_loss: 0.7008 - val_acc: 0.7582\n",
      "Epoch 505/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7466 - acc: 0.7381 - val_loss: 0.7010 - val_acc: 0.7574\n",
      "Epoch 506/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7467 - acc: 0.7377 - val_loss: 0.6985 - val_acc: 0.7589\n",
      "Epoch 507/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7444 - acc: 0.7295 - val_loss: 0.7014 - val_acc: 0.7574\n",
      "Epoch 508/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7341 - acc: 0.7426 - val_loss: 0.7000 - val_acc: 0.7582\n",
      "Epoch 509/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7405 - acc: 0.7392 - val_loss: 0.6994 - val_acc: 0.7589\n",
      "Epoch 510/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7415 - acc: 0.7344 - val_loss: 0.7006 - val_acc: 0.7582\n",
      "Epoch 511/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7482 - acc: 0.7336 - val_loss: 0.6925 - val_acc: 0.7589\n",
      "Epoch 512/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7284 - acc: 0.7452 - val_loss: 0.7005 - val_acc: 0.7574\n",
      "Epoch 513/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7539 - acc: 0.7396 - val_loss: 0.7011 - val_acc: 0.7574\n",
      "Epoch 514/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7515 - acc: 0.7359 - val_loss: 0.6993 - val_acc: 0.7589\n",
      "Epoch 515/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7389 - acc: 0.7504 - val_loss: 0.7010 - val_acc: 0.7574\n",
      "Epoch 516/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7396 - acc: 0.7444 - val_loss: 0.7012 - val_acc: 0.7574\n",
      "Epoch 517/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7338 - acc: 0.7426 - val_loss: 0.6968 - val_acc: 0.7589\n",
      "Epoch 518/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7267 - acc: 0.7515 - val_loss: 0.7007 - val_acc: 0.7582\n",
      "Epoch 519/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.7500 - acc: 0.7366 - val_loss: 0.7007 - val_acc: 0.7582\n",
      "Epoch 520/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.7318 - acc: 0.7455 - val_loss: 0.6994 - val_acc: 0.7589\n",
      "Epoch 521/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7290 - acc: 0.7481 - val_loss: 0.6993 - val_acc: 0.7582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 522/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7336 - acc: 0.7481 - val_loss: 0.7008 - val_acc: 0.7574\n",
      "Epoch 523/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7492 - acc: 0.7388 - val_loss: 0.7002 - val_acc: 0.7574\n",
      "Epoch 524/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7348 - acc: 0.7444 - val_loss: 0.7006 - val_acc: 0.7582\n",
      "Epoch 525/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7415 - acc: 0.7321 - val_loss: 0.6935 - val_acc: 0.7604\n",
      "Epoch 526/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7403 - acc: 0.7474 - val_loss: 0.6970 - val_acc: 0.7589\n",
      "Epoch 527/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7286 - acc: 0.7448 - val_loss: 0.7010 - val_acc: 0.7574\n",
      "Epoch 528/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7285 - acc: 0.7433 - val_loss: 0.6999 - val_acc: 0.7582\n",
      "Epoch 529/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7208 - acc: 0.7500 - val_loss: 0.6997 - val_acc: 0.7582\n",
      "Epoch 530/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7415 - acc: 0.7388 - val_loss: 0.7004 - val_acc: 0.7574\n",
      "Epoch 531/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7394 - acc: 0.7414 - val_loss: 0.7008 - val_acc: 0.7582\n",
      "Epoch 532/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7186 - acc: 0.7403 - val_loss: 0.6980 - val_acc: 0.7582\n",
      "Epoch 533/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7471 - acc: 0.7396 - val_loss: 0.7004 - val_acc: 0.7582\n",
      "Epoch 534/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7344 - acc: 0.7489 - val_loss: 0.7014 - val_acc: 0.7574\n",
      "Epoch 535/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7428 - acc: 0.7452 - val_loss: 0.7016 - val_acc: 0.7574\n",
      "Epoch 536/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7404 - acc: 0.7388 - val_loss: 0.6999 - val_acc: 0.7582\n",
      "Epoch 537/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7282 - acc: 0.7426 - val_loss: 0.7014 - val_acc: 0.7574\n",
      "Epoch 538/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7376 - acc: 0.7463 - val_loss: 0.6979 - val_acc: 0.7589\n",
      "Epoch 539/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7358 - acc: 0.7422 - val_loss: 0.7016 - val_acc: 0.7574\n",
      "Epoch 540/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7340 - acc: 0.7481 - val_loss: 0.6999 - val_acc: 0.7582\n",
      "Epoch 541/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7524 - acc: 0.7396 - val_loss: 0.6974 - val_acc: 0.7589\n",
      "Epoch 542/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7426 - acc: 0.7467 - val_loss: 0.7002 - val_acc: 0.7574\n",
      "Epoch 543/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7492 - acc: 0.7366 - val_loss: 0.6992 - val_acc: 0.7589\n",
      "Epoch 544/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7503 - acc: 0.7414 - val_loss: 0.7003 - val_acc: 0.7582\n",
      "Epoch 545/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7462 - acc: 0.7359 - val_loss: 0.6955 - val_acc: 0.7589\n",
      "Epoch 546/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7397 - acc: 0.7392 - val_loss: 0.7010 - val_acc: 0.7574\n",
      "Epoch 547/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7404 - acc: 0.7452 - val_loss: 0.7014 - val_acc: 0.7574\n",
      "Epoch 548/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7377 - acc: 0.7418 - val_loss: 0.7000 - val_acc: 0.7574\n",
      "Epoch 549/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7260 - acc: 0.7414 - val_loss: 0.7016 - val_acc: 0.7574\n",
      "Epoch 550/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7470 - acc: 0.7344 - val_loss: 0.7002 - val_acc: 0.7582\n",
      "Epoch 551/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7243 - acc: 0.7444 - val_loss: 0.7000 - val_acc: 0.7589\n",
      "Epoch 552/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.7468 - acc: 0.7351 - val_loss: 0.6983 - val_acc: 0.7589\n",
      "Epoch 553/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7341 - acc: 0.7426 - val_loss: 0.7012 - val_acc: 0.7574\n",
      "Epoch 554/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7411 - acc: 0.7377 - val_loss: 0.6985 - val_acc: 0.7589\n",
      "Epoch 555/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7340 - acc: 0.7493 - val_loss: 0.7006 - val_acc: 0.7589\n",
      "Epoch 556/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.7395 - acc: 0.7474 - val_loss: 0.6995 - val_acc: 0.7597\n",
      "Epoch 557/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7378 - acc: 0.7481 - val_loss: 0.6993 - val_acc: 0.7589\n",
      "Epoch 558/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7211 - acc: 0.7411 - val_loss: 0.6982 - val_acc: 0.7597\n",
      "Epoch 559/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7490 - acc: 0.7359 - val_loss: 0.7012 - val_acc: 0.7582\n",
      "Epoch 560/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7412 - acc: 0.7396 - val_loss: 0.7009 - val_acc: 0.7582\n",
      "Epoch 561/1000\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.7346 - acc: 0.7470 - val_loss: 0.7010 - val_acc: 0.7582\n",
      "Epoch 562/1000\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.7464 - acc: 0.7336 - val_loss: 0.6999 - val_acc: 0.7589\n",
      "Epoch 563/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7371 - acc: 0.7444 - val_loss: 0.6979 - val_acc: 0.7597\n",
      "Epoch 564/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7430 - acc: 0.7362 - val_loss: 0.6955 - val_acc: 0.7604\n",
      "Epoch 565/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7314 - acc: 0.7414 - val_loss: 0.6967 - val_acc: 0.7604\n",
      "\n",
      "Epoch 00565: loss improved from inf to 0.73135, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-1-000565-0.731353-0.760417.hdf5\n",
      "Epoch 566/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7174 - acc: 0.7530 - val_loss: 0.6995 - val_acc: 0.7589\n",
      "Epoch 567/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7492 - acc: 0.7262 - val_loss: 0.6988 - val_acc: 0.7589\n",
      "Epoch 568/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7259 - acc: 0.7470 - val_loss: 0.6937 - val_acc: 0.7604\n",
      "Epoch 569/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7460 - acc: 0.7452 - val_loss: 0.6977 - val_acc: 0.7604\n",
      "Epoch 570/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7379 - acc: 0.7400 - val_loss: 0.7004 - val_acc: 0.7589\n",
      "Epoch 571/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7326 - acc: 0.7381 - val_loss: 0.7004 - val_acc: 0.7589\n",
      "Epoch 572/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7329 - acc: 0.7552 - val_loss: 0.7005 - val_acc: 0.7589\n",
      "Epoch 573/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7404 - acc: 0.7422 - val_loss: 0.6966 - val_acc: 0.7597\n",
      "Epoch 574/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7375 - acc: 0.7444 - val_loss: 0.7004 - val_acc: 0.7589\n",
      "Epoch 575/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7465 - acc: 0.7411 - val_loss: 0.6991 - val_acc: 0.7597\n",
      "Epoch 576/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.7585 - acc: 0.7351 - val_loss: 0.6986 - val_acc: 0.7589\n",
      "Epoch 577/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7402 - acc: 0.7437 - val_loss: 0.7014 - val_acc: 0.7582\n",
      "Epoch 578/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7346 - acc: 0.7463 - val_loss: 0.6983 - val_acc: 0.7589\n",
      "Epoch 579/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7442 - acc: 0.7333 - val_loss: 0.7004 - val_acc: 0.7589\n",
      "Epoch 580/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7470 - acc: 0.7381 - val_loss: 0.7012 - val_acc: 0.7582\n",
      "Epoch 581/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 23ms/step - loss: 0.7444 - acc: 0.7463 - val_loss: 0.7005 - val_acc: 0.7582\n",
      "Epoch 582/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7355 - acc: 0.7444 - val_loss: 0.6988 - val_acc: 0.7597\n",
      "Epoch 583/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7269 - acc: 0.7504 - val_loss: 0.7004 - val_acc: 0.7589\n",
      "Epoch 584/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7274 - acc: 0.7467 - val_loss: 0.7006 - val_acc: 0.7582\n",
      "Epoch 585/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7372 - acc: 0.7452 - val_loss: 0.7014 - val_acc: 0.7582\n",
      "Epoch 586/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7397 - acc: 0.7422 - val_loss: 0.7012 - val_acc: 0.7582\n",
      "Epoch 587/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7349 - acc: 0.7355 - val_loss: 0.6987 - val_acc: 0.7597\n",
      "Epoch 588/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7313 - acc: 0.7459 - val_loss: 0.6986 - val_acc: 0.7597\n",
      "Epoch 589/1000\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.7429 - acc: 0.7366 - val_loss: 0.6994 - val_acc: 0.7589\n",
      "Epoch 590/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7329 - acc: 0.7463 - val_loss: 0.6999 - val_acc: 0.7589\n",
      "Epoch 591/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7366 - acc: 0.7355 - val_loss: 0.6998 - val_acc: 0.7597\n",
      "Epoch 592/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7479 - acc: 0.7448 - val_loss: 0.6993 - val_acc: 0.7589\n",
      "Epoch 593/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7386 - acc: 0.7440 - val_loss: 0.6992 - val_acc: 0.7597\n",
      "Epoch 594/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7283 - acc: 0.7481 - val_loss: 0.6987 - val_acc: 0.7589\n",
      "Epoch 595/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7428 - acc: 0.7388 - val_loss: 0.7000 - val_acc: 0.7582\n",
      "Epoch 596/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7463 - acc: 0.7355 - val_loss: 0.7012 - val_acc: 0.7582\n",
      "Epoch 597/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7327 - acc: 0.7504 - val_loss: 0.6945 - val_acc: 0.7604\n",
      "Epoch 598/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7328 - acc: 0.7426 - val_loss: 0.6993 - val_acc: 0.7597\n",
      "Epoch 599/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7347 - acc: 0.7437 - val_loss: 0.7016 - val_acc: 0.7582\n",
      "Epoch 600/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7445 - acc: 0.7433 - val_loss: 0.7002 - val_acc: 0.7589\n",
      "\n",
      "Epoch 00600: saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/1-000600-0.744534-0.758929.hdf5\n",
      "Epoch 601/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7324 - acc: 0.7440 - val_loss: 0.7008 - val_acc: 0.7589\n",
      "Epoch 602/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.7313 - acc: 0.7493 - val_loss: 0.6987 - val_acc: 0.7597\n",
      "Epoch 603/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7302 - acc: 0.7437 - val_loss: 0.7007 - val_acc: 0.7582\n",
      "Epoch 604/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7309 - acc: 0.7455 - val_loss: 0.7005 - val_acc: 0.7589\n",
      "Epoch 605/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7375 - acc: 0.7385 - val_loss: 0.7008 - val_acc: 0.7582\n",
      "Epoch 606/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7423 - acc: 0.7422 - val_loss: 0.6993 - val_acc: 0.7589\n",
      "Epoch 607/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7324 - acc: 0.7496 - val_loss: 0.7010 - val_acc: 0.7582\n",
      "Epoch 608/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7454 - acc: 0.7426 - val_loss: 0.7013 - val_acc: 0.7582\n",
      "Epoch 609/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7270 - acc: 0.7522 - val_loss: 0.7007 - val_acc: 0.7582\n",
      "Epoch 610/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7382 - acc: 0.7452 - val_loss: 0.6993 - val_acc: 0.7597\n",
      "Epoch 611/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7231 - acc: 0.7507 - val_loss: 0.7011 - val_acc: 0.7582\n",
      "Epoch 612/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7382 - acc: 0.7381 - val_loss: 0.6994 - val_acc: 0.7589\n",
      "Epoch 613/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7362 - acc: 0.7437 - val_loss: 0.7013 - val_acc: 0.7582\n",
      "Epoch 614/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7454 - acc: 0.7377 - val_loss: 0.6962 - val_acc: 0.7597\n",
      "Epoch 615/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7432 - acc: 0.7374 - val_loss: 0.7008 - val_acc: 0.7582\n",
      "Epoch 616/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7331 - acc: 0.7377 - val_loss: 0.6997 - val_acc: 0.7589\n",
      "Epoch 617/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7540 - acc: 0.7407 - val_loss: 0.6999 - val_acc: 0.7589\n",
      "Epoch 618/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7282 - acc: 0.7500 - val_loss: 0.7005 - val_acc: 0.7589\n",
      "Epoch 619/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7335 - acc: 0.7452 - val_loss: 0.7000 - val_acc: 0.7589\n",
      "Epoch 620/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7314 - acc: 0.7489 - val_loss: 0.6975 - val_acc: 0.7589\n",
      "Epoch 621/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7398 - acc: 0.7418 - val_loss: 0.7013 - val_acc: 0.7582\n",
      "Epoch 622/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7281 - acc: 0.7444 - val_loss: 0.7013 - val_acc: 0.7582\n",
      "Epoch 623/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7420 - acc: 0.7541 - val_loss: 0.6996 - val_acc: 0.7597\n",
      "Epoch 624/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7434 - acc: 0.7400 - val_loss: 0.6973 - val_acc: 0.7589\n",
      "Epoch 625/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7418 - acc: 0.7362 - val_loss: 0.7006 - val_acc: 0.7589\n",
      "Epoch 626/1000\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.7285 - acc: 0.7381 - val_loss: 0.7006 - val_acc: 0.7582\n",
      "Epoch 627/1000\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.7343 - acc: 0.7429 - val_loss: 0.7006 - val_acc: 0.7589\n",
      "Epoch 628/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7391 - acc: 0.7344 - val_loss: 0.7006 - val_acc: 0.7589\n",
      "Epoch 629/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7331 - acc: 0.7537 - val_loss: 0.7001 - val_acc: 0.7589\n",
      "Epoch 630/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7292 - acc: 0.7481 - val_loss: 0.7010 - val_acc: 0.7582\n",
      "Epoch 631/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7462 - acc: 0.7385 - val_loss: 0.7007 - val_acc: 0.7582\n",
      "Epoch 632/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7534 - acc: 0.7325 - val_loss: 0.6952 - val_acc: 0.7604\n",
      "Epoch 633/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7436 - acc: 0.7437 - val_loss: 0.7006 - val_acc: 0.7589\n",
      "Epoch 634/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7397 - acc: 0.7370 - val_loss: 0.6999 - val_acc: 0.7589\n",
      "Epoch 635/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.7427 - acc: 0.7381 - val_loss: 0.6996 - val_acc: 0.7589\n",
      "Epoch 636/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7416 - acc: 0.7310 - val_loss: 0.6992 - val_acc: 0.7589\n",
      "Epoch 637/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7279 - acc: 0.7414 - val_loss: 0.7011 - val_acc: 0.7582\n",
      "Epoch 638/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7310 - acc: 0.7541 - val_loss: 0.7014 - val_acc: 0.7582\n",
      "Epoch 639/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7374 - acc: 0.7433 - val_loss: 0.7010 - val_acc: 0.7582\n",
      "Epoch 640/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7286 - acc: 0.7496 - val_loss: 0.7010 - val_acc: 0.7582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 641/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.7392 - acc: 0.7437 - val_loss: 0.7002 - val_acc: 0.7582\n",
      "Epoch 642/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7328 - acc: 0.7478 - val_loss: 0.7014 - val_acc: 0.7582\n",
      "Epoch 643/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7348 - acc: 0.7545 - val_loss: 0.6985 - val_acc: 0.7597\n",
      "Epoch 644/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7455 - acc: 0.7440 - val_loss: 0.7006 - val_acc: 0.7582\n",
      "Epoch 645/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7418 - acc: 0.7403 - val_loss: 0.6988 - val_acc: 0.7597\n",
      "Epoch 646/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7352 - acc: 0.7400 - val_loss: 0.6990 - val_acc: 0.7589\n",
      "Epoch 647/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7589 - acc: 0.7366 - val_loss: 0.7011 - val_acc: 0.7582\n",
      "Epoch 648/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.7409 - acc: 0.7444 - val_loss: 0.7016 - val_acc: 0.7582\n",
      "Epoch 649/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7380 - acc: 0.7392 - val_loss: 0.7006 - val_acc: 0.7589\n",
      "Epoch 650/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7307 - acc: 0.7392 - val_loss: 0.7011 - val_acc: 0.7582\n",
      "Epoch 651/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7297 - acc: 0.7496 - val_loss: 0.6998 - val_acc: 0.7582\n",
      "Epoch 652/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7476 - acc: 0.7377 - val_loss: 0.6966 - val_acc: 0.7597\n",
      "Epoch 653/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7328 - acc: 0.7400 - val_loss: 0.7003 - val_acc: 0.7589\n",
      "Epoch 654/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7313 - acc: 0.7347 - val_loss: 0.6989 - val_acc: 0.7589\n",
      "Epoch 655/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7552 - acc: 0.7381 - val_loss: 0.6996 - val_acc: 0.7589\n",
      "Epoch 656/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7477 - acc: 0.7381 - val_loss: 0.6999 - val_acc: 0.7589\n",
      "Epoch 657/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7390 - acc: 0.7426 - val_loss: 0.7002 - val_acc: 0.7589\n",
      "Epoch 658/1000\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.7338 - acc: 0.7470 - val_loss: 0.7001 - val_acc: 0.7589\n",
      "Epoch 659/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7457 - acc: 0.7448 - val_loss: 0.6994 - val_acc: 0.7589\n",
      "Epoch 660/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7194 - acc: 0.7474 - val_loss: 0.6940 - val_acc: 0.7604\n",
      "Epoch 661/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7333 - acc: 0.7467 - val_loss: 0.6974 - val_acc: 0.7589\n",
      "Epoch 662/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7426 - acc: 0.7422 - val_loss: 0.7007 - val_acc: 0.7589\n",
      "Epoch 663/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7335 - acc: 0.7440 - val_loss: 0.7005 - val_acc: 0.7589\n",
      "Epoch 664/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7269 - acc: 0.7474 - val_loss: 0.7009 - val_acc: 0.7582\n",
      "Epoch 665/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7338 - acc: 0.7385 - val_loss: 0.7006 - val_acc: 0.7582\n",
      "\n",
      "Epoch 00665: loss improved from inf to 0.73382, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-1-000665-0.733816-0.758185.hdf5\n",
      "Epoch 666/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7278 - acc: 0.7481 - val_loss: 0.6980 - val_acc: 0.7589\n",
      "Epoch 667/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7273 - acc: 0.7467 - val_loss: 0.7002 - val_acc: 0.7589\n",
      "Epoch 668/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7258 - acc: 0.7429 - val_loss: 0.6932 - val_acc: 0.7597\n",
      "Epoch 669/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7397 - acc: 0.7470 - val_loss: 0.6985 - val_acc: 0.7597\n",
      "Epoch 670/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7407 - acc: 0.7448 - val_loss: 0.6999 - val_acc: 0.7589\n",
      "Epoch 671/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7402 - acc: 0.7414 - val_loss: 0.7001 - val_acc: 0.7589\n",
      "Epoch 672/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7418 - acc: 0.7362 - val_loss: 0.6994 - val_acc: 0.7597\n",
      "Epoch 673/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7390 - acc: 0.7385 - val_loss: 0.6998 - val_acc: 0.7597\n",
      "Epoch 674/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7304 - acc: 0.7422 - val_loss: 0.6982 - val_acc: 0.7604\n",
      "Epoch 675/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7373 - acc: 0.7433 - val_loss: 0.7014 - val_acc: 0.7582\n",
      "Epoch 676/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7357 - acc: 0.7396 - val_loss: 0.6989 - val_acc: 0.7589\n",
      "Epoch 677/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7383 - acc: 0.7344 - val_loss: 0.7008 - val_acc: 0.7582\n",
      "Epoch 678/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7442 - acc: 0.7433 - val_loss: 0.7001 - val_acc: 0.7589\n",
      "Epoch 679/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7282 - acc: 0.7411 - val_loss: 0.6999 - val_acc: 0.7589\n",
      "Epoch 680/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7359 - acc: 0.7437 - val_loss: 0.6975 - val_acc: 0.7589\n",
      "Epoch 681/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7161 - acc: 0.7545 - val_loss: 0.7004 - val_acc: 0.7589\n",
      "\n",
      "Epoch 00681: loss improved from 0.73382 to 0.71612, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-1-000681-0.716117-0.758929.hdf5\n",
      "Epoch 682/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7567 - acc: 0.7433 - val_loss: 0.7012 - val_acc: 0.7582\n",
      "Epoch 683/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7398 - acc: 0.7437 - val_loss: 0.7000 - val_acc: 0.7589\n",
      "Epoch 684/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7338 - acc: 0.7437 - val_loss: 0.6957 - val_acc: 0.7604\n",
      "Epoch 685/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7459 - acc: 0.7381 - val_loss: 0.6966 - val_acc: 0.7597\n",
      "Epoch 686/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7398 - acc: 0.7362 - val_loss: 0.6987 - val_acc: 0.7597\n",
      "Epoch 687/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7341 - acc: 0.7355 - val_loss: 0.6962 - val_acc: 0.7589\n",
      "Epoch 688/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7316 - acc: 0.7493 - val_loss: 0.6990 - val_acc: 0.7589\n",
      "Epoch 689/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7366 - acc: 0.7333 - val_loss: 0.6983 - val_acc: 0.7597\n",
      "Epoch 690/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7345 - acc: 0.7496 - val_loss: 0.7012 - val_acc: 0.7582\n",
      "Epoch 691/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7367 - acc: 0.7385 - val_loss: 0.7014 - val_acc: 0.7582\n",
      "Epoch 692/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7430 - acc: 0.7411 - val_loss: 0.6986 - val_acc: 0.7589\n",
      "Epoch 693/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7448 - acc: 0.7452 - val_loss: 0.6991 - val_acc: 0.7604\n",
      "Epoch 694/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7265 - acc: 0.7455 - val_loss: 0.7015 - val_acc: 0.7582\n",
      "Epoch 695/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7401 - acc: 0.7467 - val_loss: 0.6964 - val_acc: 0.7597\n",
      "Epoch 696/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.7368 - acc: 0.7463 - val_loss: 0.6999 - val_acc: 0.7589\n",
      "Epoch 697/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7562 - acc: 0.7396 - val_loss: 0.7009 - val_acc: 0.7582\n",
      "Epoch 698/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7266 - acc: 0.7433 - val_loss: 0.6987 - val_acc: 0.7597\n",
      "Epoch 699/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7359 - acc: 0.7403 - val_loss: 0.6997 - val_acc: 0.7589\n",
      "Epoch 700/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7477 - acc: 0.7333 - val_loss: 0.6992 - val_acc: 0.7589\n",
      "\n",
      "Epoch 00700: saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/1-000700-0.747670-0.758929.hdf5\n",
      "Epoch 701/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7269 - acc: 0.7511 - val_loss: 0.6998 - val_acc: 0.7589\n",
      "Epoch 702/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7295 - acc: 0.7459 - val_loss: 0.6982 - val_acc: 0.7597\n",
      "Epoch 703/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7536 - acc: 0.7374 - val_loss: 0.6993 - val_acc: 0.7589\n",
      "Epoch 704/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7440 - acc: 0.7400 - val_loss: 0.7013 - val_acc: 0.7582\n",
      "Epoch 705/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7451 - acc: 0.7388 - val_loss: 0.7012 - val_acc: 0.7582\n",
      "Epoch 706/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7313 - acc: 0.7567 - val_loss: 0.7007 - val_acc: 0.7582\n",
      "Epoch 707/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7362 - acc: 0.7422 - val_loss: 0.6972 - val_acc: 0.7597\n",
      "Epoch 708/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7412 - acc: 0.7429 - val_loss: 0.6943 - val_acc: 0.7597\n",
      "Epoch 709/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7319 - acc: 0.7377 - val_loss: 0.6980 - val_acc: 0.7589\n",
      "Epoch 710/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7332 - acc: 0.7470 - val_loss: 0.7000 - val_acc: 0.7589\n",
      "Epoch 711/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7435 - acc: 0.7411 - val_loss: 0.7009 - val_acc: 0.7582\n",
      "Epoch 712/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7271 - acc: 0.7493 - val_loss: 0.6987 - val_acc: 0.7597\n",
      "Epoch 713/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7337 - acc: 0.7459 - val_loss: 0.7012 - val_acc: 0.7582\n",
      "Epoch 714/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7375 - acc: 0.7444 - val_loss: 0.6996 - val_acc: 0.7589\n",
      "Epoch 715/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7385 - acc: 0.7422 - val_loss: 0.7014 - val_acc: 0.7582\n",
      "Epoch 716/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7548 - acc: 0.7366 - val_loss: 0.7001 - val_acc: 0.7589\n",
      "Epoch 717/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7447 - acc: 0.7396 - val_loss: 0.7014 - val_acc: 0.7582\n",
      "Epoch 718/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7424 - acc: 0.7444 - val_loss: 0.6976 - val_acc: 0.7597\n",
      "Epoch 719/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7412 - acc: 0.7470 - val_loss: 0.6997 - val_acc: 0.7589\n",
      "Epoch 720/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7517 - acc: 0.7362 - val_loss: 0.6999 - val_acc: 0.7597\n",
      "Epoch 721/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7410 - acc: 0.7366 - val_loss: 0.7013 - val_acc: 0.7582\n",
      "Epoch 722/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7462 - acc: 0.7381 - val_loss: 0.6997 - val_acc: 0.7597\n",
      "Epoch 723/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7294 - acc: 0.7440 - val_loss: 0.6979 - val_acc: 0.7589\n",
      "Epoch 724/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7492 - acc: 0.7377 - val_loss: 0.7002 - val_acc: 0.7582\n",
      "Epoch 725/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7477 - acc: 0.7407 - val_loss: 0.6993 - val_acc: 0.7597\n",
      "Epoch 726/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7488 - acc: 0.7347 - val_loss: 0.6975 - val_acc: 0.7604\n",
      "Epoch 727/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7394 - acc: 0.7437 - val_loss: 0.7013 - val_acc: 0.7582\n",
      "Epoch 728/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7451 - acc: 0.7385 - val_loss: 0.6999 - val_acc: 0.7589\n",
      "Epoch 729/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7530 - acc: 0.7299 - val_loss: 0.7001 - val_acc: 0.7597\n",
      "Epoch 730/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7488 - acc: 0.7362 - val_loss: 0.6989 - val_acc: 0.7589\n",
      "Epoch 731/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7440 - acc: 0.7478 - val_loss: 0.7004 - val_acc: 0.7589\n",
      "Epoch 732/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7415 - acc: 0.7403 - val_loss: 0.7013 - val_acc: 0.7582\n",
      "Epoch 733/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7442 - acc: 0.7444 - val_loss: 0.7010 - val_acc: 0.7582\n",
      "Epoch 734/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7375 - acc: 0.7463 - val_loss: 0.7008 - val_acc: 0.7582\n",
      "Epoch 735/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7494 - acc: 0.7418 - val_loss: 0.7007 - val_acc: 0.7589\n",
      "Epoch 736/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7517 - acc: 0.7422 - val_loss: 0.7012 - val_acc: 0.7582\n",
      "Epoch 737/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7103 - acc: 0.7504 - val_loss: 0.7012 - val_acc: 0.7582\n",
      "Epoch 738/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7249 - acc: 0.7474 - val_loss: 0.7008 - val_acc: 0.7582\n",
      "Epoch 739/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7471 - acc: 0.7440 - val_loss: 0.7002 - val_acc: 0.7597\n",
      "Epoch 740/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7466 - acc: 0.7325 - val_loss: 0.6975 - val_acc: 0.7589\n",
      "Epoch 741/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7363 - acc: 0.7463 - val_loss: 0.7000 - val_acc: 0.7597\n",
      "Epoch 742/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7325 - acc: 0.7411 - val_loss: 0.7001 - val_acc: 0.7589\n",
      "Epoch 743/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7360 - acc: 0.7433 - val_loss: 0.7006 - val_acc: 0.7582\n",
      "Epoch 744/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7352 - acc: 0.7452 - val_loss: 0.7005 - val_acc: 0.7582\n",
      "Epoch 745/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7441 - acc: 0.7496 - val_loss: 0.6994 - val_acc: 0.7589\n",
      "Epoch 746/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7382 - acc: 0.7418 - val_loss: 0.7009 - val_acc: 0.7582\n",
      "Epoch 747/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7340 - acc: 0.7414 - val_loss: 0.6996 - val_acc: 0.7597\n",
      "Epoch 748/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7375 - acc: 0.7433 - val_loss: 0.6972 - val_acc: 0.7604\n",
      "Epoch 749/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7394 - acc: 0.7489 - val_loss: 0.6976 - val_acc: 0.7589\n",
      "Epoch 750/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7529 - acc: 0.7295 - val_loss: 0.6993 - val_acc: 0.7589\n",
      "Epoch 751/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7398 - acc: 0.7444 - val_loss: 0.6984 - val_acc: 0.7589\n",
      "Epoch 752/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7288 - acc: 0.7437 - val_loss: 0.7002 - val_acc: 0.7589\n",
      "Epoch 753/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7466 - acc: 0.7396 - val_loss: 0.7007 - val_acc: 0.7582\n",
      "Epoch 754/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7373 - acc: 0.7489 - val_loss: 0.6997 - val_acc: 0.7589\n",
      "Epoch 755/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7409 - acc: 0.7411 - val_loss: 0.7010 - val_acc: 0.7582\n",
      "Epoch 756/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7491 - acc: 0.7396 - val_loss: 0.6993 - val_acc: 0.7589\n",
      "Epoch 757/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7315 - acc: 0.7403 - val_loss: 0.7002 - val_acc: 0.7589\n",
      "Epoch 758/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7258 - acc: 0.7530 - val_loss: 0.6996 - val_acc: 0.7597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 759/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7469 - acc: 0.7407 - val_loss: 0.7000 - val_acc: 0.7589\n",
      "Epoch 760/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7447 - acc: 0.7407 - val_loss: 0.7008 - val_acc: 0.7582\n",
      "Epoch 761/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7274 - acc: 0.7411 - val_loss: 0.7004 - val_acc: 0.7589\n",
      "Epoch 762/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7465 - acc: 0.7403 - val_loss: 0.7006 - val_acc: 0.7582\n",
      "Epoch 763/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7259 - acc: 0.7463 - val_loss: 0.6996 - val_acc: 0.7589\n",
      "Epoch 764/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7365 - acc: 0.7362 - val_loss: 0.7010 - val_acc: 0.7582\n",
      "Epoch 765/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7459 - acc: 0.7452 - val_loss: 0.7012 - val_acc: 0.7582\n",
      "\n",
      "Epoch 00765: loss improved from inf to 0.74589, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-1-000765-0.745887-0.758185.hdf5\n",
      "Epoch 766/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7514 - acc: 0.7359 - val_loss: 0.6994 - val_acc: 0.7597\n",
      "Epoch 767/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7462 - acc: 0.7374 - val_loss: 0.7001 - val_acc: 0.7589\n",
      "Epoch 768/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7402 - acc: 0.7485 - val_loss: 0.6989 - val_acc: 0.7589\n",
      "Epoch 769/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7276 - acc: 0.7444 - val_loss: 0.6997 - val_acc: 0.7589\n",
      "\n",
      "Epoch 00769: loss improved from 0.74589 to 0.72758, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-1-000769-0.727575-0.758929.hdf5\n",
      "Epoch 770/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7418 - acc: 0.7281 - val_loss: 0.7007 - val_acc: 0.7589\n",
      "Epoch 771/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7340 - acc: 0.7426 - val_loss: 0.6998 - val_acc: 0.7589\n",
      "Epoch 772/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7274 - acc: 0.7448 - val_loss: 0.7001 - val_acc: 0.7582\n",
      "Epoch 773/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7236 - acc: 0.7407 - val_loss: 0.7010 - val_acc: 0.7582\n",
      "\n",
      "Epoch 00773: loss improved from 0.72758 to 0.72359, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-1-000773-0.723586-0.758185.hdf5\n",
      "Epoch 774/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7363 - acc: 0.7396 - val_loss: 0.7009 - val_acc: 0.7582\n",
      "Epoch 775/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7347 - acc: 0.7426 - val_loss: 0.6960 - val_acc: 0.7589\n",
      "Epoch 776/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7319 - acc: 0.7493 - val_loss: 0.6999 - val_acc: 0.7597\n",
      "Epoch 777/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7321 - acc: 0.7329 - val_loss: 0.7003 - val_acc: 0.7582\n",
      "Epoch 778/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7266 - acc: 0.7496 - val_loss: 0.7001 - val_acc: 0.7589\n",
      "Epoch 779/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7380 - acc: 0.7325 - val_loss: 0.6995 - val_acc: 0.7589\n",
      "Epoch 780/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7411 - acc: 0.7385 - val_loss: 0.6966 - val_acc: 0.7597\n",
      "Epoch 781/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7472 - acc: 0.7467 - val_loss: 0.6989 - val_acc: 0.7597\n",
      "Epoch 782/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7422 - acc: 0.7429 - val_loss: 0.7008 - val_acc: 0.7582\n",
      "Epoch 783/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7430 - acc: 0.7385 - val_loss: 0.6930 - val_acc: 0.7597\n",
      "Epoch 784/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7330 - acc: 0.7414 - val_loss: 0.6992 - val_acc: 0.7597\n",
      "Epoch 785/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7279 - acc: 0.7478 - val_loss: 0.7009 - val_acc: 0.7582\n",
      "Epoch 786/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7452 - acc: 0.7418 - val_loss: 0.6956 - val_acc: 0.7597\n",
      "Epoch 787/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7306 - acc: 0.7463 - val_loss: 0.6973 - val_acc: 0.7597\n",
      "Epoch 788/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7387 - acc: 0.7359 - val_loss: 0.6946 - val_acc: 0.7597\n",
      "Epoch 789/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7435 - acc: 0.7388 - val_loss: 0.7012 - val_acc: 0.7582\n",
      "Epoch 790/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7504 - acc: 0.7414 - val_loss: 0.6972 - val_acc: 0.7597\n",
      "Epoch 791/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7353 - acc: 0.7414 - val_loss: 0.6979 - val_acc: 0.7589\n",
      "Epoch 792/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7434 - acc: 0.7347 - val_loss: 0.7015 - val_acc: 0.7582\n",
      "Epoch 793/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7370 - acc: 0.7448 - val_loss: 0.7006 - val_acc: 0.7582\n",
      "Epoch 794/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.7257 - acc: 0.7485 - val_loss: 0.7011 - val_acc: 0.7582\n",
      "Epoch 795/1000\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.7350 - acc: 0.7440 - val_loss: 0.7001 - val_acc: 0.7589\n",
      "Epoch 796/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7378 - acc: 0.7407 - val_loss: 0.6987 - val_acc: 0.7589\n",
      "Epoch 797/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7341 - acc: 0.7426 - val_loss: 0.6993 - val_acc: 0.7597\n",
      "Epoch 798/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7412 - acc: 0.7400 - val_loss: 0.7001 - val_acc: 0.7582\n",
      "Epoch 799/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7480 - acc: 0.7411 - val_loss: 0.6983 - val_acc: 0.7589\n",
      "Epoch 800/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7335 - acc: 0.7478 - val_loss: 0.6994 - val_acc: 0.7589\n",
      "\n",
      "Epoch 00800: saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/1-000800-0.733464-0.758929.hdf5\n",
      "Epoch 801/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7335 - acc: 0.7504 - val_loss: 0.7006 - val_acc: 0.7589\n",
      "Epoch 802/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7347 - acc: 0.7407 - val_loss: 0.6973 - val_acc: 0.7604\n",
      "Epoch 803/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7378 - acc: 0.7459 - val_loss: 0.7005 - val_acc: 0.7582\n",
      "Epoch 804/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7452 - acc: 0.7314 - val_loss: 0.6998 - val_acc: 0.7589\n",
      "Epoch 805/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7377 - acc: 0.7388 - val_loss: 0.6992 - val_acc: 0.7597\n",
      "Epoch 806/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7316 - acc: 0.7478 - val_loss: 0.6995 - val_acc: 0.7597\n",
      "Epoch 807/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7379 - acc: 0.7392 - val_loss: 0.6977 - val_acc: 0.7597\n",
      "Epoch 808/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7313 - acc: 0.7418 - val_loss: 0.7013 - val_acc: 0.7582\n",
      "Epoch 809/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7406 - acc: 0.7407 - val_loss: 0.6989 - val_acc: 0.7589\n",
      "Epoch 810/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7313 - acc: 0.7455 - val_loss: 0.7014 - val_acc: 0.7582\n",
      "Epoch 811/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7448 - acc: 0.7530 - val_loss: 0.6973 - val_acc: 0.7589\n",
      "Epoch 812/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7443 - acc: 0.7359 - val_loss: 0.7007 - val_acc: 0.7589\n",
      "Epoch 813/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7356 - acc: 0.7392 - val_loss: 0.6963 - val_acc: 0.7597\n",
      "Epoch 814/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7459 - acc: 0.7359 - val_loss: 0.6987 - val_acc: 0.7589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 815/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7261 - acc: 0.7452 - val_loss: 0.7009 - val_acc: 0.7582\n",
      "Epoch 816/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7434 - acc: 0.7366 - val_loss: 0.6993 - val_acc: 0.7597\n",
      "Epoch 817/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7401 - acc: 0.7463 - val_loss: 0.7001 - val_acc: 0.7589\n",
      "Epoch 818/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7447 - acc: 0.7381 - val_loss: 0.6990 - val_acc: 0.7597\n",
      "Epoch 819/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7418 - acc: 0.7381 - val_loss: 0.6990 - val_acc: 0.7597\n",
      "Epoch 820/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7295 - acc: 0.7370 - val_loss: 0.6982 - val_acc: 0.7597\n",
      "Epoch 821/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7363 - acc: 0.7403 - val_loss: 0.6993 - val_acc: 0.7589\n",
      "Epoch 822/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7538 - acc: 0.7310 - val_loss: 0.6994 - val_acc: 0.7597\n",
      "Epoch 823/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7315 - acc: 0.7437 - val_loss: 0.6995 - val_acc: 0.7589\n",
      "Epoch 824/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7586 - acc: 0.7351 - val_loss: 0.7003 - val_acc: 0.7582\n",
      "Epoch 825/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7392 - acc: 0.7400 - val_loss: 0.6870 - val_acc: 0.7612\n",
      "Epoch 826/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7440 - acc: 0.7429 - val_loss: 0.6980 - val_acc: 0.7597\n",
      "Epoch 827/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7328 - acc: 0.7426 - val_loss: 0.7004 - val_acc: 0.7582\n",
      "Epoch 828/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7384 - acc: 0.7470 - val_loss: 0.6977 - val_acc: 0.7604\n",
      "Epoch 829/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7438 - acc: 0.7344 - val_loss: 0.6996 - val_acc: 0.7597\n",
      "Epoch 830/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7253 - acc: 0.7474 - val_loss: 0.6994 - val_acc: 0.7597\n",
      "Epoch 831/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7369 - acc: 0.7377 - val_loss: 0.7003 - val_acc: 0.7582\n",
      "Epoch 832/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7519 - acc: 0.7396 - val_loss: 0.6994 - val_acc: 0.7589\n",
      "Epoch 833/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7427 - acc: 0.7414 - val_loss: 0.6986 - val_acc: 0.7589\n",
      "Epoch 834/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7421 - acc: 0.7422 - val_loss: 0.7001 - val_acc: 0.7589\n",
      "Epoch 835/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7274 - acc: 0.7448 - val_loss: 0.7011 - val_acc: 0.7582\n",
      "Epoch 836/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7353 - acc: 0.7374 - val_loss: 0.7008 - val_acc: 0.7582\n",
      "Epoch 837/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7223 - acc: 0.7433 - val_loss: 0.6999 - val_acc: 0.7589\n",
      "Epoch 838/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7489 - acc: 0.7362 - val_loss: 0.6970 - val_acc: 0.7597\n",
      "Epoch 839/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7330 - acc: 0.7463 - val_loss: 0.6980 - val_acc: 0.7597\n",
      "Epoch 840/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7327 - acc: 0.7467 - val_loss: 0.6977 - val_acc: 0.7589\n",
      "Epoch 841/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7228 - acc: 0.7463 - val_loss: 0.7004 - val_acc: 0.7582\n",
      "Epoch 842/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7372 - acc: 0.7448 - val_loss: 0.6964 - val_acc: 0.7597\n",
      "Epoch 843/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7373 - acc: 0.7396 - val_loss: 0.6998 - val_acc: 0.7589\n",
      "Epoch 844/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7497 - acc: 0.7318 - val_loss: 0.6957 - val_acc: 0.7597\n",
      "Epoch 845/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7237 - acc: 0.7463 - val_loss: 0.7002 - val_acc: 0.7589\n",
      "Epoch 846/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7412 - acc: 0.7411 - val_loss: 0.6991 - val_acc: 0.7597\n",
      "Epoch 847/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7318 - acc: 0.7429 - val_loss: 0.7008 - val_acc: 0.7582\n",
      "Epoch 848/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7471 - acc: 0.7437 - val_loss: 0.6977 - val_acc: 0.7597\n",
      "Epoch 849/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7456 - acc: 0.7411 - val_loss: 0.6991 - val_acc: 0.7597\n",
      "Epoch 850/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7422 - acc: 0.7336 - val_loss: 0.6995 - val_acc: 0.7589\n",
      "Epoch 851/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7306 - acc: 0.7411 - val_loss: 0.7009 - val_acc: 0.7582\n",
      "Epoch 852/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7334 - acc: 0.7440 - val_loss: 0.7009 - val_acc: 0.7582\n",
      "Epoch 853/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7416 - acc: 0.7463 - val_loss: 0.7012 - val_acc: 0.7582\n",
      "Epoch 854/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7316 - acc: 0.7370 - val_loss: 0.6996 - val_acc: 0.7589\n",
      "Epoch 855/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7432 - acc: 0.7336 - val_loss: 0.7006 - val_acc: 0.7582\n",
      "Epoch 856/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7421 - acc: 0.7414 - val_loss: 0.7005 - val_acc: 0.7589\n",
      "Epoch 857/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7611 - acc: 0.7370 - val_loss: 0.6997 - val_acc: 0.7597\n",
      "Epoch 858/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7260 - acc: 0.7452 - val_loss: 0.7006 - val_acc: 0.7582\n",
      "Epoch 859/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7392 - acc: 0.7396 - val_loss: 0.6988 - val_acc: 0.7597\n",
      "Epoch 860/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7311 - acc: 0.7467 - val_loss: 0.6993 - val_acc: 0.7589\n",
      "Epoch 861/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7491 - acc: 0.7314 - val_loss: 0.6937 - val_acc: 0.7604\n",
      "Epoch 862/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7293 - acc: 0.7411 - val_loss: 0.6977 - val_acc: 0.7589\n",
      "Epoch 863/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7451 - acc: 0.7366 - val_loss: 0.6971 - val_acc: 0.7589\n",
      "Epoch 864/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7328 - acc: 0.7433 - val_loss: 0.6986 - val_acc: 0.7589\n",
      "Epoch 865/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7251 - acc: 0.7440 - val_loss: 0.6995 - val_acc: 0.7589\n",
      "\n",
      "Epoch 00865: loss improved from inf to 0.72506, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-1-000865-0.725063-0.758929.hdf5\n",
      "Epoch 866/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7326 - acc: 0.7429 - val_loss: 0.7013 - val_acc: 0.7582\n",
      "Epoch 867/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7180 - acc: 0.7507 - val_loss: 0.6981 - val_acc: 0.7597\n",
      "Epoch 868/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7380 - acc: 0.7418 - val_loss: 0.6986 - val_acc: 0.7597\n",
      "Epoch 869/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7301 - acc: 0.7463 - val_loss: 0.6975 - val_acc: 0.7589\n",
      "Epoch 870/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7404 - acc: 0.7500 - val_loss: 0.6983 - val_acc: 0.7597\n",
      "Epoch 871/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7260 - acc: 0.7511 - val_loss: 0.6983 - val_acc: 0.7589\n",
      "Epoch 872/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7391 - acc: 0.7388 - val_loss: 0.7010 - val_acc: 0.7582\n",
      "Epoch 873/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7360 - acc: 0.7429 - val_loss: 0.6986 - val_acc: 0.7597\n",
      "Epoch 874/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7522 - acc: 0.7299 - val_loss: 0.7004 - val_acc: 0.7582\n",
      "Epoch 875/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7265 - acc: 0.7552 - val_loss: 0.7009 - val_acc: 0.7582\n",
      "Epoch 876/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7486 - acc: 0.7344 - val_loss: 0.7014 - val_acc: 0.7582\n",
      "Epoch 877/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7250 - acc: 0.7455 - val_loss: 0.6990 - val_acc: 0.7597\n",
      "\n",
      "Epoch 00877: loss improved from 0.72506 to 0.72498, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-1-000877-0.724981-0.759673.hdf5\n",
      "Epoch 878/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7410 - acc: 0.7366 - val_loss: 0.7013 - val_acc: 0.7582\n",
      "Epoch 879/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7411 - acc: 0.7429 - val_loss: 0.7004 - val_acc: 0.7582\n",
      "Epoch 880/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7466 - acc: 0.7370 - val_loss: 0.7007 - val_acc: 0.7582\n",
      "Epoch 881/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7390 - acc: 0.7437 - val_loss: 0.7004 - val_acc: 0.7589\n",
      "Epoch 882/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7421 - acc: 0.7374 - val_loss: 0.7011 - val_acc: 0.7582\n",
      "Epoch 883/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7323 - acc: 0.7452 - val_loss: 0.7010 - val_acc: 0.7582\n",
      "Epoch 884/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7539 - acc: 0.7347 - val_loss: 0.7006 - val_acc: 0.7582\n",
      "Epoch 885/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7401 - acc: 0.7374 - val_loss: 0.6991 - val_acc: 0.7597\n",
      "Epoch 886/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7452 - acc: 0.7437 - val_loss: 0.6990 - val_acc: 0.7597\n",
      "Epoch 887/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7295 - acc: 0.7493 - val_loss: 0.6962 - val_acc: 0.7597\n",
      "Epoch 888/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7475 - acc: 0.7388 - val_loss: 0.6996 - val_acc: 0.7597\n",
      "Epoch 889/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7269 - acc: 0.7411 - val_loss: 0.7004 - val_acc: 0.7582\n",
      "Epoch 890/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7353 - acc: 0.7463 - val_loss: 0.6989 - val_acc: 0.7589\n",
      "Epoch 891/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7544 - acc: 0.7310 - val_loss: 0.6987 - val_acc: 0.7597\n",
      "Epoch 892/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7417 - acc: 0.7474 - val_loss: 0.6981 - val_acc: 0.7597\n",
      "Epoch 893/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7268 - acc: 0.7485 - val_loss: 0.7005 - val_acc: 0.7582\n",
      "Epoch 894/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7454 - acc: 0.7321 - val_loss: 0.7011 - val_acc: 0.7582\n",
      "Epoch 895/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7509 - acc: 0.7426 - val_loss: 0.7008 - val_acc: 0.7582\n",
      "Epoch 896/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7388 - acc: 0.7444 - val_loss: 0.6988 - val_acc: 0.7597\n",
      "Epoch 897/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7362 - acc: 0.7470 - val_loss: 0.7001 - val_acc: 0.7582\n",
      "Epoch 898/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7334 - acc: 0.7422 - val_loss: 0.7009 - val_acc: 0.7582\n",
      "Epoch 899/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7251 - acc: 0.7489 - val_loss: 0.6993 - val_acc: 0.7597\n",
      "Epoch 900/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7353 - acc: 0.7474 - val_loss: 0.6988 - val_acc: 0.7597\n",
      "\n",
      "Epoch 00900: saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/1-000900-0.735279-0.759673.hdf5\n",
      "Epoch 901/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7522 - acc: 0.7374 - val_loss: 0.7008 - val_acc: 0.7582\n",
      "Epoch 902/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7440 - acc: 0.7400 - val_loss: 0.7008 - val_acc: 0.7582\n",
      "Epoch 903/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7335 - acc: 0.7448 - val_loss: 0.6964 - val_acc: 0.7597\n",
      "Epoch 904/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7266 - acc: 0.7493 - val_loss: 0.6986 - val_acc: 0.7589\n",
      "Epoch 905/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7368 - acc: 0.7455 - val_loss: 0.6999 - val_acc: 0.7589\n",
      "Epoch 906/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7299 - acc: 0.7470 - val_loss: 0.7003 - val_acc: 0.7589\n",
      "Epoch 907/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7396 - acc: 0.7507 - val_loss: 0.6998 - val_acc: 0.7582\n",
      "Epoch 908/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7400 - acc: 0.7385 - val_loss: 0.6997 - val_acc: 0.7582\n",
      "Epoch 909/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7490 - acc: 0.7388 - val_loss: 0.6989 - val_acc: 0.7589\n",
      "Epoch 910/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7284 - acc: 0.7463 - val_loss: 0.7006 - val_acc: 0.7582\n",
      "Epoch 911/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7275 - acc: 0.7485 - val_loss: 0.6991 - val_acc: 0.7597\n",
      "Epoch 912/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7394 - acc: 0.7429 - val_loss: 0.6985 - val_acc: 0.7597\n",
      "Epoch 913/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7419 - acc: 0.7448 - val_loss: 0.6984 - val_acc: 0.7597\n",
      "Epoch 914/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7258 - acc: 0.7411 - val_loss: 0.7006 - val_acc: 0.7582\n",
      "Epoch 915/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7397 - acc: 0.7403 - val_loss: 0.6999 - val_acc: 0.7589\n",
      "Epoch 916/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7404 - acc: 0.7463 - val_loss: 0.7012 - val_acc: 0.7582\n",
      "Epoch 917/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7443 - acc: 0.7355 - val_loss: 0.7011 - val_acc: 0.7582\n",
      "Epoch 918/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7518 - acc: 0.7347 - val_loss: 0.7012 - val_acc: 0.7582\n",
      "Epoch 919/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7422 - acc: 0.7347 - val_loss: 0.6981 - val_acc: 0.7597\n",
      "Epoch 920/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7389 - acc: 0.7374 - val_loss: 0.7000 - val_acc: 0.7582\n",
      "Epoch 921/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7489 - acc: 0.7344 - val_loss: 0.6983 - val_acc: 0.7589\n",
      "Epoch 922/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7430 - acc: 0.7426 - val_loss: 0.7000 - val_acc: 0.7582\n",
      "Epoch 923/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7359 - acc: 0.7459 - val_loss: 0.7010 - val_acc: 0.7582\n",
      "Epoch 924/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7343 - acc: 0.7437 - val_loss: 0.7002 - val_acc: 0.7589\n",
      "Epoch 925/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7247 - acc: 0.7500 - val_loss: 0.6984 - val_acc: 0.7597\n",
      "Epoch 926/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7350 - acc: 0.7463 - val_loss: 0.7003 - val_acc: 0.7582\n",
      "Epoch 927/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7507 - acc: 0.7362 - val_loss: 0.7002 - val_acc: 0.7582\n",
      "Epoch 928/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7300 - acc: 0.7433 - val_loss: 0.7003 - val_acc: 0.7589\n",
      "Epoch 929/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7323 - acc: 0.7463 - val_loss: 0.6995 - val_acc: 0.7589\n",
      "Epoch 930/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7449 - acc: 0.7336 - val_loss: 0.7002 - val_acc: 0.7589\n",
      "Epoch 931/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7461 - acc: 0.7418 - val_loss: 0.6948 - val_acc: 0.7612\n",
      "Epoch 932/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7433 - acc: 0.7411 - val_loss: 0.6995 - val_acc: 0.7589\n",
      "Epoch 933/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7482 - acc: 0.7411 - val_loss: 0.7002 - val_acc: 0.7582\n",
      "Epoch 934/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7444 - acc: 0.7440 - val_loss: 0.7012 - val_acc: 0.7582\n",
      "Epoch 935/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7271 - acc: 0.7467 - val_loss: 0.7007 - val_acc: 0.7582\n",
      "Epoch 936/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7502 - acc: 0.7455 - val_loss: 0.6992 - val_acc: 0.7589\n",
      "Epoch 937/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7350 - acc: 0.7403 - val_loss: 0.6985 - val_acc: 0.7589\n",
      "Epoch 00937: early stopping\n",
      "ModelCheckpoint 已经保存到 ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/1-final.hdf5\n",
      "save in: ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/log/20220201_2000_64_1_3_1.csv\n",
      "time: 0:13:45 s\n",
      "time: 825.0 s\n",
      "average 0.825000 s\n",
      "1 epoch finished\n",
      "--------------------   best   --------------------\n",
      "no_activities: 10\n",
      "\n",
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1348/1348 [==============================] - 1s 430us/step\n",
      "1-milan:\tacc: 74.85%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 0, 0, 7, 9, 0, 4, 0, 0, 4, 4, 0, 4, 4, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 0, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 0, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 7, 7, 7, 7, 0, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 4, 0, 7, 7, 7, 7, 4, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 0, 7, 7, 7, 7, 0, 7, 4, 7, 7, 0, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 4, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 0, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 0, 5, 5, 5, 5, 9, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 9, 5, 5, 5, 5, 7, 5, 5, 5, 5, 9, 5, 5, 0, 5, 5, 4, 5, 5, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 9, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 7, 0, 0, 9, 0, 0, 0, 0, 0, 9, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 9, 0, 0, 9, 7, 7, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 9, 0, 0, 7, 0, 0, 0, 4, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 7, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7, 0, 0, 4, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 9, 9, 0, 0, 7, 0, 7, 0, 7, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 4, 7, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 7, 0, 9, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 4, 0, 7, 4, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 5, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 4, 0, 0, 0, 0, 7, 9, 0, 0, 0, 4, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 7, 0, 5, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 4, 0, 7, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 7, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 7, 4, 4, 0, 7, 0, 0, 7, 0, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 7, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 7, 4, 0, 4, 4, 0, 4, 0, 4, 0, 4, 4, 4, 0, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 0, 7, 4, 0, 4, 0, 4, 0, 4, 0, 4, 4, 4, 7, 4, 4, 0, 7, 4, 4, 7, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 0, 4, 0, 0, 4, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 9, 0, 9, 0, 0, 9, 0, 0, 0, 9, 0, 0, 9, 0, 9, 9, 0, 0, 0, 0, 7, 0, 0, 0, 0, 7, 7, 0, 7, 0, 0, 7, 0, 7, 0, 0, 0, 7, 0, 0, 7, 0, 4, 0, 9, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.786550  0.863563  0.823259       623\n",
      "         Work   0.000000  0.000000  0.000000        25\n",
      "Take_medicine   0.000000  0.000000  0.000000        20\n",
      "        Sleep   0.000000  0.000000  0.000000        32\n",
      "        Relax   0.676190  0.500000  0.574899       142\n",
      "   Leave_Home   0.859155  0.847222  0.853147        72\n",
      "          Eat   0.000000  0.000000  0.000000         8\n",
      "         Cook   0.630705  0.826087  0.715294       184\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        30\n",
      "      Bathing   0.757085  0.882075  0.814815       212\n",
      "\n",
      "     accuracy                       0.748516      1348\n",
      "    macro avg   0.370969  0.391895  0.378141      1348\n",
      " weighted avg   0.685794  0.748516  0.712394      1348\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  30   0   0   0   0   0]\n",
      " [  0   0   0   0   1   3   0  14   7   0]\n",
      " [  0   0   0   0   0   2   0   6   0   0]\n",
      " [  0   0   0   0   2  18   0   0   0   0]\n",
      " [  0   0   0   0 187   6   0  19   0   0]\n",
      " [  0   0   0   0   1 152   0  26   5   0]\n",
      " [  0   0   0   0   3   1  61   5   2   0]\n",
      " [  0   0   0   0  14  41  10 538  20   0]\n",
      " [  0   0   0   0   1  18   0  52  71   0]\n",
      " [  0   0   0   0   8   0   0  24   0   0]]\n",
      "--------------------   final   --------------------\n",
      "no_activities: 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1348/1348 [==============================] - 1s 441us/step\n",
      "1-milan:\tacc: 75.89%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 0, 0, 7, 9, 0, 4, 0, 0, 4, 4, 0, 4, 4, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 7, 7, 2, 2, 2, 2, 7, 7, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 0, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 0, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 7, 7, 7, 7, 0, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 0, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 0, 4, 0, 7, 7, 7, 7, 4, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 0, 7, 7, 7, 7, 0, 7, 4, 7, 7, 0, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 4, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 0, 0, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 0, 5, 5, 5, 5, 9, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 0, 5, 5, 5, 5, 5, 5, 0, 5, 5, 0, 5, 5, 5, 5, 5, 9, 5, 5, 5, 5, 7, 5, 5, 5, 5, 9, 5, 5, 0, 5, 5, 4, 5, 5, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 9, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 9, 7, 0, 0, 9, 0, 0, 7, 0, 0, 9, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 7, 7, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 7, 7, 7, 7, 2, 2, 9, 7, 7, 2, 9, 0, 0, 7, 0, 0, 0, 4, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 7, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7, 0, 0, 4, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 9, 0, 0, 7, 0, 7, 0, 7, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 4, 7, 0, 0, 0, 0, 0, 0, 0, 4, 7, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 7, 0, 9, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 4, 0, 7, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 5, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 4, 0, 0, 0, 0, 7, 9, 0, 0, 0, 4, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 7, 0, 5, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 4, 0, 7, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 7, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 7, 4, 4, 0, 7, 0, 0, 7, 0, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 7, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 7, 4, 0, 4, 4, 0, 4, 0, 4, 0, 4, 4, 4, 0, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 7, 4, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 4, 7, 4, 4, 7, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 0, 4, 0, 0, 4, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 9, 0, 9, 0, 0, 9, 0, 0, 0, 9, 0, 0, 9, 0, 9, 9, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 7, 0, 0, 0, 0, 7, 0, 7, 0, 0, 0, 0, 0, 0, 7, 0, 4, 0, 9, 0, 0, 0, 0, 0, 4, 4, 0, 7, 0, 0, 0, 0, 0, 0, 0]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.784571  0.865169  0.822901       623\n",
      "         Work   0.000000  0.000000  0.000000        25\n",
      "Take_medicine   1.000000  0.450000  0.620690        20\n",
      "        Sleep   0.000000  0.000000  0.000000        32\n",
      "        Relax   0.696429  0.549296  0.614173       142\n",
      "   Leave_Home   0.857143  0.833333  0.845070        72\n",
      "          Eat   0.000000  0.000000  0.000000         8\n",
      "         Cook   0.663717  0.815217  0.731707       184\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        30\n",
      "      Bathing   0.766393  0.882075  0.820175       212\n",
      "\n",
      "     accuracy                       0.758902      1348\n",
      "    macro avg   0.476825  0.439509  0.445472      1348\n",
      " weighted avg   0.707711  0.758902  0.728227      1348\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  30   0   0   0   0   0]\n",
      " [  0   0   0   0   1   3   0  14   7   0]\n",
      " [  0   0   0   0   0   2   0   6   0   0]\n",
      " [  0   0   0   9   2   9   0   0   0   0]\n",
      " [  0   0   0   0 187   6   0  19   0   0]\n",
      " [  0   0   0   0   0 150   0  30   4   0]\n",
      " [  0   0   0   0   3   1  60   6   2   0]\n",
      " [  0   0   0   0  12  41  10 539  21   0]\n",
      " [  0   0   0   0   1  14   0  49  78   0]\n",
      " [  0   0   0   0   8   0   0  24   0   0]]\n",
      "no_activities: 10\n",
      "\n",
      "Begin training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 1.8059 - acc: 0.4851 - val_loss: 1.4777 - val_acc: 0.5774\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 1.4502 - acc: 0.5621 - val_loss: 1.2673 - val_acc: 0.6473\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 1.3152 - acc: 0.6012 - val_loss: 1.1524 - val_acc: 0.6570\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 1.2077 - acc: 0.6339 - val_loss: 1.0803 - val_acc: 0.6689\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 1.1653 - acc: 0.6462 - val_loss: 1.0408 - val_acc: 0.6667\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 1.1495 - acc: 0.6384 - val_loss: 1.0179 - val_acc: 0.7001\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 1.1166 - acc: 0.6514 - val_loss: 0.9952 - val_acc: 0.6935\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 1.0822 - acc: 0.6715 - val_loss: 0.9779 - val_acc: 0.6987\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 1.0940 - acc: 0.6641 - val_loss: 0.9665 - val_acc: 0.6987\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 1.0532 - acc: 0.6719 - val_loss: 0.9518 - val_acc: 0.7009\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 1.0488 - acc: 0.6633 - val_loss: 0.9427 - val_acc: 0.7024\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 1.0363 - acc: 0.6719 - val_loss: 0.9343 - val_acc: 0.7091\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 1.0322 - acc: 0.6756 - val_loss: 0.9293 - val_acc: 0.7001\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 1.0059 - acc: 0.6737 - val_loss: 0.9198 - val_acc: 0.7202\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.9902 - acc: 0.6905 - val_loss: 0.9072 - val_acc: 0.7247\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.9875 - acc: 0.6912 - val_loss: 0.8939 - val_acc: 0.7336\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.9691 - acc: 0.6890 - val_loss: 0.8864 - val_acc: 0.7381\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.9735 - acc: 0.6908 - val_loss: 0.8698 - val_acc: 0.7433\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.9450 - acc: 0.7009 - val_loss: 0.8606 - val_acc: 0.7440\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.9325 - acc: 0.7087 - val_loss: 0.8520 - val_acc: 0.7485\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.9415 - acc: 0.7098 - val_loss: 0.8441 - val_acc: 0.7507\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.9248 - acc: 0.7020 - val_loss: 0.8335 - val_acc: 0.7567\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.9092 - acc: 0.7173 - val_loss: 0.8279 - val_acc: 0.7552\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.9173 - acc: 0.7117 - val_loss: 0.8227 - val_acc: 0.7545\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8995 - acc: 0.7191 - val_loss: 0.8137 - val_acc: 0.7574\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.9027 - acc: 0.7221 - val_loss: 0.8113 - val_acc: 0.7612\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8972 - acc: 0.7176 - val_loss: 0.8029 - val_acc: 0.7567\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8864 - acc: 0.7214 - val_loss: 0.8008 - val_acc: 0.7530\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8755 - acc: 0.7150 - val_loss: 0.7932 - val_acc: 0.7597\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8817 - acc: 0.7184 - val_loss: 0.7915 - val_acc: 0.7589\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8716 - acc: 0.7310 - val_loss: 0.7876 - val_acc: 0.7589\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.8674 - acc: 0.7258 - val_loss: 0.7829 - val_acc: 0.7582\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8604 - acc: 0.7206 - val_loss: 0.7824 - val_acc: 0.7574\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8679 - acc: 0.7202 - val_loss: 0.7774 - val_acc: 0.7649\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8681 - acc: 0.7284 - val_loss: 0.7771 - val_acc: 0.7612\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8628 - acc: 0.7195 - val_loss: 0.7730 - val_acc: 0.7619\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8548 - acc: 0.7307 - val_loss: 0.7714 - val_acc: 0.7626\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8573 - acc: 0.7258 - val_loss: 0.7683 - val_acc: 0.7671\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8595 - acc: 0.7273 - val_loss: 0.7671 - val_acc: 0.7649\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8576 - acc: 0.7217 - val_loss: 0.7673 - val_acc: 0.7693\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8382 - acc: 0.7321 - val_loss: 0.7627 - val_acc: 0.7664\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8350 - acc: 0.7318 - val_loss: 0.7603 - val_acc: 0.7693\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.8439 - acc: 0.7254 - val_loss: 0.7605 - val_acc: 0.7693\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8302 - acc: 0.7351 - val_loss: 0.7574 - val_acc: 0.7693\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8399 - acc: 0.7262 - val_loss: 0.7550 - val_acc: 0.7671\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8220 - acc: 0.7314 - val_loss: 0.7528 - val_acc: 0.7686\n",
      "Epoch 47/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8202 - acc: 0.7426 - val_loss: 0.7504 - val_acc: 0.7716\n",
      "Epoch 48/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.8337 - acc: 0.7344 - val_loss: 0.7517 - val_acc: 0.7716\n",
      "Epoch 49/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8195 - acc: 0.7284 - val_loss: 0.7499 - val_acc: 0.7708\n",
      "Epoch 50/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8271 - acc: 0.7288 - val_loss: 0.7496 - val_acc: 0.7760\n",
      "Epoch 51/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8337 - acc: 0.7314 - val_loss: 0.7488 - val_acc: 0.7723\n",
      "Epoch 52/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.8042 - acc: 0.7426 - val_loss: 0.7445 - val_acc: 0.7701\n",
      "Epoch 53/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8054 - acc: 0.7362 - val_loss: 0.7438 - val_acc: 0.7701\n",
      "Epoch 54/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8235 - acc: 0.7388 - val_loss: 0.7392 - val_acc: 0.7731\n",
      "Epoch 55/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8070 - acc: 0.7418 - val_loss: 0.7382 - val_acc: 0.7753\n",
      "Epoch 56/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8062 - acc: 0.7366 - val_loss: 0.7340 - val_acc: 0.7701\n",
      "Epoch 57/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8108 - acc: 0.7392 - val_loss: 0.7370 - val_acc: 0.7701\n",
      "Epoch 58/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8191 - acc: 0.7258 - val_loss: 0.7344 - val_acc: 0.7738\n",
      "Epoch 59/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8018 - acc: 0.7392 - val_loss: 0.7316 - val_acc: 0.7746\n",
      "Epoch 60/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8056 - acc: 0.7355 - val_loss: 0.7315 - val_acc: 0.7723\n",
      "Epoch 61/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8002 - acc: 0.7388 - val_loss: 0.7299 - val_acc: 0.7738\n",
      "Epoch 62/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8061 - acc: 0.7351 - val_loss: 0.7268 - val_acc: 0.7731\n",
      "Epoch 63/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8111 - acc: 0.7374 - val_loss: 0.7274 - val_acc: 0.7723\n",
      "Epoch 64/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8051 - acc: 0.7411 - val_loss: 0.7286 - val_acc: 0.7731\n",
      "Epoch 65/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8080 - acc: 0.7269 - val_loss: 0.7304 - val_acc: 0.7716\n",
      "\n",
      "Epoch 00065: loss improved from inf to 0.80805, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-2-000065-0.808049-0.771577.hdf5\n",
      "Epoch 66/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8024 - acc: 0.7347 - val_loss: 0.7304 - val_acc: 0.7708\n",
      "Epoch 67/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.8121 - acc: 0.7366 - val_loss: 0.7255 - val_acc: 0.7701\n",
      "Epoch 68/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8073 - acc: 0.7381 - val_loss: 0.7252 - val_acc: 0.7693\n",
      "Epoch 69/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.8078 - acc: 0.7295 - val_loss: 0.7267 - val_acc: 0.7686\n",
      "\n",
      "Epoch 00069: loss improved from 0.80805 to 0.80779, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-2-000069-0.807790-0.768601.hdf5\n",
      "Epoch 70/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7912 - acc: 0.7385 - val_loss: 0.7216 - val_acc: 0.7716\n",
      "Epoch 71/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7901 - acc: 0.7359 - val_loss: 0.7206 - val_acc: 0.7731\n",
      "Epoch 72/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8018 - acc: 0.7336 - val_loss: 0.7201 - val_acc: 0.7671\n",
      "Epoch 73/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.8027 - acc: 0.7422 - val_loss: 0.7194 - val_acc: 0.7686\n",
      "\n",
      "Epoch 00073: loss improved from 0.80779 to 0.80265, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-2-000073-0.802651-0.768601.hdf5\n",
      "Epoch 74/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7965 - acc: 0.7411 - val_loss: 0.7189 - val_acc: 0.7738\n",
      "Epoch 75/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7891 - acc: 0.7381 - val_loss: 0.7170 - val_acc: 0.7701\n",
      "Epoch 76/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7974 - acc: 0.7329 - val_loss: 0.7114 - val_acc: 0.7708\n",
      "Epoch 77/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7892 - acc: 0.7414 - val_loss: 0.7152 - val_acc: 0.7686\n",
      "\n",
      "Epoch 00077: loss improved from 0.80265 to 0.78923, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-2-000077-0.789232-0.768601.hdf5\n",
      "Epoch 78/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7916 - acc: 0.7307 - val_loss: 0.7137 - val_acc: 0.7686\n",
      "Epoch 79/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7726 - acc: 0.7433 - val_loss: 0.7127 - val_acc: 0.7701\n",
      "Epoch 80/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7774 - acc: 0.7470 - val_loss: 0.7125 - val_acc: 0.7753\n",
      "Epoch 81/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7962 - acc: 0.7351 - val_loss: 0.7074 - val_acc: 0.7746\n",
      "Epoch 82/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7822 - acc: 0.7400 - val_loss: 0.7105 - val_acc: 0.7708\n",
      "Epoch 83/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7837 - acc: 0.7433 - val_loss: 0.7079 - val_acc: 0.7686\n",
      "Epoch 84/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7646 - acc: 0.7507 - val_loss: 0.7026 - val_acc: 0.7716\n",
      "Epoch 85/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7747 - acc: 0.7448 - val_loss: 0.7083 - val_acc: 0.7708\n",
      "\n",
      "Epoch 00085: loss improved from 0.78923 to 0.77465, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-2-000085-0.774654-0.770833.hdf5\n",
      "Epoch 86/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7883 - acc: 0.7362 - val_loss: 0.7092 - val_acc: 0.7738\n",
      "Epoch 87/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7738 - acc: 0.7414 - val_loss: 0.7032 - val_acc: 0.7723\n",
      "Epoch 88/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7610 - acc: 0.7440 - val_loss: 0.7064 - val_acc: 0.7731\n",
      "Epoch 89/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7562 - acc: 0.7392 - val_loss: 0.7040 - val_acc: 0.7746\n",
      "\n",
      "Epoch 00089: loss improved from 0.77465 to 0.75615, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-2-000089-0.756151-0.774554.hdf5\n",
      "Epoch 90/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7676 - acc: 0.7481 - val_loss: 0.7047 - val_acc: 0.7708\n",
      "Epoch 91/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7660 - acc: 0.7414 - val_loss: 0.7004 - val_acc: 0.7708\n",
      "Epoch 92/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7710 - acc: 0.7452 - val_loss: 0.7035 - val_acc: 0.7760\n",
      "Epoch 93/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7558 - acc: 0.7481 - val_loss: 0.6987 - val_acc: 0.7753\n",
      "\n",
      "Epoch 00093: loss improved from 0.75615 to 0.75581, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-2-000093-0.755808-0.775298.hdf5\n",
      "Epoch 94/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7655 - acc: 0.7485 - val_loss: 0.7016 - val_acc: 0.7768\n",
      "Epoch 95/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7674 - acc: 0.7407 - val_loss: 0.7015 - val_acc: 0.7738\n",
      "Epoch 96/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7758 - acc: 0.7418 - val_loss: 0.7009 - val_acc: 0.7723\n",
      "Epoch 97/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7705 - acc: 0.7433 - val_loss: 0.7010 - val_acc: 0.7746\n",
      "Epoch 98/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7617 - acc: 0.7437 - val_loss: 0.6978 - val_acc: 0.7731\n",
      "Epoch 99/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7747 - acc: 0.7459 - val_loss: 0.6968 - val_acc: 0.7746\n",
      "Epoch 100/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7518 - acc: 0.7478 - val_loss: 0.6962 - val_acc: 0.7716\n",
      "\n",
      "Epoch 00100: saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/2-000100-0.751831-0.771577.hdf5\n",
      "Epoch 101/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7684 - acc: 0.7448 - val_loss: 0.6972 - val_acc: 0.7708\n",
      "Epoch 102/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7585 - acc: 0.7504 - val_loss: 0.6975 - val_acc: 0.7731\n",
      "Epoch 103/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7540 - acc: 0.7489 - val_loss: 0.6956 - val_acc: 0.7708\n",
      "Epoch 104/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7643 - acc: 0.7481 - val_loss: 0.6898 - val_acc: 0.7708\n",
      "Epoch 105/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7555 - acc: 0.7511 - val_loss: 0.6927 - val_acc: 0.7731\n",
      "Epoch 106/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7501 - acc: 0.7597 - val_loss: 0.6902 - val_acc: 0.7716\n",
      "Epoch 107/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7581 - acc: 0.7463 - val_loss: 0.6922 - val_acc: 0.7738\n",
      "Epoch 108/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7718 - acc: 0.7426 - val_loss: 0.6929 - val_acc: 0.7708\n",
      "Epoch 109/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7587 - acc: 0.7496 - val_loss: 0.6951 - val_acc: 0.7701\n",
      "Epoch 110/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7507 - acc: 0.7511 - val_loss: 0.6938 - val_acc: 0.7753\n",
      "Epoch 111/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7515 - acc: 0.7511 - val_loss: 0.6902 - val_acc: 0.7716\n",
      "Epoch 112/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7328 - acc: 0.7582 - val_loss: 0.6880 - val_acc: 0.7716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7599 - acc: 0.7448 - val_loss: 0.6902 - val_acc: 0.7723\n",
      "Epoch 114/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7594 - acc: 0.7500 - val_loss: 0.6908 - val_acc: 0.7693\n",
      "Epoch 115/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7379 - acc: 0.7448 - val_loss: 0.6883 - val_acc: 0.7708\n",
      "Epoch 116/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7460 - acc: 0.7574 - val_loss: 0.6889 - val_acc: 0.7716\n",
      "Epoch 117/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7359 - acc: 0.7582 - val_loss: 0.6885 - val_acc: 0.7731\n",
      "Epoch 118/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7449 - acc: 0.7478 - val_loss: 0.6879 - val_acc: 0.7716\n",
      "Epoch 119/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7437 - acc: 0.7504 - val_loss: 0.6860 - val_acc: 0.7731\n",
      "Epoch 120/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7464 - acc: 0.7541 - val_loss: 0.6839 - val_acc: 0.7738\n",
      "Epoch 121/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7481 - acc: 0.7474 - val_loss: 0.6832 - val_acc: 0.7738\n",
      "Epoch 122/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7440 - acc: 0.7589 - val_loss: 0.6841 - val_acc: 0.7731\n",
      "Epoch 123/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7475 - acc: 0.7463 - val_loss: 0.6844 - val_acc: 0.7753\n",
      "Epoch 124/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7496 - acc: 0.7433 - val_loss: 0.6840 - val_acc: 0.7746\n",
      "Epoch 125/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7374 - acc: 0.7530 - val_loss: 0.6861 - val_acc: 0.7738\n",
      "Epoch 126/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7385 - acc: 0.7586 - val_loss: 0.6840 - val_acc: 0.7738\n",
      "Epoch 127/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7416 - acc: 0.7515 - val_loss: 0.6851 - val_acc: 0.7738\n",
      "Epoch 128/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7286 - acc: 0.7504 - val_loss: 0.6830 - val_acc: 0.7746\n",
      "Epoch 129/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7415 - acc: 0.7560 - val_loss: 0.6829 - val_acc: 0.7753\n",
      "Epoch 130/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7371 - acc: 0.7541 - val_loss: 0.6826 - val_acc: 0.7731\n",
      "Epoch 131/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7380 - acc: 0.7548 - val_loss: 0.6820 - val_acc: 0.7723\n",
      "Epoch 132/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7369 - acc: 0.7567 - val_loss: 0.6818 - val_acc: 0.7753\n",
      "Epoch 133/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7311 - acc: 0.7571 - val_loss: 0.6776 - val_acc: 0.7775\n",
      "Epoch 134/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7453 - acc: 0.7493 - val_loss: 0.6829 - val_acc: 0.7723\n",
      "Epoch 135/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7386 - acc: 0.7574 - val_loss: 0.6812 - val_acc: 0.7716\n",
      "Epoch 136/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7305 - acc: 0.7511 - val_loss: 0.6804 - val_acc: 0.7768\n",
      "Epoch 137/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7292 - acc: 0.7578 - val_loss: 0.6767 - val_acc: 0.7790\n",
      "Epoch 138/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7160 - acc: 0.7574 - val_loss: 0.6756 - val_acc: 0.7783\n",
      "Epoch 139/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7360 - acc: 0.7485 - val_loss: 0.6757 - val_acc: 0.7783\n",
      "Epoch 140/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7487 - acc: 0.7455 - val_loss: 0.6770 - val_acc: 0.7775\n",
      "Epoch 141/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7395 - acc: 0.7552 - val_loss: 0.6774 - val_acc: 0.7783\n",
      "Epoch 142/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7421 - acc: 0.7541 - val_loss: 0.6798 - val_acc: 0.7746\n",
      "Epoch 143/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7456 - acc: 0.7474 - val_loss: 0.6798 - val_acc: 0.7746\n",
      "Epoch 144/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7182 - acc: 0.7634 - val_loss: 0.6747 - val_acc: 0.7783\n",
      "Epoch 145/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7324 - acc: 0.7519 - val_loss: 0.6776 - val_acc: 0.7746\n",
      "Epoch 146/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7374 - acc: 0.7556 - val_loss: 0.6763 - val_acc: 0.7768\n",
      "Epoch 147/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7463 - acc: 0.7489 - val_loss: 0.6748 - val_acc: 0.7783\n",
      "Epoch 148/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7190 - acc: 0.7630 - val_loss: 0.6733 - val_acc: 0.7738\n",
      "Epoch 149/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7299 - acc: 0.7571 - val_loss: 0.6751 - val_acc: 0.7738\n",
      "Epoch 150/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7175 - acc: 0.7504 - val_loss: 0.6733 - val_acc: 0.7783\n",
      "Epoch 151/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7237 - acc: 0.7656 - val_loss: 0.6734 - val_acc: 0.7753\n",
      "Epoch 152/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7344 - acc: 0.7612 - val_loss: 0.6706 - val_acc: 0.7775\n",
      "Epoch 153/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7093 - acc: 0.7626 - val_loss: 0.6726 - val_acc: 0.7760\n",
      "Epoch 154/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7461 - acc: 0.7511 - val_loss: 0.6742 - val_acc: 0.7790\n",
      "Epoch 155/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7356 - acc: 0.7504 - val_loss: 0.6741 - val_acc: 0.7790\n",
      "Epoch 156/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7077 - acc: 0.7571 - val_loss: 0.6723 - val_acc: 0.7805\n",
      "Epoch 157/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7158 - acc: 0.7586 - val_loss: 0.6745 - val_acc: 0.7775\n",
      "Epoch 158/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7278 - acc: 0.7545 - val_loss: 0.6725 - val_acc: 0.7775\n",
      "Epoch 159/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7253 - acc: 0.7537 - val_loss: 0.6747 - val_acc: 0.7768\n",
      "Epoch 160/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7235 - acc: 0.7593 - val_loss: 0.6736 - val_acc: 0.7760\n",
      "Epoch 161/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7194 - acc: 0.7500 - val_loss: 0.6749 - val_acc: 0.7746\n",
      "Epoch 162/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7231 - acc: 0.7586 - val_loss: 0.6740 - val_acc: 0.7753\n",
      "Epoch 163/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7155 - acc: 0.7660 - val_loss: 0.6756 - val_acc: 0.7746\n",
      "Epoch 164/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7318 - acc: 0.7597 - val_loss: 0.6745 - val_acc: 0.7731\n",
      "Epoch 165/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7249 - acc: 0.7597 - val_loss: 0.6736 - val_acc: 0.7768\n",
      "\n",
      "Epoch 00165: loss improved from inf to 0.72487, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-2-000165-0.724868-0.776786.hdf5\n",
      "Epoch 166/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7298 - acc: 0.7533 - val_loss: 0.6754 - val_acc: 0.7760\n",
      "Epoch 167/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7131 - acc: 0.7623 - val_loss: 0.6635 - val_acc: 0.7760\n",
      "Epoch 168/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7200 - acc: 0.7467 - val_loss: 0.6711 - val_acc: 0.7753\n",
      "Epoch 169/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7365 - acc: 0.7552 - val_loss: 0.6734 - val_acc: 0.7746\n",
      "Epoch 170/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7137 - acc: 0.7571 - val_loss: 0.6699 - val_acc: 0.7805\n",
      "Epoch 171/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7213 - acc: 0.7586 - val_loss: 0.6712 - val_acc: 0.7768\n",
      "Epoch 172/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7213 - acc: 0.7511 - val_loss: 0.6711 - val_acc: 0.7768\n",
      "Epoch 173/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7292 - acc: 0.7600 - val_loss: 0.6714 - val_acc: 0.7753\n",
      "Epoch 174/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7281 - acc: 0.7496 - val_loss: 0.6738 - val_acc: 0.7760\n",
      "Epoch 175/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7269 - acc: 0.7533 - val_loss: 0.6696 - val_acc: 0.7768\n",
      "Epoch 176/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7102 - acc: 0.7619 - val_loss: 0.6705 - val_acc: 0.7768\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 177/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7031 - acc: 0.7623 - val_loss: 0.6603 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00177: loss improved from 0.72487 to 0.70306, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-2-000177-0.703062-0.779018.hdf5\n",
      "Epoch 178/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7193 - acc: 0.7586 - val_loss: 0.6695 - val_acc: 0.7760\n",
      "Epoch 179/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7100 - acc: 0.7608 - val_loss: 0.6692 - val_acc: 0.7760\n",
      "Epoch 180/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7130 - acc: 0.7608 - val_loss: 0.6692 - val_acc: 0.7775\n",
      "Epoch 181/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7150 - acc: 0.7641 - val_loss: 0.6701 - val_acc: 0.7746\n",
      "Epoch 182/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7118 - acc: 0.7645 - val_loss: 0.6673 - val_acc: 0.7760\n",
      "Epoch 183/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7083 - acc: 0.7548 - val_loss: 0.6701 - val_acc: 0.7746\n",
      "Epoch 184/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7351 - acc: 0.7545 - val_loss: 0.6670 - val_acc: 0.7753\n",
      "Epoch 185/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7226 - acc: 0.7645 - val_loss: 0.6708 - val_acc: 0.7738\n",
      "Epoch 186/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7151 - acc: 0.7638 - val_loss: 0.6678 - val_acc: 0.7760\n",
      "Epoch 187/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7115 - acc: 0.7567 - val_loss: 0.6691 - val_acc: 0.7753\n",
      "Epoch 188/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7146 - acc: 0.7634 - val_loss: 0.6695 - val_acc: 0.7753\n",
      "Epoch 189/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7097 - acc: 0.7548 - val_loss: 0.6663 - val_acc: 0.7746\n",
      "Epoch 190/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7250 - acc: 0.7507 - val_loss: 0.6667 - val_acc: 0.7790\n",
      "Epoch 191/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7171 - acc: 0.7608 - val_loss: 0.6687 - val_acc: 0.7768\n",
      "Epoch 192/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7075 - acc: 0.7693 - val_loss: 0.6662 - val_acc: 0.7798\n",
      "Epoch 193/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7214 - acc: 0.7556 - val_loss: 0.6688 - val_acc: 0.7760\n",
      "Epoch 194/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7068 - acc: 0.7604 - val_loss: 0.6672 - val_acc: 0.7760\n",
      "Epoch 195/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7082 - acc: 0.7619 - val_loss: 0.6684 - val_acc: 0.7746\n",
      "Epoch 196/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7185 - acc: 0.7560 - val_loss: 0.6693 - val_acc: 0.7746\n",
      "Epoch 197/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7195 - acc: 0.7612 - val_loss: 0.6696 - val_acc: 0.7753\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 198/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7177 - acc: 0.7589 - val_loss: 0.6700 - val_acc: 0.7738\n",
      "Epoch 199/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7087 - acc: 0.7548 - val_loss: 0.6705 - val_acc: 0.7738\n",
      "Epoch 200/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7077 - acc: 0.7556 - val_loss: 0.6701 - val_acc: 0.7746\n",
      "\n",
      "Epoch 00200: saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/2-000200-0.707682-0.774554.hdf5\n",
      "Epoch 201/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7074 - acc: 0.7552 - val_loss: 0.6696 - val_acc: 0.7760\n",
      "Epoch 202/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6987 - acc: 0.7645 - val_loss: 0.6699 - val_acc: 0.7753\n",
      "Epoch 203/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7052 - acc: 0.7604 - val_loss: 0.6665 - val_acc: 0.7768\n",
      "Epoch 204/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7140 - acc: 0.7578 - val_loss: 0.6694 - val_acc: 0.7760\n",
      "Epoch 205/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7107 - acc: 0.7634 - val_loss: 0.6682 - val_acc: 0.7760\n",
      "Epoch 206/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7185 - acc: 0.7563 - val_loss: 0.6693 - val_acc: 0.7753\n",
      "Epoch 207/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7125 - acc: 0.7634 - val_loss: 0.6684 - val_acc: 0.7760\n",
      "Epoch 208/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7170 - acc: 0.7552 - val_loss: 0.6698 - val_acc: 0.7753\n",
      "Epoch 209/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7159 - acc: 0.7586 - val_loss: 0.6696 - val_acc: 0.7753\n",
      "Epoch 210/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7124 - acc: 0.7552 - val_loss: 0.6696 - val_acc: 0.7753\n",
      "Epoch 211/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7123 - acc: 0.7552 - val_loss: 0.6692 - val_acc: 0.7760\n",
      "Epoch 212/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.6981 - acc: 0.7634 - val_loss: 0.6698 - val_acc: 0.7746\n",
      "Epoch 213/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7011 - acc: 0.7571 - val_loss: 0.6641 - val_acc: 0.7760\n",
      "Epoch 214/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7111 - acc: 0.7623 - val_loss: 0.6665 - val_acc: 0.7768\n",
      "Epoch 215/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7047 - acc: 0.7612 - val_loss: 0.6672 - val_acc: 0.7768\n",
      "Epoch 216/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7125 - acc: 0.7574 - val_loss: 0.6690 - val_acc: 0.7760\n",
      "Epoch 217/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7022 - acc: 0.7619 - val_loss: 0.6670 - val_acc: 0.7760\n",
      "Epoch 218/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.6999 - acc: 0.7612 - val_loss: 0.6663 - val_acc: 0.7768\n",
      "Epoch 219/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7096 - acc: 0.7630 - val_loss: 0.6687 - val_acc: 0.7760\n",
      "Epoch 220/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7088 - acc: 0.7548 - val_loss: 0.6649 - val_acc: 0.7775\n",
      "Epoch 221/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7215 - acc: 0.7560 - val_loss: 0.6691 - val_acc: 0.7753\n",
      "Epoch 222/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7202 - acc: 0.7634 - val_loss: 0.6655 - val_acc: 0.7768\n",
      "Epoch 223/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7357 - acc: 0.7537 - val_loss: 0.6687 - val_acc: 0.7760\n",
      "Epoch 224/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7146 - acc: 0.7619 - val_loss: 0.6679 - val_acc: 0.7760\n",
      "Epoch 225/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7240 - acc: 0.7593 - val_loss: 0.6694 - val_acc: 0.7753\n",
      "Epoch 226/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7093 - acc: 0.7541 - val_loss: 0.6678 - val_acc: 0.7753\n",
      "Epoch 227/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7242 - acc: 0.7511 - val_loss: 0.6693 - val_acc: 0.7746\n",
      "Epoch 228/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7071 - acc: 0.7634 - val_loss: 0.6691 - val_acc: 0.7746\n",
      "Epoch 229/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7075 - acc: 0.7578 - val_loss: 0.6694 - val_acc: 0.7746\n",
      "Epoch 230/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7066 - acc: 0.7634 - val_loss: 0.6692 - val_acc: 0.7753\n",
      "Epoch 231/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7086 - acc: 0.7615 - val_loss: 0.6698 - val_acc: 0.7746\n",
      "Epoch 232/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.6993 - acc: 0.7641 - val_loss: 0.6680 - val_acc: 0.7753\n",
      "\n",
      "Epoch 00232: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 233/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7058 - acc: 0.7664 - val_loss: 0.6673 - val_acc: 0.7760\n",
      "Epoch 234/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7020 - acc: 0.7645 - val_loss: 0.6683 - val_acc: 0.7753\n",
      "Epoch 235/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7093 - acc: 0.7552 - val_loss: 0.6697 - val_acc: 0.7746\n",
      "Epoch 236/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7105 - acc: 0.7649 - val_loss: 0.6693 - val_acc: 0.7746\n",
      "Epoch 237/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7165 - acc: 0.7586 - val_loss: 0.6671 - val_acc: 0.7753\n",
      "Epoch 238/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7108 - acc: 0.7600 - val_loss: 0.6684 - val_acc: 0.7760\n",
      "Epoch 239/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7168 - acc: 0.7556 - val_loss: 0.6680 - val_acc: 0.7753\n",
      "Epoch 240/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7113 - acc: 0.7641 - val_loss: 0.6686 - val_acc: 0.7753\n",
      "Epoch 241/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7205 - acc: 0.7597 - val_loss: 0.6683 - val_acc: 0.7753\n",
      "Epoch 242/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7009 - acc: 0.7597 - val_loss: 0.6694 - val_acc: 0.7746\n",
      "Epoch 243/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7162 - acc: 0.7589 - val_loss: 0.6687 - val_acc: 0.7753\n",
      "Epoch 244/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7162 - acc: 0.7600 - val_loss: 0.6695 - val_acc: 0.7738\n",
      "Epoch 245/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7121 - acc: 0.7567 - val_loss: 0.6681 - val_acc: 0.7746\n",
      "Epoch 246/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7241 - acc: 0.7619 - val_loss: 0.6693 - val_acc: 0.7738\n",
      "Epoch 247/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7124 - acc: 0.7634 - val_loss: 0.6658 - val_acc: 0.7746\n",
      "Epoch 248/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7159 - acc: 0.7560 - val_loss: 0.6693 - val_acc: 0.7738\n",
      "Epoch 249/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6996 - acc: 0.7582 - val_loss: 0.6694 - val_acc: 0.7738\n",
      "Epoch 250/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7062 - acc: 0.7608 - val_loss: 0.6679 - val_acc: 0.7753\n",
      "Epoch 251/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6963 - acc: 0.7682 - val_loss: 0.6690 - val_acc: 0.7738\n",
      "Epoch 252/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7141 - acc: 0.7604 - val_loss: 0.6649 - val_acc: 0.7753\n",
      "Epoch 253/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7135 - acc: 0.7615 - val_loss: 0.6673 - val_acc: 0.7753\n",
      "Epoch 254/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7220 - acc: 0.7600 - val_loss: 0.6683 - val_acc: 0.7746\n",
      "Epoch 255/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7135 - acc: 0.7671 - val_loss: 0.6678 - val_acc: 0.7746\n",
      "Epoch 256/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7162 - acc: 0.7563 - val_loss: 0.6693 - val_acc: 0.7738\n",
      "Epoch 257/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7216 - acc: 0.7560 - val_loss: 0.6653 - val_acc: 0.7753\n",
      "Epoch 258/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7034 - acc: 0.7682 - val_loss: 0.6688 - val_acc: 0.7738\n",
      "Epoch 259/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7343 - acc: 0.7526 - val_loss: 0.6699 - val_acc: 0.7738\n",
      "Epoch 260/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7255 - acc: 0.7649 - val_loss: 0.6686 - val_acc: 0.7746\n",
      "Epoch 261/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7184 - acc: 0.7589 - val_loss: 0.6667 - val_acc: 0.7753\n",
      "Epoch 262/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6986 - acc: 0.7626 - val_loss: 0.6657 - val_acc: 0.7753\n",
      "Epoch 263/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7241 - acc: 0.7571 - val_loss: 0.6684 - val_acc: 0.7746\n",
      "Epoch 264/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7266 - acc: 0.7519 - val_loss: 0.6687 - val_acc: 0.7738\n",
      "Epoch 265/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7196 - acc: 0.7519 - val_loss: 0.6693 - val_acc: 0.7738\n",
      "\n",
      "Epoch 00265: loss improved from inf to 0.71963, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-2-000265-0.719632-0.773810.hdf5\n",
      "Epoch 266/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7104 - acc: 0.7604 - val_loss: 0.6607 - val_acc: 0.7753\n",
      "Epoch 267/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7145 - acc: 0.7641 - val_loss: 0.6672 - val_acc: 0.7746\n",
      "Epoch 268/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7095 - acc: 0.7593 - val_loss: 0.6686 - val_acc: 0.7738\n",
      "Epoch 269/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7033 - acc: 0.7638 - val_loss: 0.6690 - val_acc: 0.7738\n",
      "\n",
      "Epoch 00269: loss improved from 0.71963 to 0.70329, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-2-000269-0.703287-0.773810.hdf5\n",
      "Epoch 270/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7091 - acc: 0.7604 - val_loss: 0.6680 - val_acc: 0.7746\n",
      "Epoch 271/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7193 - acc: 0.7615 - val_loss: 0.6687 - val_acc: 0.7746\n",
      "Epoch 272/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7024 - acc: 0.7578 - val_loss: 0.6680 - val_acc: 0.7746\n",
      "Epoch 273/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7035 - acc: 0.7582 - val_loss: 0.6679 - val_acc: 0.7746\n",
      "Epoch 274/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7216 - acc: 0.7630 - val_loss: 0.6686 - val_acc: 0.7746\n",
      "Epoch 275/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7155 - acc: 0.7593 - val_loss: 0.6692 - val_acc: 0.7738\n",
      "Epoch 276/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7067 - acc: 0.7630 - val_loss: 0.6684 - val_acc: 0.7746\n",
      "Epoch 277/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7053 - acc: 0.7660 - val_loss: 0.6681 - val_acc: 0.7746\n",
      "Epoch 278/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7000 - acc: 0.7686 - val_loss: 0.6680 - val_acc: 0.7746\n",
      "Epoch 279/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7066 - acc: 0.7530 - val_loss: 0.6684 - val_acc: 0.7738\n",
      "Epoch 280/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7126 - acc: 0.7556 - val_loss: 0.6699 - val_acc: 0.7738\n",
      "Epoch 281/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7030 - acc: 0.7664 - val_loss: 0.6696 - val_acc: 0.7738\n",
      "\n",
      "Epoch 00281: loss improved from 0.70329 to 0.70301, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-2-000281-0.703006-0.773810.hdf5\n",
      "Epoch 282/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7089 - acc: 0.7612 - val_loss: 0.6694 - val_acc: 0.7738\n",
      "Epoch 283/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7213 - acc: 0.7548 - val_loss: 0.6645 - val_acc: 0.7753\n",
      "Epoch 284/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7165 - acc: 0.7519 - val_loss: 0.6682 - val_acc: 0.7746\n",
      "Epoch 285/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7187 - acc: 0.7656 - val_loss: 0.6669 - val_acc: 0.7760\n",
      "Epoch 286/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7082 - acc: 0.7600 - val_loss: 0.6684 - val_acc: 0.7738\n",
      "Epoch 287/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7110 - acc: 0.7634 - val_loss: 0.6699 - val_acc: 0.7738\n",
      "Epoch 288/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7127 - acc: 0.7526 - val_loss: 0.6681 - val_acc: 0.7746\n",
      "Epoch 289/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7076 - acc: 0.7612 - val_loss: 0.6685 - val_acc: 0.7738\n",
      "Epoch 290/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7175 - acc: 0.7615 - val_loss: 0.6672 - val_acc: 0.7746\n",
      "Epoch 291/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7156 - acc: 0.7578 - val_loss: 0.6669 - val_acc: 0.7746\n",
      "Epoch 292/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7210 - acc: 0.7504 - val_loss: 0.6695 - val_acc: 0.7738\n",
      "Epoch 293/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7051 - acc: 0.7619 - val_loss: 0.6675 - val_acc: 0.7753\n",
      "Epoch 294/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7107 - acc: 0.7578 - val_loss: 0.6698 - val_acc: 0.7738\n",
      "Epoch 295/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7118 - acc: 0.7597 - val_loss: 0.6675 - val_acc: 0.7746\n",
      "Epoch 296/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7057 - acc: 0.7626 - val_loss: 0.6659 - val_acc: 0.7753\n",
      "Epoch 297/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7156 - acc: 0.7574 - val_loss: 0.6659 - val_acc: 0.7753\n",
      "Epoch 298/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7148 - acc: 0.7589 - val_loss: 0.6640 - val_acc: 0.7753\n",
      "Epoch 299/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7134 - acc: 0.7574 - val_loss: 0.6687 - val_acc: 0.7746\n",
      "Epoch 300/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7118 - acc: 0.7537 - val_loss: 0.6695 - val_acc: 0.7738\n",
      "\n",
      "Epoch 00300: saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/2-000300-0.711753-0.773810.hdf5\n",
      "Epoch 301/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7160 - acc: 0.7653 - val_loss: 0.6679 - val_acc: 0.7746\n",
      "Epoch 302/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.6990 - acc: 0.7679 - val_loss: 0.6691 - val_acc: 0.7738\n",
      "Epoch 303/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7051 - acc: 0.7593 - val_loss: 0.6666 - val_acc: 0.7753\n",
      "Epoch 304/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7174 - acc: 0.7567 - val_loss: 0.6676 - val_acc: 0.7753\n",
      "Epoch 305/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7182 - acc: 0.7589 - val_loss: 0.6682 - val_acc: 0.7746\n",
      "Epoch 306/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7094 - acc: 0.7615 - val_loss: 0.6674 - val_acc: 0.7753\n",
      "Epoch 307/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7111 - acc: 0.7571 - val_loss: 0.6677 - val_acc: 0.7753\n",
      "Epoch 308/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7249 - acc: 0.7522 - val_loss: 0.6677 - val_acc: 0.7746\n",
      "Epoch 309/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7218 - acc: 0.7578 - val_loss: 0.6698 - val_acc: 0.7738\n",
      "Epoch 310/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7046 - acc: 0.7664 - val_loss: 0.6697 - val_acc: 0.7738\n",
      "Epoch 311/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7075 - acc: 0.7612 - val_loss: 0.6690 - val_acc: 0.7738\n",
      "Epoch 312/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7149 - acc: 0.7612 - val_loss: 0.6687 - val_acc: 0.7746\n",
      "Epoch 313/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7146 - acc: 0.7567 - val_loss: 0.6694 - val_acc: 0.7738\n",
      "Epoch 314/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7123 - acc: 0.7615 - val_loss: 0.6670 - val_acc: 0.7753\n",
      "Epoch 315/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7155 - acc: 0.7589 - val_loss: 0.6697 - val_acc: 0.7738\n",
      "Epoch 316/1000\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.7218 - acc: 0.7586 - val_loss: 0.6683 - val_acc: 0.7738\n",
      "Epoch 317/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7186 - acc: 0.7593 - val_loss: 0.6687 - val_acc: 0.7738\n",
      "Epoch 318/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7051 - acc: 0.7630 - val_loss: 0.6695 - val_acc: 0.7738\n",
      "Epoch 319/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7101 - acc: 0.7604 - val_loss: 0.6652 - val_acc: 0.7760\n",
      "Epoch 320/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7048 - acc: 0.7604 - val_loss: 0.6690 - val_acc: 0.7738\n",
      "Epoch 321/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7055 - acc: 0.7682 - val_loss: 0.6694 - val_acc: 0.7738\n",
      "Epoch 322/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7258 - acc: 0.7478 - val_loss: 0.6674 - val_acc: 0.7746\n",
      "Epoch 323/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7144 - acc: 0.7608 - val_loss: 0.6685 - val_acc: 0.7746\n",
      "Epoch 324/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7126 - acc: 0.7556 - val_loss: 0.6680 - val_acc: 0.7746\n",
      "Epoch 325/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7001 - acc: 0.7641 - val_loss: 0.6666 - val_acc: 0.7753\n",
      "Epoch 326/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6988 - acc: 0.7653 - val_loss: 0.6655 - val_acc: 0.7753\n",
      "Epoch 327/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7167 - acc: 0.7500 - val_loss: 0.6660 - val_acc: 0.7753\n",
      "Epoch 328/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7210 - acc: 0.7608 - val_loss: 0.6689 - val_acc: 0.7738\n",
      "Epoch 329/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7131 - acc: 0.7664 - val_loss: 0.6678 - val_acc: 0.7753\n",
      "Epoch 330/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7164 - acc: 0.7589 - val_loss: 0.6688 - val_acc: 0.7738\n",
      "Epoch 331/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7083 - acc: 0.7645 - val_loss: 0.6688 - val_acc: 0.7738\n",
      "Epoch 332/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7301 - acc: 0.7478 - val_loss: 0.6695 - val_acc: 0.7738\n",
      "Epoch 333/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7013 - acc: 0.7645 - val_loss: 0.6688 - val_acc: 0.7738\n",
      "Epoch 334/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7250 - acc: 0.7634 - val_loss: 0.6665 - val_acc: 0.7753\n",
      "Epoch 335/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7020 - acc: 0.7612 - val_loss: 0.6602 - val_acc: 0.7753\n",
      "Epoch 336/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7191 - acc: 0.7571 - val_loss: 0.6683 - val_acc: 0.7746\n",
      "Epoch 337/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7106 - acc: 0.7530 - val_loss: 0.6668 - val_acc: 0.7753\n",
      "Epoch 338/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7165 - acc: 0.7530 - val_loss: 0.6690 - val_acc: 0.7738\n",
      "Epoch 339/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7189 - acc: 0.7526 - val_loss: 0.6664 - val_acc: 0.7746\n",
      "Epoch 340/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7158 - acc: 0.7560 - val_loss: 0.6682 - val_acc: 0.7746\n",
      "Epoch 341/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7072 - acc: 0.7597 - val_loss: 0.6679 - val_acc: 0.7746\n",
      "Epoch 342/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7156 - acc: 0.7533 - val_loss: 0.6679 - val_acc: 0.7753\n",
      "Epoch 343/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7172 - acc: 0.7619 - val_loss: 0.6661 - val_acc: 0.7753\n",
      "Epoch 344/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7175 - acc: 0.7515 - val_loss: 0.6675 - val_acc: 0.7746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 345/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7128 - acc: 0.7612 - val_loss: 0.6670 - val_acc: 0.7753\n",
      "Epoch 346/1000\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.7358 - acc: 0.7600 - val_loss: 0.6689 - val_acc: 0.7746\n",
      "Epoch 347/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7193 - acc: 0.7645 - val_loss: 0.6681 - val_acc: 0.7746\n",
      "Epoch 348/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.7138 - acc: 0.7519 - val_loss: 0.6654 - val_acc: 0.7760\n",
      "Epoch 349/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7175 - acc: 0.7537 - val_loss: 0.6670 - val_acc: 0.7753\n",
      "Epoch 350/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7182 - acc: 0.7530 - val_loss: 0.6690 - val_acc: 0.7738\n",
      "Epoch 351/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.7067 - acc: 0.7600 - val_loss: 0.6646 - val_acc: 0.7753\n",
      "Epoch 352/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.7186 - acc: 0.7548 - val_loss: 0.6696 - val_acc: 0.7738\n",
      "Epoch 353/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7240 - acc: 0.7533 - val_loss: 0.6677 - val_acc: 0.7746\n",
      "Epoch 354/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7045 - acc: 0.7619 - val_loss: 0.6687 - val_acc: 0.7746\n",
      "Epoch 355/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7205 - acc: 0.7563 - val_loss: 0.6678 - val_acc: 0.7746\n",
      "Epoch 356/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6952 - acc: 0.7679 - val_loss: 0.6698 - val_acc: 0.7738\n",
      "Epoch 357/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7133 - acc: 0.7563 - val_loss: 0.6663 - val_acc: 0.7753\n",
      "Epoch 358/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7214 - acc: 0.7571 - val_loss: 0.6688 - val_acc: 0.7738\n",
      "Epoch 359/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7140 - acc: 0.7626 - val_loss: 0.6696 - val_acc: 0.7738\n",
      "Epoch 360/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7013 - acc: 0.7630 - val_loss: 0.6688 - val_acc: 0.7746\n",
      "Epoch 361/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7119 - acc: 0.7626 - val_loss: 0.6691 - val_acc: 0.7738\n",
      "Epoch 362/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6988 - acc: 0.7656 - val_loss: 0.6688 - val_acc: 0.7738\n",
      "Epoch 363/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7201 - acc: 0.7619 - val_loss: 0.6682 - val_acc: 0.7746\n",
      "Epoch 364/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6982 - acc: 0.7600 - val_loss: 0.6652 - val_acc: 0.7753\n",
      "Epoch 365/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7248 - acc: 0.7481 - val_loss: 0.6693 - val_acc: 0.7738\n",
      "\n",
      "Epoch 00365: loss improved from inf to 0.72482, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-2-000365-0.724821-0.773810.hdf5\n",
      "Epoch 366/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6943 - acc: 0.7697 - val_loss: 0.6692 - val_acc: 0.7738\n",
      "Epoch 367/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7072 - acc: 0.7608 - val_loss: 0.6683 - val_acc: 0.7738\n",
      "Epoch 368/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7179 - acc: 0.7541 - val_loss: 0.6679 - val_acc: 0.7753\n",
      "Epoch 369/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7023 - acc: 0.7653 - val_loss: 0.6694 - val_acc: 0.7738\n",
      "\n",
      "Epoch 00369: loss improved from 0.72482 to 0.70229, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-2-000369-0.702294-0.773810.hdf5\n",
      "Epoch 370/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7160 - acc: 0.7600 - val_loss: 0.6699 - val_acc: 0.7738\n",
      "Epoch 371/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7119 - acc: 0.7563 - val_loss: 0.6691 - val_acc: 0.7738\n",
      "Epoch 372/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7118 - acc: 0.7626 - val_loss: 0.6677 - val_acc: 0.7746\n",
      "Epoch 373/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7219 - acc: 0.7556 - val_loss: 0.6648 - val_acc: 0.7753\n",
      "Epoch 374/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.7305 - acc: 0.7533 - val_loss: 0.6696 - val_acc: 0.7738\n",
      "Epoch 375/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7065 - acc: 0.7623 - val_loss: 0.6689 - val_acc: 0.7746\n",
      "Epoch 376/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7098 - acc: 0.7567 - val_loss: 0.6687 - val_acc: 0.7746\n",
      "Epoch 377/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7055 - acc: 0.7597 - val_loss: 0.6653 - val_acc: 0.7746\n",
      "Epoch 378/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7142 - acc: 0.7626 - val_loss: 0.6661 - val_acc: 0.7753\n",
      "Epoch 379/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7028 - acc: 0.7660 - val_loss: 0.6689 - val_acc: 0.7746\n",
      "Epoch 380/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7125 - acc: 0.7537 - val_loss: 0.6688 - val_acc: 0.7738\n",
      "Epoch 381/1000\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 0.7189 - acc: 0.7537 - val_loss: 0.6698 - val_acc: 0.7738\n",
      "Epoch 382/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7139 - acc: 0.7548 - val_loss: 0.6678 - val_acc: 0.7746\n",
      "Epoch 383/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7022 - acc: 0.7619 - val_loss: 0.6613 - val_acc: 0.7768\n",
      "Epoch 384/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7160 - acc: 0.7489 - val_loss: 0.6696 - val_acc: 0.7738\n",
      "Epoch 385/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7097 - acc: 0.7571 - val_loss: 0.6688 - val_acc: 0.7738\n",
      "Epoch 386/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7086 - acc: 0.7578 - val_loss: 0.6687 - val_acc: 0.7738\n",
      "Epoch 387/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7094 - acc: 0.7467 - val_loss: 0.6691 - val_acc: 0.7738\n",
      "Epoch 388/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7124 - acc: 0.7574 - val_loss: 0.6686 - val_acc: 0.7738\n",
      "Epoch 389/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7107 - acc: 0.7634 - val_loss: 0.6697 - val_acc: 0.7738\n",
      "Epoch 390/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7139 - acc: 0.7515 - val_loss: 0.6690 - val_acc: 0.7738\n",
      "Epoch 391/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7021 - acc: 0.7626 - val_loss: 0.6696 - val_acc: 0.7738\n",
      "Epoch 392/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7239 - acc: 0.7619 - val_loss: 0.6691 - val_acc: 0.7738\n",
      "Epoch 393/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7204 - acc: 0.7519 - val_loss: 0.6643 - val_acc: 0.7753\n",
      "Epoch 394/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7109 - acc: 0.7612 - val_loss: 0.6674 - val_acc: 0.7746\n",
      "Epoch 395/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7081 - acc: 0.7619 - val_loss: 0.6694 - val_acc: 0.7738\n",
      "Epoch 396/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7171 - acc: 0.7526 - val_loss: 0.6669 - val_acc: 0.7746\n",
      "Epoch 397/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7085 - acc: 0.7574 - val_loss: 0.6687 - val_acc: 0.7738\n",
      "Epoch 398/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7285 - acc: 0.7552 - val_loss: 0.6693 - val_acc: 0.7738\n",
      "Epoch 399/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7240 - acc: 0.7563 - val_loss: 0.6683 - val_acc: 0.7746\n",
      "Epoch 400/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7080 - acc: 0.7638 - val_loss: 0.6672 - val_acc: 0.7753\n",
      "\n",
      "Epoch 00400: saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/2-000400-0.707990-0.775298.hdf5\n",
      "Epoch 401/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7111 - acc: 0.7548 - val_loss: 0.6678 - val_acc: 0.7746\n",
      "Epoch 402/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7088 - acc: 0.7589 - val_loss: 0.6671 - val_acc: 0.7760\n",
      "Epoch 403/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7199 - acc: 0.7545 - val_loss: 0.6694 - val_acc: 0.7738\n",
      "Epoch 404/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6961 - acc: 0.7634 - val_loss: 0.6688 - val_acc: 0.7738\n",
      "Epoch 405/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7233 - acc: 0.7515 - val_loss: 0.6690 - val_acc: 0.7746\n",
      "Epoch 406/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7273 - acc: 0.7504 - val_loss: 0.6663 - val_acc: 0.7753\n",
      "Epoch 407/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6913 - acc: 0.7567 - val_loss: 0.6686 - val_acc: 0.7738\n",
      "Epoch 408/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7108 - acc: 0.7634 - val_loss: 0.6681 - val_acc: 0.7746\n",
      "Epoch 409/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7258 - acc: 0.7519 - val_loss: 0.6660 - val_acc: 0.7753\n",
      "Epoch 410/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7068 - acc: 0.7589 - val_loss: 0.6677 - val_acc: 0.7746\n",
      "Epoch 411/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7074 - acc: 0.7563 - val_loss: 0.6689 - val_acc: 0.7738\n",
      "Epoch 412/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7159 - acc: 0.7600 - val_loss: 0.6692 - val_acc: 0.7738\n",
      "Epoch 413/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7075 - acc: 0.7615 - val_loss: 0.6673 - val_acc: 0.7746\n",
      "Epoch 414/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7079 - acc: 0.7630 - val_loss: 0.6687 - val_acc: 0.7738\n",
      "Epoch 415/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7229 - acc: 0.7545 - val_loss: 0.6693 - val_acc: 0.7738\n",
      "Epoch 416/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6970 - acc: 0.7623 - val_loss: 0.6664 - val_acc: 0.7753\n",
      "Epoch 417/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7039 - acc: 0.7582 - val_loss: 0.6694 - val_acc: 0.7738\n",
      "Epoch 418/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7100 - acc: 0.7612 - val_loss: 0.6691 - val_acc: 0.7738\n",
      "Epoch 419/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7038 - acc: 0.7638 - val_loss: 0.6667 - val_acc: 0.7746\n",
      "Epoch 420/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7123 - acc: 0.7612 - val_loss: 0.6649 - val_acc: 0.7753\n",
      "Epoch 421/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7261 - acc: 0.7530 - val_loss: 0.6682 - val_acc: 0.7746\n",
      "Epoch 422/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7059 - acc: 0.7626 - val_loss: 0.6661 - val_acc: 0.7753\n",
      "Epoch 423/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7067 - acc: 0.7619 - val_loss: 0.6695 - val_acc: 0.7738\n",
      "Epoch 424/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7069 - acc: 0.7649 - val_loss: 0.6671 - val_acc: 0.7753\n",
      "Epoch 425/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7232 - acc: 0.7597 - val_loss: 0.6678 - val_acc: 0.7746\n",
      "Epoch 426/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7015 - acc: 0.7660 - val_loss: 0.6689 - val_acc: 0.7738\n",
      "Epoch 427/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7235 - acc: 0.7548 - val_loss: 0.6682 - val_acc: 0.7738\n",
      "Epoch 428/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6967 - acc: 0.7567 - val_loss: 0.6687 - val_acc: 0.7746\n",
      "Epoch 429/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7052 - acc: 0.7615 - val_loss: 0.6697 - val_acc: 0.7738\n",
      "Epoch 430/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7064 - acc: 0.7634 - val_loss: 0.6664 - val_acc: 0.7746\n",
      "Epoch 431/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7103 - acc: 0.7571 - val_loss: 0.6682 - val_acc: 0.7738\n",
      "Epoch 432/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7062 - acc: 0.7649 - val_loss: 0.6698 - val_acc: 0.7746\n",
      "Epoch 433/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7207 - acc: 0.7563 - val_loss: 0.6681 - val_acc: 0.7746\n",
      "Epoch 434/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7168 - acc: 0.7582 - val_loss: 0.6688 - val_acc: 0.7746\n",
      "Epoch 435/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7244 - acc: 0.7589 - val_loss: 0.6696 - val_acc: 0.7746\n",
      "Epoch 436/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7141 - acc: 0.7515 - val_loss: 0.6688 - val_acc: 0.7738\n",
      "Epoch 437/1000\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 0.7250 - acc: 0.7582 - val_loss: 0.6688 - val_acc: 0.7746\n",
      "Epoch 438/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7230 - acc: 0.7612 - val_loss: 0.6664 - val_acc: 0.7746\n",
      "Epoch 439/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7060 - acc: 0.7634 - val_loss: 0.6691 - val_acc: 0.7738\n",
      "Epoch 440/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7259 - acc: 0.7537 - val_loss: 0.6675 - val_acc: 0.7746\n",
      "Epoch 441/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7073 - acc: 0.7612 - val_loss: 0.6694 - val_acc: 0.7738\n",
      "Epoch 442/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7164 - acc: 0.7533 - val_loss: 0.6688 - val_acc: 0.7738\n",
      "Epoch 443/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7120 - acc: 0.7560 - val_loss: 0.6679 - val_acc: 0.7746\n",
      "Epoch 444/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7098 - acc: 0.7574 - val_loss: 0.6683 - val_acc: 0.7753\n",
      "Epoch 445/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7213 - acc: 0.7574 - val_loss: 0.6686 - val_acc: 0.7753\n",
      "Epoch 446/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7032 - acc: 0.7653 - val_loss: 0.6694 - val_acc: 0.7746\n",
      "Epoch 447/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7127 - acc: 0.7574 - val_loss: 0.6685 - val_acc: 0.7746\n",
      "Epoch 448/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7152 - acc: 0.7533 - val_loss: 0.6678 - val_acc: 0.7753\n",
      "Epoch 449/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7126 - acc: 0.7556 - val_loss: 0.6679 - val_acc: 0.7753\n",
      "Epoch 450/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6992 - acc: 0.7634 - val_loss: 0.6676 - val_acc: 0.7753\n",
      "Epoch 451/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7154 - acc: 0.7541 - val_loss: 0.6682 - val_acc: 0.7746\n",
      "Epoch 452/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7053 - acc: 0.7600 - val_loss: 0.6685 - val_acc: 0.7753\n",
      "Epoch 453/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7115 - acc: 0.7623 - val_loss: 0.6676 - val_acc: 0.7753\n",
      "Epoch 454/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7099 - acc: 0.7612 - val_loss: 0.6682 - val_acc: 0.7746\n",
      "Epoch 455/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7184 - acc: 0.7560 - val_loss: 0.6686 - val_acc: 0.7753\n",
      "Epoch 456/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7168 - acc: 0.7623 - val_loss: 0.6693 - val_acc: 0.7746\n",
      "Epoch 457/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6894 - acc: 0.7664 - val_loss: 0.6681 - val_acc: 0.7753\n",
      "Epoch 458/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7224 - acc: 0.7507 - val_loss: 0.6660 - val_acc: 0.7760\n",
      "Epoch 459/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7126 - acc: 0.7638 - val_loss: 0.6646 - val_acc: 0.7760\n",
      "Epoch 460/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7057 - acc: 0.7582 - val_loss: 0.6682 - val_acc: 0.7753\n",
      "Epoch 461/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7114 - acc: 0.7634 - val_loss: 0.6697 - val_acc: 0.7746\n",
      "Epoch 462/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6978 - acc: 0.7612 - val_loss: 0.6653 - val_acc: 0.7760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 463/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7103 - acc: 0.7548 - val_loss: 0.6689 - val_acc: 0.7746\n",
      "Epoch 464/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7115 - acc: 0.7560 - val_loss: 0.6695 - val_acc: 0.7746\n",
      "Epoch 465/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7053 - acc: 0.7578 - val_loss: 0.6694 - val_acc: 0.7746\n",
      "\n",
      "Epoch 00465: loss improved from inf to 0.70532, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-2-000465-0.705321-0.774554.hdf5\n",
      "Epoch 466/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7095 - acc: 0.7608 - val_loss: 0.6693 - val_acc: 0.7746\n",
      "Epoch 467/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7228 - acc: 0.7533 - val_loss: 0.6694 - val_acc: 0.7746\n",
      "Epoch 468/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7163 - acc: 0.7571 - val_loss: 0.6687 - val_acc: 0.7753\n",
      "Epoch 469/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6980 - acc: 0.7612 - val_loss: 0.6657 - val_acc: 0.7753\n",
      "\n",
      "Epoch 00469: loss improved from 0.70532 to 0.69805, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-2-000469-0.698049-0.775298.hdf5\n",
      "Epoch 470/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7236 - acc: 0.7571 - val_loss: 0.6687 - val_acc: 0.7746\n",
      "Epoch 471/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7098 - acc: 0.7615 - val_loss: 0.6687 - val_acc: 0.7746\n",
      "Epoch 472/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6836 - acc: 0.7638 - val_loss: 0.6678 - val_acc: 0.7753\n",
      "Epoch 473/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7054 - acc: 0.7593 - val_loss: 0.6670 - val_acc: 0.7753\n",
      "Epoch 474/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7128 - acc: 0.7541 - val_loss: 0.6682 - val_acc: 0.7753\n",
      "Epoch 475/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7112 - acc: 0.7571 - val_loss: 0.6681 - val_acc: 0.7746\n",
      "Epoch 476/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7075 - acc: 0.7600 - val_loss: 0.6650 - val_acc: 0.7760\n",
      "Epoch 477/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7006 - acc: 0.7608 - val_loss: 0.6662 - val_acc: 0.7760\n",
      "Epoch 478/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7195 - acc: 0.7638 - val_loss: 0.6688 - val_acc: 0.7746\n",
      "Epoch 479/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7010 - acc: 0.7612 - val_loss: 0.6686 - val_acc: 0.7753\n",
      "Epoch 480/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7084 - acc: 0.7608 - val_loss: 0.6688 - val_acc: 0.7746\n",
      "Epoch 481/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7084 - acc: 0.7608 - val_loss: 0.6688 - val_acc: 0.7746\n",
      "Epoch 482/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7221 - acc: 0.7496 - val_loss: 0.6693 - val_acc: 0.7746\n",
      "Epoch 483/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7250 - acc: 0.7586 - val_loss: 0.6681 - val_acc: 0.7753\n",
      "Epoch 484/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7081 - acc: 0.7626 - val_loss: 0.6672 - val_acc: 0.7760\n",
      "Epoch 485/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7015 - acc: 0.7626 - val_loss: 0.6675 - val_acc: 0.7753\n",
      "Epoch 486/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7060 - acc: 0.7615 - val_loss: 0.6693 - val_acc: 0.7746\n",
      "Epoch 487/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7112 - acc: 0.7597 - val_loss: 0.6680 - val_acc: 0.7753\n",
      "Epoch 488/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7134 - acc: 0.7645 - val_loss: 0.6677 - val_acc: 0.7753\n",
      "Epoch 489/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7066 - acc: 0.7664 - val_loss: 0.6625 - val_acc: 0.7760\n",
      "Epoch 490/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7126 - acc: 0.7578 - val_loss: 0.6689 - val_acc: 0.7746\n",
      "Epoch 491/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7086 - acc: 0.7615 - val_loss: 0.6683 - val_acc: 0.7753\n",
      "Epoch 492/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7107 - acc: 0.7511 - val_loss: 0.6683 - val_acc: 0.7753\n",
      "Epoch 493/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7190 - acc: 0.7578 - val_loss: 0.6671 - val_acc: 0.7753\n",
      "Epoch 494/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7232 - acc: 0.7560 - val_loss: 0.6672 - val_acc: 0.7753\n",
      "Epoch 495/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7227 - acc: 0.7653 - val_loss: 0.6660 - val_acc: 0.7760\n",
      "Epoch 496/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7190 - acc: 0.7567 - val_loss: 0.6684 - val_acc: 0.7746\n",
      "Epoch 497/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7087 - acc: 0.7571 - val_loss: 0.6667 - val_acc: 0.7753\n",
      "Epoch 498/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7160 - acc: 0.7541 - val_loss: 0.6681 - val_acc: 0.7753\n",
      "Epoch 499/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7234 - acc: 0.7630 - val_loss: 0.6691 - val_acc: 0.7746\n",
      "Epoch 500/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7079 - acc: 0.7560 - val_loss: 0.6657 - val_acc: 0.7760\n",
      "\n",
      "Epoch 00500: saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/2-000500-0.707937-0.776042.hdf5\n",
      "Epoch 501/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7256 - acc: 0.7519 - val_loss: 0.6692 - val_acc: 0.7746\n",
      "Epoch 502/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7103 - acc: 0.7612 - val_loss: 0.6632 - val_acc: 0.7768\n",
      "Epoch 503/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7104 - acc: 0.7638 - val_loss: 0.6663 - val_acc: 0.7760\n",
      "Epoch 504/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7042 - acc: 0.7634 - val_loss: 0.6687 - val_acc: 0.7746\n",
      "Epoch 505/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7058 - acc: 0.7623 - val_loss: 0.6691 - val_acc: 0.7746\n",
      "Epoch 506/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6915 - acc: 0.7634 - val_loss: 0.6653 - val_acc: 0.7768\n",
      "Epoch 507/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7075 - acc: 0.7522 - val_loss: 0.6692 - val_acc: 0.7746\n",
      "Epoch 508/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7150 - acc: 0.7533 - val_loss: 0.6666 - val_acc: 0.7760\n",
      "Epoch 509/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7160 - acc: 0.7563 - val_loss: 0.6683 - val_acc: 0.7753\n",
      "Epoch 510/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7196 - acc: 0.7600 - val_loss: 0.6682 - val_acc: 0.7746\n",
      "Epoch 511/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7231 - acc: 0.7545 - val_loss: 0.6676 - val_acc: 0.7753\n",
      "Epoch 512/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7156 - acc: 0.7612 - val_loss: 0.6660 - val_acc: 0.7753\n",
      "Epoch 513/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7249 - acc: 0.7623 - val_loss: 0.6693 - val_acc: 0.7746\n",
      "Epoch 514/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6996 - acc: 0.7708 - val_loss: 0.6686 - val_acc: 0.7753\n",
      "Epoch 515/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7123 - acc: 0.7623 - val_loss: 0.6677 - val_acc: 0.7753\n",
      "Epoch 516/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7224 - acc: 0.7578 - val_loss: 0.6688 - val_acc: 0.7746\n",
      "Epoch 517/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7172 - acc: 0.7690 - val_loss: 0.6693 - val_acc: 0.7746\n",
      "Epoch 518/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7097 - acc: 0.7586 - val_loss: 0.6636 - val_acc: 0.7760\n",
      "Epoch 519/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7157 - acc: 0.7667 - val_loss: 0.6666 - val_acc: 0.7753\n",
      "Epoch 520/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7274 - acc: 0.7485 - val_loss: 0.6687 - val_acc: 0.7753\n",
      "Epoch 521/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7193 - acc: 0.7519 - val_loss: 0.6686 - val_acc: 0.7746\n",
      "Epoch 522/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7180 - acc: 0.7556 - val_loss: 0.6672 - val_acc: 0.7760\n",
      "Epoch 523/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7116 - acc: 0.7582 - val_loss: 0.6694 - val_acc: 0.7746\n",
      "Epoch 524/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7056 - acc: 0.7612 - val_loss: 0.6693 - val_acc: 0.7746\n",
      "Epoch 525/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7040 - acc: 0.7656 - val_loss: 0.6688 - val_acc: 0.7753\n",
      "Epoch 526/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7066 - acc: 0.7560 - val_loss: 0.6648 - val_acc: 0.7760\n",
      "Epoch 527/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6970 - acc: 0.7675 - val_loss: 0.6659 - val_acc: 0.7753\n",
      "Epoch 528/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6962 - acc: 0.7641 - val_loss: 0.6664 - val_acc: 0.7760\n",
      "Epoch 529/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7155 - acc: 0.7530 - val_loss: 0.6672 - val_acc: 0.7753\n",
      "Epoch 530/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7030 - acc: 0.7653 - val_loss: 0.6684 - val_acc: 0.7753\n",
      "Epoch 531/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7030 - acc: 0.7560 - val_loss: 0.6661 - val_acc: 0.7760\n",
      "Epoch 532/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7248 - acc: 0.7511 - val_loss: 0.6694 - val_acc: 0.7746\n",
      "Epoch 533/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7241 - acc: 0.7619 - val_loss: 0.6664 - val_acc: 0.7760\n",
      "Epoch 534/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7373 - acc: 0.7519 - val_loss: 0.6668 - val_acc: 0.7753\n",
      "Epoch 535/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7309 - acc: 0.7600 - val_loss: 0.6642 - val_acc: 0.7768\n",
      "Epoch 536/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7065 - acc: 0.7589 - val_loss: 0.6679 - val_acc: 0.7753\n",
      "Epoch 537/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7026 - acc: 0.7634 - val_loss: 0.6684 - val_acc: 0.7753\n",
      "Epoch 538/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7034 - acc: 0.7619 - val_loss: 0.6677 - val_acc: 0.7753\n",
      "Epoch 539/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6948 - acc: 0.7656 - val_loss: 0.6683 - val_acc: 0.7753\n",
      "Epoch 540/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7170 - acc: 0.7533 - val_loss: 0.6670 - val_acc: 0.7753\n",
      "Epoch 541/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7160 - acc: 0.7567 - val_loss: 0.6692 - val_acc: 0.7746\n",
      "Epoch 542/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7190 - acc: 0.7634 - val_loss: 0.6680 - val_acc: 0.7753\n",
      "Epoch 543/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7202 - acc: 0.7563 - val_loss: 0.6693 - val_acc: 0.7746\n",
      "Epoch 544/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7061 - acc: 0.7679 - val_loss: 0.6690 - val_acc: 0.7746\n",
      "Epoch 545/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7085 - acc: 0.7574 - val_loss: 0.6692 - val_acc: 0.7746\n",
      "Epoch 546/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7057 - acc: 0.7567 - val_loss: 0.6679 - val_acc: 0.7753\n",
      "Epoch 547/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7194 - acc: 0.7586 - val_loss: 0.6634 - val_acc: 0.7768\n",
      "Epoch 548/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7212 - acc: 0.7552 - val_loss: 0.6645 - val_acc: 0.7768\n",
      "Epoch 549/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7183 - acc: 0.7515 - val_loss: 0.6690 - val_acc: 0.7746\n",
      "Epoch 550/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7063 - acc: 0.7608 - val_loss: 0.6665 - val_acc: 0.7768\n",
      "Epoch 551/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7022 - acc: 0.7589 - val_loss: 0.6663 - val_acc: 0.7760\n",
      "Epoch 552/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6962 - acc: 0.7574 - val_loss: 0.6694 - val_acc: 0.7746\n",
      "Epoch 553/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7338 - acc: 0.7530 - val_loss: 0.6644 - val_acc: 0.7760\n",
      "Epoch 554/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7095 - acc: 0.7545 - val_loss: 0.6674 - val_acc: 0.7753\n",
      "Epoch 555/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7219 - acc: 0.7615 - val_loss: 0.6573 - val_acc: 0.7775\n",
      "Epoch 556/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7164 - acc: 0.7641 - val_loss: 0.6683 - val_acc: 0.7753\n",
      "Epoch 557/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7182 - acc: 0.7556 - val_loss: 0.6690 - val_acc: 0.7746\n",
      "Epoch 558/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7019 - acc: 0.7679 - val_loss: 0.6694 - val_acc: 0.7746\n",
      "Epoch 559/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7183 - acc: 0.7567 - val_loss: 0.6675 - val_acc: 0.7753\n",
      "Epoch 560/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7204 - acc: 0.7522 - val_loss: 0.6696 - val_acc: 0.7746\n",
      "Epoch 561/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7065 - acc: 0.7608 - val_loss: 0.6690 - val_acc: 0.7746\n",
      "Epoch 562/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7179 - acc: 0.7563 - val_loss: 0.6694 - val_acc: 0.7746\n",
      "Epoch 563/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7163 - acc: 0.7574 - val_loss: 0.6667 - val_acc: 0.7753\n",
      "Epoch 564/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7160 - acc: 0.7574 - val_loss: 0.6694 - val_acc: 0.7746\n",
      "Epoch 565/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7158 - acc: 0.7630 - val_loss: 0.6687 - val_acc: 0.7746\n",
      "\n",
      "Epoch 00565: loss improved from inf to 0.71578, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-2-000565-0.715779-0.774554.hdf5\n",
      "Epoch 566/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7119 - acc: 0.7582 - val_loss: 0.6684 - val_acc: 0.7746\n",
      "Epoch 567/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6939 - acc: 0.7682 - val_loss: 0.6681 - val_acc: 0.7753\n",
      "Epoch 568/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7072 - acc: 0.7664 - val_loss: 0.6694 - val_acc: 0.7746\n",
      "Epoch 569/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7120 - acc: 0.7537 - val_loss: 0.6694 - val_acc: 0.7746\n",
      "\n",
      "Epoch 00569: loss improved from 0.71578 to 0.71195, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-2-000569-0.711951-0.774554.hdf5\n",
      "Epoch 570/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7134 - acc: 0.7574 - val_loss: 0.6672 - val_acc: 0.7753\n",
      "Epoch 571/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6991 - acc: 0.7552 - val_loss: 0.6669 - val_acc: 0.7760\n",
      "Epoch 572/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7237 - acc: 0.7556 - val_loss: 0.6692 - val_acc: 0.7746\n",
      "Epoch 573/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7213 - acc: 0.7530 - val_loss: 0.6660 - val_acc: 0.7760\n",
      "Epoch 574/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7075 - acc: 0.7552 - val_loss: 0.6659 - val_acc: 0.7760\n",
      "Epoch 575/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6959 - acc: 0.7653 - val_loss: 0.6691 - val_acc: 0.7746\n",
      "Epoch 576/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6979 - acc: 0.7697 - val_loss: 0.6652 - val_acc: 0.7760\n",
      "Epoch 577/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7104 - acc: 0.7574 - val_loss: 0.6690 - val_acc: 0.7746\n",
      "\n",
      "Epoch 00577: loss improved from 0.71195 to 0.71038, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-2-000577-0.710377-0.774554.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 578/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7119 - acc: 0.7653 - val_loss: 0.6686 - val_acc: 0.7746\n",
      "Epoch 579/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7109 - acc: 0.7578 - val_loss: 0.6691 - val_acc: 0.7746\n",
      "Epoch 580/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7236 - acc: 0.7615 - val_loss: 0.6686 - val_acc: 0.7746\n",
      "Epoch 581/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.7172 - acc: 0.7615 - val_loss: 0.6669 - val_acc: 0.7753\n",
      "Epoch 582/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7161 - acc: 0.7608 - val_loss: 0.6679 - val_acc: 0.7753\n",
      "Epoch 583/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7041 - acc: 0.7604 - val_loss: 0.6691 - val_acc: 0.7746\n",
      "Epoch 584/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7104 - acc: 0.7533 - val_loss: 0.6693 - val_acc: 0.7746\n",
      "Epoch 585/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7201 - acc: 0.7533 - val_loss: 0.6656 - val_acc: 0.7760\n",
      "Epoch 586/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7176 - acc: 0.7608 - val_loss: 0.6654 - val_acc: 0.7753\n",
      "Epoch 587/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7175 - acc: 0.7545 - val_loss: 0.6676 - val_acc: 0.7746\n",
      "Epoch 588/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7109 - acc: 0.7645 - val_loss: 0.6664 - val_acc: 0.7760\n",
      "Epoch 589/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7104 - acc: 0.7623 - val_loss: 0.6688 - val_acc: 0.7746\n",
      "Epoch 590/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7186 - acc: 0.7563 - val_loss: 0.6684 - val_acc: 0.7746\n",
      "Epoch 591/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7038 - acc: 0.7619 - val_loss: 0.6670 - val_acc: 0.7753\n",
      "Epoch 592/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7155 - acc: 0.7548 - val_loss: 0.6680 - val_acc: 0.7753\n",
      "Epoch 593/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7276 - acc: 0.7489 - val_loss: 0.6689 - val_acc: 0.7746\n",
      "Epoch 594/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7210 - acc: 0.7615 - val_loss: 0.6681 - val_acc: 0.7753\n",
      "Epoch 595/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7277 - acc: 0.7533 - val_loss: 0.6685 - val_acc: 0.7753\n",
      "Epoch 596/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6967 - acc: 0.7630 - val_loss: 0.6670 - val_acc: 0.7753\n",
      "Epoch 597/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7079 - acc: 0.7560 - val_loss: 0.6673 - val_acc: 0.7760\n",
      "\n",
      "Epoch 00597: loss improved from 0.71038 to 0.70794, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-2-000597-0.707937-0.776042.hdf5\n",
      "Epoch 598/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7242 - acc: 0.7530 - val_loss: 0.6664 - val_acc: 0.7760\n",
      "Epoch 599/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7024 - acc: 0.7608 - val_loss: 0.6669 - val_acc: 0.7760\n",
      "Epoch 600/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7255 - acc: 0.7571 - val_loss: 0.6683 - val_acc: 0.7746\n",
      "\n",
      "Epoch 00600: saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/2-000600-0.725479-0.774554.hdf5\n",
      "Epoch 601/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7200 - acc: 0.7545 - val_loss: 0.6691 - val_acc: 0.7746\n",
      "Epoch 602/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7257 - acc: 0.7530 - val_loss: 0.6647 - val_acc: 0.7753\n",
      "Epoch 603/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7152 - acc: 0.7597 - val_loss: 0.6685 - val_acc: 0.7753\n",
      "Epoch 604/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7036 - acc: 0.7619 - val_loss: 0.6679 - val_acc: 0.7753\n",
      "Epoch 605/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7088 - acc: 0.7634 - val_loss: 0.6673 - val_acc: 0.7753\n",
      "Epoch 606/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7101 - acc: 0.7630 - val_loss: 0.6683 - val_acc: 0.7753\n",
      "Epoch 607/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7187 - acc: 0.7556 - val_loss: 0.6667 - val_acc: 0.7760\n",
      "Epoch 608/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7105 - acc: 0.7623 - val_loss: 0.6672 - val_acc: 0.7753\n",
      "Epoch 609/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7281 - acc: 0.7593 - val_loss: 0.6656 - val_acc: 0.7753\n",
      "Epoch 610/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7111 - acc: 0.7582 - val_loss: 0.6676 - val_acc: 0.7753\n",
      "Epoch 611/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7024 - acc: 0.7604 - val_loss: 0.6661 - val_acc: 0.7753\n",
      "Epoch 612/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7007 - acc: 0.7638 - val_loss: 0.6678 - val_acc: 0.7753\n",
      "Epoch 613/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7186 - acc: 0.7504 - val_loss: 0.6663 - val_acc: 0.7753\n",
      "Epoch 614/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7068 - acc: 0.7641 - val_loss: 0.6689 - val_acc: 0.7746\n",
      "Epoch 615/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7132 - acc: 0.7593 - val_loss: 0.6680 - val_acc: 0.7753\n",
      "Epoch 616/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7117 - acc: 0.7563 - val_loss: 0.6662 - val_acc: 0.7768\n",
      "Epoch 617/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7217 - acc: 0.7645 - val_loss: 0.6691 - val_acc: 0.7746\n",
      "Epoch 618/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7189 - acc: 0.7552 - val_loss: 0.6684 - val_acc: 0.7753\n",
      "Epoch 619/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6960 - acc: 0.7656 - val_loss: 0.6681 - val_acc: 0.7753\n",
      "Epoch 620/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7203 - acc: 0.7533 - val_loss: 0.6693 - val_acc: 0.7746\n",
      "Epoch 621/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7111 - acc: 0.7586 - val_loss: 0.6691 - val_acc: 0.7746\n",
      "Epoch 622/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7163 - acc: 0.7552 - val_loss: 0.6690 - val_acc: 0.7753\n",
      "Epoch 623/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7206 - acc: 0.7578 - val_loss: 0.6675 - val_acc: 0.7760\n",
      "Epoch 624/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7038 - acc: 0.7615 - val_loss: 0.6674 - val_acc: 0.7753\n",
      "Epoch 625/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7138 - acc: 0.7548 - val_loss: 0.6662 - val_acc: 0.7760\n",
      "Epoch 626/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7042 - acc: 0.7600 - val_loss: 0.6676 - val_acc: 0.7753\n",
      "Epoch 627/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6913 - acc: 0.7578 - val_loss: 0.6654 - val_acc: 0.7760\n",
      "Epoch 628/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7141 - acc: 0.7571 - val_loss: 0.6688 - val_acc: 0.7746\n",
      "Epoch 629/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7007 - acc: 0.7671 - val_loss: 0.6690 - val_acc: 0.7746\n",
      "Epoch 630/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7115 - acc: 0.7567 - val_loss: 0.6673 - val_acc: 0.7753\n",
      "Epoch 631/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7164 - acc: 0.7496 - val_loss: 0.6686 - val_acc: 0.7753\n",
      "Epoch 632/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6995 - acc: 0.7645 - val_loss: 0.6663 - val_acc: 0.7760\n",
      "Epoch 633/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7090 - acc: 0.7589 - val_loss: 0.6680 - val_acc: 0.7753\n",
      "Epoch 634/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7004 - acc: 0.7608 - val_loss: 0.6689 - val_acc: 0.7746\n",
      "Epoch 635/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7304 - acc: 0.7552 - val_loss: 0.6694 - val_acc: 0.7746\n",
      "Epoch 636/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7049 - acc: 0.7630 - val_loss: 0.6688 - val_acc: 0.7746\n",
      "Epoch 637/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6970 - acc: 0.7701 - val_loss: 0.6674 - val_acc: 0.7753\n",
      "Epoch 638/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7090 - acc: 0.7600 - val_loss: 0.6685 - val_acc: 0.7753\n",
      "Epoch 639/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7154 - acc: 0.7593 - val_loss: 0.6684 - val_acc: 0.7753\n",
      "Epoch 640/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7176 - acc: 0.7574 - val_loss: 0.6683 - val_acc: 0.7746\n",
      "Epoch 641/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7154 - acc: 0.7589 - val_loss: 0.6692 - val_acc: 0.7746\n",
      "Epoch 642/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7122 - acc: 0.7593 - val_loss: 0.6674 - val_acc: 0.7753\n",
      "Epoch 643/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7055 - acc: 0.7567 - val_loss: 0.6687 - val_acc: 0.7746\n",
      "Epoch 644/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7032 - acc: 0.7600 - val_loss: 0.6646 - val_acc: 0.7768\n",
      "Epoch 645/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7125 - acc: 0.7619 - val_loss: 0.6661 - val_acc: 0.7760\n",
      "Epoch 646/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7211 - acc: 0.7571 - val_loss: 0.6674 - val_acc: 0.7753\n",
      "Epoch 647/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7066 - acc: 0.7526 - val_loss: 0.6684 - val_acc: 0.7753\n",
      "Epoch 648/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7219 - acc: 0.7593 - val_loss: 0.6672 - val_acc: 0.7760\n",
      "Epoch 649/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7159 - acc: 0.7604 - val_loss: 0.6691 - val_acc: 0.7746\n",
      "Epoch 650/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7080 - acc: 0.7612 - val_loss: 0.6680 - val_acc: 0.7753\n",
      "Epoch 651/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7087 - acc: 0.7574 - val_loss: 0.6677 - val_acc: 0.7753\n",
      "Epoch 652/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7124 - acc: 0.7563 - val_loss: 0.6685 - val_acc: 0.7746\n",
      "Epoch 653/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7141 - acc: 0.7567 - val_loss: 0.6682 - val_acc: 0.7753\n",
      "Epoch 654/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7204 - acc: 0.7597 - val_loss: 0.6694 - val_acc: 0.7746\n",
      "Epoch 655/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7060 - acc: 0.7660 - val_loss: 0.6655 - val_acc: 0.7768\n",
      "Epoch 656/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7159 - acc: 0.7615 - val_loss: 0.6674 - val_acc: 0.7753\n",
      "Epoch 657/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7038 - acc: 0.7615 - val_loss: 0.6659 - val_acc: 0.7760\n",
      "Epoch 658/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7235 - acc: 0.7545 - val_loss: 0.6627 - val_acc: 0.7768\n",
      "Epoch 659/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7087 - acc: 0.7675 - val_loss: 0.6675 - val_acc: 0.7753\n",
      "Epoch 660/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7018 - acc: 0.7582 - val_loss: 0.6646 - val_acc: 0.7760\n",
      "Epoch 661/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7247 - acc: 0.7496 - val_loss: 0.6688 - val_acc: 0.7746\n",
      "Epoch 662/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7082 - acc: 0.7645 - val_loss: 0.6680 - val_acc: 0.7753\n",
      "Epoch 663/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7072 - acc: 0.7615 - val_loss: 0.6654 - val_acc: 0.7760\n",
      "Epoch 664/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6944 - acc: 0.7693 - val_loss: 0.6677 - val_acc: 0.7753\n",
      "Epoch 665/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7047 - acc: 0.7608 - val_loss: 0.6665 - val_acc: 0.7753\n",
      "\n",
      "Epoch 00665: loss improved from inf to 0.70473, saving model to ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/Pbest-2-000665-0.704734-0.775298.hdf5\n",
      "Epoch 666/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7135 - acc: 0.7541 - val_loss: 0.6689 - val_acc: 0.7746\n",
      "Epoch 667/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6948 - acc: 0.7578 - val_loss: 0.6686 - val_acc: 0.7746\n",
      "Epoch 668/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7154 - acc: 0.7563 - val_loss: 0.6690 - val_acc: 0.7746\n",
      "Epoch 669/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7095 - acc: 0.7634 - val_loss: 0.6675 - val_acc: 0.7753\n",
      "Epoch 670/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7032 - acc: 0.7597 - val_loss: 0.6677 - val_acc: 0.7760\n",
      "Epoch 671/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7163 - acc: 0.7481 - val_loss: 0.6632 - val_acc: 0.7768\n",
      "Epoch 672/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7192 - acc: 0.7519 - val_loss: 0.6691 - val_acc: 0.7746\n",
      "Epoch 00672: early stopping\n",
      "ModelCheckpoint 已经保存到 ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/weights/2-final.hdf5\n",
      "save in: ../datasets/casas/results/WCNNR/milan/9999/20220201_2000_64_1_3_1/log/20220201_2000_64_1_3_1.csv\n",
      "time: 0:07:38 s\n",
      "time: 458.0 s\n",
      "average 0.458000 s\n",
      "2 epoch finished\n",
      "--------------------   best   --------------------\n",
      "no_activities: 10\n",
      "\n",
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1348/1348 [==============================] - 1s 480us/step\n",
      "2-milan:\tacc: 77.45%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 7, 9, 0, 0, 7, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 0, 7, 2, 2, 7, 7, 7, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 4, 7, 7, 7, 0, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 4, 0, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 0, 4, 7, 7, 4, 7, 7, 0, 7, 7, 4, 7, 0, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 9, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 4, 0, 0, 9, 0, 9, 9, 0, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 9, 0, 0, 9, 9, 9, 9, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 7, 5, 7, 7, 5, 7, 2, 2, 7, 0, 2, 2, 7, 7, 0, 0, 9, 0, 0, 5, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 7, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 4, 7, 0, 0, 0, 0, 0, 9, 9, 0, 7, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 7, 0, 7, 0, 7, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 4, 0, 9, 9, 0, 0, 0, 0, 4, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 7, 4, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 7, 0, 0, 0, 0, 0, 0, 5, 4, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 9, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 4, 4, 4, 4, 4, 4, 4, 0, 0, 4, 4, 4, 0, 4, 4, 4, 4, 4, 0, 4, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 4, 4, 4, 4, 0, 4, 0, 0, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 0, 7, 0, 0, 4, 0, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 0, 0, 4, 0, 4, 4, 4, 7, 4, 0, 0, 4, 4, 4, 4, 4, 0, 4, 4, 0, 4, 0, 4, 4, 4, 4, 0, 4, 4, 0, 4, 4, 7, 4, 4, 0, 0, 9, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 7, 9, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.774194  0.886035  0.826347       623\n",
      "         Work   0.000000  0.000000  0.000000        26\n",
      "Take_medicine   1.000000  0.300000  0.461538        20\n",
      "        Sleep   0.000000  0.000000  0.000000        32\n",
      "        Relax   0.773196  0.524476  0.625000       143\n",
      "   Leave_Home   0.902778  0.915493  0.909091        71\n",
      "          Eat   0.000000  0.000000  0.000000         7\n",
      "         Cook   0.738318  0.854054  0.791980       185\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        29\n",
      "      Bathing   0.764228  0.886792  0.820961       212\n",
      "\n",
      "     accuracy                       0.774481      1348\n",
      "    macro avg   0.495271  0.436685  0.443492      1348\n",
      " weighted avg   0.723733  0.774481  0.740746      1348\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  28   0   0   1   0   0]\n",
      " [  0   0   0   0   1   3   0  22   0   0]\n",
      " [  0   0   0   0   0   2   0   5   0   0]\n",
      " [  0   0   0   6   0  11   2   1   0   0]\n",
      " [  0   0   0   0 188   2   0  21   1   0]\n",
      " [  0   0   0   0   1 158   0  20   6   0]\n",
      " [  0   0   0   0   1   0  65   5   0   0]\n",
      " [  0   0   0   0  21  30   5 552  15   0]\n",
      " [  0   0   0   0   1   7   0  60  75   0]\n",
      " [  0   0   0   0   5   1   0  26   0   0]]\n",
      "--------------------   final   --------------------\n",
      "no_activities: 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1348/1348 [==============================] - 1s 512us/step\n",
      "2-milan:\tacc: 77.52%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 7, 9, 0, 0, 7, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 0, 7, 2, 2, 7, 7, 7, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 4, 7, 7, 7, 0, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 4, 0, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 0, 4, 7, 7, 4, 7, 7, 0, 7, 7, 4, 7, 0, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 9, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 4, 7, 0, 9, 0, 9, 9, 0, 0, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 9, 0, 0, 9, 9, 9, 9, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 7, 5, 7, 7, 5, 7, 2, 2, 7, 0, 2, 2, 7, 7, 0, 0, 9, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 7, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 4, 7, 0, 0, 0, 0, 0, 9, 9, 0, 7, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 7, 0, 7, 0, 7, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 4, 0, 9, 9, 0, 0, 0, 0, 4, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 7, 4, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 7, 0, 0, 0, 0, 0, 0, 5, 4, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 9, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 4, 4, 4, 4, 4, 4, 4, 0, 0, 4, 4, 4, 0, 4, 4, 4, 4, 4, 0, 4, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 4, 4, 4, 4, 0, 4, 0, 0, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 0, 7, 0, 0, 4, 0, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 0, 0, 4, 0, 4, 4, 4, 7, 4, 0, 0, 4, 4, 4, 4, 4, 0, 4, 4, 0, 4, 0, 4, 4, 4, 4, 0, 4, 4, 0, 4, 4, 7, 4, 4, 0, 0, 9, 0, 0, 0, 7, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 9, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 7, 9, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.777778  0.887640  0.829085       623\n",
      "         Work   0.000000  0.000000  0.000000        26\n",
      "Take_medicine   1.000000  0.300000  0.461538        20\n",
      "        Sleep   0.000000  0.000000  0.000000        32\n",
      "        Relax   0.773196  0.524476  0.625000       143\n",
      "   Leave_Home   0.902778  0.915493  0.909091        71\n",
      "          Eat   0.000000  0.000000  0.000000         7\n",
      "         Cook   0.731481  0.854054  0.788030       185\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        29\n",
      "      Bathing   0.764228  0.886792  0.820961       212\n",
      "\n",
      "     accuracy                       0.775223      1348\n",
      "    macro avg   0.494946  0.436846  0.443371      1348\n",
      " weighted avg   0.724451  0.775223  0.741469      1348\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  28   0   0   1   0   0]\n",
      " [  0   0   0   0   1   3   0  22   0   0]\n",
      " [  0   0   0   0   0   2   0   5   0   0]\n",
      " [  0   0   0   6   0  11   2   1   0   0]\n",
      " [  0   0   0   0 188   4   0  19   1   0]\n",
      " [  0   0   0   0   1 158   0  20   6   0]\n",
      " [  0   0   0   0   1   0  65   5   0   0]\n",
      " [  0   0   0   0  21  29   5 553  15   0]\n",
      " [  0   0   0   0   1   7   0  60  75   0]\n",
      " [  0   0   0   0   5   2   0  25   0   0]]\n",
      "best: current database: milan \t 76.14% (+/- 1.06%)\n",
      "final: current database: milan \t 76.49% (+/- 0.73%)\n",
      "CPU times: user 32min 2s, sys: 2min 3s, total: 34min 5s\n",
      "Wall time: 31min 25s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dict_config_cus['distance_int'] = '9999'\n",
    "train_val(dict_config_cus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "scrolled": true
   },
   "source": [
    "```bash\n",
    "best: current database: milan \t 77.48% (+/- 1.45%)\n",
    "final: current database: milan \t 77.45% (+/- 1.39%)\n",
    "CPU times: user 40min 11s, sys: 1min 43s, total: 41min 54s\n",
    "Wall time: 45min\n",
    "\n",
    "best: current database: milan \t 76.14% (+/- 1.06%)\n",
    "final: current database: milan \t 76.49% (+/- 0.73%)\n",
    "CPU times: user 32min 2s, sys: 2min 3s, total: 34min 5s\n",
    "Wall time: 31min 25s\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='constrain'>C</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current dataset: milan\n",
      "../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1\n",
      "no_activities: 10\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_10 (Embedding)     (None, 2000, 64)          172544    \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 2000, 12)          780       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 2000, 12)          0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_10 (Glo (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 18)                234       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 12)                228       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 10)                130       \n",
      "=================================================================\n",
      "Total params: 173,916\n",
      "Trainable params: 173,916\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Create subdir directory: ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights...\n",
      "Begin training ...\n",
      "Epoch 1/1000\n",
      "42/42 [==============================] - 2s 52ms/step - loss: 1.8539 - acc: 0.4568 - val_loss: 1.4394 - val_acc: 0.5454\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.3718 - acc: 0.5856 - val_loss: 1.1221 - val_acc: 0.6659\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.2341 - acc: 0.6220 - val_loss: 1.0158 - val_acc: 0.6682\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.1524 - acc: 0.6324 - val_loss: 0.9568 - val_acc: 0.7165\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0949 - acc: 0.6551 - val_loss: 0.9101 - val_acc: 0.7351\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0698 - acc: 0.6771 - val_loss: 0.8796 - val_acc: 0.7366\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0368 - acc: 0.6838 - val_loss: 0.8537 - val_acc: 0.7500\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.0195 - acc: 0.6871 - val_loss: 0.8381 - val_acc: 0.7567\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0062 - acc: 0.6927 - val_loss: 0.8068 - val_acc: 0.7604\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9768 - acc: 0.6894 - val_loss: 0.7942 - val_acc: 0.7626\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9592 - acc: 0.7016 - val_loss: 0.7826 - val_acc: 0.7589\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9468 - acc: 0.7020 - val_loss: 0.7632 - val_acc: 0.7626\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9337 - acc: 0.7098 - val_loss: 0.7484 - val_acc: 0.7656\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9297 - acc: 0.7020 - val_loss: 0.7424 - val_acc: 0.7671\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9092 - acc: 0.7169 - val_loss: 0.7354 - val_acc: 0.7619\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8888 - acc: 0.7128 - val_loss: 0.7260 - val_acc: 0.7686\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8860 - acc: 0.7210 - val_loss: 0.7192 - val_acc: 0.7649\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8796 - acc: 0.7247 - val_loss: 0.7149 - val_acc: 0.7649\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8905 - acc: 0.7050 - val_loss: 0.7059 - val_acc: 0.7693\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8707 - acc: 0.7225 - val_loss: 0.7030 - val_acc: 0.7641\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8652 - acc: 0.7262 - val_loss: 0.6987 - val_acc: 0.7619\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8627 - acc: 0.7210 - val_loss: 0.6920 - val_acc: 0.7634\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8593 - acc: 0.7195 - val_loss: 0.6899 - val_acc: 0.7604\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8467 - acc: 0.7247 - val_loss: 0.6916 - val_acc: 0.7604\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8404 - acc: 0.7288 - val_loss: 0.6826 - val_acc: 0.7679\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8382 - acc: 0.7147 - val_loss: 0.6771 - val_acc: 0.7686\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8262 - acc: 0.7329 - val_loss: 0.6786 - val_acc: 0.7693\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8255 - acc: 0.7228 - val_loss: 0.6696 - val_acc: 0.7679\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8083 - acc: 0.7262 - val_loss: 0.6660 - val_acc: 0.7649\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8064 - acc: 0.7236 - val_loss: 0.6703 - val_acc: 0.7701\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8151 - acc: 0.7284 - val_loss: 0.6641 - val_acc: 0.7671\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8258 - acc: 0.7273 - val_loss: 0.6651 - val_acc: 0.7679\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8122 - acc: 0.7284 - val_loss: 0.6607 - val_acc: 0.7693\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8092 - acc: 0.7314 - val_loss: 0.6590 - val_acc: 0.7738\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8248 - acc: 0.7314 - val_loss: 0.6600 - val_acc: 0.7731\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8005 - acc: 0.7359 - val_loss: 0.6575 - val_acc: 0.7679\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7985 - acc: 0.7366 - val_loss: 0.6562 - val_acc: 0.7775\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7876 - acc: 0.7333 - val_loss: 0.6520 - val_acc: 0.7746\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8098 - acc: 0.7336 - val_loss: 0.6487 - val_acc: 0.7775\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7939 - acc: 0.7325 - val_loss: 0.6515 - val_acc: 0.7746\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7894 - acc: 0.7299 - val_loss: 0.6475 - val_acc: 0.7775\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7896 - acc: 0.7333 - val_loss: 0.6476 - val_acc: 0.7738\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7782 - acc: 0.7362 - val_loss: 0.6452 - val_acc: 0.7738\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7955 - acc: 0.7362 - val_loss: 0.6442 - val_acc: 0.7731\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7870 - acc: 0.7347 - val_loss: 0.6406 - val_acc: 0.7812\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7794 - acc: 0.7359 - val_loss: 0.6444 - val_acc: 0.7753\n",
      "Epoch 47/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7807 - acc: 0.7392 - val_loss: 0.6427 - val_acc: 0.7820\n",
      "Epoch 48/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7845 - acc: 0.7303 - val_loss: 0.6399 - val_acc: 0.7835\n",
      "Epoch 49/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7700 - acc: 0.7474 - val_loss: 0.6376 - val_acc: 0.7850\n",
      "Epoch 50/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8002 - acc: 0.7273 - val_loss: 0.6382 - val_acc: 0.7805\n",
      "Epoch 51/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7730 - acc: 0.7344 - val_loss: 0.6357 - val_acc: 0.7820\n",
      "Epoch 52/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7698 - acc: 0.7407 - val_loss: 0.6369 - val_acc: 0.7835\n",
      "Epoch 53/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7723 - acc: 0.7411 - val_loss: 0.6370 - val_acc: 0.7798\n",
      "Epoch 54/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7606 - acc: 0.7385 - val_loss: 0.6350 - val_acc: 0.7812\n",
      "Epoch 55/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7744 - acc: 0.7381 - val_loss: 0.6324 - val_acc: 0.7805\n",
      "Epoch 56/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7691 - acc: 0.7370 - val_loss: 0.6346 - val_acc: 0.7768\n",
      "Epoch 57/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7709 - acc: 0.7388 - val_loss: 0.6327 - val_acc: 0.7820\n",
      "Epoch 58/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7604 - acc: 0.7388 - val_loss: 0.6331 - val_acc: 0.7835\n",
      "Epoch 59/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7594 - acc: 0.7429 - val_loss: 0.6268 - val_acc: 0.7827\n",
      "Epoch 60/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7503 - acc: 0.7467 - val_loss: 0.6291 - val_acc: 0.7835\n",
      "Epoch 61/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7693 - acc: 0.7385 - val_loss: 0.6275 - val_acc: 0.7798\n",
      "Epoch 62/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7466 - acc: 0.7485 - val_loss: 0.6292 - val_acc: 0.7820\n",
      "Epoch 63/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7345 - acc: 0.7444 - val_loss: 0.6277 - val_acc: 0.7835\n",
      "Epoch 64/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7579 - acc: 0.7414 - val_loss: 0.6301 - val_acc: 0.7812\n",
      "Epoch 65/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7479 - acc: 0.7474 - val_loss: 0.6285 - val_acc: 0.7827\n",
      "\n",
      "Epoch 00065: loss improved from inf to 0.74789, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-0-000065-0.747887-0.782738.hdf5\n",
      "Epoch 66/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7670 - acc: 0.7366 - val_loss: 0.6284 - val_acc: 0.7835\n",
      "Epoch 67/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7365 - acc: 0.7422 - val_loss: 0.6272 - val_acc: 0.7842\n",
      "Epoch 68/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7489 - acc: 0.7444 - val_loss: 0.6288 - val_acc: 0.7842\n",
      "Epoch 69/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7455 - acc: 0.7455 - val_loss: 0.6265 - val_acc: 0.7835\n",
      "\n",
      "Epoch 00069: loss improved from 0.74789 to 0.74554, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-0-000069-0.745539-0.783482.hdf5\n",
      "Epoch 70/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7490 - acc: 0.7444 - val_loss: 0.6224 - val_acc: 0.7865\n",
      "Epoch 71/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7299 - acc: 0.7548 - val_loss: 0.6204 - val_acc: 0.7842\n",
      "Epoch 72/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7531 - acc: 0.7426 - val_loss: 0.6209 - val_acc: 0.7857\n",
      "Epoch 73/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7437 - acc: 0.7504 - val_loss: 0.6256 - val_acc: 0.7835\n",
      "\n",
      "Epoch 00073: loss improved from 0.74554 to 0.74366, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-0-000073-0.743663-0.783482.hdf5\n",
      "Epoch 74/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7395 - acc: 0.7403 - val_loss: 0.6225 - val_acc: 0.7842\n",
      "Epoch 75/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7352 - acc: 0.7429 - val_loss: 0.6211 - val_acc: 0.7857\n",
      "Epoch 76/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7406 - acc: 0.7485 - val_loss: 0.6196 - val_acc: 0.7857\n",
      "Epoch 77/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7441 - acc: 0.7467 - val_loss: 0.6236 - val_acc: 0.7798\n",
      "Epoch 78/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7434 - acc: 0.7374 - val_loss: 0.6212 - val_acc: 0.7835\n",
      "Epoch 79/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7413 - acc: 0.7548 - val_loss: 0.6182 - val_acc: 0.7835\n",
      "Epoch 80/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7351 - acc: 0.7459 - val_loss: 0.6176 - val_acc: 0.7857\n",
      "Epoch 81/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7432 - acc: 0.7485 - val_loss: 0.6188 - val_acc: 0.7850\n",
      "\n",
      "Epoch 00081: loss improved from 0.74366 to 0.74321, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-0-000081-0.743206-0.784970.hdf5\n",
      "Epoch 82/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7376 - acc: 0.7545 - val_loss: 0.6188 - val_acc: 0.7850\n",
      "Epoch 83/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7271 - acc: 0.7467 - val_loss: 0.6168 - val_acc: 0.7842\n",
      "Epoch 84/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7430 - acc: 0.7418 - val_loss: 0.6180 - val_acc: 0.7835\n",
      "Epoch 85/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7307 - acc: 0.7440 - val_loss: 0.6145 - val_acc: 0.7842\n",
      "\n",
      "Epoch 00085: loss improved from 0.74321 to 0.73073, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-0-000085-0.730728-0.784226.hdf5\n",
      "Epoch 86/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7333 - acc: 0.7396 - val_loss: 0.6160 - val_acc: 0.7820\n",
      "Epoch 87/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7397 - acc: 0.7392 - val_loss: 0.6182 - val_acc: 0.7842\n",
      "Epoch 88/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7375 - acc: 0.7496 - val_loss: 0.6186 - val_acc: 0.7842\n",
      "Epoch 89/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7207 - acc: 0.7515 - val_loss: 0.6185 - val_acc: 0.7850\n",
      "\n",
      "Epoch 00089: loss improved from 0.73073 to 0.72068, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-0-000089-0.720678-0.784970.hdf5\n",
      "Epoch 90/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7159 - acc: 0.7496 - val_loss: 0.6100 - val_acc: 0.7872\n",
      "Epoch 91/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7281 - acc: 0.7478 - val_loss: 0.6149 - val_acc: 0.7850\n",
      "Epoch 92/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7359 - acc: 0.7467 - val_loss: 0.6164 - val_acc: 0.7842\n",
      "Epoch 93/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7395 - acc: 0.7467 - val_loss: 0.6149 - val_acc: 0.7827\n",
      "Epoch 94/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7140 - acc: 0.7537 - val_loss: 0.6132 - val_acc: 0.7835\n",
      "Epoch 95/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7312 - acc: 0.7489 - val_loss: 0.6151 - val_acc: 0.7865\n",
      "Epoch 96/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7157 - acc: 0.7481 - val_loss: 0.6116 - val_acc: 0.7827\n",
      "Epoch 97/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7266 - acc: 0.7467 - val_loss: 0.6122 - val_acc: 0.7820\n",
      "Epoch 98/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7223 - acc: 0.7511 - val_loss: 0.6127 - val_acc: 0.7827\n",
      "Epoch 99/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7244 - acc: 0.7437 - val_loss: 0.6121 - val_acc: 0.7865\n",
      "Epoch 100/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7232 - acc: 0.7493 - val_loss: 0.6126 - val_acc: 0.7835\n",
      "\n",
      "Epoch 00100: saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/0-000100-0.723168-0.783482.hdf5\n",
      "Epoch 101/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7268 - acc: 0.7437 - val_loss: 0.6110 - val_acc: 0.7820\n",
      "Epoch 102/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7256 - acc: 0.7522 - val_loss: 0.6118 - val_acc: 0.7850\n",
      "Epoch 103/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7264 - acc: 0.7496 - val_loss: 0.6118 - val_acc: 0.7812\n",
      "Epoch 104/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7343 - acc: 0.7444 - val_loss: 0.6127 - val_acc: 0.7820\n",
      "Epoch 105/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7211 - acc: 0.7481 - val_loss: 0.6137 - val_acc: 0.7857\n",
      "Epoch 106/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7156 - acc: 0.7418 - val_loss: 0.6123 - val_acc: 0.7842\n",
      "Epoch 107/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7263 - acc: 0.7526 - val_loss: 0.6100 - val_acc: 0.7842\n",
      "Epoch 108/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7322 - acc: 0.7429 - val_loss: 0.6119 - val_acc: 0.7850\n",
      "Epoch 109/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7115 - acc: 0.7563 - val_loss: 0.6098 - val_acc: 0.7812\n",
      "Epoch 110/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7112 - acc: 0.7507 - val_loss: 0.6117 - val_acc: 0.7812\n",
      "Epoch 111/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7146 - acc: 0.7511 - val_loss: 0.6102 - val_acc: 0.7805\n",
      "Epoch 112/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7094 - acc: 0.7481 - val_loss: 0.6113 - val_acc: 0.7805\n",
      "Epoch 113/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7057 - acc: 0.7556 - val_loss: 0.6111 - val_acc: 0.7820\n",
      "Epoch 114/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7117 - acc: 0.7504 - val_loss: 0.6088 - val_acc: 0.7812\n",
      "Epoch 115/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7174 - acc: 0.7493 - val_loss: 0.6109 - val_acc: 0.7820\n",
      "Epoch 116/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7252 - acc: 0.7459 - val_loss: 0.6101 - val_acc: 0.7827\n",
      "Epoch 117/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7157 - acc: 0.7504 - val_loss: 0.6091 - val_acc: 0.7805\n",
      "Epoch 118/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7024 - acc: 0.7504 - val_loss: 0.6062 - val_acc: 0.7820\n",
      "Epoch 119/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7206 - acc: 0.7507 - val_loss: 0.6088 - val_acc: 0.7835\n",
      "Epoch 120/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7186 - acc: 0.7526 - val_loss: 0.6082 - val_acc: 0.7857\n",
      "Epoch 121/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7027 - acc: 0.7470 - val_loss: 0.6080 - val_acc: 0.7805\n",
      "Epoch 122/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7133 - acc: 0.7433 - val_loss: 0.6104 - val_acc: 0.7812\n",
      "Epoch 123/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7165 - acc: 0.7426 - val_loss: 0.6095 - val_acc: 0.7805\n",
      "Epoch 124/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6909 - acc: 0.7600 - val_loss: 0.6061 - val_acc: 0.7805\n",
      "Epoch 125/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7031 - acc: 0.7515 - val_loss: 0.6036 - val_acc: 0.7812\n",
      "Epoch 126/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7166 - acc: 0.7440 - val_loss: 0.6067 - val_acc: 0.7820\n",
      "Epoch 127/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7174 - acc: 0.7548 - val_loss: 0.6079 - val_acc: 0.7820\n",
      "Epoch 128/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7035 - acc: 0.7493 - val_loss: 0.6050 - val_acc: 0.7842\n",
      "Epoch 129/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7122 - acc: 0.7500 - val_loss: 0.6068 - val_acc: 0.7812\n",
      "Epoch 130/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7070 - acc: 0.7478 - val_loss: 0.6073 - val_acc: 0.7827\n",
      "Epoch 131/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7147 - acc: 0.7533 - val_loss: 0.6048 - val_acc: 0.7827\n",
      "Epoch 132/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6965 - acc: 0.7545 - val_loss: 0.6035 - val_acc: 0.7805\n",
      "Epoch 133/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7066 - acc: 0.7489 - val_loss: 0.6069 - val_acc: 0.7820\n",
      "Epoch 134/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7153 - acc: 0.7533 - val_loss: 0.6010 - val_acc: 0.7842\n",
      "Epoch 135/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7034 - acc: 0.7537 - val_loss: 0.6009 - val_acc: 0.7827\n",
      "Epoch 136/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6888 - acc: 0.7567 - val_loss: 0.6022 - val_acc: 0.7835\n",
      "Epoch 137/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7117 - acc: 0.7485 - val_loss: 0.6034 - val_acc: 0.7805\n",
      "Epoch 138/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7116 - acc: 0.7489 - val_loss: 0.6056 - val_acc: 0.7798\n",
      "Epoch 139/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7029 - acc: 0.7519 - val_loss: 0.6033 - val_acc: 0.7812\n",
      "Epoch 140/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7050 - acc: 0.7511 - val_loss: 0.6020 - val_acc: 0.7820\n",
      "Epoch 141/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6973 - acc: 0.7597 - val_loss: 0.6017 - val_acc: 0.7805\n",
      "Epoch 142/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7034 - acc: 0.7489 - val_loss: 0.6003 - val_acc: 0.7798\n",
      "Epoch 143/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7185 - acc: 0.7440 - val_loss: 0.6030 - val_acc: 0.7812\n",
      "Epoch 144/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6995 - acc: 0.7563 - val_loss: 0.6023 - val_acc: 0.7798\n",
      "Epoch 145/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7107 - acc: 0.7474 - val_loss: 0.6053 - val_acc: 0.7798\n",
      "Epoch 146/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6990 - acc: 0.7526 - val_loss: 0.6031 - val_acc: 0.7835\n",
      "Epoch 147/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7083 - acc: 0.7463 - val_loss: 0.6026 - val_acc: 0.7850\n",
      "Epoch 148/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7029 - acc: 0.7615 - val_loss: 0.6033 - val_acc: 0.7805\n",
      "Epoch 149/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6969 - acc: 0.7545 - val_loss: 0.5998 - val_acc: 0.7820\n",
      "Epoch 150/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7054 - acc: 0.7478 - val_loss: 0.6011 - val_acc: 0.7835\n",
      "Epoch 151/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7012 - acc: 0.7541 - val_loss: 0.6036 - val_acc: 0.7798\n",
      "Epoch 152/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7025 - acc: 0.7511 - val_loss: 0.6037 - val_acc: 0.7805\n",
      "Epoch 153/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6919 - acc: 0.7600 - val_loss: 0.6019 - val_acc: 0.7805\n",
      "Epoch 154/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6919 - acc: 0.7597 - val_loss: 0.6017 - val_acc: 0.7827\n",
      "Epoch 155/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7078 - acc: 0.7504 - val_loss: 0.6025 - val_acc: 0.7812\n",
      "Epoch 156/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6993 - acc: 0.7507 - val_loss: 0.6016 - val_acc: 0.7805\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 157/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7000 - acc: 0.7582 - val_loss: 0.6005 - val_acc: 0.7820\n",
      "Epoch 158/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7106 - acc: 0.7470 - val_loss: 0.6027 - val_acc: 0.7798\n",
      "Epoch 159/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7008 - acc: 0.7537 - val_loss: 0.6002 - val_acc: 0.7827\n",
      "Epoch 160/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6807 - acc: 0.7515 - val_loss: 0.6015 - val_acc: 0.7820\n",
      "Epoch 161/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7036 - acc: 0.7519 - val_loss: 0.5999 - val_acc: 0.7827\n",
      "Epoch 162/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7112 - acc: 0.7489 - val_loss: 0.6003 - val_acc: 0.7812\n",
      "Epoch 163/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6890 - acc: 0.7493 - val_loss: 0.6020 - val_acc: 0.7805\n",
      "Epoch 164/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6911 - acc: 0.7571 - val_loss: 0.5991 - val_acc: 0.7827\n",
      "Epoch 165/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6998 - acc: 0.7507 - val_loss: 0.5998 - val_acc: 0.7812\n",
      "\n",
      "Epoch 00165: loss improved from inf to 0.69979, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-0-000165-0.699788-0.781250.hdf5\n",
      "Epoch 166/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7052 - acc: 0.7560 - val_loss: 0.5966 - val_acc: 0.7827\n",
      "Epoch 167/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6997 - acc: 0.7533 - val_loss: 0.6006 - val_acc: 0.7812\n",
      "Epoch 168/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6824 - acc: 0.7619 - val_loss: 0.5997 - val_acc: 0.7820\n",
      "Epoch 169/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6895 - acc: 0.7638 - val_loss: 0.5991 - val_acc: 0.7812\n",
      "\n",
      "Epoch 00169: loss improved from 0.69979 to 0.68955, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-0-000169-0.689547-0.781250.hdf5\n",
      "Epoch 170/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6916 - acc: 0.7519 - val_loss: 0.5966 - val_acc: 0.7820\n",
      "Epoch 171/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6888 - acc: 0.7511 - val_loss: 0.6018 - val_acc: 0.7798\n",
      "Epoch 172/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6892 - acc: 0.7511 - val_loss: 0.6007 - val_acc: 0.7805\n",
      "Epoch 173/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6882 - acc: 0.7623 - val_loss: 0.6000 - val_acc: 0.7812\n",
      "\n",
      "Epoch 00173: loss improved from 0.68955 to 0.68824, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-0-000173-0.688239-0.781250.hdf5\n",
      "Epoch 174/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6887 - acc: 0.7507 - val_loss: 0.5999 - val_acc: 0.7812\n",
      "Epoch 175/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6926 - acc: 0.7567 - val_loss: 0.5988 - val_acc: 0.7820\n",
      "Epoch 176/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6987 - acc: 0.7511 - val_loss: 0.6004 - val_acc: 0.7812\n",
      "Epoch 177/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6947 - acc: 0.7545 - val_loss: 0.6013 - val_acc: 0.7805\n",
      "Epoch 178/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6954 - acc: 0.7522 - val_loss: 0.5973 - val_acc: 0.7835\n",
      "Epoch 179/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7051 - acc: 0.7493 - val_loss: 0.6004 - val_acc: 0.7820\n",
      "Epoch 180/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6848 - acc: 0.7571 - val_loss: 0.6004 - val_acc: 0.7820\n",
      "\n",
      "Epoch 00180: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 181/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6938 - acc: 0.7630 - val_loss: 0.6003 - val_acc: 0.7805\n",
      "Epoch 182/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6876 - acc: 0.7537 - val_loss: 0.6012 - val_acc: 0.7805\n",
      "Epoch 183/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6844 - acc: 0.7626 - val_loss: 0.6016 - val_acc: 0.7805\n",
      "Epoch 184/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7010 - acc: 0.7418 - val_loss: 0.5962 - val_acc: 0.7820\n",
      "Epoch 185/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6698 - acc: 0.7649 - val_loss: 0.5993 - val_acc: 0.7820\n",
      "\n",
      "Epoch 00185: loss improved from 0.68824 to 0.66977, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-0-000185-0.669775-0.781994.hdf5\n",
      "Epoch 186/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6945 - acc: 0.7519 - val_loss: 0.6003 - val_acc: 0.7812\n",
      "Epoch 187/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6998 - acc: 0.7530 - val_loss: 0.5968 - val_acc: 0.7827\n",
      "Epoch 188/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7051 - acc: 0.7511 - val_loss: 0.6007 - val_acc: 0.7805\n",
      "Epoch 189/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7024 - acc: 0.7515 - val_loss: 0.5995 - val_acc: 0.7820\n",
      "Epoch 190/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6790 - acc: 0.7560 - val_loss: 0.5999 - val_acc: 0.7820\n",
      "Epoch 191/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6883 - acc: 0.7556 - val_loss: 0.6007 - val_acc: 0.7820\n",
      "Epoch 192/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6847 - acc: 0.7537 - val_loss: 0.5982 - val_acc: 0.7820\n",
      "Epoch 193/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6975 - acc: 0.7526 - val_loss: 0.6003 - val_acc: 0.7812\n",
      "Epoch 194/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7059 - acc: 0.7489 - val_loss: 0.5971 - val_acc: 0.7827\n",
      "Epoch 195/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6836 - acc: 0.7578 - val_loss: 0.6012 - val_acc: 0.7812\n",
      "Epoch 196/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6924 - acc: 0.7563 - val_loss: 0.6014 - val_acc: 0.7812\n",
      "Epoch 197/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6891 - acc: 0.7530 - val_loss: 0.5994 - val_acc: 0.7820\n",
      "Epoch 198/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6885 - acc: 0.7552 - val_loss: 0.6006 - val_acc: 0.7812\n",
      "Epoch 199/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6789 - acc: 0.7552 - val_loss: 0.6013 - val_acc: 0.7812\n",
      "Epoch 200/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7026 - acc: 0.7541 - val_loss: 0.6008 - val_acc: 0.7812\n",
      "\n",
      "Epoch 00200: saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/0-000200-0.702606-0.781250.hdf5\n",
      "Epoch 201/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6880 - acc: 0.7574 - val_loss: 0.6002 - val_acc: 0.7820\n",
      "Epoch 202/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6880 - acc: 0.7597 - val_loss: 0.6001 - val_acc: 0.7820\n",
      "Epoch 203/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6887 - acc: 0.7612 - val_loss: 0.6014 - val_acc: 0.7812\n",
      "Epoch 204/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6811 - acc: 0.7619 - val_loss: 0.6006 - val_acc: 0.7812\n",
      "Epoch 205/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6962 - acc: 0.7526 - val_loss: 0.5995 - val_acc: 0.7812\n",
      "\n",
      "Epoch 00205: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 206/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6891 - acc: 0.7545 - val_loss: 0.6013 - val_acc: 0.7812\n",
      "Epoch 207/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6839 - acc: 0.7560 - val_loss: 0.5990 - val_acc: 0.7827\n",
      "Epoch 208/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6879 - acc: 0.7571 - val_loss: 0.6006 - val_acc: 0.7812\n",
      "Epoch 209/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6885 - acc: 0.7567 - val_loss: 0.5995 - val_acc: 0.7820\n",
      "Epoch 210/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6943 - acc: 0.7422 - val_loss: 0.6005 - val_acc: 0.7812\n",
      "Epoch 211/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6838 - acc: 0.7578 - val_loss: 0.5994 - val_acc: 0.7827\n",
      "Epoch 212/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6813 - acc: 0.7560 - val_loss: 0.6007 - val_acc: 0.7812\n",
      "Epoch 213/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6991 - acc: 0.7489 - val_loss: 0.5988 - val_acc: 0.7827\n",
      "Epoch 214/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6959 - acc: 0.7511 - val_loss: 0.5984 - val_acc: 0.7827\n",
      "Epoch 215/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6969 - acc: 0.7567 - val_loss: 0.5999 - val_acc: 0.7820\n",
      "Epoch 216/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7078 - acc: 0.7437 - val_loss: 0.5978 - val_acc: 0.7827\n",
      "Epoch 217/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6903 - acc: 0.7522 - val_loss: 0.6004 - val_acc: 0.7812\n",
      "Epoch 218/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6910 - acc: 0.7541 - val_loss: 0.5986 - val_acc: 0.7827\n",
      "Epoch 219/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6921 - acc: 0.7623 - val_loss: 0.5997 - val_acc: 0.7820\n",
      "Epoch 220/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6921 - acc: 0.7586 - val_loss: 0.6008 - val_acc: 0.7812\n",
      "Epoch 221/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6954 - acc: 0.7537 - val_loss: 0.6010 - val_acc: 0.7812\n",
      "Epoch 222/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6902 - acc: 0.7574 - val_loss: 0.6004 - val_acc: 0.7812\n",
      "Epoch 223/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6841 - acc: 0.7571 - val_loss: 0.6013 - val_acc: 0.7812\n",
      "Epoch 224/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6986 - acc: 0.7511 - val_loss: 0.5962 - val_acc: 0.7827\n",
      "Epoch 225/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6853 - acc: 0.7537 - val_loss: 0.5999 - val_acc: 0.7820\n",
      "Epoch 226/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6967 - acc: 0.7530 - val_loss: 0.6008 - val_acc: 0.7812\n",
      "Epoch 227/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6794 - acc: 0.7530 - val_loss: 0.6005 - val_acc: 0.7812\n",
      "Epoch 228/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7004 - acc: 0.7515 - val_loss: 0.5983 - val_acc: 0.7827\n",
      "Epoch 229/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6879 - acc: 0.7537 - val_loss: 0.6011 - val_acc: 0.7812\n",
      "Epoch 230/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7042 - acc: 0.7519 - val_loss: 0.5995 - val_acc: 0.7820\n",
      "Epoch 231/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6916 - acc: 0.7515 - val_loss: 0.6003 - val_acc: 0.7820\n",
      "Epoch 232/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6994 - acc: 0.7463 - val_loss: 0.5991 - val_acc: 0.7820\n",
      "Epoch 233/1000\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 0.7012 - acc: 0.7511 - val_loss: 0.6005 - val_acc: 0.7812\n",
      "Epoch 234/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6925 - acc: 0.7582 - val_loss: 0.6012 - val_acc: 0.7812\n",
      "Epoch 235/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6997 - acc: 0.7511 - val_loss: 0.5995 - val_acc: 0.7827\n",
      "Epoch 236/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6881 - acc: 0.7571 - val_loss: 0.6007 - val_acc: 0.7812\n",
      "Epoch 237/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6762 - acc: 0.7604 - val_loss: 0.6006 - val_acc: 0.7812\n",
      "Epoch 238/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7057 - acc: 0.7504 - val_loss: 0.5976 - val_acc: 0.7835\n",
      "Epoch 239/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6774 - acc: 0.7619 - val_loss: 0.6015 - val_acc: 0.7812\n",
      "Epoch 240/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6854 - acc: 0.7563 - val_loss: 0.5997 - val_acc: 0.7820\n",
      "Epoch 241/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6927 - acc: 0.7500 - val_loss: 0.5961 - val_acc: 0.7827\n",
      "Epoch 242/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6952 - acc: 0.7522 - val_loss: 0.5985 - val_acc: 0.7827\n",
      "Epoch 243/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6956 - acc: 0.7511 - val_loss: 0.5995 - val_acc: 0.7820\n",
      "Epoch 244/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6896 - acc: 0.7459 - val_loss: 0.5984 - val_acc: 0.7827\n",
      "Epoch 245/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6946 - acc: 0.7481 - val_loss: 0.5988 - val_acc: 0.7827\n",
      "Epoch 246/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6819 - acc: 0.7526 - val_loss: 0.5995 - val_acc: 0.7820\n",
      "Epoch 247/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7077 - acc: 0.7496 - val_loss: 0.6013 - val_acc: 0.7812\n",
      "Epoch 248/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6874 - acc: 0.7511 - val_loss: 0.5991 - val_acc: 0.7820\n",
      "Epoch 249/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6884 - acc: 0.7556 - val_loss: 0.5970 - val_acc: 0.7835\n",
      "Epoch 250/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6905 - acc: 0.7582 - val_loss: 0.6004 - val_acc: 0.7820\n",
      "Epoch 251/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6892 - acc: 0.7626 - val_loss: 0.5991 - val_acc: 0.7827\n",
      "Epoch 252/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6967 - acc: 0.7560 - val_loss: 0.6009 - val_acc: 0.7812\n",
      "Epoch 253/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6968 - acc: 0.7526 - val_loss: 0.6013 - val_acc: 0.7812\n",
      "Epoch 254/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6992 - acc: 0.7556 - val_loss: 0.6000 - val_acc: 0.7820\n",
      "Epoch 255/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6878 - acc: 0.7485 - val_loss: 0.6016 - val_acc: 0.7812\n",
      "Epoch 256/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7073 - acc: 0.7467 - val_loss: 0.6000 - val_acc: 0.7820\n",
      "Epoch 257/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6869 - acc: 0.7537 - val_loss: 0.5998 - val_acc: 0.7820\n",
      "Epoch 258/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7041 - acc: 0.7463 - val_loss: 0.6009 - val_acc: 0.7812\n",
      "Epoch 259/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6823 - acc: 0.7578 - val_loss: 0.6011 - val_acc: 0.7812\n",
      "Epoch 260/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7054 - acc: 0.7455 - val_loss: 0.5985 - val_acc: 0.7827\n",
      "Epoch 261/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6943 - acc: 0.7537 - val_loss: 0.5988 - val_acc: 0.7820\n",
      "Epoch 262/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7018 - acc: 0.7474 - val_loss: 0.5942 - val_acc: 0.7850\n",
      "Epoch 263/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6878 - acc: 0.7574 - val_loss: 0.5998 - val_acc: 0.7820\n",
      "Epoch 264/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6942 - acc: 0.7552 - val_loss: 0.5978 - val_acc: 0.7827\n",
      "Epoch 265/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6864 - acc: 0.7578 - val_loss: 0.6010 - val_acc: 0.7812\n",
      "\n",
      "Epoch 00265: loss improved from inf to 0.68640, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-0-000265-0.686401-0.781250.hdf5\n",
      "Epoch 266/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6825 - acc: 0.7630 - val_loss: 0.6004 - val_acc: 0.7820\n",
      "Epoch 267/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7045 - acc: 0.7474 - val_loss: 0.5948 - val_acc: 0.7827\n",
      "Epoch 268/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6912 - acc: 0.7615 - val_loss: 0.6002 - val_acc: 0.7820\n",
      "Epoch 269/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6934 - acc: 0.7571 - val_loss: 0.6005 - val_acc: 0.7820\n",
      "Epoch 270/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6942 - acc: 0.7563 - val_loss: 0.6008 - val_acc: 0.7812\n",
      "Epoch 271/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7047 - acc: 0.7489 - val_loss: 0.5973 - val_acc: 0.7827\n",
      "Epoch 272/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6895 - acc: 0.7545 - val_loss: 0.5979 - val_acc: 0.7827\n",
      "Epoch 273/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6998 - acc: 0.7515 - val_loss: 0.5988 - val_acc: 0.7827\n",
      "Epoch 274/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6895 - acc: 0.7560 - val_loss: 0.5991 - val_acc: 0.7827\n",
      "Epoch 275/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7028 - acc: 0.7504 - val_loss: 0.5990 - val_acc: 0.7827\n",
      "Epoch 276/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7060 - acc: 0.7470 - val_loss: 0.6008 - val_acc: 0.7812\n",
      "Epoch 277/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6915 - acc: 0.7545 - val_loss: 0.6004 - val_acc: 0.7820\n",
      "Epoch 278/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6930 - acc: 0.7600 - val_loss: 0.5956 - val_acc: 0.7827\n",
      "Epoch 279/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6876 - acc: 0.7515 - val_loss: 0.6005 - val_acc: 0.7820\n",
      "Epoch 280/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6798 - acc: 0.7619 - val_loss: 0.5955 - val_acc: 0.7835\n",
      "Epoch 281/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6955 - acc: 0.7582 - val_loss: 0.6012 - val_acc: 0.7812\n",
      "Epoch 282/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7021 - acc: 0.7519 - val_loss: 0.5986 - val_acc: 0.7827\n",
      "Epoch 283/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6807 - acc: 0.7608 - val_loss: 0.5983 - val_acc: 0.7820\n",
      "Epoch 284/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6960 - acc: 0.7556 - val_loss: 0.5994 - val_acc: 0.7820\n",
      "Epoch 285/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6930 - acc: 0.7574 - val_loss: 0.6014 - val_acc: 0.7812\n",
      "Epoch 286/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7036 - acc: 0.7500 - val_loss: 0.6009 - val_acc: 0.7812\n",
      "Epoch 287/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6914 - acc: 0.7619 - val_loss: 0.6005 - val_acc: 0.7820\n",
      "Epoch 288/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6933 - acc: 0.7623 - val_loss: 0.5989 - val_acc: 0.7827\n",
      "Epoch 289/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6910 - acc: 0.7563 - val_loss: 0.6007 - val_acc: 0.7820\n",
      "Epoch 290/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6903 - acc: 0.7511 - val_loss: 0.5963 - val_acc: 0.7827\n",
      "Epoch 291/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7033 - acc: 0.7511 - val_loss: 0.6003 - val_acc: 0.7820\n",
      "Epoch 292/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7040 - acc: 0.7374 - val_loss: 0.5992 - val_acc: 0.7820\n",
      "Epoch 293/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6875 - acc: 0.7530 - val_loss: 0.5983 - val_acc: 0.7827\n",
      "Epoch 294/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6849 - acc: 0.7567 - val_loss: 0.6003 - val_acc: 0.7820\n",
      "Epoch 295/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.6890 - acc: 0.7560 - val_loss: 0.5995 - val_acc: 0.7827\n",
      "Epoch 296/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7029 - acc: 0.7467 - val_loss: 0.5995 - val_acc: 0.7827\n",
      "Epoch 297/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6920 - acc: 0.7545 - val_loss: 0.6008 - val_acc: 0.7820\n",
      "Epoch 298/1000\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.7059 - acc: 0.7548 - val_loss: 0.6009 - val_acc: 0.7812\n",
      "Epoch 299/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6883 - acc: 0.7586 - val_loss: 0.6011 - val_acc: 0.7812\n",
      "Epoch 300/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6896 - acc: 0.7556 - val_loss: 0.5994 - val_acc: 0.7820\n",
      "\n",
      "Epoch 00300: saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/0-000300-0.689591-0.781994.hdf5\n",
      "Epoch 301/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6784 - acc: 0.7600 - val_loss: 0.5979 - val_acc: 0.7827\n",
      "Epoch 302/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6866 - acc: 0.7515 - val_loss: 0.5990 - val_acc: 0.7820\n",
      "Epoch 303/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6890 - acc: 0.7653 - val_loss: 0.5999 - val_acc: 0.7827\n",
      "Epoch 304/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6876 - acc: 0.7571 - val_loss: 0.5993 - val_acc: 0.7820\n",
      "Epoch 305/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6952 - acc: 0.7574 - val_loss: 0.5997 - val_acc: 0.7820\n",
      "Epoch 306/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6991 - acc: 0.7567 - val_loss: 0.6001 - val_acc: 0.7820\n",
      "Epoch 307/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7090 - acc: 0.7444 - val_loss: 0.5990 - val_acc: 0.7827\n",
      "Epoch 308/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6829 - acc: 0.7597 - val_loss: 0.6004 - val_acc: 0.7812\n",
      "Epoch 309/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6768 - acc: 0.7545 - val_loss: 0.6012 - val_acc: 0.7812\n",
      "Epoch 310/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7013 - acc: 0.7515 - val_loss: 0.5996 - val_acc: 0.7820\n",
      "Epoch 311/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6939 - acc: 0.7589 - val_loss: 0.6004 - val_acc: 0.7820\n",
      "Epoch 312/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7020 - acc: 0.7511 - val_loss: 0.5996 - val_acc: 0.7820\n",
      "Epoch 313/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6796 - acc: 0.7574 - val_loss: 0.6000 - val_acc: 0.7820\n",
      "Epoch 314/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6906 - acc: 0.7470 - val_loss: 0.5999 - val_acc: 0.7820\n",
      "Epoch 315/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6777 - acc: 0.7578 - val_loss: 0.5999 - val_acc: 0.7820\n",
      "Epoch 316/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6982 - acc: 0.7533 - val_loss: 0.5999 - val_acc: 0.7820\n",
      "Epoch 317/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6903 - acc: 0.7593 - val_loss: 0.6003 - val_acc: 0.7812\n",
      "Epoch 318/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6967 - acc: 0.7548 - val_loss: 0.5998 - val_acc: 0.7820\n",
      "Epoch 319/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6894 - acc: 0.7526 - val_loss: 0.5999 - val_acc: 0.7820\n",
      "Epoch 320/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6930 - acc: 0.7612 - val_loss: 0.6002 - val_acc: 0.7820\n",
      "Epoch 321/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6925 - acc: 0.7582 - val_loss: 0.5967 - val_acc: 0.7835\n",
      "Epoch 322/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7037 - acc: 0.7504 - val_loss: 0.6004 - val_acc: 0.7812\n",
      "Epoch 323/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7003 - acc: 0.7563 - val_loss: 0.5994 - val_acc: 0.7827\n",
      "Epoch 324/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7111 - acc: 0.7470 - val_loss: 0.5990 - val_acc: 0.7820\n",
      "Epoch 325/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6937 - acc: 0.7563 - val_loss: 0.5979 - val_acc: 0.7827\n",
      "Epoch 326/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6895 - acc: 0.7541 - val_loss: 0.6000 - val_acc: 0.7820\n",
      "Epoch 327/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6840 - acc: 0.7612 - val_loss: 0.5994 - val_acc: 0.7820\n",
      "Epoch 328/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6959 - acc: 0.7526 - val_loss: 0.5985 - val_acc: 0.7827\n",
      "Epoch 329/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7006 - acc: 0.7463 - val_loss: 0.6011 - val_acc: 0.7812\n",
      "Epoch 330/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6852 - acc: 0.7530 - val_loss: 0.5980 - val_acc: 0.7835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6749 - acc: 0.7563 - val_loss: 0.6004 - val_acc: 0.7812\n",
      "Epoch 332/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6891 - acc: 0.7623 - val_loss: 0.5986 - val_acc: 0.7827\n",
      "Epoch 333/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6819 - acc: 0.7589 - val_loss: 0.5994 - val_acc: 0.7820\n",
      "Epoch 334/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6877 - acc: 0.7608 - val_loss: 0.5986 - val_acc: 0.7820\n",
      "Epoch 335/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6923 - acc: 0.7571 - val_loss: 0.6000 - val_acc: 0.7812\n",
      "Epoch 336/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6989 - acc: 0.7474 - val_loss: 0.6003 - val_acc: 0.7820\n",
      "Epoch 337/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6949 - acc: 0.7493 - val_loss: 0.5990 - val_acc: 0.7827\n",
      "Epoch 338/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7018 - acc: 0.7563 - val_loss: 0.5991 - val_acc: 0.7827\n",
      "Epoch 339/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6978 - acc: 0.7496 - val_loss: 0.6009 - val_acc: 0.7812\n",
      "Epoch 340/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6893 - acc: 0.7630 - val_loss: 0.5998 - val_acc: 0.7812\n",
      "Epoch 341/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7047 - acc: 0.7556 - val_loss: 0.5985 - val_acc: 0.7827\n",
      "Epoch 342/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6936 - acc: 0.7533 - val_loss: 0.5992 - val_acc: 0.7820\n",
      "Epoch 343/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6827 - acc: 0.7563 - val_loss: 0.5994 - val_acc: 0.7827\n",
      "Epoch 344/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6892 - acc: 0.7597 - val_loss: 0.6002 - val_acc: 0.7820\n",
      "Epoch 345/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6940 - acc: 0.7522 - val_loss: 0.5990 - val_acc: 0.7827\n",
      "Epoch 346/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7066 - acc: 0.7493 - val_loss: 0.5993 - val_acc: 0.7820\n",
      "Epoch 347/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6922 - acc: 0.7500 - val_loss: 0.6014 - val_acc: 0.7812\n",
      "Epoch 348/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6877 - acc: 0.7582 - val_loss: 0.6013 - val_acc: 0.7812\n",
      "Epoch 349/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6940 - acc: 0.7493 - val_loss: 0.6007 - val_acc: 0.7812\n",
      "Epoch 350/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6936 - acc: 0.7478 - val_loss: 0.5960 - val_acc: 0.7835\n",
      "Epoch 351/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7045 - acc: 0.7519 - val_loss: 0.5983 - val_acc: 0.7827\n",
      "Epoch 352/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6828 - acc: 0.7537 - val_loss: 0.6001 - val_acc: 0.7820\n",
      "Epoch 353/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6789 - acc: 0.7563 - val_loss: 0.5978 - val_acc: 0.7827\n",
      "Epoch 354/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6954 - acc: 0.7452 - val_loss: 0.6006 - val_acc: 0.7820\n",
      "Epoch 355/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6876 - acc: 0.7537 - val_loss: 0.6011 - val_acc: 0.7812\n",
      "Epoch 356/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6895 - acc: 0.7459 - val_loss: 0.6000 - val_acc: 0.7820\n",
      "Epoch 357/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6982 - acc: 0.7541 - val_loss: 0.6001 - val_acc: 0.7820\n",
      "Epoch 358/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7076 - acc: 0.7485 - val_loss: 0.5990 - val_acc: 0.7827\n",
      "Epoch 359/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6938 - acc: 0.7548 - val_loss: 0.6001 - val_acc: 0.7820\n",
      "Epoch 360/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6874 - acc: 0.7600 - val_loss: 0.6004 - val_acc: 0.7820\n",
      "Epoch 361/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6839 - acc: 0.7556 - val_loss: 0.5993 - val_acc: 0.7820\n",
      "Epoch 362/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6887 - acc: 0.7459 - val_loss: 0.6008 - val_acc: 0.7812\n",
      "Epoch 363/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6907 - acc: 0.7619 - val_loss: 0.5999 - val_acc: 0.7820\n",
      "Epoch 364/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.6839 - acc: 0.7537 - val_loss: 0.6003 - val_acc: 0.7812\n",
      "Epoch 365/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6895 - acc: 0.7600 - val_loss: 0.5997 - val_acc: 0.7820\n",
      "\n",
      "Epoch 00365: loss improved from inf to 0.68948, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-0-000365-0.689480-0.781994.hdf5\n",
      "Epoch 366/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6813 - acc: 0.7556 - val_loss: 0.5957 - val_acc: 0.7827\n",
      "Epoch 367/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6803 - acc: 0.7541 - val_loss: 0.6008 - val_acc: 0.7812\n",
      "Epoch 368/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7014 - acc: 0.7537 - val_loss: 0.5998 - val_acc: 0.7820\n",
      "Epoch 369/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6931 - acc: 0.7578 - val_loss: 0.5991 - val_acc: 0.7827\n",
      "Epoch 370/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6714 - acc: 0.7619 - val_loss: 0.5987 - val_acc: 0.7827\n",
      "Epoch 371/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6954 - acc: 0.7600 - val_loss: 0.5997 - val_acc: 0.7820\n",
      "Epoch 372/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6973 - acc: 0.7530 - val_loss: 0.5991 - val_acc: 0.7820\n",
      "Epoch 373/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6925 - acc: 0.7541 - val_loss: 0.6003 - val_acc: 0.7812\n",
      "Epoch 374/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6972 - acc: 0.7522 - val_loss: 0.6006 - val_acc: 0.7812\n",
      "Epoch 375/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6977 - acc: 0.7485 - val_loss: 0.6009 - val_acc: 0.7812\n",
      "Epoch 376/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7129 - acc: 0.7496 - val_loss: 0.5994 - val_acc: 0.7820\n",
      "Epoch 377/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6818 - acc: 0.7630 - val_loss: 0.6002 - val_acc: 0.7820\n",
      "\n",
      "Epoch 00377: loss improved from 0.68948 to 0.68185, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-0-000377-0.681846-0.781994.hdf5\n",
      "Epoch 378/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6864 - acc: 0.7522 - val_loss: 0.5986 - val_acc: 0.7827\n",
      "Epoch 379/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6852 - acc: 0.7653 - val_loss: 0.6001 - val_acc: 0.7820\n",
      "Epoch 380/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6882 - acc: 0.7623 - val_loss: 0.6005 - val_acc: 0.7820\n",
      "Epoch 381/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6906 - acc: 0.7619 - val_loss: 0.5979 - val_acc: 0.7827\n",
      "Epoch 382/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6807 - acc: 0.7560 - val_loss: 0.5952 - val_acc: 0.7820\n",
      "Epoch 383/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6952 - acc: 0.7641 - val_loss: 0.5993 - val_acc: 0.7820\n",
      "Epoch 384/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6975 - acc: 0.7459 - val_loss: 0.5995 - val_acc: 0.7827\n",
      "Epoch 385/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7067 - acc: 0.7511 - val_loss: 0.6003 - val_acc: 0.7812\n",
      "Epoch 00385: early stopping\n",
      "ModelCheckpoint 已经保存到 ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/0-final.hdf5\n",
      "Create subdir directory: ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/log...\n",
      "save in: ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/log/20220201_2000_64_1_3_1.csv\n",
      "time: 0:10:15 s\n",
      "time: 615.0 s\n",
      "average 0.615000 s\n",
      "0 epoch finished\n",
      "--------------------   best   --------------------\n",
      "no_activities: 10\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1349/1349 [==============================] - 0s 331us/step\n",
      "0-milan:\tacc: 78.21%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [3, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 7, 0, 4, 0, 0, 7, 7, 7, 7, 7, 7, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 4, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 4, 0, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 7, 9, 0, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 0, 7, 7, 7, 7, 0, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 4, 0, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 7, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 0, 5, 5, 0, 5, 5, 0, 4, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 0, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 9, 9, 0, 9, 9, 9, 3, 9, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 0, 0, 0, 7, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 4, 0, 0, 0, 0, 7, 7, 7, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 7, 0, 9, 9, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 7, 0, 0, 9, 9, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 0, 7, 7, 0, 0, 0, 4, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 7, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 4, 9, 7, 4, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 7, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 4, 7, 7, 0, 0, 4, 0, 0, 0, 7, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 4, 4, 4, 0, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 0, 4, 0, 4, 4, 0, 4, 4, 4, 4, 0, 7, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 3, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 0, 7, 4, 0, 0, 0, 0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.788184  0.878010  0.830676       623\n",
      "         Work   0.000000  0.000000  0.000000        26\n",
      "Take_medicine   0.000000  0.000000  0.000000        20\n",
      "        Sleep   0.700000  0.218750  0.333333        32\n",
      "        Relax   0.710938  0.636364  0.671587       143\n",
      "   Leave_Home   0.923077  0.845070  0.882353        71\n",
      "          Eat   0.000000  0.000000  0.000000         7\n",
      "         Cook   0.740088  0.908108  0.815534       185\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        30\n",
      "      Bathing   0.808889  0.858491  0.832952       212\n",
      "\n",
      "     accuracy                       0.782061      1349\n",
      "    macro avg   0.467118  0.434479  0.436643      1349\n",
      " weighted avg   0.733167  0.782061  0.751906      1349\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  29   0   0   0   0   1]\n",
      " [  0   0   0   0   0   0   0  24   2   0]\n",
      " [  0   0   0   0   0   3   0   3   1   0]\n",
      " [  0   0   0   0   0  20   0   0   0   0]\n",
      " [  0   0   0   0 182   2   0  25   2   1]\n",
      " [  0   0   0   0   1 168   0  13   3   0]\n",
      " [  0   0   0   0   0   2  60   7   2   0]\n",
      " [  0   0   0   0  13  30   5 547  27   1]\n",
      " [  0   0   0   0   0   2   0  50  91   0]\n",
      " [  0   0   0   0   0   0   0  25   0   7]]\n",
      "--------------------   final   --------------------\n",
      "no_activities: 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1349/1349 [==============================] - 0s 342us/step\n",
      "0-milan:\tacc: 78.21%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [3, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 7, 0, 4, 0, 0, 7, 7, 7, 7, 7, 7, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 4, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 4, 0, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 7, 9, 0, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 0, 7, 7, 7, 7, 0, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 4, 0, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 7, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 0, 5, 5, 0, 5, 5, 0, 4, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 0, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 9, 9, 0, 9, 9, 9, 3, 9, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 0, 0, 0, 7, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 4, 0, 0, 0, 0, 7, 7, 7, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 7, 0, 9, 9, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 7, 0, 0, 9, 9, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 0, 7, 7, 0, 0, 0, 4, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 7, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 4, 9, 7, 4, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 7, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 4, 7, 7, 0, 0, 4, 0, 0, 0, 7, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 4, 4, 4, 0, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 0, 4, 0, 4, 4, 0, 4, 4, 4, 4, 0, 7, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 3, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 4, 0, 0, 0, 7, 4, 0, 0, 0, 0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.788184  0.878010  0.830676       623\n",
      "         Work   0.000000  0.000000  0.000000        26\n",
      "Take_medicine   0.000000  0.000000  0.000000        20\n",
      "        Sleep   0.700000  0.218750  0.333333        32\n",
      "        Relax   0.710938  0.636364  0.671587       143\n",
      "   Leave_Home   0.923077  0.845070  0.882353        71\n",
      "          Eat   0.000000  0.000000  0.000000         7\n",
      "         Cook   0.740088  0.908108  0.815534       185\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        30\n",
      "      Bathing   0.808889  0.858491  0.832952       212\n",
      "\n",
      "     accuracy                       0.782061      1349\n",
      "    macro avg   0.467118  0.434479  0.436643      1349\n",
      " weighted avg   0.733167  0.782061  0.751906      1349\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  29   0   0   0   0   1]\n",
      " [  0   0   0   0   0   0   0  24   2   0]\n",
      " [  0   0   0   0   0   3   0   3   1   0]\n",
      " [  0   0   0   0   0  20   0   0   0   0]\n",
      " [  0   0   0   0 182   2   0  25   2   1]\n",
      " [  0   0   0   0   1 168   0  13   3   0]\n",
      " [  0   0   0   0   0   2  60   7   2   0]\n",
      " [  0   0   0   0  13  30   5 547  27   1]\n",
      " [  0   0   0   0   0   2   0  50  91   0]\n",
      " [  0   0   0   0   0   0   0  25   0   7]]\n",
      "no_activities: 10\n",
      "\n",
      "Begin training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "42/42 [==============================] - 2s 54ms/step - loss: 1.9989 - acc: 0.2541 - val_loss: 1.5296 - val_acc: 0.6183\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.4405 - acc: 0.5647 - val_loss: 1.1913 - val_acc: 0.6496\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.2778 - acc: 0.5986 - val_loss: 1.0638 - val_acc: 0.7202\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.1709 - acc: 0.6462 - val_loss: 0.9931 - val_acc: 0.7359\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.1290 - acc: 0.6391 - val_loss: 0.9502 - val_acc: 0.7240\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0827 - acc: 0.6555 - val_loss: 0.9133 - val_acc: 0.7418\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0262 - acc: 0.6715 - val_loss: 0.8848 - val_acc: 0.7359\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0336 - acc: 0.6752 - val_loss: 0.8693 - val_acc: 0.7344\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9933 - acc: 0.6786 - val_loss: 0.8448 - val_acc: 0.7448\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9769 - acc: 0.6920 - val_loss: 0.8332 - val_acc: 0.7418\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.9432 - acc: 0.7005 - val_loss: 0.8208 - val_acc: 0.7507\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9583 - acc: 0.6834 - val_loss: 0.8087 - val_acc: 0.7455\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9472 - acc: 0.6990 - val_loss: 0.8014 - val_acc: 0.7485\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9258 - acc: 0.7009 - val_loss: 0.7908 - val_acc: 0.7478\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9194 - acc: 0.7028 - val_loss: 0.7794 - val_acc: 0.7522\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9147 - acc: 0.7042 - val_loss: 0.7755 - val_acc: 0.7515\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8975 - acc: 0.7143 - val_loss: 0.7664 - val_acc: 0.7507\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8960 - acc: 0.7076 - val_loss: 0.7622 - val_acc: 0.7507\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8792 - acc: 0.7106 - val_loss: 0.7561 - val_acc: 0.7515\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8668 - acc: 0.7106 - val_loss: 0.7543 - val_acc: 0.7560\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8763 - acc: 0.7225 - val_loss: 0.7507 - val_acc: 0.7545\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8627 - acc: 0.7173 - val_loss: 0.7451 - val_acc: 0.7500\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8634 - acc: 0.7240 - val_loss: 0.7371 - val_acc: 0.7552\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8573 - acc: 0.7188 - val_loss: 0.7366 - val_acc: 0.7552\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8442 - acc: 0.7240 - val_loss: 0.7333 - val_acc: 0.7574\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8653 - acc: 0.7169 - val_loss: 0.7329 - val_acc: 0.7589\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8367 - acc: 0.7318 - val_loss: 0.7309 - val_acc: 0.7574\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8475 - acc: 0.7199 - val_loss: 0.7257 - val_acc: 0.7574\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8435 - acc: 0.7173 - val_loss: 0.7248 - val_acc: 0.7552\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.8348 - acc: 0.7284 - val_loss: 0.7192 - val_acc: 0.7582\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8336 - acc: 0.7281 - val_loss: 0.7189 - val_acc: 0.7574\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8259 - acc: 0.7321 - val_loss: 0.7142 - val_acc: 0.7560\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8081 - acc: 0.7362 - val_loss: 0.7119 - val_acc: 0.7574\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8277 - acc: 0.7210 - val_loss: 0.7098 - val_acc: 0.7597\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.8256 - acc: 0.7340 - val_loss: 0.7122 - val_acc: 0.7619\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8147 - acc: 0.7333 - val_loss: 0.7086 - val_acc: 0.7604\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8157 - acc: 0.7388 - val_loss: 0.7062 - val_acc: 0.7582\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8195 - acc: 0.7266 - val_loss: 0.7031 - val_acc: 0.7626\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8207 - acc: 0.7403 - val_loss: 0.7026 - val_acc: 0.7626\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8004 - acc: 0.7385 - val_loss: 0.6971 - val_acc: 0.7604\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8038 - acc: 0.7362 - val_loss: 0.7014 - val_acc: 0.7574\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8038 - acc: 0.7355 - val_loss: 0.6977 - val_acc: 0.7626\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8016 - acc: 0.7403 - val_loss: 0.6975 - val_acc: 0.7641\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7874 - acc: 0.7381 - val_loss: 0.6940 - val_acc: 0.7656\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7816 - acc: 0.7422 - val_loss: 0.6931 - val_acc: 0.7641\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7840 - acc: 0.7411 - val_loss: 0.6954 - val_acc: 0.7626\n",
      "Epoch 47/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8070 - acc: 0.7318 - val_loss: 0.6965 - val_acc: 0.7626\n",
      "Epoch 48/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7851 - acc: 0.7310 - val_loss: 0.6911 - val_acc: 0.7664\n",
      "Epoch 49/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8057 - acc: 0.7333 - val_loss: 0.6917 - val_acc: 0.7634\n",
      "Epoch 50/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7871 - acc: 0.7426 - val_loss: 0.6901 - val_acc: 0.7656\n",
      "Epoch 51/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7669 - acc: 0.7448 - val_loss: 0.6897 - val_acc: 0.7686\n",
      "Epoch 52/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7884 - acc: 0.7351 - val_loss: 0.6889 - val_acc: 0.7641\n",
      "Epoch 53/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7838 - acc: 0.7504 - val_loss: 0.6888 - val_acc: 0.7656\n",
      "Epoch 54/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7746 - acc: 0.7467 - val_loss: 0.6863 - val_acc: 0.7664\n",
      "Epoch 55/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7580 - acc: 0.7448 - val_loss: 0.6859 - val_acc: 0.7656\n",
      "Epoch 56/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7740 - acc: 0.7310 - val_loss: 0.6872 - val_acc: 0.7649\n",
      "Epoch 57/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7627 - acc: 0.7463 - val_loss: 0.6835 - val_acc: 0.7641\n",
      "Epoch 58/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7759 - acc: 0.7340 - val_loss: 0.6816 - val_acc: 0.7656\n",
      "Epoch 59/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7615 - acc: 0.7470 - val_loss: 0.6807 - val_acc: 0.7641\n",
      "Epoch 60/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7656 - acc: 0.7470 - val_loss: 0.6814 - val_acc: 0.7656\n",
      "Epoch 61/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7703 - acc: 0.7533 - val_loss: 0.6828 - val_acc: 0.7641\n",
      "Epoch 62/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7609 - acc: 0.7533 - val_loss: 0.6807 - val_acc: 0.7656\n",
      "Epoch 63/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7827 - acc: 0.7429 - val_loss: 0.6835 - val_acc: 0.7626\n",
      "Epoch 64/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7656 - acc: 0.7426 - val_loss: 0.6794 - val_acc: 0.7671\n",
      "Epoch 65/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7586 - acc: 0.7481 - val_loss: 0.6781 - val_acc: 0.7649\n",
      "\n",
      "Epoch 00065: loss improved from inf to 0.75859, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-1-000065-0.758589-0.764881.hdf5\n",
      "Epoch 66/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7576 - acc: 0.7504 - val_loss: 0.6798 - val_acc: 0.7619\n",
      "Epoch 67/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7510 - acc: 0.7563 - val_loss: 0.6787 - val_acc: 0.7664\n",
      "Epoch 68/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7582 - acc: 0.7403 - val_loss: 0.6765 - val_acc: 0.7641\n",
      "Epoch 69/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7476 - acc: 0.7537 - val_loss: 0.6753 - val_acc: 0.7604\n",
      "\n",
      "Epoch 00069: loss improved from 0.75859 to 0.74757, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-1-000069-0.747574-0.760417.hdf5\n",
      "Epoch 70/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7561 - acc: 0.7455 - val_loss: 0.6784 - val_acc: 0.7634\n",
      "Epoch 71/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7583 - acc: 0.7504 - val_loss: 0.6725 - val_acc: 0.7626\n",
      "Epoch 72/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7601 - acc: 0.7519 - val_loss: 0.6734 - val_acc: 0.7649\n",
      "Epoch 73/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7496 - acc: 0.7463 - val_loss: 0.6716 - val_acc: 0.7693\n",
      "Epoch 74/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7478 - acc: 0.7556 - val_loss: 0.6732 - val_acc: 0.7679\n",
      "Epoch 75/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7561 - acc: 0.7452 - val_loss: 0.6736 - val_acc: 0.7664\n",
      "Epoch 76/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7336 - acc: 0.7597 - val_loss: 0.6738 - val_acc: 0.7612\n",
      "Epoch 77/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7330 - acc: 0.7567 - val_loss: 0.6717 - val_acc: 0.7626\n",
      "\n",
      "Epoch 00077: loss improved from 0.74757 to 0.73302, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-1-000077-0.733020-0.762649.hdf5\n",
      "Epoch 78/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7637 - acc: 0.7414 - val_loss: 0.6691 - val_acc: 0.7634\n",
      "Epoch 79/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7488 - acc: 0.7481 - val_loss: 0.6724 - val_acc: 0.7664\n",
      "Epoch 80/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7279 - acc: 0.7478 - val_loss: 0.6731 - val_acc: 0.7634\n",
      "Epoch 81/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7516 - acc: 0.7489 - val_loss: 0.6726 - val_acc: 0.7604\n",
      "Epoch 82/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7533 - acc: 0.7433 - val_loss: 0.6722 - val_acc: 0.7612\n",
      "Epoch 83/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7533 - acc: 0.7437 - val_loss: 0.6698 - val_acc: 0.7641\n",
      "Epoch 84/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7505 - acc: 0.7448 - val_loss: 0.6682 - val_acc: 0.7708\n",
      "Epoch 85/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7453 - acc: 0.7526 - val_loss: 0.6685 - val_acc: 0.7693\n",
      "Epoch 86/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7387 - acc: 0.7485 - val_loss: 0.6697 - val_acc: 0.7612\n",
      "Epoch 87/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7340 - acc: 0.7467 - val_loss: 0.6704 - val_acc: 0.7597\n",
      "Epoch 88/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7543 - acc: 0.7470 - val_loss: 0.6685 - val_acc: 0.7619\n",
      "Epoch 89/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7317 - acc: 0.7515 - val_loss: 0.6688 - val_acc: 0.7649\n",
      "\n",
      "Epoch 00089: loss improved from 0.73302 to 0.73167, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-1-000089-0.731672-0.764881.hdf5\n",
      "Epoch 90/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7469 - acc: 0.7571 - val_loss: 0.6696 - val_acc: 0.7634\n",
      "Epoch 91/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7486 - acc: 0.7474 - val_loss: 0.6676 - val_acc: 0.7641\n",
      "Epoch 92/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7374 - acc: 0.7452 - val_loss: 0.6678 - val_acc: 0.7634\n",
      "Epoch 93/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7437 - acc: 0.7470 - val_loss: 0.6668 - val_acc: 0.7679\n",
      "Epoch 94/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7412 - acc: 0.7478 - val_loss: 0.6672 - val_acc: 0.7649\n",
      "Epoch 95/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7271 - acc: 0.7530 - val_loss: 0.6671 - val_acc: 0.7686\n",
      "Epoch 96/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7304 - acc: 0.7463 - val_loss: 0.6677 - val_acc: 0.7634\n",
      "Epoch 97/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7304 - acc: 0.7381 - val_loss: 0.6661 - val_acc: 0.7656\n",
      "\n",
      "Epoch 00097: loss improved from 0.73167 to 0.73044, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-1-000097-0.730440-0.765625.hdf5\n",
      "Epoch 98/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7275 - acc: 0.7519 - val_loss: 0.6630 - val_acc: 0.7664\n",
      "Epoch 99/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7328 - acc: 0.7455 - val_loss: 0.6656 - val_acc: 0.7679\n",
      "Epoch 100/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7363 - acc: 0.7515 - val_loss: 0.6653 - val_acc: 0.7664\n",
      "\n",
      "Epoch 00100: saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/1-000100-0.736261-0.766369.hdf5\n",
      "Epoch 101/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7360 - acc: 0.7578 - val_loss: 0.6658 - val_acc: 0.7679\n",
      "Epoch 102/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7459 - acc: 0.7429 - val_loss: 0.6601 - val_acc: 0.7656\n",
      "Epoch 103/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7314 - acc: 0.7496 - val_loss: 0.6617 - val_acc: 0.7701\n",
      "Epoch 104/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7363 - acc: 0.7422 - val_loss: 0.6611 - val_acc: 0.7679\n",
      "Epoch 105/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7400 - acc: 0.7470 - val_loss: 0.6620 - val_acc: 0.7701\n",
      "Epoch 106/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7301 - acc: 0.7511 - val_loss: 0.6595 - val_acc: 0.7671\n",
      "Epoch 107/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7171 - acc: 0.7530 - val_loss: 0.6612 - val_acc: 0.7679\n",
      "Epoch 108/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7388 - acc: 0.7526 - val_loss: 0.6626 - val_acc: 0.7693\n",
      "Epoch 109/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7328 - acc: 0.7507 - val_loss: 0.6585 - val_acc: 0.7693\n",
      "Epoch 110/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7247 - acc: 0.7455 - val_loss: 0.6621 - val_acc: 0.7649\n",
      "Epoch 111/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7384 - acc: 0.7485 - val_loss: 0.6593 - val_acc: 0.7664\n",
      "Epoch 112/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7246 - acc: 0.7500 - val_loss: 0.6619 - val_acc: 0.7701\n",
      "Epoch 113/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7330 - acc: 0.7481 - val_loss: 0.6600 - val_acc: 0.7693\n",
      "Epoch 114/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7261 - acc: 0.7541 - val_loss: 0.6567 - val_acc: 0.7679\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7345 - acc: 0.7478 - val_loss: 0.6591 - val_acc: 0.7701\n",
      "Epoch 116/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7302 - acc: 0.7574 - val_loss: 0.6581 - val_acc: 0.7723\n",
      "Epoch 117/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7374 - acc: 0.7459 - val_loss: 0.6590 - val_acc: 0.7708\n",
      "Epoch 118/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7263 - acc: 0.7515 - val_loss: 0.6545 - val_acc: 0.7656\n",
      "Epoch 119/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7195 - acc: 0.7623 - val_loss: 0.6542 - val_acc: 0.7723\n",
      "Epoch 120/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7223 - acc: 0.7545 - val_loss: 0.6584 - val_acc: 0.7716\n",
      "Epoch 121/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7280 - acc: 0.7545 - val_loss: 0.6577 - val_acc: 0.7693\n",
      "Epoch 122/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7215 - acc: 0.7567 - val_loss: 0.6573 - val_acc: 0.7679\n",
      "Epoch 123/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7150 - acc: 0.7619 - val_loss: 0.6579 - val_acc: 0.7664\n",
      "Epoch 124/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7107 - acc: 0.7511 - val_loss: 0.6568 - val_acc: 0.7649\n",
      "Epoch 125/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7259 - acc: 0.7541 - val_loss: 0.6575 - val_acc: 0.7701\n",
      "Epoch 126/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7269 - acc: 0.7604 - val_loss: 0.6564 - val_acc: 0.7716\n",
      "Epoch 127/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6990 - acc: 0.7574 - val_loss: 0.6561 - val_acc: 0.7701\n",
      "Epoch 128/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7431 - acc: 0.7448 - val_loss: 0.6555 - val_acc: 0.7671\n",
      "Epoch 129/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7066 - acc: 0.7574 - val_loss: 0.6583 - val_acc: 0.7671\n",
      "Epoch 130/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7211 - acc: 0.7463 - val_loss: 0.6577 - val_acc: 0.7671\n",
      "Epoch 131/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7295 - acc: 0.7452 - val_loss: 0.6584 - val_acc: 0.7664\n",
      "Epoch 132/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7163 - acc: 0.7545 - val_loss: 0.6550 - val_acc: 0.7679\n",
      "Epoch 133/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7180 - acc: 0.7414 - val_loss: 0.6561 - val_acc: 0.7686\n",
      "Epoch 134/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7192 - acc: 0.7586 - val_loss: 0.6558 - val_acc: 0.7686\n",
      "Epoch 135/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7216 - acc: 0.7526 - val_loss: 0.6557 - val_acc: 0.7686\n",
      "Epoch 136/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7182 - acc: 0.7545 - val_loss: 0.6562 - val_acc: 0.7708\n",
      "Epoch 137/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7224 - acc: 0.7537 - val_loss: 0.6555 - val_acc: 0.7716\n",
      "Epoch 138/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7201 - acc: 0.7522 - val_loss: 0.6553 - val_acc: 0.7664\n",
      "Epoch 139/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7135 - acc: 0.7556 - val_loss: 0.6520 - val_acc: 0.7708\n",
      "Epoch 140/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7174 - acc: 0.7623 - val_loss: 0.6531 - val_acc: 0.7716\n",
      "Epoch 141/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6993 - acc: 0.7623 - val_loss: 0.6541 - val_acc: 0.7701\n",
      "Epoch 142/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7149 - acc: 0.7522 - val_loss: 0.6524 - val_acc: 0.7671\n",
      "Epoch 143/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7213 - acc: 0.7507 - val_loss: 0.6530 - val_acc: 0.7708\n",
      "Epoch 144/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7052 - acc: 0.7571 - val_loss: 0.6511 - val_acc: 0.7708\n",
      "Epoch 145/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7142 - acc: 0.7500 - val_loss: 0.6515 - val_acc: 0.7716\n",
      "Epoch 146/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7146 - acc: 0.7574 - val_loss: 0.6522 - val_acc: 0.7701\n",
      "Epoch 147/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6900 - acc: 0.7638 - val_loss: 0.6533 - val_acc: 0.7716\n",
      "Epoch 148/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7068 - acc: 0.7578 - val_loss: 0.6520 - val_acc: 0.7701\n",
      "Epoch 149/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6997 - acc: 0.7541 - val_loss: 0.6521 - val_acc: 0.7701\n",
      "Epoch 150/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7156 - acc: 0.7537 - val_loss: 0.6513 - val_acc: 0.7723\n",
      "Epoch 151/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7037 - acc: 0.7604 - val_loss: 0.6529 - val_acc: 0.7701\n",
      "Epoch 152/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7112 - acc: 0.7526 - val_loss: 0.6506 - val_acc: 0.7679\n",
      "Epoch 153/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7152 - acc: 0.7530 - val_loss: 0.6486 - val_acc: 0.7693\n",
      "Epoch 154/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7017 - acc: 0.7533 - val_loss: 0.6513 - val_acc: 0.7679\n",
      "Epoch 155/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6900 - acc: 0.7593 - val_loss: 0.6490 - val_acc: 0.7701\n",
      "Epoch 156/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7166 - acc: 0.7574 - val_loss: 0.6469 - val_acc: 0.7701\n",
      "Epoch 157/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6926 - acc: 0.7515 - val_loss: 0.6511 - val_acc: 0.7686\n",
      "Epoch 158/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6984 - acc: 0.7552 - val_loss: 0.6493 - val_acc: 0.7723\n",
      "Epoch 159/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6998 - acc: 0.7537 - val_loss: 0.6513 - val_acc: 0.7671\n",
      "Epoch 160/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6909 - acc: 0.7574 - val_loss: 0.6502 - val_acc: 0.7679\n",
      "Epoch 161/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7005 - acc: 0.7582 - val_loss: 0.6512 - val_acc: 0.7679\n",
      "Epoch 162/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6905 - acc: 0.7604 - val_loss: 0.6509 - val_acc: 0.7664\n",
      "Epoch 163/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6920 - acc: 0.7515 - val_loss: 0.6500 - val_acc: 0.7716\n",
      "Epoch 164/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7178 - acc: 0.7504 - val_loss: 0.6494 - val_acc: 0.7716\n",
      "Epoch 165/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6912 - acc: 0.7485 - val_loss: 0.6461 - val_acc: 0.7738\n",
      "\n",
      "Epoch 00165: loss improved from inf to 0.69120, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-1-000165-0.691201-0.773810.hdf5\n",
      "Epoch 166/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7050 - acc: 0.7500 - val_loss: 0.6508 - val_acc: 0.7716\n",
      "Epoch 167/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7006 - acc: 0.7548 - val_loss: 0.6493 - val_acc: 0.7701\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 168/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6856 - acc: 0.7708 - val_loss: 0.6501 - val_acc: 0.7716\n",
      "Epoch 169/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7001 - acc: 0.7571 - val_loss: 0.6491 - val_acc: 0.7738\n",
      "Epoch 170/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6779 - acc: 0.7600 - val_loss: 0.6487 - val_acc: 0.7738\n",
      "Epoch 171/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7093 - acc: 0.7582 - val_loss: 0.6459 - val_acc: 0.7746\n",
      "Epoch 172/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6890 - acc: 0.7563 - val_loss: 0.6470 - val_acc: 0.7738\n",
      "Epoch 173/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7047 - acc: 0.7541 - val_loss: 0.6487 - val_acc: 0.7723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7038 - acc: 0.7563 - val_loss: 0.6491 - val_acc: 0.7731\n",
      "Epoch 175/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6941 - acc: 0.7634 - val_loss: 0.6455 - val_acc: 0.7731\n",
      "Epoch 176/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7166 - acc: 0.7560 - val_loss: 0.6461 - val_acc: 0.7738\n",
      "Epoch 177/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6828 - acc: 0.7623 - val_loss: 0.6457 - val_acc: 0.7716\n",
      "\n",
      "Epoch 00177: loss improved from 0.69120 to 0.68283, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-1-000177-0.682827-0.771577.hdf5\n",
      "Epoch 178/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6963 - acc: 0.7548 - val_loss: 0.6497 - val_acc: 0.7731\n",
      "Epoch 179/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6743 - acc: 0.7571 - val_loss: 0.6491 - val_acc: 0.7723\n",
      "Epoch 180/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7014 - acc: 0.7586 - val_loss: 0.6471 - val_acc: 0.7708\n",
      "Epoch 181/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7018 - acc: 0.7519 - val_loss: 0.6502 - val_acc: 0.7701\n",
      "Epoch 182/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6880 - acc: 0.7667 - val_loss: 0.6484 - val_acc: 0.7723\n",
      "Epoch 183/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7171 - acc: 0.7556 - val_loss: 0.6500 - val_acc: 0.7693\n",
      "Epoch 184/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6823 - acc: 0.7664 - val_loss: 0.6492 - val_acc: 0.7716\n",
      "Epoch 185/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7004 - acc: 0.7604 - val_loss: 0.6481 - val_acc: 0.7723\n",
      "Epoch 186/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7002 - acc: 0.7604 - val_loss: 0.6484 - val_acc: 0.7723\n",
      "Epoch 187/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7083 - acc: 0.7578 - val_loss: 0.6501 - val_acc: 0.7716\n",
      "Epoch 188/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7021 - acc: 0.7578 - val_loss: 0.6454 - val_acc: 0.7723\n",
      "Epoch 189/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7056 - acc: 0.7567 - val_loss: 0.6498 - val_acc: 0.7716\n",
      "Epoch 190/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.6779 - acc: 0.7675 - val_loss: 0.6500 - val_acc: 0.7708\n",
      "Epoch 191/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6928 - acc: 0.7578 - val_loss: 0.6496 - val_acc: 0.7716\n",
      "Epoch 192/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6963 - acc: 0.7541 - val_loss: 0.6464 - val_acc: 0.7723\n",
      "Epoch 193/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7065 - acc: 0.7597 - val_loss: 0.6501 - val_acc: 0.7708\n",
      "Epoch 194/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6851 - acc: 0.7664 - val_loss: 0.6485 - val_acc: 0.7716\n",
      "Epoch 195/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.7035 - acc: 0.7541 - val_loss: 0.6489 - val_acc: 0.7716\n",
      "Epoch 196/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7053 - acc: 0.7608 - val_loss: 0.6477 - val_acc: 0.7716\n",
      "Epoch 197/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6999 - acc: 0.7612 - val_loss: 0.6501 - val_acc: 0.7716\n",
      "Epoch 198/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6968 - acc: 0.7612 - val_loss: 0.6499 - val_acc: 0.7716\n",
      "Epoch 199/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6743 - acc: 0.7667 - val_loss: 0.6482 - val_acc: 0.7723\n",
      "\n",
      "Epoch 00199: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 200/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6966 - acc: 0.7537 - val_loss: 0.6499 - val_acc: 0.7716\n",
      "\n",
      "Epoch 00200: saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/1-000200-0.696615-0.771577.hdf5\n",
      "Epoch 201/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7035 - acc: 0.7582 - val_loss: 0.6491 - val_acc: 0.7716\n",
      "Epoch 202/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6878 - acc: 0.7574 - val_loss: 0.6495 - val_acc: 0.7716\n",
      "Epoch 203/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6993 - acc: 0.7597 - val_loss: 0.6484 - val_acc: 0.7723\n",
      "Epoch 204/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7060 - acc: 0.7548 - val_loss: 0.6454 - val_acc: 0.7738\n",
      "Epoch 205/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6951 - acc: 0.7608 - val_loss: 0.6496 - val_acc: 0.7716\n",
      "Epoch 206/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6924 - acc: 0.7578 - val_loss: 0.6488 - val_acc: 0.7731\n",
      "Epoch 207/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7167 - acc: 0.7582 - val_loss: 0.6496 - val_acc: 0.7723\n",
      "Epoch 208/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6993 - acc: 0.7548 - val_loss: 0.6496 - val_acc: 0.7723\n",
      "Epoch 209/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7048 - acc: 0.7582 - val_loss: 0.6457 - val_acc: 0.7731\n",
      "Epoch 210/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6854 - acc: 0.7615 - val_loss: 0.6496 - val_acc: 0.7723\n",
      "Epoch 211/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6909 - acc: 0.7589 - val_loss: 0.6482 - val_acc: 0.7738\n",
      "Epoch 212/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6911 - acc: 0.7593 - val_loss: 0.6479 - val_acc: 0.7738\n",
      "Epoch 213/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7155 - acc: 0.7574 - val_loss: 0.6498 - val_acc: 0.7723\n",
      "Epoch 214/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6963 - acc: 0.7552 - val_loss: 0.6477 - val_acc: 0.7738\n",
      "Epoch 215/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7039 - acc: 0.7615 - val_loss: 0.6490 - val_acc: 0.7723\n",
      "Epoch 216/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6944 - acc: 0.7626 - val_loss: 0.6477 - val_acc: 0.7731\n",
      "Epoch 217/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6824 - acc: 0.7545 - val_loss: 0.6478 - val_acc: 0.7731\n",
      "Epoch 218/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7033 - acc: 0.7560 - val_loss: 0.6491 - val_acc: 0.7723\n",
      "Epoch 219/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6953 - acc: 0.7578 - val_loss: 0.6493 - val_acc: 0.7723\n",
      "\n",
      "Epoch 00219: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 220/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7034 - acc: 0.7615 - val_loss: 0.6482 - val_acc: 0.7731\n",
      "Epoch 221/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7020 - acc: 0.7597 - val_loss: 0.6488 - val_acc: 0.7731\n",
      "Epoch 222/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7027 - acc: 0.7526 - val_loss: 0.6490 - val_acc: 0.7723\n",
      "Epoch 223/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.6831 - acc: 0.7664 - val_loss: 0.6485 - val_acc: 0.7731\n",
      "Epoch 224/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6920 - acc: 0.7615 - val_loss: 0.6490 - val_acc: 0.7731\n",
      "Epoch 225/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7085 - acc: 0.7463 - val_loss: 0.6485 - val_acc: 0.7731\n",
      "Epoch 226/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7004 - acc: 0.7537 - val_loss: 0.6492 - val_acc: 0.7723\n",
      "Epoch 227/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6943 - acc: 0.7582 - val_loss: 0.6486 - val_acc: 0.7731\n",
      "Epoch 228/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6916 - acc: 0.7656 - val_loss: 0.6488 - val_acc: 0.7731\n",
      "Epoch 229/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7124 - acc: 0.7481 - val_loss: 0.6500 - val_acc: 0.7723\n",
      "Epoch 230/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7032 - acc: 0.7556 - val_loss: 0.6460 - val_acc: 0.7731\n",
      "Epoch 231/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7045 - acc: 0.7597 - val_loss: 0.6481 - val_acc: 0.7731\n",
      "Epoch 232/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7121 - acc: 0.7522 - val_loss: 0.6483 - val_acc: 0.7731\n",
      "Epoch 233/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6984 - acc: 0.7586 - val_loss: 0.6494 - val_acc: 0.7723\n",
      "Epoch 234/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7139 - acc: 0.7507 - val_loss: 0.6487 - val_acc: 0.7731\n",
      "Epoch 235/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7036 - acc: 0.7563 - val_loss: 0.6498 - val_acc: 0.7723\n",
      "Epoch 236/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7049 - acc: 0.7556 - val_loss: 0.6490 - val_acc: 0.7731\n",
      "Epoch 237/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7002 - acc: 0.7496 - val_loss: 0.6490 - val_acc: 0.7731\n",
      "Epoch 238/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7091 - acc: 0.7437 - val_loss: 0.6492 - val_acc: 0.7723\n",
      "Epoch 239/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6975 - acc: 0.7582 - val_loss: 0.6488 - val_acc: 0.7731\n",
      "Epoch 240/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7018 - acc: 0.7597 - val_loss: 0.6476 - val_acc: 0.7731\n",
      "Epoch 241/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6759 - acc: 0.7623 - val_loss: 0.6500 - val_acc: 0.7723\n",
      "Epoch 242/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6862 - acc: 0.7630 - val_loss: 0.6433 - val_acc: 0.7746\n",
      "Epoch 243/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6944 - acc: 0.7574 - val_loss: 0.6492 - val_acc: 0.7723\n",
      "Epoch 244/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6903 - acc: 0.7645 - val_loss: 0.6489 - val_acc: 0.7723\n",
      "Epoch 245/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6851 - acc: 0.7638 - val_loss: 0.6466 - val_acc: 0.7738\n",
      "Epoch 246/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7185 - acc: 0.7519 - val_loss: 0.6484 - val_acc: 0.7731\n",
      "Epoch 247/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6848 - acc: 0.7641 - val_loss: 0.6495 - val_acc: 0.7723\n",
      "Epoch 248/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6880 - acc: 0.7690 - val_loss: 0.6466 - val_acc: 0.7738\n",
      "Epoch 249/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6948 - acc: 0.7578 - val_loss: 0.6489 - val_acc: 0.7723\n",
      "Epoch 250/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7128 - acc: 0.7571 - val_loss: 0.6451 - val_acc: 0.7746\n",
      "Epoch 251/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7022 - acc: 0.7522 - val_loss: 0.6469 - val_acc: 0.7731\n",
      "Epoch 252/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6956 - acc: 0.7560 - val_loss: 0.6477 - val_acc: 0.7731\n",
      "Epoch 253/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6981 - acc: 0.7545 - val_loss: 0.6466 - val_acc: 0.7731\n",
      "Epoch 254/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6960 - acc: 0.7574 - val_loss: 0.6471 - val_acc: 0.7731\n",
      "Epoch 255/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7095 - acc: 0.7634 - val_loss: 0.6495 - val_acc: 0.7723\n",
      "Epoch 256/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6919 - acc: 0.7612 - val_loss: 0.6484 - val_acc: 0.7731\n",
      "Epoch 257/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6983 - acc: 0.7593 - val_loss: 0.6486 - val_acc: 0.7731\n",
      "Epoch 258/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7169 - acc: 0.7463 - val_loss: 0.6474 - val_acc: 0.7731\n",
      "Epoch 259/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6814 - acc: 0.7612 - val_loss: 0.6463 - val_acc: 0.7738\n",
      "Epoch 260/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6917 - acc: 0.7533 - val_loss: 0.6499 - val_acc: 0.7723\n",
      "Epoch 261/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7078 - acc: 0.7511 - val_loss: 0.6477 - val_acc: 0.7738\n",
      "Epoch 262/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6801 - acc: 0.7649 - val_loss: 0.6476 - val_acc: 0.7731\n",
      "Epoch 263/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6976 - acc: 0.7515 - val_loss: 0.6444 - val_acc: 0.7753\n",
      "Epoch 264/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6974 - acc: 0.7548 - val_loss: 0.6469 - val_acc: 0.7731\n",
      "Epoch 265/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7036 - acc: 0.7556 - val_loss: 0.6495 - val_acc: 0.7723\n",
      "\n",
      "Epoch 00265: loss improved from inf to 0.70363, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-1-000265-0.703632-0.772321.hdf5\n",
      "Epoch 266/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7029 - acc: 0.7615 - val_loss: 0.6497 - val_acc: 0.7723\n",
      "Epoch 267/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6917 - acc: 0.7545 - val_loss: 0.6490 - val_acc: 0.7723\n",
      "Epoch 268/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6955 - acc: 0.7634 - val_loss: 0.6486 - val_acc: 0.7731\n",
      "Epoch 269/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7083 - acc: 0.7545 - val_loss: 0.6476 - val_acc: 0.7738\n",
      "Epoch 270/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6984 - acc: 0.7563 - val_loss: 0.6484 - val_acc: 0.7731\n",
      "Epoch 271/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6939 - acc: 0.7556 - val_loss: 0.6479 - val_acc: 0.7731\n",
      "Epoch 272/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6979 - acc: 0.7530 - val_loss: 0.6442 - val_acc: 0.7746\n",
      "Epoch 273/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7050 - acc: 0.7560 - val_loss: 0.6496 - val_acc: 0.7723\n",
      "Epoch 274/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7038 - acc: 0.7515 - val_loss: 0.6495 - val_acc: 0.7723\n",
      "Epoch 275/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7015 - acc: 0.7593 - val_loss: 0.6472 - val_acc: 0.7731\n",
      "Epoch 276/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6960 - acc: 0.7556 - val_loss: 0.6488 - val_acc: 0.7731\n",
      "Epoch 277/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7007 - acc: 0.7530 - val_loss: 0.6490 - val_acc: 0.7723\n",
      "\n",
      "Epoch 00277: loss improved from 0.70363 to 0.70071, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-1-000277-0.700707-0.772321.hdf5\n",
      "Epoch 278/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7108 - acc: 0.7533 - val_loss: 0.6462 - val_acc: 0.7738\n",
      "Epoch 279/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6898 - acc: 0.7727 - val_loss: 0.6493 - val_acc: 0.7723\n",
      "Epoch 280/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6918 - acc: 0.7541 - val_loss: 0.6482 - val_acc: 0.7738\n",
      "Epoch 281/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6988 - acc: 0.7541 - val_loss: 0.6492 - val_acc: 0.7723\n",
      "\n",
      "Epoch 00281: loss improved from 0.70071 to 0.69883, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-1-000281-0.698826-0.772321.hdf5\n",
      "Epoch 282/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6934 - acc: 0.7563 - val_loss: 0.6488 - val_acc: 0.7731\n",
      "Epoch 283/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6876 - acc: 0.7653 - val_loss: 0.6459 - val_acc: 0.7753\n",
      "Epoch 284/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6897 - acc: 0.7586 - val_loss: 0.6494 - val_acc: 0.7723\n",
      "Epoch 285/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6865 - acc: 0.7623 - val_loss: 0.6484 - val_acc: 0.7738\n",
      "\n",
      "Epoch 00285: loss improved from 0.69883 to 0.68650, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-1-000285-0.686503-0.773810.hdf5\n",
      "Epoch 286/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7002 - acc: 0.7597 - val_loss: 0.6490 - val_acc: 0.7731\n",
      "Epoch 287/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.6917 - acc: 0.7671 - val_loss: 0.6490 - val_acc: 0.7723\n",
      "Epoch 288/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6933 - acc: 0.7697 - val_loss: 0.6488 - val_acc: 0.7731\n",
      "Epoch 289/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6921 - acc: 0.7649 - val_loss: 0.6500 - val_acc: 0.7723\n",
      "Epoch 290/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7007 - acc: 0.7552 - val_loss: 0.6491 - val_acc: 0.7723\n",
      "Epoch 291/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7099 - acc: 0.7526 - val_loss: 0.6500 - val_acc: 0.7723\n",
      "Epoch 292/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6955 - acc: 0.7586 - val_loss: 0.6486 - val_acc: 0.7731\n",
      "Epoch 293/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6980 - acc: 0.7582 - val_loss: 0.6491 - val_acc: 0.7723\n",
      "Epoch 294/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6990 - acc: 0.7533 - val_loss: 0.6466 - val_acc: 0.7738\n",
      "Epoch 295/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7057 - acc: 0.7526 - val_loss: 0.6489 - val_acc: 0.7731\n",
      "Epoch 296/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6813 - acc: 0.7541 - val_loss: 0.6493 - val_acc: 0.7723\n",
      "Epoch 297/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6961 - acc: 0.7593 - val_loss: 0.6449 - val_acc: 0.7738\n",
      "Epoch 298/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6986 - acc: 0.7567 - val_loss: 0.6496 - val_acc: 0.7723\n",
      "Epoch 299/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6941 - acc: 0.7619 - val_loss: 0.6488 - val_acc: 0.7731\n",
      "Epoch 300/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6914 - acc: 0.7593 - val_loss: 0.6492 - val_acc: 0.7723\n",
      "\n",
      "Epoch 00300: saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/1-000300-0.691357-0.772321.hdf5\n",
      "Epoch 301/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6944 - acc: 0.7586 - val_loss: 0.6477 - val_acc: 0.7738\n",
      "Epoch 302/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7070 - acc: 0.7500 - val_loss: 0.6496 - val_acc: 0.7723\n",
      "Epoch 303/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6913 - acc: 0.7623 - val_loss: 0.6487 - val_acc: 0.7731\n",
      "Epoch 304/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6847 - acc: 0.7589 - val_loss: 0.6485 - val_acc: 0.7731\n",
      "Epoch 305/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7025 - acc: 0.7578 - val_loss: 0.6487 - val_acc: 0.7731\n",
      "Epoch 306/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6810 - acc: 0.7638 - val_loss: 0.6475 - val_acc: 0.7738\n",
      "Epoch 307/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6932 - acc: 0.7578 - val_loss: 0.6497 - val_acc: 0.7723\n",
      "Epoch 308/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6953 - acc: 0.7626 - val_loss: 0.6491 - val_acc: 0.7731\n",
      "Epoch 309/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6899 - acc: 0.7586 - val_loss: 0.6486 - val_acc: 0.7731\n",
      "Epoch 310/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6787 - acc: 0.7608 - val_loss: 0.6435 - val_acc: 0.7738\n",
      "Epoch 311/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7018 - acc: 0.7526 - val_loss: 0.6475 - val_acc: 0.7738\n",
      "Epoch 312/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6940 - acc: 0.7515 - val_loss: 0.6477 - val_acc: 0.7738\n",
      "Epoch 313/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6889 - acc: 0.7612 - val_loss: 0.6466 - val_acc: 0.7738\n",
      "Epoch 314/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7005 - acc: 0.7519 - val_loss: 0.6460 - val_acc: 0.7738\n",
      "Epoch 315/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6982 - acc: 0.7597 - val_loss: 0.6461 - val_acc: 0.7738\n",
      "Epoch 316/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6979 - acc: 0.7612 - val_loss: 0.6497 - val_acc: 0.7723\n",
      "Epoch 317/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6969 - acc: 0.7619 - val_loss: 0.6420 - val_acc: 0.7738\n",
      "Epoch 318/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7007 - acc: 0.7582 - val_loss: 0.6491 - val_acc: 0.7731\n",
      "Epoch 319/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6918 - acc: 0.7630 - val_loss: 0.6498 - val_acc: 0.7723\n",
      "Epoch 320/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6994 - acc: 0.7634 - val_loss: 0.6472 - val_acc: 0.7738\n",
      "Epoch 321/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6928 - acc: 0.7600 - val_loss: 0.6497 - val_acc: 0.7723\n",
      "Epoch 322/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6872 - acc: 0.7634 - val_loss: 0.6489 - val_acc: 0.7731\n",
      "Epoch 323/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7078 - acc: 0.7545 - val_loss: 0.6489 - val_acc: 0.7731\n",
      "Epoch 324/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6886 - acc: 0.7641 - val_loss: 0.6495 - val_acc: 0.7723\n",
      "Epoch 325/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7050 - acc: 0.7619 - val_loss: 0.6491 - val_acc: 0.7723\n",
      "Epoch 326/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6985 - acc: 0.7522 - val_loss: 0.6497 - val_acc: 0.7723\n",
      "Epoch 327/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6970 - acc: 0.7578 - val_loss: 0.6448 - val_acc: 0.7746\n",
      "Epoch 328/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6874 - acc: 0.7701 - val_loss: 0.6455 - val_acc: 0.7738\n",
      "Epoch 329/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6918 - acc: 0.7623 - val_loss: 0.6484 - val_acc: 0.7731\n",
      "Epoch 330/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7033 - acc: 0.7485 - val_loss: 0.6461 - val_acc: 0.7738\n",
      "Epoch 331/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6941 - acc: 0.7608 - val_loss: 0.6488 - val_acc: 0.7723\n",
      "Epoch 332/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7043 - acc: 0.7615 - val_loss: 0.6463 - val_acc: 0.7738\n",
      "Epoch 333/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6991 - acc: 0.7593 - val_loss: 0.6489 - val_acc: 0.7723\n",
      "Epoch 334/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6958 - acc: 0.7615 - val_loss: 0.6480 - val_acc: 0.7731\n",
      "Epoch 335/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7221 - acc: 0.7533 - val_loss: 0.6491 - val_acc: 0.7731\n",
      "Epoch 336/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7008 - acc: 0.7511 - val_loss: 0.6486 - val_acc: 0.7723\n",
      "Epoch 337/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7035 - acc: 0.7548 - val_loss: 0.6494 - val_acc: 0.7723\n",
      "Epoch 338/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6909 - acc: 0.7608 - val_loss: 0.6494 - val_acc: 0.7723\n",
      "Epoch 339/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6779 - acc: 0.7645 - val_loss: 0.6473 - val_acc: 0.7731\n",
      "Epoch 340/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7059 - acc: 0.7548 - val_loss: 0.6488 - val_acc: 0.7731\n",
      "Epoch 341/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7142 - acc: 0.7500 - val_loss: 0.6454 - val_acc: 0.7738\n",
      "Epoch 342/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6860 - acc: 0.7656 - val_loss: 0.6489 - val_acc: 0.7723\n",
      "Epoch 343/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6873 - acc: 0.7645 - val_loss: 0.6452 - val_acc: 0.7731\n",
      "Epoch 344/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6782 - acc: 0.7660 - val_loss: 0.6497 - val_acc: 0.7723\n",
      "Epoch 345/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6915 - acc: 0.7664 - val_loss: 0.6489 - val_acc: 0.7731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 346/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6738 - acc: 0.7612 - val_loss: 0.6495 - val_acc: 0.7723\n",
      "Epoch 347/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7024 - acc: 0.7556 - val_loss: 0.6464 - val_acc: 0.7738\n",
      "Epoch 348/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6893 - acc: 0.7645 - val_loss: 0.6467 - val_acc: 0.7738\n",
      "Epoch 349/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7029 - acc: 0.7578 - val_loss: 0.6491 - val_acc: 0.7723\n",
      "Epoch 350/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6776 - acc: 0.7612 - val_loss: 0.6486 - val_acc: 0.7731\n",
      "Epoch 351/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6810 - acc: 0.7719 - val_loss: 0.6495 - val_acc: 0.7723\n",
      "Epoch 352/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7066 - acc: 0.7537 - val_loss: 0.6466 - val_acc: 0.7731\n",
      "Epoch 353/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7173 - acc: 0.7507 - val_loss: 0.6470 - val_acc: 0.7731\n",
      "Epoch 354/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6825 - acc: 0.7582 - val_loss: 0.6493 - val_acc: 0.7723\n",
      "Epoch 355/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6998 - acc: 0.7586 - val_loss: 0.6485 - val_acc: 0.7731\n",
      "Epoch 356/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6913 - acc: 0.7645 - val_loss: 0.6497 - val_acc: 0.7723\n",
      "Epoch 357/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6893 - acc: 0.7556 - val_loss: 0.6496 - val_acc: 0.7716\n",
      "Epoch 358/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7017 - acc: 0.7541 - val_loss: 0.6493 - val_acc: 0.7716\n",
      "Epoch 359/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6865 - acc: 0.7600 - val_loss: 0.6485 - val_acc: 0.7723\n",
      "Epoch 360/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6897 - acc: 0.7634 - val_loss: 0.6480 - val_acc: 0.7723\n",
      "Epoch 361/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7024 - acc: 0.7604 - val_loss: 0.6485 - val_acc: 0.7723\n",
      "Epoch 362/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6831 - acc: 0.7615 - val_loss: 0.6486 - val_acc: 0.7723\n",
      "Epoch 363/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7014 - acc: 0.7496 - val_loss: 0.6496 - val_acc: 0.7716\n",
      "Epoch 364/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6956 - acc: 0.7511 - val_loss: 0.6495 - val_acc: 0.7708\n",
      "Epoch 365/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7173 - acc: 0.7545 - val_loss: 0.6481 - val_acc: 0.7716\n",
      "\n",
      "Epoch 00365: loss improved from inf to 0.71734, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-1-000365-0.717340-0.771577.hdf5\n",
      "Epoch 366/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7052 - acc: 0.7582 - val_loss: 0.6493 - val_acc: 0.7708\n",
      "Epoch 367/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7029 - acc: 0.7526 - val_loss: 0.6494 - val_acc: 0.7708\n",
      "Epoch 368/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6821 - acc: 0.7660 - val_loss: 0.6498 - val_acc: 0.7708\n",
      "Epoch 369/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6919 - acc: 0.7630 - val_loss: 0.6495 - val_acc: 0.7708\n",
      "\n",
      "Epoch 00369: loss improved from 0.71734 to 0.69188, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-1-000369-0.691876-0.770833.hdf5\n",
      "Epoch 370/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7070 - acc: 0.7604 - val_loss: 0.6484 - val_acc: 0.7716\n",
      "Epoch 371/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6934 - acc: 0.7571 - val_loss: 0.6477 - val_acc: 0.7716\n",
      "Epoch 372/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6889 - acc: 0.7649 - val_loss: 0.6495 - val_acc: 0.7708\n",
      "Epoch 373/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7062 - acc: 0.7563 - val_loss: 0.6479 - val_acc: 0.7723\n",
      "Epoch 374/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6965 - acc: 0.7567 - val_loss: 0.6488 - val_acc: 0.7716\n",
      "Epoch 375/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6875 - acc: 0.7645 - val_loss: 0.6473 - val_acc: 0.7716\n",
      "Epoch 376/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6891 - acc: 0.7641 - val_loss: 0.6469 - val_acc: 0.7716\n",
      "Epoch 377/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6755 - acc: 0.7686 - val_loss: 0.6472 - val_acc: 0.7716\n",
      "\n",
      "Epoch 00377: loss improved from 0.69188 to 0.67553, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-1-000377-0.675533-0.771577.hdf5\n",
      "Epoch 378/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7160 - acc: 0.7515 - val_loss: 0.6457 - val_acc: 0.7723\n",
      "Epoch 379/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7011 - acc: 0.7526 - val_loss: 0.6449 - val_acc: 0.7723\n",
      "Epoch 380/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7067 - acc: 0.7571 - val_loss: 0.6466 - val_acc: 0.7723\n",
      "Epoch 381/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7057 - acc: 0.7567 - val_loss: 0.6475 - val_acc: 0.7716\n",
      "Epoch 382/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7045 - acc: 0.7604 - val_loss: 0.6479 - val_acc: 0.7716\n",
      "Epoch 383/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6990 - acc: 0.7589 - val_loss: 0.6466 - val_acc: 0.7716\n",
      "Epoch 384/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7029 - acc: 0.7530 - val_loss: 0.6484 - val_acc: 0.7716\n",
      "Epoch 385/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6855 - acc: 0.7641 - val_loss: 0.6497 - val_acc: 0.7708\n",
      "Epoch 386/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6779 - acc: 0.7578 - val_loss: 0.6484 - val_acc: 0.7716\n",
      "Epoch 387/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6908 - acc: 0.7537 - val_loss: 0.6489 - val_acc: 0.7708\n",
      "Epoch 388/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6895 - acc: 0.7578 - val_loss: 0.6486 - val_acc: 0.7716\n",
      "Epoch 389/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6923 - acc: 0.7653 - val_loss: 0.6481 - val_acc: 0.7716\n",
      "Epoch 390/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6957 - acc: 0.7649 - val_loss: 0.6434 - val_acc: 0.7723\n",
      "Epoch 391/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6925 - acc: 0.7563 - val_loss: 0.6496 - val_acc: 0.7708\n",
      "Epoch 392/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6996 - acc: 0.7571 - val_loss: 0.6494 - val_acc: 0.7708\n",
      "Epoch 393/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7121 - acc: 0.7604 - val_loss: 0.6470 - val_acc: 0.7716\n",
      "Epoch 394/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7105 - acc: 0.7533 - val_loss: 0.6487 - val_acc: 0.7716\n",
      "Epoch 395/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6894 - acc: 0.7619 - val_loss: 0.6457 - val_acc: 0.7731\n",
      "Epoch 396/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6967 - acc: 0.7552 - val_loss: 0.6483 - val_acc: 0.7716\n",
      "Epoch 397/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7118 - acc: 0.7537 - val_loss: 0.6476 - val_acc: 0.7716\n",
      "Epoch 398/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6962 - acc: 0.7586 - val_loss: 0.6492 - val_acc: 0.7708\n",
      "Epoch 399/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6909 - acc: 0.7649 - val_loss: 0.6485 - val_acc: 0.7716\n",
      "Epoch 400/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6982 - acc: 0.7511 - val_loss: 0.6448 - val_acc: 0.7723\n",
      "\n",
      "Epoch 00400: saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/1-000400-0.698173-0.772321.hdf5\n",
      "Epoch 401/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6929 - acc: 0.7612 - val_loss: 0.6481 - val_acc: 0.7716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 402/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7042 - acc: 0.7545 - val_loss: 0.6498 - val_acc: 0.7708\n",
      "Epoch 403/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6890 - acc: 0.7641 - val_loss: 0.6494 - val_acc: 0.7708\n",
      "Epoch 404/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7167 - acc: 0.7519 - val_loss: 0.6494 - val_acc: 0.7708\n",
      "Epoch 405/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6934 - acc: 0.7563 - val_loss: 0.6463 - val_acc: 0.7723\n",
      "Epoch 406/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7030 - acc: 0.7600 - val_loss: 0.6489 - val_acc: 0.7708\n",
      "Epoch 407/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6941 - acc: 0.7615 - val_loss: 0.6484 - val_acc: 0.7716\n",
      "Epoch 408/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7058 - acc: 0.7489 - val_loss: 0.6459 - val_acc: 0.7731\n",
      "Epoch 409/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6949 - acc: 0.7612 - val_loss: 0.6490 - val_acc: 0.7708\n",
      "Epoch 410/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6935 - acc: 0.7567 - val_loss: 0.6493 - val_acc: 0.7708\n",
      "Epoch 411/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6878 - acc: 0.7634 - val_loss: 0.6496 - val_acc: 0.7708\n",
      "Epoch 412/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7026 - acc: 0.7586 - val_loss: 0.6486 - val_acc: 0.7708\n",
      "Epoch 413/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6974 - acc: 0.7604 - val_loss: 0.6480 - val_acc: 0.7716\n",
      "Epoch 414/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7099 - acc: 0.7522 - val_loss: 0.6484 - val_acc: 0.7716\n",
      "Epoch 415/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7068 - acc: 0.7586 - val_loss: 0.6473 - val_acc: 0.7716\n",
      "Epoch 416/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7010 - acc: 0.7589 - val_loss: 0.6497 - val_acc: 0.7708\n",
      "Epoch 417/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6878 - acc: 0.7541 - val_loss: 0.6486 - val_acc: 0.7716\n",
      "Epoch 418/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6994 - acc: 0.7612 - val_loss: 0.6469 - val_acc: 0.7723\n",
      "Epoch 419/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6968 - acc: 0.7619 - val_loss: 0.6484 - val_acc: 0.7716\n",
      "Epoch 420/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7071 - acc: 0.7619 - val_loss: 0.6474 - val_acc: 0.7716\n",
      "Epoch 421/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7056 - acc: 0.7604 - val_loss: 0.6469 - val_acc: 0.7716\n",
      "Epoch 422/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7031 - acc: 0.7600 - val_loss: 0.6477 - val_acc: 0.7716\n",
      "Epoch 423/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6967 - acc: 0.7608 - val_loss: 0.6471 - val_acc: 0.7716\n",
      "Epoch 424/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6955 - acc: 0.7630 - val_loss: 0.6495 - val_acc: 0.7708\n",
      "Epoch 425/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6949 - acc: 0.7563 - val_loss: 0.6483 - val_acc: 0.7716\n",
      "Epoch 426/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6978 - acc: 0.7619 - val_loss: 0.6467 - val_acc: 0.7723\n",
      "Epoch 427/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6897 - acc: 0.7604 - val_loss: 0.6468 - val_acc: 0.7723\n",
      "Epoch 428/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6927 - acc: 0.7589 - val_loss: 0.6481 - val_acc: 0.7723\n",
      "Epoch 429/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7114 - acc: 0.7548 - val_loss: 0.6496 - val_acc: 0.7708\n",
      "Epoch 430/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6840 - acc: 0.7682 - val_loss: 0.6468 - val_acc: 0.7716\n",
      "Epoch 431/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6889 - acc: 0.7634 - val_loss: 0.6471 - val_acc: 0.7723\n",
      "Epoch 432/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6922 - acc: 0.7608 - val_loss: 0.6477 - val_acc: 0.7723\n",
      "Epoch 433/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6809 - acc: 0.7604 - val_loss: 0.6471 - val_acc: 0.7723\n",
      "Epoch 434/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6904 - acc: 0.7578 - val_loss: 0.6490 - val_acc: 0.7708\n",
      "Epoch 435/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6998 - acc: 0.7552 - val_loss: 0.6494 - val_acc: 0.7708\n",
      "Epoch 436/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7138 - acc: 0.7537 - val_loss: 0.6492 - val_acc: 0.7708\n",
      "Epoch 437/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6905 - acc: 0.7612 - val_loss: 0.6464 - val_acc: 0.7723\n",
      "Epoch 438/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6947 - acc: 0.7634 - val_loss: 0.6492 - val_acc: 0.7708\n",
      "Epoch 439/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7070 - acc: 0.7626 - val_loss: 0.6449 - val_acc: 0.7723\n",
      "Epoch 440/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6972 - acc: 0.7574 - val_loss: 0.6483 - val_acc: 0.7716\n",
      "Epoch 441/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6796 - acc: 0.7615 - val_loss: 0.6474 - val_acc: 0.7723\n",
      "Epoch 442/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7028 - acc: 0.7556 - val_loss: 0.6451 - val_acc: 0.7723\n",
      "Epoch 443/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7074 - acc: 0.7597 - val_loss: 0.6487 - val_acc: 0.7708\n",
      "Epoch 444/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6928 - acc: 0.7556 - val_loss: 0.6480 - val_acc: 0.7716\n",
      "Epoch 445/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6971 - acc: 0.7530 - val_loss: 0.6494 - val_acc: 0.7708\n",
      "Epoch 446/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7052 - acc: 0.7522 - val_loss: 0.6489 - val_acc: 0.7708\n",
      "Epoch 447/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7205 - acc: 0.7496 - val_loss: 0.6497 - val_acc: 0.7708\n",
      "Epoch 448/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6966 - acc: 0.7526 - val_loss: 0.6495 - val_acc: 0.7708\n",
      "Epoch 449/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6888 - acc: 0.7586 - val_loss: 0.6497 - val_acc: 0.7708\n",
      "Epoch 450/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6944 - acc: 0.7507 - val_loss: 0.6483 - val_acc: 0.7716\n",
      "Epoch 451/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6853 - acc: 0.7649 - val_loss: 0.6493 - val_acc: 0.7708\n",
      "Epoch 452/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7041 - acc: 0.7563 - val_loss: 0.6492 - val_acc: 0.7708\n",
      "Epoch 453/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6935 - acc: 0.7675 - val_loss: 0.6489 - val_acc: 0.7708\n",
      "Epoch 454/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7074 - acc: 0.7504 - val_loss: 0.6478 - val_acc: 0.7723\n",
      "Epoch 455/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7052 - acc: 0.7522 - val_loss: 0.6465 - val_acc: 0.7716\n",
      "Epoch 456/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7025 - acc: 0.7574 - val_loss: 0.6485 - val_acc: 0.7708\n",
      "Epoch 457/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6923 - acc: 0.7533 - val_loss: 0.6457 - val_acc: 0.7716\n",
      "Epoch 458/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6952 - acc: 0.7589 - val_loss: 0.6494 - val_acc: 0.7708\n",
      "Epoch 459/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6896 - acc: 0.7660 - val_loss: 0.6490 - val_acc: 0.7708\n",
      "Epoch 460/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6866 - acc: 0.7645 - val_loss: 0.6474 - val_acc: 0.7716\n",
      "Epoch 461/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7010 - acc: 0.7615 - val_loss: 0.6489 - val_acc: 0.7716\n",
      "Epoch 462/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6946 - acc: 0.7533 - val_loss: 0.6490 - val_acc: 0.7716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 463/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6943 - acc: 0.7567 - val_loss: 0.6494 - val_acc: 0.7708\n",
      "Epoch 464/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6964 - acc: 0.7615 - val_loss: 0.6494 - val_acc: 0.7708\n",
      "Epoch 465/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6992 - acc: 0.7593 - val_loss: 0.6460 - val_acc: 0.7723\n",
      "\n",
      "Epoch 00465: loss improved from inf to 0.69919, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-1-000465-0.699187-0.772321.hdf5\n",
      "Epoch 466/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6922 - acc: 0.7533 - val_loss: 0.6469 - val_acc: 0.7723\n",
      "Epoch 467/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7037 - acc: 0.7522 - val_loss: 0.6494 - val_acc: 0.7708\n",
      "Epoch 468/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7202 - acc: 0.7478 - val_loss: 0.6458 - val_acc: 0.7716\n",
      "Epoch 469/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6986 - acc: 0.7608 - val_loss: 0.6494 - val_acc: 0.7708\n",
      "\n",
      "Epoch 00469: loss improved from 0.69919 to 0.69859, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-1-000469-0.698593-0.770833.hdf5\n",
      "Epoch 470/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6900 - acc: 0.7560 - val_loss: 0.6487 - val_acc: 0.7708\n",
      "Epoch 471/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7045 - acc: 0.7589 - val_loss: 0.6488 - val_acc: 0.7716\n",
      "Epoch 472/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7015 - acc: 0.7537 - val_loss: 0.6491 - val_acc: 0.7708\n",
      "Epoch 473/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6934 - acc: 0.7615 - val_loss: 0.6485 - val_acc: 0.7708\n",
      "\n",
      "Epoch 00473: loss improved from 0.69859 to 0.69341, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-1-000473-0.693409-0.770833.hdf5\n",
      "Epoch 474/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7023 - acc: 0.7582 - val_loss: 0.6467 - val_acc: 0.7716\n",
      "Epoch 475/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7017 - acc: 0.7574 - val_loss: 0.6493 - val_acc: 0.7708\n",
      "Epoch 476/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6863 - acc: 0.7608 - val_loss: 0.6477 - val_acc: 0.7716\n",
      "Epoch 477/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6865 - acc: 0.7653 - val_loss: 0.6470 - val_acc: 0.7716\n",
      "\n",
      "Epoch 00477: loss improved from 0.69341 to 0.68650, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-1-000477-0.686497-0.771577.hdf5\n",
      "Epoch 478/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6881 - acc: 0.7571 - val_loss: 0.6488 - val_acc: 0.7716\n",
      "Epoch 479/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6966 - acc: 0.7589 - val_loss: 0.6485 - val_acc: 0.7716\n",
      "Epoch 480/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7043 - acc: 0.7578 - val_loss: 0.6492 - val_acc: 0.7708\n",
      "Epoch 481/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7009 - acc: 0.7567 - val_loss: 0.6475 - val_acc: 0.7716\n",
      "Epoch 482/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6896 - acc: 0.7634 - val_loss: 0.6456 - val_acc: 0.7723\n",
      "Epoch 483/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6874 - acc: 0.7500 - val_loss: 0.6486 - val_acc: 0.7716\n",
      "Epoch 484/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6936 - acc: 0.7541 - val_loss: 0.6480 - val_acc: 0.7716\n",
      "Epoch 485/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6935 - acc: 0.7630 - val_loss: 0.6471 - val_acc: 0.7723\n",
      "Epoch 486/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6930 - acc: 0.7600 - val_loss: 0.6482 - val_acc: 0.7723\n",
      "Epoch 487/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7115 - acc: 0.7563 - val_loss: 0.6492 - val_acc: 0.7708\n",
      "Epoch 488/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6852 - acc: 0.7667 - val_loss: 0.6494 - val_acc: 0.7708\n",
      "Epoch 489/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6825 - acc: 0.7626 - val_loss: 0.6489 - val_acc: 0.7716\n",
      "\n",
      "Epoch 00489: loss improved from 0.68650 to 0.68245, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-1-000489-0.682455-0.771577.hdf5\n",
      "Epoch 490/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7028 - acc: 0.7589 - val_loss: 0.6475 - val_acc: 0.7716\n",
      "Epoch 491/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7006 - acc: 0.7619 - val_loss: 0.6490 - val_acc: 0.7708\n",
      "Epoch 492/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7068 - acc: 0.7537 - val_loss: 0.6486 - val_acc: 0.7716\n",
      "Epoch 493/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6858 - acc: 0.7597 - val_loss: 0.6459 - val_acc: 0.7723\n",
      "Epoch 494/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6877 - acc: 0.7582 - val_loss: 0.6485 - val_acc: 0.7716\n",
      "Epoch 495/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6906 - acc: 0.7615 - val_loss: 0.6469 - val_acc: 0.7716\n",
      "Epoch 496/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7023 - acc: 0.7586 - val_loss: 0.6439 - val_acc: 0.7723\n",
      "Epoch 497/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6958 - acc: 0.7582 - val_loss: 0.6496 - val_acc: 0.7708\n",
      "Epoch 498/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6917 - acc: 0.7597 - val_loss: 0.6445 - val_acc: 0.7716\n",
      "Epoch 499/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7127 - acc: 0.7507 - val_loss: 0.6460 - val_acc: 0.7731\n",
      "Epoch 500/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6960 - acc: 0.7641 - val_loss: 0.6474 - val_acc: 0.7731\n",
      "\n",
      "Epoch 00500: saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/1-000500-0.696021-0.773065.hdf5\n",
      "Epoch 501/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7008 - acc: 0.7578 - val_loss: 0.6491 - val_acc: 0.7708\n",
      "Epoch 502/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6897 - acc: 0.7608 - val_loss: 0.6473 - val_acc: 0.7716\n",
      "Epoch 503/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6894 - acc: 0.7675 - val_loss: 0.6456 - val_acc: 0.7731\n",
      "Epoch 504/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7101 - acc: 0.7541 - val_loss: 0.6476 - val_acc: 0.7716\n",
      "Epoch 505/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6977 - acc: 0.7552 - val_loss: 0.6477 - val_acc: 0.7716\n",
      "Epoch 506/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7034 - acc: 0.7496 - val_loss: 0.6478 - val_acc: 0.7716\n",
      "Epoch 507/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6901 - acc: 0.7545 - val_loss: 0.6491 - val_acc: 0.7708\n",
      "Epoch 508/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6735 - acc: 0.7634 - val_loss: 0.6444 - val_acc: 0.7716\n",
      "Epoch 509/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7026 - acc: 0.7541 - val_loss: 0.6482 - val_acc: 0.7716\n",
      "Epoch 510/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7026 - acc: 0.7612 - val_loss: 0.6491 - val_acc: 0.7708\n",
      "Epoch 511/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6977 - acc: 0.7582 - val_loss: 0.6472 - val_acc: 0.7716\n",
      "Epoch 512/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6872 - acc: 0.7630 - val_loss: 0.6472 - val_acc: 0.7716\n",
      "Epoch 513/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6895 - acc: 0.7493 - val_loss: 0.6474 - val_acc: 0.7716\n",
      "Epoch 514/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6961 - acc: 0.7548 - val_loss: 0.6452 - val_acc: 0.7723\n",
      "Epoch 515/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7030 - acc: 0.7612 - val_loss: 0.6493 - val_acc: 0.7708\n",
      "Epoch 516/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6877 - acc: 0.7660 - val_loss: 0.6454 - val_acc: 0.7731\n",
      "Epoch 517/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7020 - acc: 0.7552 - val_loss: 0.6468 - val_acc: 0.7716\n",
      "Epoch 518/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6945 - acc: 0.7612 - val_loss: 0.6441 - val_acc: 0.7716\n",
      "Epoch 519/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6984 - acc: 0.7574 - val_loss: 0.6452 - val_acc: 0.7723\n",
      "Epoch 520/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6943 - acc: 0.7612 - val_loss: 0.6483 - val_acc: 0.7723\n",
      "Epoch 521/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7008 - acc: 0.7526 - val_loss: 0.6471 - val_acc: 0.7723\n",
      "Epoch 522/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7116 - acc: 0.7507 - val_loss: 0.6489 - val_acc: 0.7716\n",
      "Epoch 523/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7102 - acc: 0.7448 - val_loss: 0.6469 - val_acc: 0.7723\n",
      "Epoch 524/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6902 - acc: 0.7664 - val_loss: 0.6456 - val_acc: 0.7716\n",
      "Epoch 525/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7024 - acc: 0.7560 - val_loss: 0.6475 - val_acc: 0.7716\n",
      "Epoch 526/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6954 - acc: 0.7589 - val_loss: 0.6480 - val_acc: 0.7716\n",
      "Epoch 527/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6936 - acc: 0.7507 - val_loss: 0.6482 - val_acc: 0.7716\n",
      "Epoch 528/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6888 - acc: 0.7664 - val_loss: 0.6454 - val_acc: 0.7723\n",
      "Epoch 529/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7040 - acc: 0.7537 - val_loss: 0.6490 - val_acc: 0.7708\n",
      "Epoch 530/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6952 - acc: 0.7571 - val_loss: 0.6479 - val_acc: 0.7708\n",
      "Epoch 531/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6867 - acc: 0.7593 - val_loss: 0.6480 - val_acc: 0.7716\n",
      "Epoch 532/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6958 - acc: 0.7638 - val_loss: 0.6489 - val_acc: 0.7708\n",
      "Epoch 533/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6977 - acc: 0.7567 - val_loss: 0.6482 - val_acc: 0.7716\n",
      "Epoch 534/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6840 - acc: 0.7552 - val_loss: 0.6484 - val_acc: 0.7716\n",
      "Epoch 535/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6829 - acc: 0.7682 - val_loss: 0.6490 - val_acc: 0.7708\n",
      "Epoch 536/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7165 - acc: 0.7556 - val_loss: 0.6492 - val_acc: 0.7708\n",
      "Epoch 537/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7029 - acc: 0.7597 - val_loss: 0.6471 - val_acc: 0.7723\n",
      "Epoch 538/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6917 - acc: 0.7578 - val_loss: 0.6457 - val_acc: 0.7731\n",
      "Epoch 539/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6955 - acc: 0.7563 - val_loss: 0.6491 - val_acc: 0.7708\n",
      "Epoch 540/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6928 - acc: 0.7560 - val_loss: 0.6495 - val_acc: 0.7708\n",
      "Epoch 541/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7077 - acc: 0.7552 - val_loss: 0.6484 - val_acc: 0.7708\n",
      "Epoch 542/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6851 - acc: 0.7615 - val_loss: 0.6484 - val_acc: 0.7716\n",
      "Epoch 543/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7040 - acc: 0.7600 - val_loss: 0.6469 - val_acc: 0.7731\n",
      "Epoch 544/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7062 - acc: 0.7589 - val_loss: 0.6483 - val_acc: 0.7716\n",
      "Epoch 545/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6911 - acc: 0.7615 - val_loss: 0.6490 - val_acc: 0.7708\n",
      "Epoch 546/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6869 - acc: 0.7530 - val_loss: 0.6467 - val_acc: 0.7723\n",
      "Epoch 547/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7099 - acc: 0.7552 - val_loss: 0.6472 - val_acc: 0.7723\n",
      "Epoch 548/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7049 - acc: 0.7593 - val_loss: 0.6493 - val_acc: 0.7716\n",
      "Epoch 549/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7052 - acc: 0.7496 - val_loss: 0.6472 - val_acc: 0.7731\n",
      "Epoch 550/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7038 - acc: 0.7500 - val_loss: 0.6488 - val_acc: 0.7716\n",
      "Epoch 551/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7001 - acc: 0.7574 - val_loss: 0.6453 - val_acc: 0.7731\n",
      "Epoch 552/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7000 - acc: 0.7560 - val_loss: 0.6493 - val_acc: 0.7716\n",
      "Epoch 553/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6830 - acc: 0.7563 - val_loss: 0.6453 - val_acc: 0.7731\n",
      "Epoch 554/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7038 - acc: 0.7586 - val_loss: 0.6451 - val_acc: 0.7731\n",
      "Epoch 555/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6915 - acc: 0.7634 - val_loss: 0.6489 - val_acc: 0.7723\n",
      "Epoch 556/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6942 - acc: 0.7608 - val_loss: 0.6484 - val_acc: 0.7716\n",
      "Epoch 557/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7026 - acc: 0.7526 - val_loss: 0.6486 - val_acc: 0.7716\n",
      "Epoch 558/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7031 - acc: 0.7556 - val_loss: 0.6492 - val_acc: 0.7716\n",
      "Epoch 559/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7069 - acc: 0.7574 - val_loss: 0.6454 - val_acc: 0.7731\n",
      "Epoch 560/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6946 - acc: 0.7600 - val_loss: 0.6492 - val_acc: 0.7716\n",
      "Epoch 561/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6910 - acc: 0.7604 - val_loss: 0.6479 - val_acc: 0.7723\n",
      "Epoch 562/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7101 - acc: 0.7582 - val_loss: 0.6472 - val_acc: 0.7738\n",
      "Epoch 563/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6964 - acc: 0.7586 - val_loss: 0.6463 - val_acc: 0.7723\n",
      "Epoch 564/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6959 - acc: 0.7619 - val_loss: 0.6471 - val_acc: 0.7723\n",
      "Epoch 565/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7036 - acc: 0.7593 - val_loss: 0.6497 - val_acc: 0.7716\n",
      "\n",
      "Epoch 00565: loss improved from inf to 0.70361, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-1-000565-0.703614-0.771577.hdf5\n",
      "Epoch 566/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7075 - acc: 0.7604 - val_loss: 0.6478 - val_acc: 0.7723\n",
      "Epoch 567/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6978 - acc: 0.7582 - val_loss: 0.6495 - val_acc: 0.7716\n",
      "Epoch 568/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7064 - acc: 0.7615 - val_loss: 0.6476 - val_acc: 0.7723\n",
      "Epoch 569/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7104 - acc: 0.7545 - val_loss: 0.6492 - val_acc: 0.7716\n",
      "Epoch 570/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6986 - acc: 0.7608 - val_loss: 0.6497 - val_acc: 0.7716\n",
      "Epoch 571/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7030 - acc: 0.7545 - val_loss: 0.6496 - val_acc: 0.7716\n",
      "Epoch 572/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7048 - acc: 0.7597 - val_loss: 0.6478 - val_acc: 0.7723\n",
      "Epoch 573/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7056 - acc: 0.7519 - val_loss: 0.6488 - val_acc: 0.7716\n",
      "Epoch 574/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6770 - acc: 0.7675 - val_loss: 0.6474 - val_acc: 0.7723\n",
      "Epoch 575/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6972 - acc: 0.7541 - val_loss: 0.6493 - val_acc: 0.7716\n",
      "Epoch 576/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6930 - acc: 0.7608 - val_loss: 0.6478 - val_acc: 0.7723\n",
      "Epoch 577/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7095 - acc: 0.7507 - val_loss: 0.6485 - val_acc: 0.7716\n",
      "Epoch 578/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7018 - acc: 0.7619 - val_loss: 0.6473 - val_acc: 0.7723\n",
      "Epoch 579/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6930 - acc: 0.7619 - val_loss: 0.6492 - val_acc: 0.7716\n",
      "Epoch 580/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6913 - acc: 0.7545 - val_loss: 0.6489 - val_acc: 0.7716\n",
      "Epoch 581/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6909 - acc: 0.7619 - val_loss: 0.6494 - val_acc: 0.7716\n",
      "\n",
      "Epoch 00581: loss improved from 0.70361 to 0.69093, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-1-000581-0.690930-0.771577.hdf5\n",
      "Epoch 582/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6992 - acc: 0.7589 - val_loss: 0.6493 - val_acc: 0.7716\n",
      "Epoch 583/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7011 - acc: 0.7522 - val_loss: 0.6453 - val_acc: 0.7738\n",
      "Epoch 584/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7086 - acc: 0.7589 - val_loss: 0.6476 - val_acc: 0.7723\n",
      "Epoch 585/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7083 - acc: 0.7608 - val_loss: 0.6491 - val_acc: 0.7723\n",
      "Epoch 586/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6887 - acc: 0.7526 - val_loss: 0.6456 - val_acc: 0.7731\n",
      "Epoch 587/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6909 - acc: 0.7630 - val_loss: 0.6481 - val_acc: 0.7723\n",
      "Epoch 588/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6878 - acc: 0.7649 - val_loss: 0.6470 - val_acc: 0.7731\n",
      "Epoch 589/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7005 - acc: 0.7604 - val_loss: 0.6483 - val_acc: 0.7723\n",
      "Epoch 590/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7007 - acc: 0.7653 - val_loss: 0.6495 - val_acc: 0.7716\n",
      "Epoch 591/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6851 - acc: 0.7582 - val_loss: 0.6485 - val_acc: 0.7723\n",
      "Epoch 592/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7039 - acc: 0.7526 - val_loss: 0.6485 - val_acc: 0.7723\n",
      "Epoch 593/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7056 - acc: 0.7526 - val_loss: 0.6457 - val_acc: 0.7731\n",
      "Epoch 594/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6917 - acc: 0.7597 - val_loss: 0.6486 - val_acc: 0.7723\n",
      "Epoch 595/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7000 - acc: 0.7597 - val_loss: 0.6472 - val_acc: 0.7723\n",
      "Epoch 596/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6905 - acc: 0.7507 - val_loss: 0.6457 - val_acc: 0.7731\n",
      "Epoch 597/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6938 - acc: 0.7597 - val_loss: 0.6492 - val_acc: 0.7716\n",
      "Epoch 598/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7038 - acc: 0.7560 - val_loss: 0.6477 - val_acc: 0.7723\n",
      "Epoch 599/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6933 - acc: 0.7582 - val_loss: 0.6488 - val_acc: 0.7723\n",
      "Epoch 600/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6960 - acc: 0.7626 - val_loss: 0.6493 - val_acc: 0.7716\n",
      "\n",
      "Epoch 00600: saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/1-000600-0.696044-0.771577.hdf5\n",
      "Epoch 601/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7021 - acc: 0.7604 - val_loss: 0.6490 - val_acc: 0.7716\n",
      "Epoch 602/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7000 - acc: 0.7571 - val_loss: 0.6485 - val_acc: 0.7716\n",
      "Epoch 603/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6973 - acc: 0.7582 - val_loss: 0.6491 - val_acc: 0.7723\n",
      "Epoch 604/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6933 - acc: 0.7582 - val_loss: 0.6488 - val_acc: 0.7731\n",
      "Epoch 605/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6943 - acc: 0.7563 - val_loss: 0.6488 - val_acc: 0.7723\n",
      "Epoch 606/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6886 - acc: 0.7686 - val_loss: 0.6492 - val_acc: 0.7723\n",
      "Epoch 607/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6871 - acc: 0.7623 - val_loss: 0.6486 - val_acc: 0.7731\n",
      "Epoch 608/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6809 - acc: 0.7653 - val_loss: 0.6482 - val_acc: 0.7738\n",
      "Epoch 609/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6961 - acc: 0.7560 - val_loss: 0.6476 - val_acc: 0.7731\n",
      "Epoch 610/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6833 - acc: 0.7682 - val_loss: 0.6476 - val_acc: 0.7731\n",
      "Epoch 611/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6924 - acc: 0.7586 - val_loss: 0.6489 - val_acc: 0.7723\n",
      "Epoch 612/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7093 - acc: 0.7515 - val_loss: 0.6475 - val_acc: 0.7731\n",
      "Epoch 613/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7008 - acc: 0.7459 - val_loss: 0.6491 - val_acc: 0.7723\n",
      "Epoch 614/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7027 - acc: 0.7537 - val_loss: 0.6470 - val_acc: 0.7731\n",
      "Epoch 615/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6797 - acc: 0.7600 - val_loss: 0.6466 - val_acc: 0.7738\n",
      "Epoch 616/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6959 - acc: 0.7541 - val_loss: 0.6478 - val_acc: 0.7738\n",
      "Epoch 617/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6945 - acc: 0.7615 - val_loss: 0.6491 - val_acc: 0.7723\n",
      "Epoch 618/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6843 - acc: 0.7656 - val_loss: 0.6460 - val_acc: 0.7738\n",
      "Epoch 619/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6854 - acc: 0.7608 - val_loss: 0.6480 - val_acc: 0.7731\n",
      "Epoch 620/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6801 - acc: 0.7630 - val_loss: 0.6480 - val_acc: 0.7731\n",
      "Epoch 621/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7060 - acc: 0.7533 - val_loss: 0.6495 - val_acc: 0.7723\n",
      "Epoch 622/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6901 - acc: 0.7612 - val_loss: 0.6490 - val_acc: 0.7723\n",
      "Epoch 623/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7062 - acc: 0.7574 - val_loss: 0.6446 - val_acc: 0.7738\n",
      "Epoch 624/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6955 - acc: 0.7586 - val_loss: 0.6483 - val_acc: 0.7731\n",
      "Epoch 625/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7023 - acc: 0.7515 - val_loss: 0.6455 - val_acc: 0.7731\n",
      "Epoch 626/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6983 - acc: 0.7574 - val_loss: 0.6485 - val_acc: 0.7731\n",
      "Epoch 627/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6982 - acc: 0.7600 - val_loss: 0.6464 - val_acc: 0.7738\n",
      "Epoch 628/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6993 - acc: 0.7571 - val_loss: 0.6484 - val_acc: 0.7723\n",
      "Epoch 629/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6780 - acc: 0.7623 - val_loss: 0.6476 - val_acc: 0.7731\n",
      "Epoch 630/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7007 - acc: 0.7619 - val_loss: 0.6495 - val_acc: 0.7716\n",
      "Epoch 631/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6894 - acc: 0.7597 - val_loss: 0.6478 - val_acc: 0.7731\n",
      "Epoch 632/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6962 - acc: 0.7586 - val_loss: 0.6459 - val_acc: 0.7723\n",
      "Epoch 633/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7021 - acc: 0.7519 - val_loss: 0.6485 - val_acc: 0.7723\n",
      "Epoch 634/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7102 - acc: 0.7519 - val_loss: 0.6473 - val_acc: 0.7738\n",
      "Epoch 635/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6932 - acc: 0.7571 - val_loss: 0.6476 - val_acc: 0.7738\n",
      "Epoch 636/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6922 - acc: 0.7586 - val_loss: 0.6482 - val_acc: 0.7731\n",
      "Epoch 637/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6801 - acc: 0.7634 - val_loss: 0.6452 - val_acc: 0.7738\n",
      "Epoch 638/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7108 - acc: 0.7526 - val_loss: 0.6469 - val_acc: 0.7731\n",
      "Epoch 639/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7030 - acc: 0.7589 - val_loss: 0.6475 - val_acc: 0.7731\n",
      "Epoch 640/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6744 - acc: 0.7638 - val_loss: 0.6460 - val_acc: 0.7738\n",
      "Epoch 641/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6952 - acc: 0.7582 - val_loss: 0.6481 - val_acc: 0.7731\n",
      "Epoch 642/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6963 - acc: 0.7563 - val_loss: 0.6496 - val_acc: 0.7723\n",
      "Epoch 643/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6923 - acc: 0.7567 - val_loss: 0.6494 - val_acc: 0.7723\n",
      "Epoch 644/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6977 - acc: 0.7574 - val_loss: 0.6466 - val_acc: 0.7731\n",
      "Epoch 645/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6996 - acc: 0.7515 - val_loss: 0.6473 - val_acc: 0.7731\n",
      "Epoch 646/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6943 - acc: 0.7537 - val_loss: 0.6468 - val_acc: 0.7731\n",
      "Epoch 647/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7033 - acc: 0.7489 - val_loss: 0.6486 - val_acc: 0.7731\n",
      "Epoch 648/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6942 - acc: 0.7563 - val_loss: 0.6486 - val_acc: 0.7731\n",
      "Epoch 649/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7026 - acc: 0.7493 - val_loss: 0.6490 - val_acc: 0.7723\n",
      "Epoch 650/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6850 - acc: 0.7615 - val_loss: 0.6481 - val_acc: 0.7731\n",
      "Epoch 651/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7004 - acc: 0.7578 - val_loss: 0.6489 - val_acc: 0.7723\n",
      "Epoch 652/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6974 - acc: 0.7556 - val_loss: 0.6484 - val_acc: 0.7731\n",
      "Epoch 653/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7046 - acc: 0.7526 - val_loss: 0.6494 - val_acc: 0.7716\n",
      "Epoch 654/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6999 - acc: 0.7589 - val_loss: 0.6495 - val_acc: 0.7716\n",
      "Epoch 655/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7053 - acc: 0.7552 - val_loss: 0.6452 - val_acc: 0.7731\n",
      "Epoch 656/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7078 - acc: 0.7593 - val_loss: 0.6476 - val_acc: 0.7723\n",
      "Epoch 657/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7126 - acc: 0.7496 - val_loss: 0.6491 - val_acc: 0.7716\n",
      "Epoch 658/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.6997 - acc: 0.7567 - val_loss: 0.6469 - val_acc: 0.7731\n",
      "Epoch 659/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7019 - acc: 0.7582 - val_loss: 0.6481 - val_acc: 0.7723\n",
      "Epoch 660/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7105 - acc: 0.7500 - val_loss: 0.6495 - val_acc: 0.7716\n",
      "Epoch 661/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7061 - acc: 0.7519 - val_loss: 0.6495 - val_acc: 0.7716\n",
      "Epoch 662/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7003 - acc: 0.7548 - val_loss: 0.6447 - val_acc: 0.7723\n",
      "Epoch 663/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6947 - acc: 0.7556 - val_loss: 0.6495 - val_acc: 0.7716\n",
      "Epoch 664/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6883 - acc: 0.7634 - val_loss: 0.6473 - val_acc: 0.7738\n",
      "Epoch 665/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6937 - acc: 0.7664 - val_loss: 0.6475 - val_acc: 0.7731\n",
      "\n",
      "Epoch 00665: loss improved from inf to 0.69368, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-1-000665-0.693684-0.773065.hdf5\n",
      "Epoch 666/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6882 - acc: 0.7623 - val_loss: 0.6436 - val_acc: 0.7746\n",
      "Epoch 667/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6969 - acc: 0.7619 - val_loss: 0.6438 - val_acc: 0.7723\n",
      "Epoch 668/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6956 - acc: 0.7682 - val_loss: 0.6488 - val_acc: 0.7716\n",
      "Epoch 669/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7126 - acc: 0.7489 - val_loss: 0.6495 - val_acc: 0.7716\n",
      "Epoch 670/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6926 - acc: 0.7623 - val_loss: 0.6489 - val_acc: 0.7716\n",
      "Epoch 671/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6906 - acc: 0.7604 - val_loss: 0.6494 - val_acc: 0.7716\n",
      "Epoch 672/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7003 - acc: 0.7548 - val_loss: 0.6478 - val_acc: 0.7708\n",
      "Epoch 673/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7058 - acc: 0.7556 - val_loss: 0.6493 - val_acc: 0.7708\n",
      "Epoch 674/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6847 - acc: 0.7597 - val_loss: 0.6467 - val_acc: 0.7716\n",
      "Epoch 675/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6918 - acc: 0.7556 - val_loss: 0.6484 - val_acc: 0.7716\n",
      "Epoch 676/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6782 - acc: 0.7679 - val_loss: 0.6493 - val_acc: 0.7708\n",
      "Epoch 677/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6976 - acc: 0.7630 - val_loss: 0.6471 - val_acc: 0.7723\n",
      "Epoch 678/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6989 - acc: 0.7533 - val_loss: 0.6483 - val_acc: 0.7708\n",
      "Epoch 679/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7069 - acc: 0.7560 - val_loss: 0.6494 - val_acc: 0.7708\n",
      "Epoch 680/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6956 - acc: 0.7608 - val_loss: 0.6492 - val_acc: 0.7708\n",
      "Epoch 681/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7031 - acc: 0.7548 - val_loss: 0.6469 - val_acc: 0.7723\n",
      "Epoch 682/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6932 - acc: 0.7641 - val_loss: 0.6497 - val_acc: 0.7708\n",
      "Epoch 683/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6902 - acc: 0.7615 - val_loss: 0.6493 - val_acc: 0.7708\n",
      "Epoch 684/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7036 - acc: 0.7567 - val_loss: 0.6476 - val_acc: 0.7716\n",
      "Epoch 685/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6796 - acc: 0.7649 - val_loss: 0.6475 - val_acc: 0.7716\n",
      "\n",
      "Epoch 00685: loss improved from 0.69368 to 0.67959, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-1-000685-0.679594-0.771577.hdf5\n",
      "Epoch 686/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7051 - acc: 0.7574 - val_loss: 0.6471 - val_acc: 0.7723\n",
      "Epoch 687/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6925 - acc: 0.7567 - val_loss: 0.6491 - val_acc: 0.7708\n",
      "Epoch 688/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6899 - acc: 0.7574 - val_loss: 0.6460 - val_acc: 0.7716\n",
      "Epoch 689/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6915 - acc: 0.7604 - val_loss: 0.6487 - val_acc: 0.7716\n",
      "Epoch 690/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6932 - acc: 0.7574 - val_loss: 0.6460 - val_acc: 0.7723\n",
      "Epoch 691/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7100 - acc: 0.7537 - val_loss: 0.6477 - val_acc: 0.7723\n",
      "Epoch 692/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6963 - acc: 0.7589 - val_loss: 0.6494 - val_acc: 0.7708\n",
      "Epoch 693/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6952 - acc: 0.7623 - val_loss: 0.6449 - val_acc: 0.7731\n",
      "Epoch 694/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6946 - acc: 0.7615 - val_loss: 0.6479 - val_acc: 0.7716\n",
      "Epoch 695/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7107 - acc: 0.7481 - val_loss: 0.6494 - val_acc: 0.7708\n",
      "Epoch 696/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7102 - acc: 0.7537 - val_loss: 0.6492 - val_acc: 0.7708\n",
      "Epoch 697/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6926 - acc: 0.7582 - val_loss: 0.6494 - val_acc: 0.7708\n",
      "Epoch 698/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7002 - acc: 0.7589 - val_loss: 0.6494 - val_acc: 0.7708\n",
      "Epoch 699/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6959 - acc: 0.7563 - val_loss: 0.6492 - val_acc: 0.7708\n",
      "Epoch 700/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6858 - acc: 0.7671 - val_loss: 0.6469 - val_acc: 0.7716\n",
      "\n",
      "Epoch 00700: saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/1-000700-0.685771-0.771577.hdf5\n",
      "Epoch 701/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6912 - acc: 0.7563 - val_loss: 0.6480 - val_acc: 0.7716\n",
      "Epoch 702/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6913 - acc: 0.7615 - val_loss: 0.6452 - val_acc: 0.7723\n",
      "Epoch 703/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6961 - acc: 0.7578 - val_loss: 0.6477 - val_acc: 0.7723\n",
      "Epoch 704/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6806 - acc: 0.7660 - val_loss: 0.6489 - val_acc: 0.7708\n",
      "Epoch 705/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6886 - acc: 0.7630 - val_loss: 0.6452 - val_acc: 0.7723\n",
      "Epoch 706/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7084 - acc: 0.7582 - val_loss: 0.6483 - val_acc: 0.7716\n",
      "Epoch 707/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6986 - acc: 0.7612 - val_loss: 0.6489 - val_acc: 0.7708\n",
      "Epoch 708/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6988 - acc: 0.7556 - val_loss: 0.6484 - val_acc: 0.7716\n",
      "Epoch 00708: early stopping\n",
      "ModelCheckpoint 已经保存到 ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/1-final.hdf5\n",
      "save in: ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/log/20220201_2000_64_1_3_1.csv\n",
      "time: 0:18:40 s\n",
      "time: 1120.0 s\n",
      "average 1.120000 s\n",
      "1 epoch finished\n",
      "--------------------   best   --------------------\n",
      "no_activities: 10\n",
      "\n",
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1348/1348 [==============================] - 1s 412us/step\n",
      "1-milan:\tacc: 77.23%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 4, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 7, 0, 0, 0, 0, 7, 2, 2, 2, 2, 2, 7, 7, 2, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 5, 9, 9, 9, 9, 0, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 4, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 4, 9, 9, 9, 9, 0, 7, 7, 7, 7, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 0, 7, 0, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 4, 7, 7, 7, 7, 0, 7, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 0, 7, 4, 7, 7, 0, 0, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 4, 7, 0, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 0, 7, 7, 0, 0, 7, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 0, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 9, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 3, 9, 9, 9, 9, 9, 0, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 4, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 0, 0, 0, 0, 9, 7, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7, 2, 7, 2, 7, 9, 7, 7, 2, 9, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 7, 7, 0, 4, 0, 7, 5, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 7, 0, 0, 9, 7, 0, 0, 9, 0, 0, 0, 0, 7, 0, 0, 0, 0, 4, 0, 7, 0, 0, 0, 0, 7, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 4, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 9, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 7, 0, 0, 0, 0, 7, 7, 0, 0, 0, 7, 0, 9, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 7, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 4, 7, 4, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 4, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7, 0, 0, 0, 0, 7, 0, 0, 0, 7, 4, 4, 4, 4, 4, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 0, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 7, 4, 0, 4, 4, 0, 4, 4, 0, 0, 4, 4, 4, 0, 4, 4, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 7, 4, 0, 4, 4, 4, 4, 0, 0, 0, 4, 0, 4, 0, 4, 4, 4, 0, 4, 4, 4, 0, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 0, 4, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 9, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 7, 0, 4, 0, 4, 0, 0, 0, 0, 7, 0, 4, 0, 9, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.777620  0.881220  0.826185       623\n",
      "         Work   0.000000  0.000000  0.000000        25\n",
      "Take_medicine   1.000000  0.450000  0.620690        20\n",
      "        Sleep   0.500000  0.031250  0.058824        32\n",
      "        Relax   0.696429  0.549296  0.614173       142\n",
      "   Leave_Home   0.906667  0.944444  0.925170        72\n",
      "          Eat   0.000000  0.000000  0.000000         8\n",
      "         Cook   0.718447  0.804348  0.758974       184\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        30\n",
      "      Bathing   0.789916  0.886792  0.835556       212\n",
      "\n",
      "     accuracy                       0.772255      1348\n",
      "    macro avg   0.538908  0.454735  0.463957      1348\n",
      " weighted avg   0.730183  0.772255  0.741560      1348\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  29   0   0   1   0   0]\n",
      " [  0   0   0   0   0   1   0  20   4   0]\n",
      " [  0   0   0   0   0   2   0   6   0   0]\n",
      " [  0   0   0   9   2   9   0   0   0   0]\n",
      " [  0   0   0   0 188   5   1  14   3   1]\n",
      " [  0   0   0   0   0 148   0  30   6   0]\n",
      " [  0   0   0   0   1   1  68   2   0   0]\n",
      " [  0   0   0   0  13  35   5 549  21   0]\n",
      " [  0   0   0   0   1   5   1  57  78   0]\n",
      " [  0   0   0   0   4   0   0  27   0   1]]\n",
      "--------------------   final   --------------------\n",
      "no_activities: 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1348/1348 [==============================] - 1s 407us/step\n",
      "1-milan:\tacc: 77.15%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 4, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 7, 0, 0, 0, 0, 7, 2, 2, 2, 2, 2, 7, 7, 2, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 5, 9, 9, 9, 9, 0, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 4, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 4, 9, 9, 9, 9, 0, 7, 7, 7, 7, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 0, 7, 0, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 4, 7, 7, 7, 7, 0, 7, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 0, 7, 4, 7, 7, 0, 0, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 4, 7, 0, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 0, 7, 7, 0, 0, 7, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 0, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 9, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 3, 9, 9, 9, 9, 9, 0, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 4, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 0, 0, 0, 0, 9, 7, 0, 0, 9, 0, 0, 0, 0, 7, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7, 2, 7, 2, 7, 9, 7, 7, 2, 9, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 7, 7, 0, 4, 0, 7, 5, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 7, 0, 0, 9, 7, 0, 0, 9, 0, 0, 0, 0, 7, 0, 0, 0, 0, 4, 0, 7, 0, 0, 0, 0, 7, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 4, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 9, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 7, 0, 0, 0, 0, 7, 7, 0, 0, 0, 7, 0, 9, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 7, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 4, 7, 4, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 4, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7, 0, 0, 0, 0, 7, 0, 0, 0, 7, 4, 4, 4, 4, 4, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 0, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 7, 4, 0, 4, 4, 0, 4, 4, 0, 0, 4, 4, 4, 0, 4, 4, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 7, 4, 0, 4, 4, 4, 4, 0, 0, 0, 4, 0, 4, 0, 4, 4, 4, 0, 4, 4, 4, 0, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 0, 4, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 9, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 7, 0, 4, 0, 4, 0, 0, 0, 0, 7, 0, 4, 0, 9, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.777305  0.879615  0.825301       623\n",
      "         Work   0.000000  0.000000  0.000000        25\n",
      "Take_medicine   1.000000  0.450000  0.620690        20\n",
      "        Sleep   0.500000  0.031250  0.058824        32\n",
      "        Relax   0.696429  0.549296  0.614173       142\n",
      "   Leave_Home   0.906667  0.944444  0.925170        72\n",
      "          Eat   0.000000  0.000000  0.000000         8\n",
      "         Cook   0.714976  0.804348  0.757033       184\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        30\n",
      "      Bathing   0.789916  0.886792  0.835556       212\n",
      "\n",
      "     accuracy                       0.771513      1348\n",
      "    macro avg   0.538529  0.454575  0.463675      1348\n",
      " weighted avg   0.729563  0.771513  0.740887      1348\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  29   0   0   1   0   0]\n",
      " [  0   0   0   0   0   1   0  20   4   0]\n",
      " [  0   0   0   0   0   2   0   6   0   0]\n",
      " [  0   0   0   9   2   9   0   0   0   0]\n",
      " [  0   0   0   0 188   5   1  14   3   1]\n",
      " [  0   0   0   0   0 148   0  30   6   0]\n",
      " [  0   0   0   0   1   1  68   2   0   0]\n",
      " [  0   0   0   0  13  36   5 548  21   0]\n",
      " [  0   0   0   0   1   5   1  57  78   0]\n",
      " [  0   0   0   0   4   0   0  27   0   1]]\n",
      "no_activities: 10\n",
      "\n",
      "Begin training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "42/42 [==============================] - 2s 56ms/step - loss: 1.6522 - acc: 0.4803 - val_loss: 1.3365 - val_acc: 0.5640\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.3294 - acc: 0.5733 - val_loss: 1.1324 - val_acc: 0.6458\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.2068 - acc: 0.6146 - val_loss: 1.0560 - val_acc: 0.6689\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.1296 - acc: 0.6157 - val_loss: 0.9960 - val_acc: 0.6749\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.0614 - acc: 0.6376 - val_loss: 0.9516 - val_acc: 0.6897\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0292 - acc: 0.6592 - val_loss: 0.9247 - val_acc: 0.6942\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.0127 - acc: 0.6667 - val_loss: 0.8934 - val_acc: 0.6882\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9911 - acc: 0.6667 - val_loss: 0.8798 - val_acc: 0.7016\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9725 - acc: 0.6808 - val_loss: 0.8656 - val_acc: 0.7083\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9593 - acc: 0.6830 - val_loss: 0.8451 - val_acc: 0.7128\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9214 - acc: 0.6908 - val_loss: 0.8243 - val_acc: 0.7247\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9172 - acc: 0.7020 - val_loss: 0.8175 - val_acc: 0.7254\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9011 - acc: 0.7068 - val_loss: 0.8023 - val_acc: 0.7359\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.8889 - acc: 0.7039 - val_loss: 0.7964 - val_acc: 0.7336\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8802 - acc: 0.7106 - val_loss: 0.7897 - val_acc: 0.7374\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8731 - acc: 0.7091 - val_loss: 0.7782 - val_acc: 0.7388\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8639 - acc: 0.7147 - val_loss: 0.7777 - val_acc: 0.7351\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8696 - acc: 0.7106 - val_loss: 0.7698 - val_acc: 0.7381\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8395 - acc: 0.7180 - val_loss: 0.7628 - val_acc: 0.7403\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8465 - acc: 0.7228 - val_loss: 0.7593 - val_acc: 0.7374\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8433 - acc: 0.7132 - val_loss: 0.7510 - val_acc: 0.7329\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8352 - acc: 0.7169 - val_loss: 0.7489 - val_acc: 0.7388\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8291 - acc: 0.7277 - val_loss: 0.7443 - val_acc: 0.7344\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8279 - acc: 0.7121 - val_loss: 0.7391 - val_acc: 0.7374\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8295 - acc: 0.7299 - val_loss: 0.7376 - val_acc: 0.7418\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8204 - acc: 0.7154 - val_loss: 0.7345 - val_acc: 0.7455\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8150 - acc: 0.7303 - val_loss: 0.7355 - val_acc: 0.7433\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8117 - acc: 0.7277 - val_loss: 0.7267 - val_acc: 0.7440\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8166 - acc: 0.7333 - val_loss: 0.7232 - val_acc: 0.7470\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8131 - acc: 0.7236 - val_loss: 0.7227 - val_acc: 0.7485\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7928 - acc: 0.7336 - val_loss: 0.7192 - val_acc: 0.7359\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7974 - acc: 0.7262 - val_loss: 0.7224 - val_acc: 0.7396\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7756 - acc: 0.7262 - val_loss: 0.7169 - val_acc: 0.7381\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7909 - acc: 0.7288 - val_loss: 0.7130 - val_acc: 0.7545\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7982 - acc: 0.7299 - val_loss: 0.7130 - val_acc: 0.7470\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7914 - acc: 0.7336 - val_loss: 0.7122 - val_acc: 0.7470\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7841 - acc: 0.7314 - val_loss: 0.7139 - val_acc: 0.7470\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7816 - acc: 0.7321 - val_loss: 0.7097 - val_acc: 0.7515\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7896 - acc: 0.7262 - val_loss: 0.7066 - val_acc: 0.7500\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7746 - acc: 0.7414 - val_loss: 0.7044 - val_acc: 0.7522\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7734 - acc: 0.7374 - val_loss: 0.7052 - val_acc: 0.7515\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7711 - acc: 0.7344 - val_loss: 0.7044 - val_acc: 0.7478\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7476 - acc: 0.7459 - val_loss: 0.6990 - val_acc: 0.7537\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7812 - acc: 0.7355 - val_loss: 0.7005 - val_acc: 0.7507\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7865 - acc: 0.7273 - val_loss: 0.6996 - val_acc: 0.7530\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7645 - acc: 0.7396 - val_loss: 0.6988 - val_acc: 0.7552\n",
      "Epoch 47/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7627 - acc: 0.7333 - val_loss: 0.6957 - val_acc: 0.7522\n",
      "Epoch 48/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7557 - acc: 0.7366 - val_loss: 0.6971 - val_acc: 0.7493\n",
      "Epoch 49/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7602 - acc: 0.7422 - val_loss: 0.6939 - val_acc: 0.7522\n",
      "Epoch 50/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7630 - acc: 0.7269 - val_loss: 0.6911 - val_acc: 0.7552\n",
      "Epoch 51/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7611 - acc: 0.7347 - val_loss: 0.6938 - val_acc: 0.7515\n",
      "Epoch 52/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7466 - acc: 0.7500 - val_loss: 0.6901 - val_acc: 0.7545\n",
      "Epoch 53/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7336 - acc: 0.7470 - val_loss: 0.6860 - val_acc: 0.7582\n",
      "Epoch 54/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7413 - acc: 0.7433 - val_loss: 0.6864 - val_acc: 0.7612\n",
      "Epoch 55/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7481 - acc: 0.7433 - val_loss: 0.6908 - val_acc: 0.7582\n",
      "Epoch 56/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7510 - acc: 0.7381 - val_loss: 0.6892 - val_acc: 0.7567\n",
      "Epoch 57/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7557 - acc: 0.7519 - val_loss: 0.6839 - val_acc: 0.7582\n",
      "Epoch 58/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7334 - acc: 0.7474 - val_loss: 0.6858 - val_acc: 0.7604\n",
      "Epoch 59/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7539 - acc: 0.7444 - val_loss: 0.6867 - val_acc: 0.7626\n",
      "Epoch 60/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7599 - acc: 0.7377 - val_loss: 0.6855 - val_acc: 0.7634\n",
      "Epoch 61/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7485 - acc: 0.7470 - val_loss: 0.6876 - val_acc: 0.7626\n",
      "Epoch 62/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7515 - acc: 0.7377 - val_loss: 0.6851 - val_acc: 0.7567\n",
      "Epoch 63/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7470 - acc: 0.7392 - val_loss: 0.6854 - val_acc: 0.7567\n",
      "Epoch 64/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7376 - acc: 0.7422 - val_loss: 0.6851 - val_acc: 0.7574\n",
      "Epoch 65/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7379 - acc: 0.7463 - val_loss: 0.6838 - val_acc: 0.7612\n",
      "\n",
      "Epoch 00065: loss improved from inf to 0.73790, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-2-000065-0.737903-0.761161.hdf5\n",
      "Epoch 66/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7310 - acc: 0.7411 - val_loss: 0.6790 - val_acc: 0.7656\n",
      "Epoch 67/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7336 - acc: 0.7500 - val_loss: 0.6804 - val_acc: 0.7679\n",
      "Epoch 68/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7280 - acc: 0.7493 - val_loss: 0.6798 - val_acc: 0.7634\n",
      "Epoch 69/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7322 - acc: 0.7414 - val_loss: 0.6792 - val_acc: 0.7679\n",
      "\n",
      "Epoch 00069: loss improved from 0.73790 to 0.73223, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-2-000069-0.732232-0.767857.hdf5\n",
      "Epoch 70/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7245 - acc: 0.7429 - val_loss: 0.6769 - val_acc: 0.7634\n",
      "Epoch 71/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7384 - acc: 0.7422 - val_loss: 0.6751 - val_acc: 0.7664\n",
      "Epoch 72/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7213 - acc: 0.7474 - val_loss: 0.6772 - val_acc: 0.7664\n",
      "Epoch 73/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7249 - acc: 0.7403 - val_loss: 0.6767 - val_acc: 0.7589\n",
      "\n",
      "Epoch 00073: loss improved from 0.73223 to 0.72492, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-2-000073-0.724923-0.758929.hdf5\n",
      "Epoch 74/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7378 - acc: 0.7440 - val_loss: 0.6774 - val_acc: 0.7574\n",
      "Epoch 75/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7402 - acc: 0.7318 - val_loss: 0.6754 - val_acc: 0.7597\n",
      "Epoch 76/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7165 - acc: 0.7470 - val_loss: 0.6739 - val_acc: 0.7641\n",
      "Epoch 77/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7388 - acc: 0.7500 - val_loss: 0.6754 - val_acc: 0.7612\n",
      "Epoch 78/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7277 - acc: 0.7440 - val_loss: 0.6705 - val_acc: 0.7686\n",
      "Epoch 79/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7238 - acc: 0.7411 - val_loss: 0.6728 - val_acc: 0.7604\n",
      "Epoch 80/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7297 - acc: 0.7470 - val_loss: 0.6689 - val_acc: 0.7619\n",
      "Epoch 81/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7295 - acc: 0.7459 - val_loss: 0.6680 - val_acc: 0.7626\n",
      "Epoch 82/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7082 - acc: 0.7493 - val_loss: 0.6688 - val_acc: 0.7634\n",
      "Epoch 83/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7311 - acc: 0.7507 - val_loss: 0.6685 - val_acc: 0.7626\n",
      "Epoch 84/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7226 - acc: 0.7515 - val_loss: 0.6674 - val_acc: 0.7626\n",
      "Epoch 85/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7175 - acc: 0.7522 - val_loss: 0.6684 - val_acc: 0.7641\n",
      "\n",
      "Epoch 00085: loss improved from 0.72492 to 0.71755, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-2-000085-0.717545-0.764137.hdf5\n",
      "Epoch 86/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7065 - acc: 0.7571 - val_loss: 0.6678 - val_acc: 0.7693\n",
      "Epoch 87/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7357 - acc: 0.7396 - val_loss: 0.6692 - val_acc: 0.7716\n",
      "Epoch 88/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7116 - acc: 0.7545 - val_loss: 0.6691 - val_acc: 0.7597\n",
      "Epoch 89/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7144 - acc: 0.7604 - val_loss: 0.6672 - val_acc: 0.7671\n",
      "\n",
      "Epoch 00089: loss improved from 0.71755 to 0.71440, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-2-000089-0.714397-0.767113.hdf5\n",
      "Epoch 90/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7206 - acc: 0.7515 - val_loss: 0.6687 - val_acc: 0.7626\n",
      "Epoch 91/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7102 - acc: 0.7459 - val_loss: 0.6661 - val_acc: 0.7626\n",
      "Epoch 92/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7127 - acc: 0.7537 - val_loss: 0.6652 - val_acc: 0.7664\n",
      "Epoch 93/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7373 - acc: 0.7474 - val_loss: 0.6652 - val_acc: 0.7656\n",
      "Epoch 94/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7173 - acc: 0.7589 - val_loss: 0.6650 - val_acc: 0.7679\n",
      "Epoch 95/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7218 - acc: 0.7515 - val_loss: 0.6658 - val_acc: 0.7649\n",
      "Epoch 96/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7230 - acc: 0.7533 - val_loss: 0.6656 - val_acc: 0.7649\n",
      "Epoch 97/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7134 - acc: 0.7489 - val_loss: 0.6654 - val_acc: 0.7634\n",
      "\n",
      "Epoch 00097: loss improved from 0.71440 to 0.71339, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-2-000097-0.713389-0.763393.hdf5\n",
      "Epoch 98/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7145 - acc: 0.7530 - val_loss: 0.6651 - val_acc: 0.7664\n",
      "Epoch 99/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7115 - acc: 0.7485 - val_loss: 0.6613 - val_acc: 0.7649\n",
      "Epoch 100/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7309 - acc: 0.7448 - val_loss: 0.6657 - val_acc: 0.7664\n",
      "\n",
      "Epoch 00100: saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/2-000100-0.730877-0.766369.hdf5\n",
      "Epoch 101/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7183 - acc: 0.7481 - val_loss: 0.6629 - val_acc: 0.7686\n",
      "Epoch 102/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7274 - acc: 0.7507 - val_loss: 0.6665 - val_acc: 0.7693\n",
      "Epoch 103/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7105 - acc: 0.7485 - val_loss: 0.6645 - val_acc: 0.7604\n",
      "Epoch 104/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7216 - acc: 0.7511 - val_loss: 0.6638 - val_acc: 0.7656\n",
      "Epoch 105/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7081 - acc: 0.7470 - val_loss: 0.6630 - val_acc: 0.7656\n",
      "Epoch 106/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7143 - acc: 0.7552 - val_loss: 0.6613 - val_acc: 0.7634\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 107/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7085 - acc: 0.7522 - val_loss: 0.6634 - val_acc: 0.7671\n",
      "Epoch 108/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7003 - acc: 0.7556 - val_loss: 0.6610 - val_acc: 0.7671\n",
      "Epoch 109/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6998 - acc: 0.7571 - val_loss: 0.6619 - val_acc: 0.7679\n",
      "Epoch 110/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7183 - acc: 0.7515 - val_loss: 0.6631 - val_acc: 0.7671\n",
      "Epoch 111/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6956 - acc: 0.7541 - val_loss: 0.6627 - val_acc: 0.7656\n",
      "Epoch 112/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7109 - acc: 0.7522 - val_loss: 0.6622 - val_acc: 0.7671\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6975 - acc: 0.7522 - val_loss: 0.6621 - val_acc: 0.7664\n",
      "Epoch 114/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6926 - acc: 0.7556 - val_loss: 0.6611 - val_acc: 0.7671\n",
      "Epoch 115/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7033 - acc: 0.7541 - val_loss: 0.6609 - val_acc: 0.7679\n",
      "Epoch 116/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6934 - acc: 0.7556 - val_loss: 0.6628 - val_acc: 0.7671\n",
      "Epoch 117/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6839 - acc: 0.7623 - val_loss: 0.6601 - val_acc: 0.7679\n",
      "Epoch 118/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7064 - acc: 0.7515 - val_loss: 0.6618 - val_acc: 0.7671\n",
      "Epoch 119/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6932 - acc: 0.7504 - val_loss: 0.6617 - val_acc: 0.7679\n",
      "Epoch 120/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6978 - acc: 0.7597 - val_loss: 0.6614 - val_acc: 0.7671\n",
      "Epoch 121/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7012 - acc: 0.7515 - val_loss: 0.6622 - val_acc: 0.7664\n",
      "Epoch 122/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7044 - acc: 0.7526 - val_loss: 0.6572 - val_acc: 0.7671\n",
      "Epoch 123/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7027 - acc: 0.7556 - val_loss: 0.6593 - val_acc: 0.7679\n",
      "Epoch 124/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7069 - acc: 0.7522 - val_loss: 0.6577 - val_acc: 0.7693\n",
      "Epoch 125/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7010 - acc: 0.7474 - val_loss: 0.6613 - val_acc: 0.7671\n",
      "Epoch 126/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7095 - acc: 0.7474 - val_loss: 0.6597 - val_acc: 0.7679\n",
      "Epoch 127/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7134 - acc: 0.7511 - val_loss: 0.6612 - val_acc: 0.7641\n",
      "Epoch 128/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6974 - acc: 0.7537 - val_loss: 0.6606 - val_acc: 0.7671\n",
      "Epoch 129/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7027 - acc: 0.7526 - val_loss: 0.6609 - val_acc: 0.7664\n",
      "Epoch 130/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7053 - acc: 0.7552 - val_loss: 0.6558 - val_acc: 0.7679\n",
      "Epoch 131/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6913 - acc: 0.7600 - val_loss: 0.6605 - val_acc: 0.7679\n",
      "Epoch 132/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7025 - acc: 0.7552 - val_loss: 0.6580 - val_acc: 0.7679\n",
      "Epoch 133/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6908 - acc: 0.7522 - val_loss: 0.6546 - val_acc: 0.7693\n",
      "Epoch 134/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6996 - acc: 0.7612 - val_loss: 0.6604 - val_acc: 0.7671\n",
      "Epoch 135/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7069 - acc: 0.7530 - val_loss: 0.6610 - val_acc: 0.7664\n",
      "Epoch 136/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7135 - acc: 0.7459 - val_loss: 0.6589 - val_acc: 0.7664\n",
      "Epoch 137/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6905 - acc: 0.7545 - val_loss: 0.6602 - val_acc: 0.7664\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 138/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6967 - acc: 0.7496 - val_loss: 0.6610 - val_acc: 0.7656\n",
      "Epoch 139/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6941 - acc: 0.7496 - val_loss: 0.6595 - val_acc: 0.7671\n",
      "Epoch 140/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7044 - acc: 0.7656 - val_loss: 0.6604 - val_acc: 0.7656\n",
      "Epoch 141/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6954 - acc: 0.7615 - val_loss: 0.6608 - val_acc: 0.7656\n",
      "Epoch 142/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7027 - acc: 0.7515 - val_loss: 0.6610 - val_acc: 0.7671\n",
      "Epoch 143/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7010 - acc: 0.7485 - val_loss: 0.6608 - val_acc: 0.7664\n",
      "Epoch 144/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6994 - acc: 0.7530 - val_loss: 0.6580 - val_acc: 0.7686\n",
      "Epoch 145/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7233 - acc: 0.7452 - val_loss: 0.6613 - val_acc: 0.7664\n",
      "Epoch 146/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6989 - acc: 0.7541 - val_loss: 0.6587 - val_acc: 0.7679\n",
      "Epoch 147/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6969 - acc: 0.7474 - val_loss: 0.6602 - val_acc: 0.7679\n",
      "Epoch 148/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7096 - acc: 0.7504 - val_loss: 0.6592 - val_acc: 0.7671\n",
      "Epoch 149/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7009 - acc: 0.7600 - val_loss: 0.6606 - val_acc: 0.7656\n",
      "Epoch 150/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6959 - acc: 0.7411 - val_loss: 0.6611 - val_acc: 0.7656\n",
      "Epoch 151/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6981 - acc: 0.7537 - val_loss: 0.6578 - val_acc: 0.7671\n",
      "Epoch 152/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6877 - acc: 0.7623 - val_loss: 0.6607 - val_acc: 0.7656\n",
      "Epoch 153/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6983 - acc: 0.7481 - val_loss: 0.6613 - val_acc: 0.7656\n",
      "Epoch 154/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6915 - acc: 0.7597 - val_loss: 0.6584 - val_acc: 0.7671\n",
      "Epoch 155/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7139 - acc: 0.7426 - val_loss: 0.6598 - val_acc: 0.7664\n",
      "Epoch 156/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6882 - acc: 0.7563 - val_loss: 0.6600 - val_acc: 0.7664\n",
      "Epoch 157/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6915 - acc: 0.7630 - val_loss: 0.6589 - val_acc: 0.7679\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 158/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7256 - acc: 0.7515 - val_loss: 0.6606 - val_acc: 0.7671\n",
      "Epoch 159/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6997 - acc: 0.7489 - val_loss: 0.6603 - val_acc: 0.7671\n",
      "Epoch 160/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6843 - acc: 0.7653 - val_loss: 0.6604 - val_acc: 0.7671\n",
      "Epoch 161/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6990 - acc: 0.7563 - val_loss: 0.6569 - val_acc: 0.7679\n",
      "Epoch 162/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7193 - acc: 0.7440 - val_loss: 0.6594 - val_acc: 0.7671\n",
      "Epoch 163/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7035 - acc: 0.7552 - val_loss: 0.6596 - val_acc: 0.7679\n",
      "Epoch 164/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7094 - acc: 0.7589 - val_loss: 0.6600 - val_acc: 0.7671\n",
      "Epoch 165/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7025 - acc: 0.7530 - val_loss: 0.6593 - val_acc: 0.7679\n",
      "\n",
      "Epoch 00165: loss improved from inf to 0.70252, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-2-000165-0.702524-0.767857.hdf5\n",
      "Epoch 166/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6971 - acc: 0.7589 - val_loss: 0.6570 - val_acc: 0.7686\n",
      "Epoch 167/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7110 - acc: 0.7582 - val_loss: 0.6610 - val_acc: 0.7671\n",
      "Epoch 168/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6953 - acc: 0.7541 - val_loss: 0.6595 - val_acc: 0.7679\n",
      "Epoch 169/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7052 - acc: 0.7507 - val_loss: 0.6605 - val_acc: 0.7671\n",
      "Epoch 170/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6876 - acc: 0.7600 - val_loss: 0.6577 - val_acc: 0.7679\n",
      "Epoch 171/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7022 - acc: 0.7567 - val_loss: 0.6558 - val_acc: 0.7686\n",
      "Epoch 172/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7044 - acc: 0.7489 - val_loss: 0.6575 - val_acc: 0.7686\n",
      "Epoch 173/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6960 - acc: 0.7519 - val_loss: 0.6541 - val_acc: 0.7693\n",
      "\n",
      "Epoch 00173: loss improved from 0.70252 to 0.69604, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-2-000173-0.696039-0.769345.hdf5\n",
      "Epoch 174/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7078 - acc: 0.7493 - val_loss: 0.6591 - val_acc: 0.7679\n",
      "Epoch 175/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7085 - acc: 0.7511 - val_loss: 0.6603 - val_acc: 0.7671\n",
      "Epoch 176/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7089 - acc: 0.7515 - val_loss: 0.6569 - val_acc: 0.7686\n",
      "Epoch 177/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6975 - acc: 0.7612 - val_loss: 0.6613 - val_acc: 0.7671\n",
      "Epoch 178/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7010 - acc: 0.7522 - val_loss: 0.6594 - val_acc: 0.7686\n",
      "Epoch 179/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6919 - acc: 0.7533 - val_loss: 0.6525 - val_acc: 0.7686\n",
      "Epoch 180/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6893 - acc: 0.7548 - val_loss: 0.6582 - val_acc: 0.7686\n",
      "Epoch 181/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6983 - acc: 0.7533 - val_loss: 0.6599 - val_acc: 0.7671\n",
      "Epoch 182/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7014 - acc: 0.7522 - val_loss: 0.6555 - val_acc: 0.7693\n",
      "Epoch 183/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6897 - acc: 0.7593 - val_loss: 0.6595 - val_acc: 0.7679\n",
      "Epoch 184/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6951 - acc: 0.7548 - val_loss: 0.6595 - val_acc: 0.7686\n",
      "Epoch 185/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6935 - acc: 0.7522 - val_loss: 0.6598 - val_acc: 0.7679\n",
      "\n",
      "Epoch 00185: loss improved from 0.69604 to 0.69353, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-2-000185-0.693533-0.767857.hdf5\n",
      "Epoch 186/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6834 - acc: 0.7526 - val_loss: 0.6599 - val_acc: 0.7671\n",
      "Epoch 187/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6904 - acc: 0.7563 - val_loss: 0.6606 - val_acc: 0.7671\n",
      "Epoch 188/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7164 - acc: 0.7478 - val_loss: 0.6589 - val_acc: 0.7679\n",
      "Epoch 189/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6997 - acc: 0.7474 - val_loss: 0.6592 - val_acc: 0.7671\n",
      "Epoch 190/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7038 - acc: 0.7526 - val_loss: 0.6603 - val_acc: 0.7671\n",
      "Epoch 191/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7087 - acc: 0.7560 - val_loss: 0.6600 - val_acc: 0.7679\n",
      "Epoch 192/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6861 - acc: 0.7563 - val_loss: 0.6584 - val_acc: 0.7679\n",
      "Epoch 193/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6953 - acc: 0.7604 - val_loss: 0.6607 - val_acc: 0.7671\n",
      "Epoch 194/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6964 - acc: 0.7496 - val_loss: 0.6570 - val_acc: 0.7686\n",
      "Epoch 195/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7028 - acc: 0.7552 - val_loss: 0.6608 - val_acc: 0.7671\n",
      "Epoch 196/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6947 - acc: 0.7552 - val_loss: 0.6596 - val_acc: 0.7679\n",
      "Epoch 197/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6823 - acc: 0.7500 - val_loss: 0.6599 - val_acc: 0.7679\n",
      "\n",
      "Epoch 00197: loss improved from 0.69353 to 0.68228, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-2-000197-0.682285-0.767857.hdf5\n",
      "Epoch 198/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6876 - acc: 0.7589 - val_loss: 0.6611 - val_acc: 0.7671\n",
      "Epoch 199/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7007 - acc: 0.7541 - val_loss: 0.6595 - val_acc: 0.7686\n",
      "Epoch 200/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7002 - acc: 0.7552 - val_loss: 0.6611 - val_acc: 0.7671\n",
      "\n",
      "Epoch 00200: saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/2-000200-0.700243-0.767113.hdf5\n",
      "Epoch 201/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6977 - acc: 0.7467 - val_loss: 0.6598 - val_acc: 0.7679\n",
      "Epoch 202/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7060 - acc: 0.7500 - val_loss: 0.6561 - val_acc: 0.7686\n",
      "Epoch 203/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7062 - acc: 0.7556 - val_loss: 0.6600 - val_acc: 0.7679\n",
      "Epoch 204/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6932 - acc: 0.7608 - val_loss: 0.6557 - val_acc: 0.7693\n",
      "Epoch 205/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6965 - acc: 0.7548 - val_loss: 0.6599 - val_acc: 0.7679\n",
      "Epoch 206/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6833 - acc: 0.7571 - val_loss: 0.6593 - val_acc: 0.7686\n",
      "Epoch 207/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6956 - acc: 0.7530 - val_loss: 0.6586 - val_acc: 0.7679\n",
      "Epoch 208/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7049 - acc: 0.7511 - val_loss: 0.6606 - val_acc: 0.7671\n",
      "Epoch 209/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6996 - acc: 0.7600 - val_loss: 0.6600 - val_acc: 0.7679\n",
      "Epoch 210/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7047 - acc: 0.7537 - val_loss: 0.6541 - val_acc: 0.7693\n",
      "Epoch 211/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6993 - acc: 0.7556 - val_loss: 0.6597 - val_acc: 0.7679\n",
      "Epoch 212/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6942 - acc: 0.7645 - val_loss: 0.6573 - val_acc: 0.7686\n",
      "Epoch 213/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6963 - acc: 0.7533 - val_loss: 0.6594 - val_acc: 0.7679\n",
      "Epoch 214/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7108 - acc: 0.7563 - val_loss: 0.6605 - val_acc: 0.7671\n",
      "Epoch 215/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6985 - acc: 0.7578 - val_loss: 0.6583 - val_acc: 0.7679\n",
      "Epoch 216/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7087 - acc: 0.7545 - val_loss: 0.6603 - val_acc: 0.7671\n",
      "Epoch 217/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6944 - acc: 0.7545 - val_loss: 0.6587 - val_acc: 0.7679\n",
      "Epoch 218/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7179 - acc: 0.7496 - val_loss: 0.6598 - val_acc: 0.7679\n",
      "Epoch 219/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6886 - acc: 0.7533 - val_loss: 0.6591 - val_acc: 0.7679\n",
      "Epoch 220/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6904 - acc: 0.7597 - val_loss: 0.6589 - val_acc: 0.7693\n",
      "Epoch 221/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7100 - acc: 0.7493 - val_loss: 0.6602 - val_acc: 0.7671\n",
      "Epoch 222/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6784 - acc: 0.7548 - val_loss: 0.6611 - val_acc: 0.7664\n",
      "Epoch 223/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7099 - acc: 0.7552 - val_loss: 0.6612 - val_acc: 0.7664\n",
      "Epoch 224/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7034 - acc: 0.7533 - val_loss: 0.6599 - val_acc: 0.7671\n",
      "Epoch 225/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6955 - acc: 0.7533 - val_loss: 0.6608 - val_acc: 0.7664\n",
      "Epoch 226/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6872 - acc: 0.7634 - val_loss: 0.6598 - val_acc: 0.7671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 227/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7010 - acc: 0.7548 - val_loss: 0.6608 - val_acc: 0.7664\n",
      "Epoch 228/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6927 - acc: 0.7649 - val_loss: 0.6552 - val_acc: 0.7679\n",
      "Epoch 229/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7015 - acc: 0.7582 - val_loss: 0.6602 - val_acc: 0.7664\n",
      "Epoch 230/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6950 - acc: 0.7533 - val_loss: 0.6583 - val_acc: 0.7679\n",
      "Epoch 231/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6960 - acc: 0.7582 - val_loss: 0.6587 - val_acc: 0.7671\n",
      "Epoch 232/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6896 - acc: 0.7500 - val_loss: 0.6604 - val_acc: 0.7671\n",
      "Epoch 233/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6995 - acc: 0.7545 - val_loss: 0.6604 - val_acc: 0.7671\n",
      "Epoch 234/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6944 - acc: 0.7530 - val_loss: 0.6596 - val_acc: 0.7679\n",
      "Epoch 235/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6891 - acc: 0.7641 - val_loss: 0.6607 - val_acc: 0.7671\n",
      "Epoch 236/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7027 - acc: 0.7567 - val_loss: 0.6608 - val_acc: 0.7664\n",
      "Epoch 237/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7145 - acc: 0.7526 - val_loss: 0.6589 - val_acc: 0.7679\n",
      "Epoch 238/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7013 - acc: 0.7545 - val_loss: 0.6581 - val_acc: 0.7679\n",
      "Epoch 239/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7161 - acc: 0.7548 - val_loss: 0.6593 - val_acc: 0.7671\n",
      "Epoch 240/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6977 - acc: 0.7612 - val_loss: 0.6555 - val_acc: 0.7679\n",
      "Epoch 241/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6864 - acc: 0.7560 - val_loss: 0.6590 - val_acc: 0.7679\n",
      "Epoch 242/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7060 - acc: 0.7478 - val_loss: 0.6561 - val_acc: 0.7686\n",
      "Epoch 243/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6995 - acc: 0.7474 - val_loss: 0.6607 - val_acc: 0.7664\n",
      "Epoch 244/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6952 - acc: 0.7563 - val_loss: 0.6583 - val_acc: 0.7679\n",
      "Epoch 245/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7049 - acc: 0.7507 - val_loss: 0.6583 - val_acc: 0.7686\n",
      "Epoch 246/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7121 - acc: 0.7537 - val_loss: 0.6598 - val_acc: 0.7664\n",
      "Epoch 247/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7000 - acc: 0.7474 - val_loss: 0.6582 - val_acc: 0.7671\n",
      "Epoch 248/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6906 - acc: 0.7545 - val_loss: 0.6600 - val_acc: 0.7664\n",
      "Epoch 249/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6883 - acc: 0.7533 - val_loss: 0.6606 - val_acc: 0.7664\n",
      "Epoch 250/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7101 - acc: 0.7474 - val_loss: 0.6578 - val_acc: 0.7671\n",
      "Epoch 251/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6906 - acc: 0.7489 - val_loss: 0.6608 - val_acc: 0.7664\n",
      "Epoch 252/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6966 - acc: 0.7597 - val_loss: 0.6510 - val_acc: 0.7686\n",
      "Epoch 253/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6939 - acc: 0.7522 - val_loss: 0.6586 - val_acc: 0.7671\n",
      "Epoch 254/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6955 - acc: 0.7574 - val_loss: 0.6594 - val_acc: 0.7671\n",
      "Epoch 255/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7186 - acc: 0.7526 - val_loss: 0.6604 - val_acc: 0.7664\n",
      "Epoch 256/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6937 - acc: 0.7571 - val_loss: 0.6607 - val_acc: 0.7664\n",
      "Epoch 257/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6864 - acc: 0.7597 - val_loss: 0.6608 - val_acc: 0.7664\n",
      "Epoch 258/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6977 - acc: 0.7571 - val_loss: 0.6576 - val_acc: 0.7671\n",
      "Epoch 259/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7051 - acc: 0.7459 - val_loss: 0.6596 - val_acc: 0.7671\n",
      "Epoch 260/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7009 - acc: 0.7630 - val_loss: 0.6585 - val_acc: 0.7671\n",
      "Epoch 261/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6975 - acc: 0.7571 - val_loss: 0.6605 - val_acc: 0.7664\n",
      "Epoch 262/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6946 - acc: 0.7664 - val_loss: 0.6606 - val_acc: 0.7664\n",
      "Epoch 263/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6883 - acc: 0.7593 - val_loss: 0.6590 - val_acc: 0.7671\n",
      "Epoch 264/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6783 - acc: 0.7634 - val_loss: 0.6602 - val_acc: 0.7664\n",
      "Epoch 265/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7009 - acc: 0.7604 - val_loss: 0.6607 - val_acc: 0.7664\n",
      "\n",
      "Epoch 00265: loss improved from inf to 0.70090, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-2-000265-0.700897-0.766369.hdf5\n",
      "Epoch 266/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6909 - acc: 0.7671 - val_loss: 0.6608 - val_acc: 0.7664\n",
      "Epoch 267/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7114 - acc: 0.7496 - val_loss: 0.6579 - val_acc: 0.7679\n",
      "Epoch 268/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7088 - acc: 0.7574 - val_loss: 0.6587 - val_acc: 0.7671\n",
      "Epoch 269/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7103 - acc: 0.7537 - val_loss: 0.6586 - val_acc: 0.7671\n",
      "Epoch 270/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6933 - acc: 0.7578 - val_loss: 0.6595 - val_acc: 0.7671\n",
      "Epoch 271/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7033 - acc: 0.7511 - val_loss: 0.6575 - val_acc: 0.7671\n",
      "Epoch 272/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6819 - acc: 0.7560 - val_loss: 0.6565 - val_acc: 0.7679\n",
      "Epoch 273/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6921 - acc: 0.7571 - val_loss: 0.6586 - val_acc: 0.7679\n",
      "\n",
      "Epoch 00273: loss improved from 0.70090 to 0.69209, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-2-000273-0.692090-0.767857.hdf5\n",
      "Epoch 274/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7267 - acc: 0.7481 - val_loss: 0.6609 - val_acc: 0.7664\n",
      "Epoch 275/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7041 - acc: 0.7522 - val_loss: 0.6602 - val_acc: 0.7664\n",
      "Epoch 276/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7026 - acc: 0.7545 - val_loss: 0.6559 - val_acc: 0.7679\n",
      "Epoch 277/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7090 - acc: 0.7478 - val_loss: 0.6570 - val_acc: 0.7679\n",
      "Epoch 278/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7171 - acc: 0.7489 - val_loss: 0.6579 - val_acc: 0.7671\n",
      "Epoch 279/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7012 - acc: 0.7519 - val_loss: 0.6596 - val_acc: 0.7671\n",
      "Epoch 280/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6981 - acc: 0.7548 - val_loss: 0.6606 - val_acc: 0.7664\n",
      "Epoch 281/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6975 - acc: 0.7567 - val_loss: 0.6598 - val_acc: 0.7671\n",
      "Epoch 282/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6964 - acc: 0.7593 - val_loss: 0.6531 - val_acc: 0.7686\n",
      "Epoch 283/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7071 - acc: 0.7493 - val_loss: 0.6573 - val_acc: 0.7679\n",
      "Epoch 284/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7041 - acc: 0.7608 - val_loss: 0.6590 - val_acc: 0.7671\n",
      "Epoch 285/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7049 - acc: 0.7507 - val_loss: 0.6583 - val_acc: 0.7679\n",
      "Epoch 286/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7032 - acc: 0.7545 - val_loss: 0.6596 - val_acc: 0.7664\n",
      "Epoch 287/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6979 - acc: 0.7530 - val_loss: 0.6597 - val_acc: 0.7671\n",
      "Epoch 288/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6956 - acc: 0.7515 - val_loss: 0.6602 - val_acc: 0.7664\n",
      "Epoch 289/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7013 - acc: 0.7526 - val_loss: 0.6595 - val_acc: 0.7671\n",
      "Epoch 290/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6991 - acc: 0.7560 - val_loss: 0.6605 - val_acc: 0.7664\n",
      "Epoch 291/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6853 - acc: 0.7634 - val_loss: 0.6586 - val_acc: 0.7679\n",
      "Epoch 292/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7009 - acc: 0.7530 - val_loss: 0.6610 - val_acc: 0.7664\n",
      "Epoch 293/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7034 - acc: 0.7504 - val_loss: 0.6596 - val_acc: 0.7664\n",
      "Epoch 294/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7136 - acc: 0.7545 - val_loss: 0.6568 - val_acc: 0.7686\n",
      "Epoch 295/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6980 - acc: 0.7496 - val_loss: 0.6602 - val_acc: 0.7664\n",
      "Epoch 296/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6843 - acc: 0.7623 - val_loss: 0.6599 - val_acc: 0.7671\n",
      "Epoch 297/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6943 - acc: 0.7511 - val_loss: 0.6609 - val_acc: 0.7664\n",
      "Epoch 298/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7003 - acc: 0.7541 - val_loss: 0.6597 - val_acc: 0.7664\n",
      "Epoch 299/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6951 - acc: 0.7560 - val_loss: 0.6602 - val_acc: 0.7671\n",
      "Epoch 300/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6949 - acc: 0.7615 - val_loss: 0.6608 - val_acc: 0.7664\n",
      "\n",
      "Epoch 00300: saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/2-000300-0.694896-0.766369.hdf5\n",
      "Epoch 301/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7025 - acc: 0.7537 - val_loss: 0.6601 - val_acc: 0.7664\n",
      "Epoch 302/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6964 - acc: 0.7478 - val_loss: 0.6590 - val_acc: 0.7679\n",
      "Epoch 303/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6953 - acc: 0.7593 - val_loss: 0.6599 - val_acc: 0.7664\n",
      "Epoch 304/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7100 - acc: 0.7545 - val_loss: 0.6590 - val_acc: 0.7671\n",
      "Epoch 305/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7077 - acc: 0.7522 - val_loss: 0.6602 - val_acc: 0.7664\n",
      "Epoch 306/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6883 - acc: 0.7541 - val_loss: 0.6569 - val_acc: 0.7686\n",
      "Epoch 307/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6943 - acc: 0.7567 - val_loss: 0.6596 - val_acc: 0.7664\n",
      "Epoch 308/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6910 - acc: 0.7567 - val_loss: 0.6594 - val_acc: 0.7679\n",
      "Epoch 309/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7002 - acc: 0.7571 - val_loss: 0.6604 - val_acc: 0.7664\n",
      "Epoch 310/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6861 - acc: 0.7560 - val_loss: 0.6607 - val_acc: 0.7671\n",
      "Epoch 311/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6957 - acc: 0.7526 - val_loss: 0.6577 - val_acc: 0.7679\n",
      "Epoch 312/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7124 - acc: 0.7560 - val_loss: 0.6599 - val_acc: 0.7671\n",
      "Epoch 313/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7091 - acc: 0.7511 - val_loss: 0.6601 - val_acc: 0.7671\n",
      "Epoch 314/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7024 - acc: 0.7571 - val_loss: 0.6603 - val_acc: 0.7671\n",
      "Epoch 315/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6984 - acc: 0.7444 - val_loss: 0.6588 - val_acc: 0.7679\n",
      "Epoch 316/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6909 - acc: 0.7545 - val_loss: 0.6599 - val_acc: 0.7679\n",
      "Epoch 317/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6999 - acc: 0.7556 - val_loss: 0.6600 - val_acc: 0.7671\n",
      "Epoch 318/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6884 - acc: 0.7548 - val_loss: 0.6605 - val_acc: 0.7671\n",
      "Epoch 319/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7105 - acc: 0.7578 - val_loss: 0.6567 - val_acc: 0.7693\n",
      "Epoch 320/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6954 - acc: 0.7574 - val_loss: 0.6575 - val_acc: 0.7671\n",
      "Epoch 321/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7081 - acc: 0.7489 - val_loss: 0.6593 - val_acc: 0.7679\n",
      "Epoch 322/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6908 - acc: 0.7563 - val_loss: 0.6577 - val_acc: 0.7671\n",
      "Epoch 323/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6845 - acc: 0.7578 - val_loss: 0.6605 - val_acc: 0.7664\n",
      "Epoch 324/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6923 - acc: 0.7519 - val_loss: 0.6591 - val_acc: 0.7671\n",
      "Epoch 325/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6922 - acc: 0.7526 - val_loss: 0.6586 - val_acc: 0.7686\n",
      "Epoch 326/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6996 - acc: 0.7489 - val_loss: 0.6608 - val_acc: 0.7671\n",
      "Epoch 327/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6915 - acc: 0.7667 - val_loss: 0.6596 - val_acc: 0.7679\n",
      "Epoch 328/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6920 - acc: 0.7604 - val_loss: 0.6609 - val_acc: 0.7664\n",
      "Epoch 329/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7046 - acc: 0.7537 - val_loss: 0.6577 - val_acc: 0.7679\n",
      "Epoch 330/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6922 - acc: 0.7586 - val_loss: 0.6600 - val_acc: 0.7664\n",
      "Epoch 331/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6860 - acc: 0.7626 - val_loss: 0.6569 - val_acc: 0.7679\n",
      "Epoch 332/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6971 - acc: 0.7474 - val_loss: 0.6583 - val_acc: 0.7686\n",
      "Epoch 333/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6844 - acc: 0.7630 - val_loss: 0.6595 - val_acc: 0.7664\n",
      "Epoch 334/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6932 - acc: 0.7638 - val_loss: 0.6578 - val_acc: 0.7671\n",
      "Epoch 335/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6950 - acc: 0.7567 - val_loss: 0.6571 - val_acc: 0.7679\n",
      "Epoch 336/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6993 - acc: 0.7511 - val_loss: 0.6597 - val_acc: 0.7671\n",
      "Epoch 337/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6765 - acc: 0.7626 - val_loss: 0.6588 - val_acc: 0.7679\n",
      "Epoch 338/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7107 - acc: 0.7548 - val_loss: 0.6597 - val_acc: 0.7671\n",
      "Epoch 339/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7066 - acc: 0.7563 - val_loss: 0.6600 - val_acc: 0.7679\n",
      "Epoch 340/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6943 - acc: 0.7571 - val_loss: 0.6603 - val_acc: 0.7664\n",
      "Epoch 341/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7133 - acc: 0.7537 - val_loss: 0.6587 - val_acc: 0.7671\n",
      "Epoch 342/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6972 - acc: 0.7630 - val_loss: 0.6578 - val_acc: 0.7679\n",
      "Epoch 343/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6954 - acc: 0.7571 - val_loss: 0.6593 - val_acc: 0.7671\n",
      "Epoch 344/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7015 - acc: 0.7496 - val_loss: 0.6601 - val_acc: 0.7671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 345/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7052 - acc: 0.7489 - val_loss: 0.6597 - val_acc: 0.7671\n",
      "Epoch 346/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6985 - acc: 0.7571 - val_loss: 0.6609 - val_acc: 0.7671\n",
      "Epoch 347/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7013 - acc: 0.7448 - val_loss: 0.6595 - val_acc: 0.7679\n",
      "Epoch 348/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6986 - acc: 0.7563 - val_loss: 0.6592 - val_acc: 0.7679\n",
      "Epoch 349/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7049 - acc: 0.7515 - val_loss: 0.6604 - val_acc: 0.7671\n",
      "Epoch 350/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6921 - acc: 0.7589 - val_loss: 0.6580 - val_acc: 0.7686\n",
      "Epoch 351/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6954 - acc: 0.7467 - val_loss: 0.6590 - val_acc: 0.7686\n",
      "Epoch 352/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7034 - acc: 0.7574 - val_loss: 0.6576 - val_acc: 0.7679\n",
      "Epoch 353/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6976 - acc: 0.7556 - val_loss: 0.6603 - val_acc: 0.7671\n",
      "Epoch 354/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6939 - acc: 0.7586 - val_loss: 0.6584 - val_acc: 0.7679\n",
      "Epoch 355/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6945 - acc: 0.7563 - val_loss: 0.6591 - val_acc: 0.7671\n",
      "Epoch 356/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6978 - acc: 0.7522 - val_loss: 0.6592 - val_acc: 0.7679\n",
      "Epoch 357/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6888 - acc: 0.7582 - val_loss: 0.6605 - val_acc: 0.7671\n",
      "Epoch 358/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7071 - acc: 0.7545 - val_loss: 0.6604 - val_acc: 0.7671\n",
      "Epoch 359/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7159 - acc: 0.7411 - val_loss: 0.6579 - val_acc: 0.7686\n",
      "Epoch 360/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6895 - acc: 0.7653 - val_loss: 0.6593 - val_acc: 0.7679\n",
      "Epoch 361/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6984 - acc: 0.7504 - val_loss: 0.6586 - val_acc: 0.7679\n",
      "Epoch 362/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6970 - acc: 0.7626 - val_loss: 0.6601 - val_acc: 0.7671\n",
      "Epoch 363/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7036 - acc: 0.7496 - val_loss: 0.6591 - val_acc: 0.7679\n",
      "Epoch 364/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7052 - acc: 0.7515 - val_loss: 0.6595 - val_acc: 0.7679\n",
      "Epoch 365/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7016 - acc: 0.7541 - val_loss: 0.6572 - val_acc: 0.7693\n",
      "\n",
      "Epoch 00365: loss improved from inf to 0.70161, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-2-000365-0.701606-0.769345.hdf5\n",
      "Epoch 366/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7070 - acc: 0.7533 - val_loss: 0.6592 - val_acc: 0.7686\n",
      "Epoch 367/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6906 - acc: 0.7493 - val_loss: 0.6587 - val_acc: 0.7679\n",
      "Epoch 368/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6780 - acc: 0.7615 - val_loss: 0.6595 - val_acc: 0.7679\n",
      "Epoch 369/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6927 - acc: 0.7507 - val_loss: 0.6606 - val_acc: 0.7664\n",
      "\n",
      "Epoch 00369: loss improved from 0.70161 to 0.69266, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-2-000369-0.692656-0.766369.hdf5\n",
      "Epoch 370/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7097 - acc: 0.7530 - val_loss: 0.6573 - val_acc: 0.7671\n",
      "Epoch 371/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6961 - acc: 0.7582 - val_loss: 0.6549 - val_acc: 0.7679\n",
      "Epoch 372/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6971 - acc: 0.7526 - val_loss: 0.6597 - val_acc: 0.7671\n",
      "Epoch 373/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7036 - acc: 0.7545 - val_loss: 0.6606 - val_acc: 0.7664\n",
      "Epoch 374/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7088 - acc: 0.7533 - val_loss: 0.6594 - val_acc: 0.7671\n",
      "Epoch 375/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7004 - acc: 0.7530 - val_loss: 0.6595 - val_acc: 0.7671\n",
      "Epoch 376/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6966 - acc: 0.7519 - val_loss: 0.6583 - val_acc: 0.7679\n",
      "Epoch 377/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7151 - acc: 0.7474 - val_loss: 0.6585 - val_acc: 0.7686\n",
      "Epoch 378/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6959 - acc: 0.7519 - val_loss: 0.6606 - val_acc: 0.7671\n",
      "Epoch 379/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6852 - acc: 0.7593 - val_loss: 0.6600 - val_acc: 0.7679\n",
      "Epoch 380/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7099 - acc: 0.7489 - val_loss: 0.6583 - val_acc: 0.7679\n",
      "Epoch 381/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7054 - acc: 0.7563 - val_loss: 0.6598 - val_acc: 0.7679\n",
      "Epoch 382/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6991 - acc: 0.7589 - val_loss: 0.6606 - val_acc: 0.7664\n",
      "Epoch 383/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6986 - acc: 0.7586 - val_loss: 0.6602 - val_acc: 0.7664\n",
      "Epoch 384/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6915 - acc: 0.7541 - val_loss: 0.6598 - val_acc: 0.7671\n",
      "Epoch 385/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6912 - acc: 0.7507 - val_loss: 0.6598 - val_acc: 0.7664\n",
      "\n",
      "Epoch 00385: loss improved from 0.69266 to 0.69120, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-2-000385-0.691203-0.766369.hdf5\n",
      "Epoch 386/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7067 - acc: 0.7481 - val_loss: 0.6592 - val_acc: 0.7679\n",
      "Epoch 387/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7031 - acc: 0.7489 - val_loss: 0.6591 - val_acc: 0.7679\n",
      "Epoch 388/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7015 - acc: 0.7552 - val_loss: 0.6590 - val_acc: 0.7671\n",
      "Epoch 389/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7022 - acc: 0.7597 - val_loss: 0.6601 - val_acc: 0.7664\n",
      "Epoch 390/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7115 - acc: 0.7467 - val_loss: 0.6605 - val_acc: 0.7664\n",
      "Epoch 391/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7102 - acc: 0.7470 - val_loss: 0.6586 - val_acc: 0.7679\n",
      "Epoch 392/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6794 - acc: 0.7638 - val_loss: 0.6600 - val_acc: 0.7671\n",
      "Epoch 393/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6994 - acc: 0.7493 - val_loss: 0.6580 - val_acc: 0.7686\n",
      "Epoch 394/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6975 - acc: 0.7537 - val_loss: 0.6579 - val_acc: 0.7679\n",
      "Epoch 395/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6975 - acc: 0.7597 - val_loss: 0.6581 - val_acc: 0.7671\n",
      "Epoch 396/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6978 - acc: 0.7556 - val_loss: 0.6602 - val_acc: 0.7679\n",
      "Epoch 397/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6985 - acc: 0.7582 - val_loss: 0.6601 - val_acc: 0.7664\n",
      "Epoch 398/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6914 - acc: 0.7578 - val_loss: 0.6592 - val_acc: 0.7679\n",
      "Epoch 399/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7015 - acc: 0.7560 - val_loss: 0.6597 - val_acc: 0.7671\n",
      "Epoch 400/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7020 - acc: 0.7489 - val_loss: 0.6589 - val_acc: 0.7671\n",
      "\n",
      "Epoch 00400: saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/2-000400-0.702024-0.767113.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7018 - acc: 0.7463 - val_loss: 0.6605 - val_acc: 0.7664\n",
      "Epoch 402/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7066 - acc: 0.7519 - val_loss: 0.6600 - val_acc: 0.7664\n",
      "Epoch 403/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6946 - acc: 0.7667 - val_loss: 0.6596 - val_acc: 0.7671\n",
      "Epoch 404/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6912 - acc: 0.7630 - val_loss: 0.6602 - val_acc: 0.7671\n",
      "Epoch 405/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6992 - acc: 0.7552 - val_loss: 0.6587 - val_acc: 0.7679\n",
      "Epoch 406/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6980 - acc: 0.7589 - val_loss: 0.6598 - val_acc: 0.7664\n",
      "Epoch 407/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7091 - acc: 0.7522 - val_loss: 0.6600 - val_acc: 0.7671\n",
      "Epoch 408/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7106 - acc: 0.7485 - val_loss: 0.6581 - val_acc: 0.7671\n",
      "Epoch 409/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7010 - acc: 0.7530 - val_loss: 0.6564 - val_acc: 0.7679\n",
      "Epoch 410/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7160 - acc: 0.7474 - val_loss: 0.6598 - val_acc: 0.7671\n",
      "Epoch 411/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6938 - acc: 0.7571 - val_loss: 0.6599 - val_acc: 0.7679\n",
      "Epoch 412/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6925 - acc: 0.7515 - val_loss: 0.6547 - val_acc: 0.7693\n",
      "Epoch 413/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6921 - acc: 0.7537 - val_loss: 0.6582 - val_acc: 0.7686\n",
      "Epoch 414/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7013 - acc: 0.7586 - val_loss: 0.6598 - val_acc: 0.7671\n",
      "Epoch 415/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6888 - acc: 0.7612 - val_loss: 0.6586 - val_acc: 0.7679\n",
      "Epoch 416/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7033 - acc: 0.7552 - val_loss: 0.6596 - val_acc: 0.7679\n",
      "Epoch 417/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6959 - acc: 0.7545 - val_loss: 0.6590 - val_acc: 0.7679\n",
      "Epoch 418/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7128 - acc: 0.7560 - val_loss: 0.6566 - val_acc: 0.7686\n",
      "Epoch 419/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7028 - acc: 0.7582 - val_loss: 0.6591 - val_acc: 0.7679\n",
      "Epoch 420/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6978 - acc: 0.7485 - val_loss: 0.6524 - val_acc: 0.7686\n",
      "Epoch 421/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7087 - acc: 0.7511 - val_loss: 0.6593 - val_acc: 0.7664\n",
      "Epoch 422/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6907 - acc: 0.7634 - val_loss: 0.6601 - val_acc: 0.7671\n",
      "Epoch 423/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6887 - acc: 0.7615 - val_loss: 0.6572 - val_acc: 0.7671\n",
      "Epoch 424/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6951 - acc: 0.7548 - val_loss: 0.6587 - val_acc: 0.7664\n",
      "Epoch 425/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6946 - acc: 0.7467 - val_loss: 0.6555 - val_acc: 0.7686\n",
      "Epoch 426/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7017 - acc: 0.7567 - val_loss: 0.6587 - val_acc: 0.7671\n",
      "Epoch 427/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7010 - acc: 0.7574 - val_loss: 0.6593 - val_acc: 0.7671\n",
      "Epoch 428/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7007 - acc: 0.7593 - val_loss: 0.6587 - val_acc: 0.7671\n",
      "Epoch 429/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7010 - acc: 0.7578 - val_loss: 0.6594 - val_acc: 0.7671\n",
      "Epoch 430/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6997 - acc: 0.7530 - val_loss: 0.6608 - val_acc: 0.7671\n",
      "Epoch 431/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6991 - acc: 0.7522 - val_loss: 0.6592 - val_acc: 0.7679\n",
      "Epoch 432/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7205 - acc: 0.7478 - val_loss: 0.6581 - val_acc: 0.7679\n",
      "Epoch 433/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6836 - acc: 0.7574 - val_loss: 0.6578 - val_acc: 0.7671\n",
      "Epoch 434/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6866 - acc: 0.7586 - val_loss: 0.6570 - val_acc: 0.7679\n",
      "Epoch 435/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7087 - acc: 0.7533 - val_loss: 0.6599 - val_acc: 0.7664\n",
      "Epoch 436/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7004 - acc: 0.7545 - val_loss: 0.6586 - val_acc: 0.7671\n",
      "Epoch 437/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6990 - acc: 0.7597 - val_loss: 0.6573 - val_acc: 0.7671\n",
      "Epoch 438/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7013 - acc: 0.7530 - val_loss: 0.6602 - val_acc: 0.7664\n",
      "Epoch 439/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7036 - acc: 0.7608 - val_loss: 0.6598 - val_acc: 0.7664\n",
      "Epoch 440/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7001 - acc: 0.7582 - val_loss: 0.6578 - val_acc: 0.7679\n",
      "Epoch 441/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7007 - acc: 0.7500 - val_loss: 0.6598 - val_acc: 0.7671\n",
      "Epoch 442/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6912 - acc: 0.7619 - val_loss: 0.6572 - val_acc: 0.7679\n",
      "Epoch 443/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6948 - acc: 0.7530 - val_loss: 0.6598 - val_acc: 0.7671\n",
      "Epoch 444/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7071 - acc: 0.7649 - val_loss: 0.6583 - val_acc: 0.7671\n",
      "Epoch 445/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6991 - acc: 0.7519 - val_loss: 0.6583 - val_acc: 0.7679\n",
      "Epoch 446/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7003 - acc: 0.7556 - val_loss: 0.6587 - val_acc: 0.7671\n",
      "Epoch 447/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6919 - acc: 0.7582 - val_loss: 0.6601 - val_acc: 0.7671\n",
      "Epoch 448/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6885 - acc: 0.7522 - val_loss: 0.6585 - val_acc: 0.7679\n",
      "Epoch 449/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7000 - acc: 0.7597 - val_loss: 0.6604 - val_acc: 0.7664\n",
      "Epoch 450/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6973 - acc: 0.7507 - val_loss: 0.6604 - val_acc: 0.7664\n",
      "Epoch 451/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6927 - acc: 0.7507 - val_loss: 0.6600 - val_acc: 0.7664\n",
      "Epoch 452/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7111 - acc: 0.7560 - val_loss: 0.6573 - val_acc: 0.7671\n",
      "Epoch 453/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7060 - acc: 0.7552 - val_loss: 0.6594 - val_acc: 0.7671\n",
      "Epoch 454/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7075 - acc: 0.7530 - val_loss: 0.6597 - val_acc: 0.7664\n",
      "Epoch 455/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7009 - acc: 0.7600 - val_loss: 0.6595 - val_acc: 0.7671\n",
      "Epoch 456/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7005 - acc: 0.7522 - val_loss: 0.6578 - val_acc: 0.7671\n",
      "Epoch 457/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6909 - acc: 0.7515 - val_loss: 0.6578 - val_acc: 0.7671\n",
      "Epoch 458/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6982 - acc: 0.7552 - val_loss: 0.6600 - val_acc: 0.7664\n",
      "Epoch 459/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7104 - acc: 0.7515 - val_loss: 0.6591 - val_acc: 0.7671\n",
      "Epoch 460/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6933 - acc: 0.7619 - val_loss: 0.6601 - val_acc: 0.7664\n",
      "Epoch 461/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7079 - acc: 0.7545 - val_loss: 0.6587 - val_acc: 0.7679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 462/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6857 - acc: 0.7552 - val_loss: 0.6597 - val_acc: 0.7671\n",
      "Epoch 463/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7020 - acc: 0.7582 - val_loss: 0.6588 - val_acc: 0.7671\n",
      "Epoch 464/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6990 - acc: 0.7507 - val_loss: 0.6599 - val_acc: 0.7664\n",
      "Epoch 465/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6905 - acc: 0.7552 - val_loss: 0.6589 - val_acc: 0.7671\n",
      "\n",
      "Epoch 00465: loss improved from inf to 0.69052, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-2-000465-0.690520-0.767113.hdf5\n",
      "Epoch 466/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6926 - acc: 0.7586 - val_loss: 0.6582 - val_acc: 0.7671\n",
      "Epoch 467/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7030 - acc: 0.7560 - val_loss: 0.6585 - val_acc: 0.7679\n",
      "Epoch 468/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7012 - acc: 0.7552 - val_loss: 0.6596 - val_acc: 0.7671\n",
      "Epoch 469/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7007 - acc: 0.7552 - val_loss: 0.6602 - val_acc: 0.7671\n",
      "Epoch 470/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6960 - acc: 0.7619 - val_loss: 0.6593 - val_acc: 0.7671\n",
      "Epoch 471/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6943 - acc: 0.7545 - val_loss: 0.6593 - val_acc: 0.7671\n",
      "Epoch 472/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7107 - acc: 0.7522 - val_loss: 0.6602 - val_acc: 0.7671\n",
      "Epoch 473/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7033 - acc: 0.7537 - val_loss: 0.6560 - val_acc: 0.7679\n",
      "Epoch 474/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7018 - acc: 0.7548 - val_loss: 0.6595 - val_acc: 0.7671\n",
      "Epoch 475/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6972 - acc: 0.7630 - val_loss: 0.6588 - val_acc: 0.7671\n",
      "Epoch 476/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6891 - acc: 0.7556 - val_loss: 0.6592 - val_acc: 0.7664\n",
      "Epoch 477/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7073 - acc: 0.7478 - val_loss: 0.6570 - val_acc: 0.7671\n",
      "Epoch 478/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6944 - acc: 0.7567 - val_loss: 0.6602 - val_acc: 0.7664\n",
      "Epoch 479/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6913 - acc: 0.7574 - val_loss: 0.6603 - val_acc: 0.7664\n",
      "Epoch 480/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6923 - acc: 0.7552 - val_loss: 0.6594 - val_acc: 0.7671\n",
      "Epoch 481/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6982 - acc: 0.7571 - val_loss: 0.6594 - val_acc: 0.7671\n",
      "Epoch 482/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6901 - acc: 0.7537 - val_loss: 0.6599 - val_acc: 0.7671\n",
      "Epoch 483/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7009 - acc: 0.7530 - val_loss: 0.6566 - val_acc: 0.7679\n",
      "Epoch 484/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7155 - acc: 0.7470 - val_loss: 0.6594 - val_acc: 0.7671\n",
      "Epoch 485/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6943 - acc: 0.7571 - val_loss: 0.6601 - val_acc: 0.7664\n",
      "Epoch 486/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7093 - acc: 0.7444 - val_loss: 0.6574 - val_acc: 0.7671\n",
      "Epoch 487/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6862 - acc: 0.7660 - val_loss: 0.6564 - val_acc: 0.7679\n",
      "Epoch 488/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6790 - acc: 0.7530 - val_loss: 0.6594 - val_acc: 0.7671\n",
      "Epoch 489/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7032 - acc: 0.7533 - val_loss: 0.6591 - val_acc: 0.7671\n",
      "Epoch 490/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6959 - acc: 0.7537 - val_loss: 0.6606 - val_acc: 0.7664\n",
      "Epoch 491/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7012 - acc: 0.7586 - val_loss: 0.6590 - val_acc: 0.7671\n",
      "Epoch 492/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6955 - acc: 0.7515 - val_loss: 0.6586 - val_acc: 0.7671\n",
      "Epoch 493/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6882 - acc: 0.7537 - val_loss: 0.6599 - val_acc: 0.7671\n",
      "\n",
      "Epoch 00493: loss improved from 0.69052 to 0.68818, saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/Pbest-2-000493-0.688183-0.767113.hdf5\n",
      "Epoch 494/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7028 - acc: 0.7533 - val_loss: 0.6605 - val_acc: 0.7664\n",
      "Epoch 495/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7003 - acc: 0.7556 - val_loss: 0.6603 - val_acc: 0.7664\n",
      "Epoch 496/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7062 - acc: 0.7533 - val_loss: 0.6593 - val_acc: 0.7671\n",
      "Epoch 497/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6921 - acc: 0.7455 - val_loss: 0.6592 - val_acc: 0.7671\n",
      "Epoch 498/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7105 - acc: 0.7556 - val_loss: 0.6595 - val_acc: 0.7671\n",
      "Epoch 499/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6871 - acc: 0.7604 - val_loss: 0.6534 - val_acc: 0.7686\n",
      "Epoch 500/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6964 - acc: 0.7545 - val_loss: 0.6595 - val_acc: 0.7671\n",
      "\n",
      "Epoch 00500: saving model to ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/2-000500-0.696376-0.767113.hdf5\n",
      "Epoch 501/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6967 - acc: 0.7556 - val_loss: 0.6578 - val_acc: 0.7671\n",
      "Epoch 502/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7009 - acc: 0.7586 - val_loss: 0.6590 - val_acc: 0.7671\n",
      "Epoch 503/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7115 - acc: 0.7507 - val_loss: 0.6588 - val_acc: 0.7671\n",
      "Epoch 504/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6983 - acc: 0.7600 - val_loss: 0.6556 - val_acc: 0.7693\n",
      "Epoch 505/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6822 - acc: 0.7608 - val_loss: 0.6593 - val_acc: 0.7671\n",
      "Epoch 506/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7087 - acc: 0.7504 - val_loss: 0.6577 - val_acc: 0.7679\n",
      "Epoch 507/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7061 - acc: 0.7571 - val_loss: 0.6587 - val_acc: 0.7671\n",
      "Epoch 508/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7154 - acc: 0.7530 - val_loss: 0.6593 - val_acc: 0.7671\n",
      "Epoch 509/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6901 - acc: 0.7530 - val_loss: 0.6580 - val_acc: 0.7671\n",
      "Epoch 510/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.6826 - acc: 0.7641 - val_loss: 0.6600 - val_acc: 0.7664\n",
      "Epoch 511/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6986 - acc: 0.7496 - val_loss: 0.6582 - val_acc: 0.7679\n",
      "Epoch 512/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7089 - acc: 0.7548 - val_loss: 0.6573 - val_acc: 0.7679\n",
      "Epoch 513/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6949 - acc: 0.7571 - val_loss: 0.6597 - val_acc: 0.7671\n",
      "Epoch 514/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.6846 - acc: 0.7660 - val_loss: 0.6576 - val_acc: 0.7671\n",
      "Epoch 515/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.6935 - acc: 0.7560 - val_loss: 0.6590 - val_acc: 0.7671\n",
      "Epoch 516/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6931 - acc: 0.7615 - val_loss: 0.6585 - val_acc: 0.7679\n",
      "Epoch 517/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7048 - acc: 0.7604 - val_loss: 0.6589 - val_acc: 0.7671\n",
      "Epoch 518/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6984 - acc: 0.7548 - val_loss: 0.6587 - val_acc: 0.7671\n",
      "Epoch 519/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7142 - acc: 0.7507 - val_loss: 0.6577 - val_acc: 0.7671\n",
      "Epoch 520/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7071 - acc: 0.7626 - val_loss: 0.6576 - val_acc: 0.7679\n",
      "Epoch 521/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7167 - acc: 0.7507 - val_loss: 0.6565 - val_acc: 0.7671\n",
      "Epoch 522/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6918 - acc: 0.7597 - val_loss: 0.6596 - val_acc: 0.7664\n",
      "Epoch 523/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6942 - acc: 0.7586 - val_loss: 0.6582 - val_acc: 0.7671\n",
      "Epoch 524/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7118 - acc: 0.7545 - val_loss: 0.6594 - val_acc: 0.7664\n",
      "Epoch 525/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7068 - acc: 0.7600 - val_loss: 0.6598 - val_acc: 0.7671\n",
      "Epoch 526/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6956 - acc: 0.7574 - val_loss: 0.6587 - val_acc: 0.7671\n",
      "Epoch 527/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6874 - acc: 0.7589 - val_loss: 0.6597 - val_acc: 0.7671\n",
      "Epoch 528/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6925 - acc: 0.7626 - val_loss: 0.6585 - val_acc: 0.7671\n",
      "Epoch 529/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7090 - acc: 0.7470 - val_loss: 0.6583 - val_acc: 0.7671\n",
      "Epoch 530/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7132 - acc: 0.7504 - val_loss: 0.6596 - val_acc: 0.7671\n",
      "Epoch 531/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6903 - acc: 0.7567 - val_loss: 0.6589 - val_acc: 0.7671\n",
      "Epoch 532/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7108 - acc: 0.7504 - val_loss: 0.6600 - val_acc: 0.7664\n",
      "Epoch 533/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7045 - acc: 0.7519 - val_loss: 0.6604 - val_acc: 0.7664\n",
      "Epoch 534/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6994 - acc: 0.7519 - val_loss: 0.6585 - val_acc: 0.7671\n",
      "Epoch 535/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6973 - acc: 0.7500 - val_loss: 0.6544 - val_acc: 0.7679\n",
      "Epoch 536/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6881 - acc: 0.7593 - val_loss: 0.6561 - val_acc: 0.7679\n",
      "Epoch 537/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7183 - acc: 0.7522 - val_loss: 0.6562 - val_acc: 0.7679\n",
      "Epoch 00537: early stopping\n",
      "ModelCheckpoint 已经保存到 ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/weights/2-final.hdf5\n",
      "save in: ../datasets/casas/results/WCNNR/milan/999/20220201_2000_64_1_3_1/log/20220201_2000_64_1_3_1.csv\n",
      "time: 0:14:10 s\n",
      "time: 850.0 s\n",
      "average 0.850000 s\n",
      "2 epoch finished\n",
      "--------------------   best   --------------------\n",
      "no_activities: 10\n",
      "\n",
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1348/1348 [==============================] - 1s 442us/step\n",
      "2-milan:\tacc: 76.71%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 7, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 7, 0, 0, 4, 0, 4, 0, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 7, 0, 7, 0, 7, 7, 7, 7, 7, 7, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 0, 7, 7, 7, 0, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 0, 7, 0, 0, 7, 7, 7, 0, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 0, 7, 7, 7, 0, 7, 0, 7, 7, 7, 7, 0, 7, 0, 0, 0, 7, 7, 0, 7, 7, 7, 7, 0, 0, 7, 7, 4, 7, 7, 9, 7, 7, 4, 7, 7, 7, 7, 7, 7, 0, 0, 7, 0, 7, 7, 9, 7, 7, 7, 7, 0, 7, 0, 7, 7, 7, 7, 7, 0, 7, 7, 7, 0, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 0, 0, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 3, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 0, 0, 0, 0, 9, 0, 9, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 9, 0, 0, 0, 9, 9, 9, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 9, 9, 9, 7, 0, 0, 0, 0, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 4, 7, 0, 0, 0, 7, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 9, 9, 0, 7, 0, 0, 7, 0, 7, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 7, 0, 7, 0, 7, 0, 0, 0, 5, 7, 9, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 4, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 4, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 3, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 4, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7, 7, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 4, 4, 0, 4, 4, 4, 4, 0, 4, 0, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 0, 4, 0, 4, 0, 4, 4, 4, 4, 0, 0, 0, 4, 4, 4, 0, 0, 0, 4, 4, 0, 0, 4, 4, 0, 0, 4, 4, 0, 4, 4, 0, 4, 4, 0, 4, 4, 9, 7, 4, 0, 0, 4, 4, 4, 4, 0, 0, 4, 4, 0, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 0, 4, 4, 0, 3, 0, 3, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 9, 3, 0, 0, 0, 3, 9, 9, 0, 0, 0, 0, 3, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 4, 4, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 4, 0, 0, 4, 0, 0, 0]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.769339  0.878010  0.820090       623\n",
      "         Work   0.000000  0.000000  0.000000        26\n",
      "Take_medicine   0.000000  0.000000  0.000000        20\n",
      "        Sleep   0.583333  0.218750  0.318182        32\n",
      "        Relax   0.792079  0.559441  0.655738       143\n",
      "   Leave_Home   0.914286  0.901408  0.907801        71\n",
      "          Eat   0.000000  0.000000  0.000000         7\n",
      "         Cook   0.711538  0.800000  0.753181       185\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        29\n",
      "      Bathing   0.764228  0.886792  0.820961       212\n",
      "\n",
      "     accuracy                       0.767062      1348\n",
      "    macro avg   0.453480  0.424440  0.427595      1348\n",
      " weighted avg   0.719434  0.767062  0.736428      1348\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  28   0   0   1   0   0]\n",
      " [  0   0   0   0   0   3   0  20   3   0]\n",
      " [  0   0   0   0   0   3   0   4   0   0]\n",
      " [  0   0   0   0   0  20   0   0   0   0]\n",
      " [  0   0   0   0 188   2   0  21   0   1]\n",
      " [  0   0   0   0   3 148   0  32   2   0]\n",
      " [  0   0   0   0   1   0  64   5   1   0]\n",
      " [  0   0   0   0  21  30   6 547  15   4]\n",
      " [  0   0   0   0   1   2   0  60  80   0]\n",
      " [  0   0   0   0   4   0   0  21   0   7]]\n",
      "--------------------   final   --------------------\n",
      "no_activities: 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1348/1348 [==============================] - 1s 420us/step\n",
      "2-milan:\tacc: 76.71%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 7, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 7, 0, 0, 4, 0, 4, 0, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 7, 0, 7, 0, 7, 7, 7, 7, 7, 7, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 0, 7, 7, 7, 0, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 0, 7, 0, 0, 7, 7, 7, 0, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 0, 7, 7, 7, 0, 7, 0, 7, 7, 7, 7, 0, 7, 0, 0, 0, 7, 7, 0, 7, 7, 7, 7, 0, 0, 7, 7, 4, 7, 7, 9, 7, 7, 4, 7, 7, 7, 7, 7, 7, 0, 0, 7, 0, 7, 7, 9, 7, 7, 7, 7, 0, 7, 0, 7, 7, 7, 7, 7, 0, 7, 7, 7, 0, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 0, 0, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 3, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 0, 0, 0, 0, 9, 0, 9, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 9, 0, 0, 0, 9, 9, 9, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 9, 9, 9, 7, 0, 0, 0, 0, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 4, 7, 0, 0, 0, 7, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 9, 9, 0, 7, 0, 0, 7, 0, 7, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 7, 0, 7, 0, 7, 0, 0, 0, 5, 7, 9, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 4, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 4, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 3, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 4, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7, 7, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 4, 4, 0, 4, 4, 4, 4, 0, 4, 0, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 0, 4, 0, 4, 0, 4, 4, 4, 4, 0, 0, 0, 4, 4, 4, 0, 0, 0, 4, 4, 0, 0, 4, 4, 0, 0, 4, 4, 0, 4, 4, 0, 4, 4, 0, 4, 4, 9, 7, 4, 0, 0, 4, 4, 4, 4, 0, 0, 4, 4, 0, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 0, 4, 4, 0, 3, 9, 3, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 9, 3, 0, 9, 0, 3, 9, 9, 0, 0, 0, 0, 3, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 4, 4, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 4, 0, 0, 4, 0, 0, 0]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.772277  0.876404  0.821053       623\n",
      "         Work   0.000000  0.000000  0.000000        26\n",
      "Take_medicine   0.000000  0.000000  0.000000        20\n",
      "        Sleep   0.583333  0.218750  0.318182        32\n",
      "        Relax   0.792079  0.559441  0.655738       143\n",
      "   Leave_Home   0.914286  0.901408  0.907801        71\n",
      "          Eat   0.000000  0.000000  0.000000         7\n",
      "         Cook   0.711538  0.800000  0.753181       185\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        29\n",
      "      Bathing   0.756000  0.891509  0.818182       212\n",
      "\n",
      "     accuracy                       0.767062      1348\n",
      "    macro avg   0.452951  0.424751  0.427414      1348\n",
      " weighted avg   0.719498  0.767062  0.736435      1348\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  28   0   0   1   0   0]\n",
      " [  0   0   0   0   0   3   0  20   3   0]\n",
      " [  0   0   0   0   0   3   0   4   0   0]\n",
      " [  0   0   0   0   0  20   0   0   0   0]\n",
      " [  0   0   0   0 189   2   0  20   0   1]\n",
      " [  0   0   0   0   3 148   0  32   2   0]\n",
      " [  0   0   0   0   1   0  64   5   1   0]\n",
      " [  0   0   0   0  22  30   6 546  15   4]\n",
      " [  0   0   0   0   1   2   0  60  80   0]\n",
      " [  0   0   0   0   6   0   0  19   0   7]]\n",
      "best: current database: milan \t 77.38% (+/- 0.62%)\n",
      "final: current database: milan \t 77.35% (+/- 0.63%)\n",
      "CPU times: user 38min 38s, sys: 1min 39s, total: 40min 17s\n",
      "Wall time: 43min 13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dict_config_cus['distance_int'] = '999'\n",
    "train_val(dict_config_cus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "scrolled": true
   },
   "source": [
    "```bash\n",
    "best: current database: milan \t 77.38% (+/- 0.62%)\n",
    "final: current database: milan \t 77.35% (+/- 0.63%)\n",
    "CPU times: user 38min 38s, sys: 1min 39s, total: 40min 17s\n",
    "Wall time: 43min 13s\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='constrain_1'>CS_1</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current dataset: milan\n",
      "../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1\n",
      "no_activities: 10\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_19 (Embedding)     (None, 2000, 64)          172544    \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 2000, 12)          780       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 2000, 12)          0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_19 (Glo (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 18)                234       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 12)                228       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 10)                130       \n",
      "=================================================================\n",
      "Total params: 173,916\n",
      "Trainable params: 173,916\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Create subdir directory: ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights...\n",
      "Begin training ...\n",
      "Epoch 1/1000\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.8190 - acc: 0.4501 - val_loss: 1.2310 - val_acc: 0.6057\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.1567 - acc: 0.6871 - val_loss: 0.8995 - val_acc: 0.8371\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.9048 - acc: 0.7891 - val_loss: 0.6475 - val_acc: 0.8438\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7014 - acc: 0.8211 - val_loss: 0.5079 - val_acc: 0.8475\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6213 - acc: 0.8285 - val_loss: 0.4574 - val_acc: 0.8475\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.5852 - acc: 0.8382 - val_loss: 0.4272 - val_acc: 0.8951\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.5591 - acc: 0.8504 - val_loss: 0.4074 - val_acc: 0.9003\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.5292 - acc: 0.8597 - val_loss: 0.3901 - val_acc: 0.9003\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.5026 - acc: 0.8638 - val_loss: 0.3724 - val_acc: 0.9010\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.4850 - acc: 0.8672 - val_loss: 0.3610 - val_acc: 0.9010\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.4697 - acc: 0.8668 - val_loss: 0.3487 - val_acc: 0.9040\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.4661 - acc: 0.8754 - val_loss: 0.3405 - val_acc: 0.9010\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.4541 - acc: 0.8776 - val_loss: 0.3341 - val_acc: 0.9010\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.4464 - acc: 0.8754 - val_loss: 0.3249 - val_acc: 0.9010\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.4348 - acc: 0.8735 - val_loss: 0.3248 - val_acc: 0.9003\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.4361 - acc: 0.8746 - val_loss: 0.3169 - val_acc: 0.9010\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.4026 - acc: 0.8832 - val_loss: 0.3154 - val_acc: 0.9003\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.4150 - acc: 0.8810 - val_loss: 0.3125 - val_acc: 0.9055\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.4267 - acc: 0.8817 - val_loss: 0.3026 - val_acc: 0.9018\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3916 - acc: 0.8832 - val_loss: 0.3013 - val_acc: 0.9070\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.4009 - acc: 0.8865 - val_loss: 0.3005 - val_acc: 0.9070\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3862 - acc: 0.8865 - val_loss: 0.2953 - val_acc: 0.9070\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3870 - acc: 0.8821 - val_loss: 0.2944 - val_acc: 0.9070\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.3990 - acc: 0.8828 - val_loss: 0.2936 - val_acc: 0.9070\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3820 - acc: 0.8880 - val_loss: 0.2884 - val_acc: 0.9077\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3899 - acc: 0.8813 - val_loss: 0.2882 - val_acc: 0.9070\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3717 - acc: 0.8891 - val_loss: 0.2824 - val_acc: 0.9070\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3588 - acc: 0.8929 - val_loss: 0.2821 - val_acc: 0.9062\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3697 - acc: 0.8869 - val_loss: 0.2807 - val_acc: 0.9070\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3679 - acc: 0.8862 - val_loss: 0.2796 - val_acc: 0.9062\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3656 - acc: 0.8891 - val_loss: 0.2775 - val_acc: 0.9062\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3707 - acc: 0.8876 - val_loss: 0.2749 - val_acc: 0.9062\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3640 - acc: 0.8925 - val_loss: 0.2732 - val_acc: 0.9070\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3462 - acc: 0.8932 - val_loss: 0.2714 - val_acc: 0.9062\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3549 - acc: 0.8996 - val_loss: 0.2694 - val_acc: 0.9062\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3661 - acc: 0.8906 - val_loss: 0.2678 - val_acc: 0.9062\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3525 - acc: 0.8917 - val_loss: 0.2672 - val_acc: 0.9092\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.3569 - acc: 0.8969 - val_loss: 0.2647 - val_acc: 0.9137\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3432 - acc: 0.8996 - val_loss: 0.2635 - val_acc: 0.9137\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3418 - acc: 0.8940 - val_loss: 0.2612 - val_acc: 0.9308\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3321 - acc: 0.8988 - val_loss: 0.2594 - val_acc: 0.9144\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3392 - acc: 0.8936 - val_loss: 0.2578 - val_acc: 0.9129\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3436 - acc: 0.8958 - val_loss: 0.2578 - val_acc: 0.9129\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3539 - acc: 0.8958 - val_loss: 0.2571 - val_acc: 0.9137\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3500 - acc: 0.8996 - val_loss: 0.2547 - val_acc: 0.9129\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3269 - acc: 0.9048 - val_loss: 0.2538 - val_acc: 0.9137\n",
      "Epoch 47/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3486 - acc: 0.8966 - val_loss: 0.2526 - val_acc: 0.9301\n",
      "Epoch 48/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3236 - acc: 0.9044 - val_loss: 0.2509 - val_acc: 0.9308\n",
      "Epoch 49/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3472 - acc: 0.8973 - val_loss: 0.2501 - val_acc: 0.9301\n",
      "Epoch 50/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3337 - acc: 0.8969 - val_loss: 0.2471 - val_acc: 0.9308\n",
      "Epoch 51/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3433 - acc: 0.8940 - val_loss: 0.2481 - val_acc: 0.9301\n",
      "Epoch 52/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3177 - acc: 0.9025 - val_loss: 0.2463 - val_acc: 0.9308\n",
      "Epoch 53/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3371 - acc: 0.8981 - val_loss: 0.2463 - val_acc: 0.9315\n",
      "Epoch 54/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3248 - acc: 0.8999 - val_loss: 0.2467 - val_acc: 0.9308\n",
      "Epoch 55/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3216 - acc: 0.8999 - val_loss: 0.2469 - val_acc: 0.9308\n",
      "Epoch 56/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3282 - acc: 0.9010 - val_loss: 0.2451 - val_acc: 0.9308\n",
      "Epoch 57/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3159 - acc: 0.9040 - val_loss: 0.2443 - val_acc: 0.9308\n",
      "Epoch 58/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3280 - acc: 0.9059 - val_loss: 0.2421 - val_acc: 0.9323\n",
      "Epoch 59/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3401 - acc: 0.8977 - val_loss: 0.2422 - val_acc: 0.9308\n",
      "Epoch 60/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3162 - acc: 0.9062 - val_loss: 0.2408 - val_acc: 0.9308\n",
      "Epoch 61/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3245 - acc: 0.9033 - val_loss: 0.2417 - val_acc: 0.9368\n",
      "Epoch 62/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3188 - acc: 0.9044 - val_loss: 0.2411 - val_acc: 0.9368\n",
      "Epoch 63/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3288 - acc: 0.9055 - val_loss: 0.2405 - val_acc: 0.9368\n",
      "Epoch 64/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3199 - acc: 0.9051 - val_loss: 0.2386 - val_acc: 0.9375\n",
      "Epoch 65/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3321 - acc: 0.9033 - val_loss: 0.2390 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00065: loss improved from inf to 0.33210, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-0-000065-0.332096-0.937500.hdf5\n",
      "Epoch 66/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3239 - acc: 0.9033 - val_loss: 0.2319 - val_acc: 0.9375\n",
      "Epoch 67/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3285 - acc: 0.9048 - val_loss: 0.2391 - val_acc: 0.9368\n",
      "Epoch 68/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2998 - acc: 0.9126 - val_loss: 0.2387 - val_acc: 0.9375\n",
      "Epoch 69/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3164 - acc: 0.9062 - val_loss: 0.2373 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00069: loss improved from 0.33210 to 0.31641, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-0-000069-0.316406-0.936756.hdf5\n",
      "Epoch 70/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3125 - acc: 0.9085 - val_loss: 0.2366 - val_acc: 0.9375\n",
      "Epoch 71/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3156 - acc: 0.9092 - val_loss: 0.2371 - val_acc: 0.9375\n",
      "Epoch 72/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3103 - acc: 0.9103 - val_loss: 0.2370 - val_acc: 0.9375\n",
      "Epoch 73/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.3196 - acc: 0.9096 - val_loss: 0.2348 - val_acc: 0.9382\n",
      "Epoch 74/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3222 - acc: 0.9029 - val_loss: 0.2362 - val_acc: 0.9375\n",
      "Epoch 75/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2980 - acc: 0.9115 - val_loss: 0.2347 - val_acc: 0.9375\n",
      "Epoch 76/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3001 - acc: 0.9096 - val_loss: 0.2348 - val_acc: 0.9375\n",
      "Epoch 77/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3130 - acc: 0.9111 - val_loss: 0.2290 - val_acc: 0.9382\n",
      "\n",
      "Epoch 00077: loss improved from 0.31641 to 0.31296, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-0-000077-0.312957-0.938244.hdf5\n",
      "Epoch 78/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3046 - acc: 0.9111 - val_loss: 0.2339 - val_acc: 0.9360\n",
      "Epoch 79/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3055 - acc: 0.9092 - val_loss: 0.2342 - val_acc: 0.9368\n",
      "Epoch 80/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3033 - acc: 0.9118 - val_loss: 0.2345 - val_acc: 0.9360\n",
      "Epoch 81/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3073 - acc: 0.9059 - val_loss: 0.2340 - val_acc: 0.9360\n",
      "\n",
      "Epoch 00081: loss improved from 0.31296 to 0.30733, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-0-000081-0.307329-0.936012.hdf5\n",
      "Epoch 82/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2972 - acc: 0.9111 - val_loss: 0.2327 - val_acc: 0.9375\n",
      "Epoch 83/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3031 - acc: 0.9178 - val_loss: 0.2329 - val_acc: 0.9375\n",
      "Epoch 84/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3126 - acc: 0.9055 - val_loss: 0.2323 - val_acc: 0.9360\n",
      "Epoch 85/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2922 - acc: 0.9126 - val_loss: 0.2310 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00085: loss improved from 0.30733 to 0.29220, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-0-000085-0.292201-0.936756.hdf5\n",
      "Epoch 86/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3127 - acc: 0.9070 - val_loss: 0.2322 - val_acc: 0.9375\n",
      "Epoch 87/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2926 - acc: 0.9115 - val_loss: 0.2316 - val_acc: 0.9375\n",
      "Epoch 88/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3050 - acc: 0.9129 - val_loss: 0.2312 - val_acc: 0.9375\n",
      "Epoch 89/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2926 - acc: 0.9152 - val_loss: 0.2306 - val_acc: 0.9375\n",
      "Epoch 90/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2817 - acc: 0.9170 - val_loss: 0.2301 - val_acc: 0.9382\n",
      "Epoch 91/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3180 - acc: 0.9040 - val_loss: 0.2313 - val_acc: 0.9375\n",
      "Epoch 92/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3148 - acc: 0.9074 - val_loss: 0.2302 - val_acc: 0.9368\n",
      "Epoch 93/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3092 - acc: 0.9059 - val_loss: 0.2311 - val_acc: 0.9375\n",
      "Epoch 94/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2996 - acc: 0.9107 - val_loss: 0.2316 - val_acc: 0.9360\n",
      "Epoch 95/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3095 - acc: 0.9092 - val_loss: 0.2313 - val_acc: 0.9375\n",
      "Epoch 96/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3071 - acc: 0.9074 - val_loss: 0.2303 - val_acc: 0.9360\n",
      "Epoch 97/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2921 - acc: 0.9107 - val_loss: 0.2303 - val_acc: 0.9360\n",
      "\n",
      "Epoch 00097: loss improved from 0.29220 to 0.29212, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-0-000097-0.292121-0.936012.hdf5\n",
      "Epoch 98/1000\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 0.2984 - acc: 0.9070 - val_loss: 0.2280 - val_acc: 0.9368\n",
      "Epoch 99/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2964 - acc: 0.9070 - val_loss: 0.2302 - val_acc: 0.9375\n",
      "Epoch 100/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2984 - acc: 0.9126 - val_loss: 0.2300 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00100: saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/0-000100-0.298379-0.937500.hdf5\n",
      "Epoch 101/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3007 - acc: 0.9074 - val_loss: 0.2294 - val_acc: 0.9375\n",
      "Epoch 102/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2832 - acc: 0.9122 - val_loss: 0.2283 - val_acc: 0.9375\n",
      "Epoch 103/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3028 - acc: 0.9096 - val_loss: 0.2282 - val_acc: 0.9375\n",
      "Epoch 104/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2860 - acc: 0.9111 - val_loss: 0.2288 - val_acc: 0.9375\n",
      "Epoch 105/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2996 - acc: 0.9074 - val_loss: 0.2291 - val_acc: 0.9375\n",
      "Epoch 106/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2864 - acc: 0.9111 - val_loss: 0.2236 - val_acc: 0.9382\n",
      "Epoch 107/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2973 - acc: 0.9089 - val_loss: 0.2280 - val_acc: 0.9375\n",
      "Epoch 108/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2858 - acc: 0.9148 - val_loss: 0.2277 - val_acc: 0.9375\n",
      "Epoch 109/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2959 - acc: 0.9129 - val_loss: 0.2288 - val_acc: 0.9405\n",
      "Epoch 110/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2902 - acc: 0.9163 - val_loss: 0.2240 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 111/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2901 - acc: 0.9111 - val_loss: 0.2243 - val_acc: 0.9412\n",
      "Epoch 112/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3007 - acc: 0.9137 - val_loss: 0.2266 - val_acc: 0.9412\n",
      "Epoch 113/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2782 - acc: 0.9189 - val_loss: 0.2277 - val_acc: 0.9405\n",
      "Epoch 114/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2916 - acc: 0.9189 - val_loss: 0.2258 - val_acc: 0.9412\n",
      "Epoch 115/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2816 - acc: 0.9178 - val_loss: 0.2276 - val_acc: 0.9405\n",
      "Epoch 116/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3058 - acc: 0.9096 - val_loss: 0.2269 - val_acc: 0.9405\n",
      "Epoch 117/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2846 - acc: 0.9152 - val_loss: 0.2277 - val_acc: 0.9405\n",
      "Epoch 118/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2962 - acc: 0.9141 - val_loss: 0.2247 - val_acc: 0.9412\n",
      "Epoch 119/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2909 - acc: 0.9129 - val_loss: 0.2275 - val_acc: 0.9405\n",
      "Epoch 120/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2850 - acc: 0.9156 - val_loss: 0.2270 - val_acc: 0.9405\n",
      "Epoch 121/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3038 - acc: 0.9129 - val_loss: 0.2259 - val_acc: 0.9412\n",
      "Epoch 122/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2985 - acc: 0.9118 - val_loss: 0.2276 - val_acc: 0.9390\n",
      "Epoch 123/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2954 - acc: 0.9148 - val_loss: 0.2271 - val_acc: 0.9390\n",
      "Epoch 124/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2978 - acc: 0.9144 - val_loss: 0.2260 - val_acc: 0.9397\n",
      "Epoch 125/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3021 - acc: 0.9107 - val_loss: 0.2267 - val_acc: 0.9405\n",
      "Epoch 126/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2785 - acc: 0.9174 - val_loss: 0.2269 - val_acc: 0.9405\n",
      "Epoch 127/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2795 - acc: 0.9200 - val_loss: 0.2268 - val_acc: 0.9405\n",
      "Epoch 128/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2865 - acc: 0.9159 - val_loss: 0.2269 - val_acc: 0.9405\n",
      "Epoch 129/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3066 - acc: 0.9115 - val_loss: 0.2271 - val_acc: 0.9405\n",
      "Epoch 130/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2933 - acc: 0.9141 - val_loss: 0.2257 - val_acc: 0.9397\n",
      "Epoch 131/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2999 - acc: 0.9144 - val_loss: 0.2270 - val_acc: 0.9390\n",
      "Epoch 132/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2769 - acc: 0.9167 - val_loss: 0.2270 - val_acc: 0.9390\n",
      "Epoch 133/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2955 - acc: 0.9107 - val_loss: 0.2267 - val_acc: 0.9390\n",
      "Epoch 134/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2917 - acc: 0.9133 - val_loss: 0.2256 - val_acc: 0.9412\n",
      "Epoch 135/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2960 - acc: 0.9133 - val_loss: 0.2270 - val_acc: 0.9390\n",
      "Epoch 136/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2865 - acc: 0.9185 - val_loss: 0.2263 - val_acc: 0.9405\n",
      "Epoch 137/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2899 - acc: 0.9189 - val_loss: 0.2270 - val_acc: 0.9405\n",
      "Epoch 138/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2890 - acc: 0.9182 - val_loss: 0.2270 - val_acc: 0.9405\n",
      "Epoch 139/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2846 - acc: 0.9144 - val_loss: 0.2264 - val_acc: 0.9405\n",
      "Epoch 140/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2954 - acc: 0.9115 - val_loss: 0.2251 - val_acc: 0.9442\n",
      "Epoch 141/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2854 - acc: 0.9159 - val_loss: 0.2267 - val_acc: 0.9420\n",
      "Epoch 142/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2863 - acc: 0.9156 - val_loss: 0.2256 - val_acc: 0.9442\n",
      "Epoch 143/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2805 - acc: 0.9152 - val_loss: 0.2256 - val_acc: 0.9427\n",
      "Epoch 144/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2852 - acc: 0.9178 - val_loss: 0.2268 - val_acc: 0.9420\n",
      "Epoch 145/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2841 - acc: 0.9178 - val_loss: 0.2269 - val_acc: 0.9435\n",
      "Epoch 146/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2876 - acc: 0.9159 - val_loss: 0.2268 - val_acc: 0.9435\n",
      "Epoch 147/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2901 - acc: 0.9185 - val_loss: 0.2269 - val_acc: 0.9435\n",
      "Epoch 148/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2862 - acc: 0.9129 - val_loss: 0.2269 - val_acc: 0.9420\n",
      "Epoch 149/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2986 - acc: 0.9070 - val_loss: 0.2268 - val_acc: 0.9420\n",
      "Epoch 150/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3006 - acc: 0.9092 - val_loss: 0.2249 - val_acc: 0.9427\n",
      "Epoch 151/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2872 - acc: 0.9167 - val_loss: 0.2258 - val_acc: 0.9427\n",
      "Epoch 152/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2829 - acc: 0.9178 - val_loss: 0.2265 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 153/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2894 - acc: 0.9174 - val_loss: 0.2267 - val_acc: 0.9420\n",
      "Epoch 154/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2833 - acc: 0.9170 - val_loss: 0.2268 - val_acc: 0.9420\n",
      "Epoch 155/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2802 - acc: 0.9126 - val_loss: 0.2262 - val_acc: 0.9420\n",
      "Epoch 156/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2894 - acc: 0.9163 - val_loss: 0.2187 - val_acc: 0.9427\n",
      "Epoch 157/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2827 - acc: 0.9189 - val_loss: 0.2259 - val_acc: 0.9420\n",
      "Epoch 158/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2836 - acc: 0.9137 - val_loss: 0.2267 - val_acc: 0.9420\n",
      "Epoch 159/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2874 - acc: 0.9182 - val_loss: 0.2267 - val_acc: 0.9420\n",
      "Epoch 160/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3188 - acc: 0.9081 - val_loss: 0.2214 - val_acc: 0.9435\n",
      "Epoch 161/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.2908 - acc: 0.9085 - val_loss: 0.2267 - val_acc: 0.9420\n",
      "Epoch 162/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2996 - acc: 0.9103 - val_loss: 0.2267 - val_acc: 0.9420\n",
      "Epoch 163/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3017 - acc: 0.9066 - val_loss: 0.2268 - val_acc: 0.9420\n",
      "Epoch 164/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2876 - acc: 0.9070 - val_loss: 0.2265 - val_acc: 0.9420\n",
      "Epoch 165/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2960 - acc: 0.9178 - val_loss: 0.2267 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00165: loss improved from inf to 0.29600, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-0-000165-0.296000-0.941964.hdf5\n",
      "Epoch 166/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3026 - acc: 0.9081 - val_loss: 0.2266 - val_acc: 0.9420\n",
      "Epoch 167/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2975 - acc: 0.9122 - val_loss: 0.2266 - val_acc: 0.9420\n",
      "Epoch 168/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2989 - acc: 0.9118 - val_loss: 0.2266 - val_acc: 0.9420\n",
      "Epoch 169/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2852 - acc: 0.9170 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00169: loss improved from 0.29600 to 0.28516, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-0-000169-0.285160-0.941964.hdf5\n",
      "Epoch 170/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2907 - acc: 0.9126 - val_loss: 0.2267 - val_acc: 0.9420\n",
      "Epoch 171/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2839 - acc: 0.9137 - val_loss: 0.2259 - val_acc: 0.9427\n",
      "Epoch 172/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2789 - acc: 0.9174 - val_loss: 0.2267 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 173/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.3063 - acc: 0.9107 - val_loss: 0.2263 - val_acc: 0.9420\n",
      "Epoch 174/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2867 - acc: 0.9159 - val_loss: 0.2216 - val_acc: 0.9427\n",
      "Epoch 175/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2777 - acc: 0.9167 - val_loss: 0.2261 - val_acc: 0.9420\n",
      "Epoch 176/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3080 - acc: 0.9092 - val_loss: 0.2255 - val_acc: 0.9427\n",
      "Epoch 177/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2907 - acc: 0.9133 - val_loss: 0.2268 - val_acc: 0.9420\n",
      "Epoch 178/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2929 - acc: 0.9122 - val_loss: 0.2267 - val_acc: 0.9420\n",
      "Epoch 179/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2868 - acc: 0.9133 - val_loss: 0.2265 - val_acc: 0.9420\n",
      "Epoch 180/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2863 - acc: 0.9185 - val_loss: 0.2261 - val_acc: 0.9427\n",
      "Epoch 181/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2802 - acc: 0.9163 - val_loss: 0.2238 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00181: loss improved from 0.28516 to 0.28018, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-0-000181-0.280185-0.943452.hdf5\n",
      "Epoch 182/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2895 - acc: 0.9126 - val_loss: 0.2251 - val_acc: 0.9427\n",
      "Epoch 183/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2821 - acc: 0.9182 - val_loss: 0.2266 - val_acc: 0.9420\n",
      "Epoch 184/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2935 - acc: 0.9122 - val_loss: 0.2268 - val_acc: 0.9420\n",
      "Epoch 185/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2856 - acc: 0.9148 - val_loss: 0.2267 - val_acc: 0.9420\n",
      "Epoch 186/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2719 - acc: 0.9193 - val_loss: 0.2266 - val_acc: 0.9420\n",
      "Epoch 187/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2893 - acc: 0.9107 - val_loss: 0.2236 - val_acc: 0.9427\n",
      "Epoch 188/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2946 - acc: 0.9141 - val_loss: 0.2256 - val_acc: 0.9420\n",
      "Epoch 189/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2896 - acc: 0.9152 - val_loss: 0.2267 - val_acc: 0.9420\n",
      "Epoch 190/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2771 - acc: 0.9193 - val_loss: 0.2265 - val_acc: 0.9420\n",
      "Epoch 191/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2965 - acc: 0.9148 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 192/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2879 - acc: 0.9148 - val_loss: 0.2267 - val_acc: 0.9420\n",
      "Epoch 193/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2806 - acc: 0.9208 - val_loss: 0.2267 - val_acc: 0.9420\n",
      "Epoch 194/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2990 - acc: 0.9144 - val_loss: 0.2265 - val_acc: 0.9420\n",
      "Epoch 195/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2966 - acc: 0.9148 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 196/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3028 - acc: 0.9111 - val_loss: 0.2267 - val_acc: 0.9420\n",
      "Epoch 197/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3016 - acc: 0.9118 - val_loss: 0.2172 - val_acc: 0.9427\n",
      "Epoch 198/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2957 - acc: 0.9111 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 199/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2865 - acc: 0.9189 - val_loss: 0.2267 - val_acc: 0.9420\n",
      "Epoch 200/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2878 - acc: 0.9133 - val_loss: 0.2177 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00200: saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/0-000200-0.287812-0.942708.hdf5\n",
      "Epoch 201/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2958 - acc: 0.9148 - val_loss: 0.2266 - val_acc: 0.9420\n",
      "Epoch 202/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2925 - acc: 0.9096 - val_loss: 0.2267 - val_acc: 0.9420\n",
      "Epoch 203/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2899 - acc: 0.9141 - val_loss: 0.2247 - val_acc: 0.9427\n",
      "Epoch 204/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2906 - acc: 0.9141 - val_loss: 0.2267 - val_acc: 0.9420\n",
      "Epoch 205/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2861 - acc: 0.9148 - val_loss: 0.2246 - val_acc: 0.9427\n",
      "Epoch 206/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2968 - acc: 0.9126 - val_loss: 0.2267 - val_acc: 0.9420\n",
      "Epoch 207/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2943 - acc: 0.9137 - val_loss: 0.2234 - val_acc: 0.9427\n",
      "Epoch 208/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2773 - acc: 0.9163 - val_loss: 0.2246 - val_acc: 0.9427\n",
      "Epoch 209/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2972 - acc: 0.9152 - val_loss: 0.2261 - val_acc: 0.9420\n",
      "Epoch 210/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2888 - acc: 0.9118 - val_loss: 0.2260 - val_acc: 0.9420\n",
      "Epoch 211/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2929 - acc: 0.9170 - val_loss: 0.2262 - val_acc: 0.9420\n",
      "Epoch 212/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2941 - acc: 0.9122 - val_loss: 0.2267 - val_acc: 0.9420\n",
      "Epoch 213/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2885 - acc: 0.9152 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 214/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2837 - acc: 0.9159 - val_loss: 0.2266 - val_acc: 0.9420\n",
      "Epoch 215/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2855 - acc: 0.9122 - val_loss: 0.2258 - val_acc: 0.9427\n",
      "Epoch 216/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2892 - acc: 0.9141 - val_loss: 0.2255 - val_acc: 0.9427\n",
      "Epoch 217/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2923 - acc: 0.9141 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 218/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2845 - acc: 0.9141 - val_loss: 0.2266 - val_acc: 0.9420\n",
      "Epoch 219/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2841 - acc: 0.9193 - val_loss: 0.2250 - val_acc: 0.9427\n",
      "Epoch 220/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2966 - acc: 0.9141 - val_loss: 0.2266 - val_acc: 0.9420\n",
      "Epoch 221/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2801 - acc: 0.9137 - val_loss: 0.2259 - val_acc: 0.9420\n",
      "Epoch 222/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2734 - acc: 0.9204 - val_loss: 0.2251 - val_acc: 0.9427\n",
      "Epoch 223/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2827 - acc: 0.9144 - val_loss: 0.2265 - val_acc: 0.9420\n",
      "Epoch 224/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2900 - acc: 0.9129 - val_loss: 0.2252 - val_acc: 0.9427\n",
      "Epoch 225/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2930 - acc: 0.9156 - val_loss: 0.2261 - val_acc: 0.9420\n",
      "Epoch 226/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2846 - acc: 0.9152 - val_loss: 0.2266 - val_acc: 0.9420\n",
      "Epoch 227/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2872 - acc: 0.9133 - val_loss: 0.2263 - val_acc: 0.9420\n",
      "Epoch 228/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2918 - acc: 0.9156 - val_loss: 0.2259 - val_acc: 0.9420\n",
      "Epoch 229/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2891 - acc: 0.9163 - val_loss: 0.2258 - val_acc: 0.9427\n",
      "Epoch 230/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2883 - acc: 0.9182 - val_loss: 0.2229 - val_acc: 0.9427\n",
      "Epoch 231/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2945 - acc: 0.9144 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 232/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2908 - acc: 0.9137 - val_loss: 0.2249 - val_acc: 0.9427\n",
      "Epoch 233/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2656 - acc: 0.9208 - val_loss: 0.2259 - val_acc: 0.9420\n",
      "Epoch 234/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2794 - acc: 0.9148 - val_loss: 0.2266 - val_acc: 0.9420\n",
      "Epoch 235/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2900 - acc: 0.9152 - val_loss: 0.2265 - val_acc: 0.9420\n",
      "Epoch 236/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2828 - acc: 0.9208 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 237/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2823 - acc: 0.9178 - val_loss: 0.2265 - val_acc: 0.9420\n",
      "Epoch 238/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2789 - acc: 0.9204 - val_loss: 0.2257 - val_acc: 0.9427\n",
      "Epoch 239/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2859 - acc: 0.9118 - val_loss: 0.2265 - val_acc: 0.9420\n",
      "Epoch 240/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2961 - acc: 0.9163 - val_loss: 0.2266 - val_acc: 0.9420\n",
      "Epoch 241/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2835 - acc: 0.9182 - val_loss: 0.2259 - val_acc: 0.9420\n",
      "Epoch 242/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2833 - acc: 0.9122 - val_loss: 0.2253 - val_acc: 0.9427\n",
      "Epoch 243/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2746 - acc: 0.9174 - val_loss: 0.2266 - val_acc: 0.9420\n",
      "Epoch 244/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2880 - acc: 0.9185 - val_loss: 0.2265 - val_acc: 0.9420\n",
      "Epoch 245/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2874 - acc: 0.9163 - val_loss: 0.2266 - val_acc: 0.9420\n",
      "Epoch 246/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2849 - acc: 0.9148 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 247/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2978 - acc: 0.9141 - val_loss: 0.2265 - val_acc: 0.9420\n",
      "Epoch 248/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2937 - acc: 0.9159 - val_loss: 0.2266 - val_acc: 0.9420\n",
      "Epoch 249/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2970 - acc: 0.9103 - val_loss: 0.2266 - val_acc: 0.9420\n",
      "Epoch 250/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2821 - acc: 0.9144 - val_loss: 0.2266 - val_acc: 0.9420\n",
      "Epoch 251/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2918 - acc: 0.9096 - val_loss: 0.2262 - val_acc: 0.9420\n",
      "Epoch 252/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2943 - acc: 0.9126 - val_loss: 0.2246 - val_acc: 0.9427\n",
      "Epoch 253/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2882 - acc: 0.9129 - val_loss: 0.2259 - val_acc: 0.9420\n",
      "Epoch 254/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2779 - acc: 0.9230 - val_loss: 0.2247 - val_acc: 0.9427\n",
      "Epoch 255/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2847 - acc: 0.9115 - val_loss: 0.2263 - val_acc: 0.9420\n",
      "Epoch 256/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2816 - acc: 0.9193 - val_loss: 0.2259 - val_acc: 0.9420\n",
      "Epoch 257/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2774 - acc: 0.9185 - val_loss: 0.2216 - val_acc: 0.9427\n",
      "Epoch 258/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2841 - acc: 0.9133 - val_loss: 0.2250 - val_acc: 0.9427\n",
      "Epoch 259/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2970 - acc: 0.9126 - val_loss: 0.2263 - val_acc: 0.9420\n",
      "Epoch 260/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2835 - acc: 0.9163 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 261/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2790 - acc: 0.9156 - val_loss: 0.2265 - val_acc: 0.9420\n",
      "Epoch 262/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.2766 - acc: 0.9219 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 263/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2865 - acc: 0.9129 - val_loss: 0.2263 - val_acc: 0.9420\n",
      "Epoch 264/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2803 - acc: 0.9200 - val_loss: 0.2266 - val_acc: 0.9420\n",
      "Epoch 265/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2762 - acc: 0.9148 - val_loss: 0.2260 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00265: loss improved from inf to 0.27624, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-0-000265-0.276242-0.941964.hdf5\n",
      "Epoch 266/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2825 - acc: 0.9185 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 267/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2873 - acc: 0.9122 - val_loss: 0.2265 - val_acc: 0.9420\n",
      "Epoch 268/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.2937 - acc: 0.9129 - val_loss: 0.2235 - val_acc: 0.9427\n",
      "Epoch 269/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2940 - acc: 0.9159 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 270/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2807 - acc: 0.9174 - val_loss: 0.2240 - val_acc: 0.9435\n",
      "Epoch 271/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2843 - acc: 0.9133 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 272/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2896 - acc: 0.9133 - val_loss: 0.2265 - val_acc: 0.9420\n",
      "Epoch 273/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2709 - acc: 0.9182 - val_loss: 0.2235 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00273: loss improved from 0.27624 to 0.27087, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-0-000273-0.270867-0.942708.hdf5\n",
      "Epoch 274/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2873 - acc: 0.9156 - val_loss: 0.2261 - val_acc: 0.9420\n",
      "Epoch 275/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3015 - acc: 0.9115 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 276/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2844 - acc: 0.9144 - val_loss: 0.2263 - val_acc: 0.9420\n",
      "Epoch 277/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2686 - acc: 0.9230 - val_loss: 0.2261 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00277: loss improved from 0.27087 to 0.26860, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-0-000277-0.268596-0.941964.hdf5\n",
      "Epoch 278/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2824 - acc: 0.9178 - val_loss: 0.2265 - val_acc: 0.9420\n",
      "Epoch 279/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2840 - acc: 0.9126 - val_loss: 0.2265 - val_acc: 0.9420\n",
      "Epoch 280/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2875 - acc: 0.9178 - val_loss: 0.2265 - val_acc: 0.9420\n",
      "Epoch 281/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2911 - acc: 0.9115 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 282/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2940 - acc: 0.9126 - val_loss: 0.2265 - val_acc: 0.9420\n",
      "Epoch 283/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2903 - acc: 0.9152 - val_loss: 0.2263 - val_acc: 0.9420\n",
      "Epoch 284/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2879 - acc: 0.9185 - val_loss: 0.2248 - val_acc: 0.9427\n",
      "Epoch 285/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2829 - acc: 0.9152 - val_loss: 0.2265 - val_acc: 0.9420\n",
      "Epoch 286/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2911 - acc: 0.9152 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 287/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2715 - acc: 0.9170 - val_loss: 0.2263 - val_acc: 0.9420\n",
      "Epoch 288/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2771 - acc: 0.9215 - val_loss: 0.2263 - val_acc: 0.9420\n",
      "Epoch 289/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2890 - acc: 0.9133 - val_loss: 0.2263 - val_acc: 0.9420\n",
      "Epoch 290/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2787 - acc: 0.9156 - val_loss: 0.2265 - val_acc: 0.9420\n",
      "Epoch 291/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2846 - acc: 0.9196 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 292/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2969 - acc: 0.9137 - val_loss: 0.2222 - val_acc: 0.9442\n",
      "Epoch 293/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2959 - acc: 0.9118 - val_loss: 0.2249 - val_acc: 0.9427\n",
      "Epoch 294/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2830 - acc: 0.9196 - val_loss: 0.2261 - val_acc: 0.9420\n",
      "Epoch 295/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2978 - acc: 0.9126 - val_loss: 0.2260 - val_acc: 0.9420\n",
      "Epoch 296/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2895 - acc: 0.9152 - val_loss: 0.2247 - val_acc: 0.9427\n",
      "Epoch 297/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2861 - acc: 0.9148 - val_loss: 0.2253 - val_acc: 0.9427\n",
      "Epoch 298/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2978 - acc: 0.9122 - val_loss: 0.2265 - val_acc: 0.9420\n",
      "Epoch 299/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2980 - acc: 0.9103 - val_loss: 0.2248 - val_acc: 0.9427\n",
      "Epoch 300/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2856 - acc: 0.9159 - val_loss: 0.2260 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00300: saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/0-000300-0.285587-0.941964.hdf5\n",
      "Epoch 301/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2852 - acc: 0.9129 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 302/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2848 - acc: 0.9163 - val_loss: 0.2245 - val_acc: 0.9427\n",
      "Epoch 303/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3005 - acc: 0.9077 - val_loss: 0.2261 - val_acc: 0.9420\n",
      "Epoch 304/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3013 - acc: 0.9100 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 305/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3021 - acc: 0.9133 - val_loss: 0.2263 - val_acc: 0.9420\n",
      "Epoch 306/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2992 - acc: 0.9118 - val_loss: 0.2248 - val_acc: 0.9427\n",
      "Epoch 307/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2890 - acc: 0.9122 - val_loss: 0.2261 - val_acc: 0.9420\n",
      "Epoch 308/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2996 - acc: 0.9122 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 309/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2889 - acc: 0.9178 - val_loss: 0.2256 - val_acc: 0.9420\n",
      "Epoch 310/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2879 - acc: 0.9167 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 311/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2984 - acc: 0.9126 - val_loss: 0.2248 - val_acc: 0.9427\n",
      "Epoch 312/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2786 - acc: 0.9193 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 313/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2721 - acc: 0.9167 - val_loss: 0.2253 - val_acc: 0.9427\n",
      "Epoch 314/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2934 - acc: 0.9185 - val_loss: 0.2263 - val_acc: 0.9420\n",
      "Epoch 315/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2951 - acc: 0.9129 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 316/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2922 - acc: 0.9148 - val_loss: 0.2263 - val_acc: 0.9420\n",
      "Epoch 317/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2769 - acc: 0.9222 - val_loss: 0.2229 - val_acc: 0.9435\n",
      "Epoch 318/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2839 - acc: 0.9103 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 319/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2958 - acc: 0.9152 - val_loss: 0.2263 - val_acc: 0.9420\n",
      "Epoch 320/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2742 - acc: 0.9174 - val_loss: 0.2256 - val_acc: 0.9427\n",
      "Epoch 321/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2857 - acc: 0.9167 - val_loss: 0.2245 - val_acc: 0.9427\n",
      "Epoch 322/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2949 - acc: 0.9137 - val_loss: 0.2253 - val_acc: 0.9427\n",
      "Epoch 323/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2937 - acc: 0.9174 - val_loss: 0.2262 - val_acc: 0.9420\n",
      "Epoch 324/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2882 - acc: 0.9126 - val_loss: 0.2252 - val_acc: 0.9427\n",
      "Epoch 325/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2965 - acc: 0.9115 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 326/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2887 - acc: 0.9167 - val_loss: 0.2252 - val_acc: 0.9427\n",
      "Epoch 327/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2966 - acc: 0.9115 - val_loss: 0.2238 - val_acc: 0.9427\n",
      "Epoch 328/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2829 - acc: 0.9115 - val_loss: 0.2259 - val_acc: 0.9420\n",
      "Epoch 329/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2773 - acc: 0.9178 - val_loss: 0.2261 - val_acc: 0.9420\n",
      "Epoch 330/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2834 - acc: 0.9118 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 331/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2853 - acc: 0.9156 - val_loss: 0.2241 - val_acc: 0.9427\n",
      "Epoch 332/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2911 - acc: 0.9122 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 333/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.2940 - acc: 0.9137 - val_loss: 0.2251 - val_acc: 0.9427\n",
      "Epoch 334/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2925 - acc: 0.9096 - val_loss: 0.2262 - val_acc: 0.9420\n",
      "Epoch 335/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2822 - acc: 0.9118 - val_loss: 0.2263 - val_acc: 0.9420\n",
      "Epoch 336/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2828 - acc: 0.9167 - val_loss: 0.2256 - val_acc: 0.9427\n",
      "Epoch 337/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2917 - acc: 0.9141 - val_loss: 0.2263 - val_acc: 0.9420\n",
      "Epoch 338/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2887 - acc: 0.9163 - val_loss: 0.2261 - val_acc: 0.9420\n",
      "Epoch 339/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2778 - acc: 0.9252 - val_loss: 0.2244 - val_acc: 0.9427\n",
      "Epoch 340/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2910 - acc: 0.9156 - val_loss: 0.2262 - val_acc: 0.9420\n",
      "Epoch 341/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2858 - acc: 0.9115 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 342/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2748 - acc: 0.9163 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 343/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2878 - acc: 0.9137 - val_loss: 0.2260 - val_acc: 0.9420\n",
      "Epoch 344/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2999 - acc: 0.9107 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 345/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2896 - acc: 0.9152 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 346/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2913 - acc: 0.9137 - val_loss: 0.2255 - val_acc: 0.9427\n",
      "Epoch 347/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2882 - acc: 0.9111 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 348/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2997 - acc: 0.9100 - val_loss: 0.2213 - val_acc: 0.9427\n",
      "Epoch 349/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2867 - acc: 0.9156 - val_loss: 0.2262 - val_acc: 0.9420\n",
      "Epoch 350/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2899 - acc: 0.9111 - val_loss: 0.2259 - val_acc: 0.9420\n",
      "Epoch 351/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2824 - acc: 0.9148 - val_loss: 0.2259 - val_acc: 0.9420\n",
      "Epoch 352/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3036 - acc: 0.9074 - val_loss: 0.2263 - val_acc: 0.9420\n",
      "Epoch 353/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2927 - acc: 0.9170 - val_loss: 0.2262 - val_acc: 0.9420\n",
      "Epoch 354/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2932 - acc: 0.9126 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 355/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2956 - acc: 0.9103 - val_loss: 0.2263 - val_acc: 0.9420\n",
      "Epoch 356/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2889 - acc: 0.9129 - val_loss: 0.2176 - val_acc: 0.9427\n",
      "Epoch 357/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2898 - acc: 0.9144 - val_loss: 0.2261 - val_acc: 0.9420\n",
      "Epoch 358/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2840 - acc: 0.9085 - val_loss: 0.2261 - val_acc: 0.9420\n",
      "Epoch 359/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2902 - acc: 0.9129 - val_loss: 0.2263 - val_acc: 0.9420\n",
      "Epoch 360/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2970 - acc: 0.9156 - val_loss: 0.2262 - val_acc: 0.9420\n",
      "Epoch 361/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2760 - acc: 0.9234 - val_loss: 0.2260 - val_acc: 0.9420\n",
      "Epoch 362/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2943 - acc: 0.9118 - val_loss: 0.2260 - val_acc: 0.9420\n",
      "Epoch 363/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2893 - acc: 0.9141 - val_loss: 0.2262 - val_acc: 0.9420\n",
      "Epoch 364/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2823 - acc: 0.9156 - val_loss: 0.2263 - val_acc: 0.9420\n",
      "Epoch 365/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2912 - acc: 0.9115 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00365: loss improved from inf to 0.29115, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-0-000365-0.291150-0.941964.hdf5\n",
      "Epoch 366/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2962 - acc: 0.9118 - val_loss: 0.2252 - val_acc: 0.9427\n",
      "Epoch 367/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2701 - acc: 0.9178 - val_loss: 0.2254 - val_acc: 0.9427\n",
      "Epoch 368/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2821 - acc: 0.9193 - val_loss: 0.2241 - val_acc: 0.9427\n",
      "Epoch 369/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2894 - acc: 0.9126 - val_loss: 0.2247 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00369: loss improved from 0.29115 to 0.28943, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-0-000369-0.289429-0.942708.hdf5\n",
      "Epoch 370/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2867 - acc: 0.9137 - val_loss: 0.2257 - val_acc: 0.9420\n",
      "Epoch 371/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2857 - acc: 0.9174 - val_loss: 0.2263 - val_acc: 0.9420\n",
      "Epoch 372/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2997 - acc: 0.9115 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 373/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.2882 - acc: 0.9182 - val_loss: 0.2262 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00373: loss improved from 0.28943 to 0.28819, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-0-000373-0.288195-0.941964.hdf5\n",
      "Epoch 374/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2876 - acc: 0.9196 - val_loss: 0.2262 - val_acc: 0.9420\n",
      "Epoch 375/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2775 - acc: 0.9152 - val_loss: 0.2252 - val_acc: 0.9427\n",
      "Epoch 376/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2834 - acc: 0.9126 - val_loss: 0.2262 - val_acc: 0.9420\n",
      "Epoch 377/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2849 - acc: 0.9129 - val_loss: 0.2248 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00377: loss improved from 0.28819 to 0.28494, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-0-000377-0.284937-0.942708.hdf5\n",
      "Epoch 378/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2708 - acc: 0.9163 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 379/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2847 - acc: 0.9152 - val_loss: 0.2261 - val_acc: 0.9420\n",
      "Epoch 380/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2806 - acc: 0.9170 - val_loss: 0.2262 - val_acc: 0.9420\n",
      "Epoch 381/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2824 - acc: 0.9126 - val_loss: 0.2263 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00381: loss improved from 0.28494 to 0.28244, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-0-000381-0.282444-0.941964.hdf5\n",
      "Epoch 382/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2843 - acc: 0.9182 - val_loss: 0.2179 - val_acc: 0.9435\n",
      "Epoch 383/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2794 - acc: 0.9167 - val_loss: 0.2261 - val_acc: 0.9420\n",
      "Epoch 384/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2814 - acc: 0.9159 - val_loss: 0.2254 - val_acc: 0.9420\n",
      "Epoch 385/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2750 - acc: 0.9189 - val_loss: 0.2256 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00385: loss improved from 0.28244 to 0.27505, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-0-000385-0.275049-0.942708.hdf5\n",
      "Epoch 386/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2826 - acc: 0.9126 - val_loss: 0.2263 - val_acc: 0.9420\n",
      "Epoch 387/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2959 - acc: 0.9156 - val_loss: 0.2261 - val_acc: 0.9420\n",
      "Epoch 388/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2894 - acc: 0.9174 - val_loss: 0.2262 - val_acc: 0.9420\n",
      "Epoch 389/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2954 - acc: 0.9141 - val_loss: 0.2243 - val_acc: 0.9427\n",
      "Epoch 390/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2971 - acc: 0.9059 - val_loss: 0.2263 - val_acc: 0.9420\n",
      "Epoch 391/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3069 - acc: 0.9111 - val_loss: 0.2259 - val_acc: 0.9420\n",
      "Epoch 392/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2869 - acc: 0.9208 - val_loss: 0.2261 - val_acc: 0.9420\n",
      "Epoch 393/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2955 - acc: 0.9100 - val_loss: 0.2260 - val_acc: 0.9420\n",
      "Epoch 394/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2954 - acc: 0.9111 - val_loss: 0.2262 - val_acc: 0.9420\n",
      "Epoch 395/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2885 - acc: 0.9156 - val_loss: 0.2262 - val_acc: 0.9420\n",
      "Epoch 396/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2906 - acc: 0.9163 - val_loss: 0.2261 - val_acc: 0.9420\n",
      "Epoch 397/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2890 - acc: 0.9126 - val_loss: 0.2263 - val_acc: 0.9420\n",
      "Epoch 398/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2854 - acc: 0.9159 - val_loss: 0.2261 - val_acc: 0.9420\n",
      "Epoch 399/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2859 - acc: 0.9156 - val_loss: 0.2206 - val_acc: 0.9427\n",
      "Epoch 400/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2840 - acc: 0.9115 - val_loss: 0.2258 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00400: saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/0-000400-0.284014-0.941964.hdf5\n",
      "Epoch 401/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2827 - acc: 0.9107 - val_loss: 0.2260 - val_acc: 0.9420\n",
      "Epoch 402/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2901 - acc: 0.9126 - val_loss: 0.2262 - val_acc: 0.9420\n",
      "Epoch 403/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2731 - acc: 0.9222 - val_loss: 0.2261 - val_acc: 0.9420\n",
      "Epoch 404/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2868 - acc: 0.9163 - val_loss: 0.2202 - val_acc: 0.9435\n",
      "Epoch 405/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2814 - acc: 0.9137 - val_loss: 0.2250 - val_acc: 0.9427\n",
      "Epoch 406/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2886 - acc: 0.9137 - val_loss: 0.2252 - val_acc: 0.9427\n",
      "Epoch 407/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3053 - acc: 0.9066 - val_loss: 0.2251 - val_acc: 0.9427\n",
      "Epoch 408/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2889 - acc: 0.9111 - val_loss: 0.2250 - val_acc: 0.9427\n",
      "Epoch 409/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2853 - acc: 0.9159 - val_loss: 0.2259 - val_acc: 0.9420\n",
      "Epoch 410/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2922 - acc: 0.9204 - val_loss: 0.2258 - val_acc: 0.9420\n",
      "Epoch 411/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2828 - acc: 0.9144 - val_loss: 0.2255 - val_acc: 0.9427\n",
      "Epoch 412/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2983 - acc: 0.9103 - val_loss: 0.2261 - val_acc: 0.9420\n",
      "Epoch 413/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2932 - acc: 0.9152 - val_loss: 0.2263 - val_acc: 0.9420\n",
      "Epoch 414/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2838 - acc: 0.9144 - val_loss: 0.2262 - val_acc: 0.9420\n",
      "Epoch 415/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2745 - acc: 0.9182 - val_loss: 0.2261 - val_acc: 0.9420\n",
      "Epoch 416/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2781 - acc: 0.9185 - val_loss: 0.2262 - val_acc: 0.9420\n",
      "Epoch 417/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2995 - acc: 0.9144 - val_loss: 0.2240 - val_acc: 0.9427\n",
      "Epoch 418/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2857 - acc: 0.9163 - val_loss: 0.2246 - val_acc: 0.9427\n",
      "Epoch 419/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3015 - acc: 0.9133 - val_loss: 0.2260 - val_acc: 0.9420\n",
      "Epoch 420/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2931 - acc: 0.9156 - val_loss: 0.2260 - val_acc: 0.9420\n",
      "Epoch 421/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2784 - acc: 0.9170 - val_loss: 0.2239 - val_acc: 0.9427\n",
      "Epoch 422/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2729 - acc: 0.9137 - val_loss: 0.2182 - val_acc: 0.9427\n",
      "Epoch 423/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2897 - acc: 0.9159 - val_loss: 0.2235 - val_acc: 0.9427\n",
      "Epoch 424/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2780 - acc: 0.9174 - val_loss: 0.2262 - val_acc: 0.9420\n",
      "Epoch 425/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2709 - acc: 0.9234 - val_loss: 0.2254 - val_acc: 0.9420\n",
      "Epoch 426/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2785 - acc: 0.9174 - val_loss: 0.2262 - val_acc: 0.9420\n",
      "Epoch 427/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2760 - acc: 0.9226 - val_loss: 0.2262 - val_acc: 0.9420\n",
      "Epoch 428/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2965 - acc: 0.9144 - val_loss: 0.2262 - val_acc: 0.9420\n",
      "Epoch 429/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2988 - acc: 0.9096 - val_loss: 0.2262 - val_acc: 0.9420\n",
      "Epoch 430/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2962 - acc: 0.9118 - val_loss: 0.2255 - val_acc: 0.9420\n",
      "Epoch 431/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2801 - acc: 0.9156 - val_loss: 0.2250 - val_acc: 0.9427\n",
      "Epoch 432/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2869 - acc: 0.9148 - val_loss: 0.2243 - val_acc: 0.9427\n",
      "Epoch 433/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2824 - acc: 0.9185 - val_loss: 0.2259 - val_acc: 0.9420\n",
      "Epoch 00433: early stopping\n",
      "ModelCheckpoint 已经保存到 ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/0-final.hdf5\n",
      "Create subdir directory: ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/log...\n",
      "save in: ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/log/20220201_2000_64_1_3_1.csv\n",
      "time: 0:11:36 s\n",
      "time: 696.0 s\n",
      "average 0.696000 s\n",
      "0 epoch finished\n",
      "--------------------   best   --------------------\n",
      "no_activities: 10\n",
      "\n",
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1349/1349 [==============================] - 1s 497us/step\n",
      "0-milan:\tacc: 94.22%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [3, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 0, 3, 0, 0, 3, 0, 0, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 4, 0, 0, 0, 0, 0, 2, 7, 7, 1, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 2, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 2, 7, 7, 7, 2, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 3, 9, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7, 7, 2, 2, 7, 2, 2, 7, 7, 2, 2, 7, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 0, 7, 3, 0, 3, 7, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.968454  0.985554  0.976929       623\n",
      "         Work   0.941176  0.615385  0.744186        26\n",
      "Take_medicine   0.692308  0.450000  0.545455        20\n",
      "        Sleep   0.794118  0.843750  0.818182        32\n",
      "        Relax   0.986207  1.000000  0.993056       143\n",
      "   Leave_Home   0.971831  0.971831  0.971831        71\n",
      "          Eat   0.000000  0.000000  0.000000         7\n",
      "         Cook   0.923858  0.983784  0.952880       185\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        30\n",
      "      Bathing   0.886555  0.995283  0.937778       212\n",
      "\n",
      "     accuracy                       0.942179      1349\n",
      "    macro avg   0.716451  0.684559  0.694030      1349\n",
      " weighted avg   0.916209  0.942179  0.927476      1349\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  26   0   0   3   0   1]\n",
      " [  0  16   0   1   0   1   0   6   0   2]\n",
      " [  0   0   0   0   0   0   0   6   1   0]\n",
      " [  0   1   0   9   0  10   0   0   0   0]\n",
      " [  0   0   0   0 211   0   0   1   0   0]\n",
      " [  0   0   0   3   0 182   0   0   0   0]\n",
      " [  0   0   0   0   0   0  69   1   1   0]\n",
      " [  0   0   0   0   1   2   2 614   0   4]\n",
      " [  0   0   0   0   0   0   0   0 143   0]\n",
      " [  0   0   0   0   0   2   0   3   0  27]]\n",
      "--------------------   final   --------------------\n",
      "no_activities: 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1349/1349 [==============================] - 1s 521us/step\n",
      "0-milan:\tacc: 94.22%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [3, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 0, 3, 0, 0, 3, 0, 0, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 4, 0, 0, 0, 0, 0, 2, 7, 7, 1, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 2, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 2, 7, 7, 7, 2, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 3, 9, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7, 7, 2, 2, 7, 2, 2, 7, 7, 2, 2, 7, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 0, 7, 3, 0, 3, 7, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.968454  0.985554  0.976929       623\n",
      "         Work   0.941176  0.615385  0.744186        26\n",
      "Take_medicine   0.692308  0.450000  0.545455        20\n",
      "        Sleep   0.794118  0.843750  0.818182        32\n",
      "        Relax   0.986207  1.000000  0.993056       143\n",
      "   Leave_Home   0.971831  0.971831  0.971831        71\n",
      "          Eat   0.000000  0.000000  0.000000         7\n",
      "         Cook   0.923858  0.983784  0.952880       185\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        30\n",
      "      Bathing   0.886555  0.995283  0.937778       212\n",
      "\n",
      "     accuracy                       0.942179      1349\n",
      "    macro avg   0.716451  0.684559  0.694030      1349\n",
      " weighted avg   0.916209  0.942179  0.927476      1349\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  26   0   0   3   0   1]\n",
      " [  0  16   0   1   0   1   0   6   0   2]\n",
      " [  0   0   0   0   0   0   0   6   1   0]\n",
      " [  0   1   0   9   0  10   0   0   0   0]\n",
      " [  0   0   0   0 211   0   0   1   0   0]\n",
      " [  0   0   0   3   0 182   0   0   0   0]\n",
      " [  0   0   0   0   0   0  69   1   1   0]\n",
      " [  0   0   0   0   1   2   2 614   0   4]\n",
      " [  0   0   0   0   0   0   0   0 143   0]\n",
      " [  0   0   0   0   0   2   0   3   0  27]]\n",
      "no_activities: 10\n",
      "\n",
      "Begin training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "42/42 [==============================] - 3s 66ms/step - loss: 1.4065 - acc: 0.5882 - val_loss: 0.8733 - val_acc: 0.7388\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9242 - acc: 0.7347 - val_loss: 0.6743 - val_acc: 0.8445\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7560 - acc: 0.7839 - val_loss: 0.5641 - val_acc: 0.8445\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6752 - acc: 0.8010 - val_loss: 0.5076 - val_acc: 0.8408\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.5898 - acc: 0.8132 - val_loss: 0.4652 - val_acc: 0.8423\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.5835 - acc: 0.8170 - val_loss: 0.4388 - val_acc: 0.8750\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.5474 - acc: 0.8274 - val_loss: 0.4203 - val_acc: 0.8735\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.5060 - acc: 0.8411 - val_loss: 0.3983 - val_acc: 0.8914\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.4864 - acc: 0.8527 - val_loss: 0.3805 - val_acc: 0.9129\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.4606 - acc: 0.8545 - val_loss: 0.3676 - val_acc: 0.9159\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.4484 - acc: 0.8590 - val_loss: 0.3581 - val_acc: 0.9159\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.4267 - acc: 0.8676 - val_loss: 0.3477 - val_acc: 0.9167\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.4321 - acc: 0.8720 - val_loss: 0.3416 - val_acc: 0.9182\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.4215 - acc: 0.8746 - val_loss: 0.3284 - val_acc: 0.9182\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.4082 - acc: 0.8772 - val_loss: 0.3251 - val_acc: 0.9271\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.4003 - acc: 0.8806 - val_loss: 0.3189 - val_acc: 0.9271\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3989 - acc: 0.8824 - val_loss: 0.3118 - val_acc: 0.9345\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3865 - acc: 0.8836 - val_loss: 0.3040 - val_acc: 0.9345\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3716 - acc: 0.8884 - val_loss: 0.3010 - val_acc: 0.9345\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3723 - acc: 0.8873 - val_loss: 0.2968 - val_acc: 0.9338\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3584 - acc: 0.8917 - val_loss: 0.2922 - val_acc: 0.9412\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3673 - acc: 0.8943 - val_loss: 0.2889 - val_acc: 0.9412\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3531 - acc: 0.8992 - val_loss: 0.2859 - val_acc: 0.9412\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3394 - acc: 0.9007 - val_loss: 0.2830 - val_acc: 0.9412\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3524 - acc: 0.8966 - val_loss: 0.2781 - val_acc: 0.9420\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3517 - acc: 0.8981 - val_loss: 0.2751 - val_acc: 0.9420\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3481 - acc: 0.8947 - val_loss: 0.2724 - val_acc: 0.9420\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3323 - acc: 0.9014 - val_loss: 0.2698 - val_acc: 0.9420\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3333 - acc: 0.9051 - val_loss: 0.2673 - val_acc: 0.9420\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3311 - acc: 0.9029 - val_loss: 0.2635 - val_acc: 0.9427\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3321 - acc: 0.8992 - val_loss: 0.2627 - val_acc: 0.9420\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3205 - acc: 0.9066 - val_loss: 0.2613 - val_acc: 0.9420\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3167 - acc: 0.9044 - val_loss: 0.2610 - val_acc: 0.9427\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3274 - acc: 0.9089 - val_loss: 0.2595 - val_acc: 0.9427\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3304 - acc: 0.9007 - val_loss: 0.2571 - val_acc: 0.9427\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3031 - acc: 0.9092 - val_loss: 0.2554 - val_acc: 0.9420\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3286 - acc: 0.9010 - val_loss: 0.2537 - val_acc: 0.9427\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3139 - acc: 0.9040 - val_loss: 0.2493 - val_acc: 0.9442\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3183 - acc: 0.9014 - val_loss: 0.2524 - val_acc: 0.9442\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3060 - acc: 0.9051 - val_loss: 0.2505 - val_acc: 0.9427\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3143 - acc: 0.9029 - val_loss: 0.2506 - val_acc: 0.9435\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2921 - acc: 0.9074 - val_loss: 0.2493 - val_acc: 0.9442\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3019 - acc: 0.9059 - val_loss: 0.2488 - val_acc: 0.9442\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2930 - acc: 0.9137 - val_loss: 0.2475 - val_acc: 0.9449\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3048 - acc: 0.9051 - val_loss: 0.2485 - val_acc: 0.9442\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3040 - acc: 0.9092 - val_loss: 0.2481 - val_acc: 0.9442\n",
      "Epoch 47/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2891 - acc: 0.9126 - val_loss: 0.2470 - val_acc: 0.9442\n",
      "Epoch 48/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2930 - acc: 0.9100 - val_loss: 0.2459 - val_acc: 0.9442\n",
      "Epoch 49/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3122 - acc: 0.9014 - val_loss: 0.2463 - val_acc: 0.9442\n",
      "Epoch 50/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2868 - acc: 0.9167 - val_loss: 0.2442 - val_acc: 0.9442\n",
      "Epoch 51/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2913 - acc: 0.9133 - val_loss: 0.2442 - val_acc: 0.9442\n",
      "Epoch 52/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2980 - acc: 0.9081 - val_loss: 0.2437 - val_acc: 0.9449\n",
      "Epoch 53/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2896 - acc: 0.9074 - val_loss: 0.2442 - val_acc: 0.9449\n",
      "Epoch 54/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2869 - acc: 0.9148 - val_loss: 0.2442 - val_acc: 0.9442\n",
      "Epoch 55/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2862 - acc: 0.9133 - val_loss: 0.2423 - val_acc: 0.9457\n",
      "Epoch 56/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2930 - acc: 0.9133 - val_loss: 0.2430 - val_acc: 0.9435\n",
      "Epoch 57/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2937 - acc: 0.9089 - val_loss: 0.2435 - val_acc: 0.9435\n",
      "Epoch 58/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2939 - acc: 0.9092 - val_loss: 0.2442 - val_acc: 0.9435\n",
      "Epoch 59/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3009 - acc: 0.9074 - val_loss: 0.2434 - val_acc: 0.9442\n",
      "Epoch 60/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2806 - acc: 0.9111 - val_loss: 0.2427 - val_acc: 0.9442\n",
      "Epoch 61/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2892 - acc: 0.9111 - val_loss: 0.2421 - val_acc: 0.9442\n",
      "Epoch 62/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2863 - acc: 0.9051 - val_loss: 0.2428 - val_acc: 0.9442\n",
      "Epoch 63/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2824 - acc: 0.9137 - val_loss: 0.2428 - val_acc: 0.9442\n",
      "Epoch 64/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2915 - acc: 0.9092 - val_loss: 0.2437 - val_acc: 0.9442\n",
      "Epoch 65/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2858 - acc: 0.9152 - val_loss: 0.2406 - val_acc: 0.9449\n",
      "\n",
      "Epoch 00065: loss improved from inf to 0.28583, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-1-000065-0.285833-0.944940.hdf5\n",
      "Epoch 66/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2861 - acc: 0.9137 - val_loss: 0.2410 - val_acc: 0.9442\n",
      "Epoch 67/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2918 - acc: 0.9107 - val_loss: 0.2419 - val_acc: 0.9442\n",
      "Epoch 68/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2757 - acc: 0.9129 - val_loss: 0.2415 - val_acc: 0.9442\n",
      "Epoch 69/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2826 - acc: 0.9115 - val_loss: 0.2427 - val_acc: 0.9442\n",
      "\n",
      "Epoch 00069: loss improved from 0.28583 to 0.28261, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-1-000069-0.282606-0.944196.hdf5\n",
      "Epoch 70/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2919 - acc: 0.9055 - val_loss: 0.2423 - val_acc: 0.9442\n",
      "Epoch 71/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2787 - acc: 0.9122 - val_loss: 0.2432 - val_acc: 0.9442\n",
      "Epoch 72/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2793 - acc: 0.9141 - val_loss: 0.2416 - val_acc: 0.9442\n",
      "Epoch 73/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2795 - acc: 0.9092 - val_loss: 0.2411 - val_acc: 0.9442\n",
      "\n",
      "Epoch 00073: loss improved from 0.28261 to 0.27945, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-1-000073-0.279452-0.944196.hdf5\n",
      "Epoch 74/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2756 - acc: 0.9111 - val_loss: 0.2387 - val_acc: 0.9449\n",
      "Epoch 75/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2792 - acc: 0.9122 - val_loss: 0.2378 - val_acc: 0.9449\n",
      "Epoch 76/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2698 - acc: 0.9170 - val_loss: 0.2376 - val_acc: 0.9457\n",
      "Epoch 77/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2728 - acc: 0.9137 - val_loss: 0.2399 - val_acc: 0.9442\n",
      "\n",
      "Epoch 00077: loss improved from 0.27945 to 0.27281, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-1-000077-0.272808-0.944196.hdf5\n",
      "Epoch 78/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2646 - acc: 0.9193 - val_loss: 0.2391 - val_acc: 0.9449\n",
      "Epoch 79/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2683 - acc: 0.9144 - val_loss: 0.2371 - val_acc: 0.9449\n",
      "Epoch 80/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2706 - acc: 0.9122 - val_loss: 0.2382 - val_acc: 0.9442\n",
      "Epoch 81/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2916 - acc: 0.9092 - val_loss: 0.2394 - val_acc: 0.9442\n",
      "Epoch 82/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2747 - acc: 0.9152 - val_loss: 0.2388 - val_acc: 0.9442\n",
      "Epoch 83/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2680 - acc: 0.9148 - val_loss: 0.2392 - val_acc: 0.9442\n",
      "Epoch 84/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2800 - acc: 0.9141 - val_loss: 0.2383 - val_acc: 0.9449\n",
      "Epoch 85/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2697 - acc: 0.9148 - val_loss: 0.2398 - val_acc: 0.9442\n",
      "\n",
      "Epoch 00085: loss improved from 0.27281 to 0.26970, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-1-000085-0.269704-0.944196.hdf5\n",
      "Epoch 86/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2795 - acc: 0.9137 - val_loss: 0.2407 - val_acc: 0.9442\n",
      "Epoch 87/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2697 - acc: 0.9152 - val_loss: 0.2388 - val_acc: 0.9442\n",
      "Epoch 88/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2701 - acc: 0.9126 - val_loss: 0.2392 - val_acc: 0.9435\n",
      "Epoch 89/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2627 - acc: 0.9148 - val_loss: 0.2379 - val_acc: 0.9442\n",
      "\n",
      "Epoch 00089: loss improved from 0.26970 to 0.26271, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-1-000089-0.262706-0.944196.hdf5\n",
      "Epoch 90/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2782 - acc: 0.9141 - val_loss: 0.2390 - val_acc: 0.9442\n",
      "Epoch 91/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2676 - acc: 0.9159 - val_loss: 0.2393 - val_acc: 0.9442\n",
      "Epoch 92/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2667 - acc: 0.9167 - val_loss: 0.2357 - val_acc: 0.9449\n",
      "Epoch 93/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2732 - acc: 0.9133 - val_loss: 0.2358 - val_acc: 0.9442\n",
      "Epoch 94/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2674 - acc: 0.9115 - val_loss: 0.2333 - val_acc: 0.9449\n",
      "Epoch 95/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2689 - acc: 0.9189 - val_loss: 0.2373 - val_acc: 0.9442\n",
      "Epoch 96/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2588 - acc: 0.9170 - val_loss: 0.2352 - val_acc: 0.9449\n",
      "Epoch 97/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2588 - acc: 0.9167 - val_loss: 0.2363 - val_acc: 0.9442\n",
      "\n",
      "Epoch 00097: loss improved from 0.26271 to 0.25878, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-1-000097-0.258783-0.944196.hdf5\n",
      "Epoch 98/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2646 - acc: 0.9115 - val_loss: 0.2354 - val_acc: 0.9457\n",
      "Epoch 99/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2735 - acc: 0.9129 - val_loss: 0.2320 - val_acc: 0.9457\n",
      "Epoch 100/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2672 - acc: 0.9170 - val_loss: 0.2372 - val_acc: 0.9449\n",
      "\n",
      "Epoch 00100: saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/1-000100-0.267158-0.944940.hdf5\n",
      "Epoch 101/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2673 - acc: 0.9163 - val_loss: 0.2366 - val_acc: 0.9442\n",
      "Epoch 102/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2650 - acc: 0.9122 - val_loss: 0.2361 - val_acc: 0.9442\n",
      "Epoch 103/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2611 - acc: 0.9174 - val_loss: 0.2384 - val_acc: 0.9435\n",
      "Epoch 104/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2583 - acc: 0.9129 - val_loss: 0.2369 - val_acc: 0.9442\n",
      "Epoch 105/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2719 - acc: 0.9111 - val_loss: 0.2382 - val_acc: 0.9442\n",
      "Epoch 106/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2611 - acc: 0.9144 - val_loss: 0.2369 - val_acc: 0.9442\n",
      "Epoch 107/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2566 - acc: 0.9148 - val_loss: 0.2372 - val_acc: 0.9412\n",
      "Epoch 108/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2631 - acc: 0.9196 - val_loss: 0.2378 - val_acc: 0.9405\n",
      "Epoch 109/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2566 - acc: 0.9222 - val_loss: 0.2333 - val_acc: 0.9457\n",
      "Epoch 110/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2722 - acc: 0.9163 - val_loss: 0.2366 - val_acc: 0.9405\n",
      "Epoch 111/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2658 - acc: 0.9174 - val_loss: 0.2371 - val_acc: 0.9405\n",
      "Epoch 112/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2538 - acc: 0.9208 - val_loss: 0.2363 - val_acc: 0.9412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2715 - acc: 0.9115 - val_loss: 0.2356 - val_acc: 0.9412\n",
      "Epoch 114/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2528 - acc: 0.9230 - val_loss: 0.2348 - val_acc: 0.9420\n",
      "Epoch 115/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2528 - acc: 0.9189 - val_loss: 0.2343 - val_acc: 0.9412\n",
      "Epoch 116/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2645 - acc: 0.9204 - val_loss: 0.2331 - val_acc: 0.9420\n",
      "Epoch 117/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2639 - acc: 0.9159 - val_loss: 0.2351 - val_acc: 0.9412\n",
      "Epoch 118/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2695 - acc: 0.9163 - val_loss: 0.2352 - val_acc: 0.9412\n",
      "Epoch 119/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2587 - acc: 0.9159 - val_loss: 0.2345 - val_acc: 0.9412\n",
      "Epoch 120/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2631 - acc: 0.9122 - val_loss: 0.2287 - val_acc: 0.9427\n",
      "Epoch 121/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2569 - acc: 0.9167 - val_loss: 0.2343 - val_acc: 0.9412\n",
      "Epoch 122/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2542 - acc: 0.9196 - val_loss: 0.2339 - val_acc: 0.9412\n",
      "Epoch 123/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2597 - acc: 0.9167 - val_loss: 0.2340 - val_acc: 0.9412\n",
      "Epoch 124/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2497 - acc: 0.9200 - val_loss: 0.2350 - val_acc: 0.9412\n",
      "Epoch 125/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2527 - acc: 0.9200 - val_loss: 0.2361 - val_acc: 0.9412\n",
      "Epoch 126/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2547 - acc: 0.9129 - val_loss: 0.2366 - val_acc: 0.9405\n",
      "Epoch 127/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2490 - acc: 0.9237 - val_loss: 0.2362 - val_acc: 0.9405\n",
      "Epoch 128/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2569 - acc: 0.9200 - val_loss: 0.2313 - val_acc: 0.9412\n",
      "Epoch 129/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2519 - acc: 0.9200 - val_loss: 0.2358 - val_acc: 0.9405\n",
      "Epoch 130/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2674 - acc: 0.9148 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 131/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2591 - acc: 0.9185 - val_loss: 0.2361 - val_acc: 0.9405\n",
      "Epoch 132/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2524 - acc: 0.9193 - val_loss: 0.2370 - val_acc: 0.9412\n",
      "Epoch 133/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2440 - acc: 0.9211 - val_loss: 0.2360 - val_acc: 0.9420\n",
      "Epoch 134/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2516 - acc: 0.9193 - val_loss: 0.2340 - val_acc: 0.9420\n",
      "Epoch 135/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2519 - acc: 0.9211 - val_loss: 0.2357 - val_acc: 0.9412\n",
      "Epoch 136/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2526 - acc: 0.9211 - val_loss: 0.2355 - val_acc: 0.9412\n",
      "Epoch 137/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2577 - acc: 0.9133 - val_loss: 0.2349 - val_acc: 0.9412\n",
      "Epoch 138/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2536 - acc: 0.9163 - val_loss: 0.2366 - val_acc: 0.9405\n",
      "Epoch 139/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2416 - acc: 0.9222 - val_loss: 0.2350 - val_acc: 0.9405\n",
      "Epoch 140/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2550 - acc: 0.9200 - val_loss: 0.2364 - val_acc: 0.9405\n",
      "Epoch 141/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2435 - acc: 0.9193 - val_loss: 0.2358 - val_acc: 0.9405\n",
      "Epoch 142/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2551 - acc: 0.9170 - val_loss: 0.2360 - val_acc: 0.9405\n",
      "Epoch 143/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2525 - acc: 0.9170 - val_loss: 0.2368 - val_acc: 0.9405\n",
      "Epoch 144/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2571 - acc: 0.9193 - val_loss: 0.2353 - val_acc: 0.9412\n",
      "Epoch 145/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2620 - acc: 0.9118 - val_loss: 0.2364 - val_acc: 0.9405\n",
      "Epoch 146/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2413 - acc: 0.9237 - val_loss: 0.2349 - val_acc: 0.9405\n",
      "Epoch 147/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2314 - acc: 0.9208 - val_loss: 0.2343 - val_acc: 0.9405\n",
      "Epoch 148/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2586 - acc: 0.9196 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 149/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2494 - acc: 0.9185 - val_loss: 0.2343 - val_acc: 0.9405\n",
      "Epoch 150/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2346 - acc: 0.9263 - val_loss: 0.2344 - val_acc: 0.9405\n",
      "Epoch 151/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2449 - acc: 0.9249 - val_loss: 0.2355 - val_acc: 0.9405\n",
      "Epoch 152/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2568 - acc: 0.9185 - val_loss: 0.2348 - val_acc: 0.9405\n",
      "Epoch 153/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2543 - acc: 0.9170 - val_loss: 0.2346 - val_acc: 0.9405\n",
      "Epoch 154/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2468 - acc: 0.9200 - val_loss: 0.2357 - val_acc: 0.9405\n",
      "Epoch 155/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2587 - acc: 0.9189 - val_loss: 0.2310 - val_acc: 0.9412\n",
      "Epoch 156/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2516 - acc: 0.9185 - val_loss: 0.2310 - val_acc: 0.9412\n",
      "Epoch 157/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2530 - acc: 0.9167 - val_loss: 0.2242 - val_acc: 0.9412\n",
      "Epoch 158/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2415 - acc: 0.9219 - val_loss: 0.2341 - val_acc: 0.9405\n",
      "Epoch 159/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2539 - acc: 0.9208 - val_loss: 0.2322 - val_acc: 0.9412\n",
      "Epoch 160/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2411 - acc: 0.9178 - val_loss: 0.2339 - val_acc: 0.9412\n",
      "Epoch 161/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2491 - acc: 0.9159 - val_loss: 0.2347 - val_acc: 0.9412\n",
      "Epoch 162/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2543 - acc: 0.9156 - val_loss: 0.2342 - val_acc: 0.9405\n",
      "Epoch 163/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2441 - acc: 0.9267 - val_loss: 0.2338 - val_acc: 0.9405\n",
      "Epoch 164/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2456 - acc: 0.9196 - val_loss: 0.2330 - val_acc: 0.9420\n",
      "Epoch 165/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2446 - acc: 0.9219 - val_loss: 0.2353 - val_acc: 0.9405\n",
      "\n",
      "Epoch 00165: loss improved from inf to 0.24463, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-1-000165-0.244631-0.940476.hdf5\n",
      "Epoch 166/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2532 - acc: 0.9193 - val_loss: 0.2353 - val_acc: 0.9412\n",
      "Epoch 167/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2597 - acc: 0.9193 - val_loss: 0.2339 - val_acc: 0.9405\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 168/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2346 - acc: 0.9222 - val_loss: 0.2341 - val_acc: 0.9405\n",
      "Epoch 169/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2551 - acc: 0.9189 - val_loss: 0.2344 - val_acc: 0.9405\n",
      "Epoch 170/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2607 - acc: 0.9144 - val_loss: 0.2349 - val_acc: 0.9405\n",
      "Epoch 171/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2519 - acc: 0.9152 - val_loss: 0.2354 - val_acc: 0.9405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2451 - acc: 0.9219 - val_loss: 0.2349 - val_acc: 0.9405\n",
      "Epoch 173/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2459 - acc: 0.9163 - val_loss: 0.2343 - val_acc: 0.9412\n",
      "Epoch 174/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2558 - acc: 0.9122 - val_loss: 0.2353 - val_acc: 0.9405\n",
      "Epoch 175/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2613 - acc: 0.9174 - val_loss: 0.2350 - val_acc: 0.9405\n",
      "Epoch 176/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2473 - acc: 0.9193 - val_loss: 0.2348 - val_acc: 0.9405\n",
      "Epoch 177/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2445 - acc: 0.9215 - val_loss: 0.2345 - val_acc: 0.9412\n",
      "\n",
      "Epoch 00177: loss improved from 0.24463 to 0.24454, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-1-000177-0.244543-0.941220.hdf5\n",
      "Epoch 178/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2333 - acc: 0.9245 - val_loss: 0.2349 - val_acc: 0.9405\n",
      "Epoch 179/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2461 - acc: 0.9230 - val_loss: 0.2354 - val_acc: 0.9405\n",
      "Epoch 180/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2512 - acc: 0.9204 - val_loss: 0.2353 - val_acc: 0.9405\n",
      "Epoch 181/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2560 - acc: 0.9163 - val_loss: 0.2353 - val_acc: 0.9405\n",
      "Epoch 182/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2449 - acc: 0.9215 - val_loss: 0.2353 - val_acc: 0.9405\n",
      "Epoch 183/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2472 - acc: 0.9174 - val_loss: 0.2355 - val_acc: 0.9405\n",
      "Epoch 184/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2486 - acc: 0.9193 - val_loss: 0.2348 - val_acc: 0.9405\n",
      "Epoch 185/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2391 - acc: 0.9237 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "\n",
      "Epoch 00185: loss improved from 0.24454 to 0.23914, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-1-000185-0.239142-0.940476.hdf5\n",
      "Epoch 186/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2464 - acc: 0.9222 - val_loss: 0.2331 - val_acc: 0.9412\n",
      "Epoch 187/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2509 - acc: 0.9237 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "\n",
      "Epoch 00187: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 188/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2440 - acc: 0.9219 - val_loss: 0.2348 - val_acc: 0.9412\n",
      "Epoch 189/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2523 - acc: 0.9196 - val_loss: 0.2311 - val_acc: 0.9412\n",
      "Epoch 190/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2557 - acc: 0.9208 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 191/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2385 - acc: 0.9219 - val_loss: 0.2344 - val_acc: 0.9412\n",
      "Epoch 192/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2433 - acc: 0.9226 - val_loss: 0.2350 - val_acc: 0.9405\n",
      "Epoch 193/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2401 - acc: 0.9237 - val_loss: 0.2353 - val_acc: 0.9405\n",
      "Epoch 194/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2465 - acc: 0.9189 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 195/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2550 - acc: 0.9178 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 196/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2443 - acc: 0.9196 - val_loss: 0.2341 - val_acc: 0.9412\n",
      "Epoch 197/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2460 - acc: 0.9182 - val_loss: 0.2332 - val_acc: 0.9412\n",
      "Epoch 198/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2457 - acc: 0.9230 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 199/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2457 - acc: 0.9193 - val_loss: 0.2350 - val_acc: 0.9405\n",
      "Epoch 200/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2422 - acc: 0.9178 - val_loss: 0.2350 - val_acc: 0.9405\n",
      "\n",
      "Epoch 00200: saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/1-000200-0.242188-0.940476.hdf5\n",
      "Epoch 201/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2320 - acc: 0.9215 - val_loss: 0.2350 - val_acc: 0.9405\n",
      "Epoch 202/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2454 - acc: 0.9241 - val_loss: 0.2333 - val_acc: 0.9412\n",
      "Epoch 203/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2341 - acc: 0.9245 - val_loss: 0.2349 - val_acc: 0.9405\n",
      "Epoch 204/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2393 - acc: 0.9245 - val_loss: 0.2340 - val_acc: 0.9405\n",
      "Epoch 205/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2527 - acc: 0.9178 - val_loss: 0.2346 - val_acc: 0.9405\n",
      "Epoch 206/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2499 - acc: 0.9170 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 207/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2575 - acc: 0.9196 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "\n",
      "Epoch 00207: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 208/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2345 - acc: 0.9241 - val_loss: 0.2348 - val_acc: 0.9405\n",
      "Epoch 209/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2367 - acc: 0.9245 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 210/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2413 - acc: 0.9211 - val_loss: 0.2350 - val_acc: 0.9405\n",
      "Epoch 211/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2462 - acc: 0.9241 - val_loss: 0.2342 - val_acc: 0.9412\n",
      "Epoch 212/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2526 - acc: 0.9174 - val_loss: 0.2342 - val_acc: 0.9412\n",
      "Epoch 213/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2463 - acc: 0.9230 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 214/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2357 - acc: 0.9252 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 215/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2511 - acc: 0.9182 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 216/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2385 - acc: 0.9282 - val_loss: 0.2346 - val_acc: 0.9405\n",
      "Epoch 217/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2493 - acc: 0.9219 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 218/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2537 - acc: 0.9156 - val_loss: 0.2348 - val_acc: 0.9405\n",
      "Epoch 219/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2295 - acc: 0.9237 - val_loss: 0.2347 - val_acc: 0.9405\n",
      "Epoch 220/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2489 - acc: 0.9174 - val_loss: 0.2349 - val_acc: 0.9405\n",
      "Epoch 221/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2411 - acc: 0.9204 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 222/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2429 - acc: 0.9263 - val_loss: 0.2336 - val_acc: 0.9412\n",
      "Epoch 223/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2484 - acc: 0.9189 - val_loss: 0.2349 - val_acc: 0.9405\n",
      "Epoch 224/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2478 - acc: 0.9167 - val_loss: 0.2346 - val_acc: 0.9405\n",
      "Epoch 225/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2519 - acc: 0.9208 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 226/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2413 - acc: 0.9204 - val_loss: 0.2347 - val_acc: 0.9405\n",
      "Epoch 227/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2439 - acc: 0.9237 - val_loss: 0.2342 - val_acc: 0.9412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 228/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2307 - acc: 0.9222 - val_loss: 0.2327 - val_acc: 0.9412\n",
      "Epoch 229/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2567 - acc: 0.9174 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 230/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2390 - acc: 0.9252 - val_loss: 0.2349 - val_acc: 0.9405\n",
      "Epoch 231/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.2353 - acc: 0.9241 - val_loss: 0.2349 - val_acc: 0.9405\n",
      "Epoch 232/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2436 - acc: 0.9196 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 233/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2402 - acc: 0.9211 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 234/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2401 - acc: 0.9226 - val_loss: 0.2343 - val_acc: 0.9412\n",
      "Epoch 235/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2271 - acc: 0.9286 - val_loss: 0.2349 - val_acc: 0.9405\n",
      "Epoch 236/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2592 - acc: 0.9129 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 237/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2398 - acc: 0.9237 - val_loss: 0.2344 - val_acc: 0.9412\n",
      "Epoch 238/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2442 - acc: 0.9193 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 239/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2476 - acc: 0.9185 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 240/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2397 - acc: 0.9226 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 241/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2457 - acc: 0.9219 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 242/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2399 - acc: 0.9252 - val_loss: 0.2325 - val_acc: 0.9412\n",
      "Epoch 243/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2454 - acc: 0.9211 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 244/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2467 - acc: 0.9204 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 245/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2493 - acc: 0.9182 - val_loss: 0.2346 - val_acc: 0.9405\n",
      "Epoch 246/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2369 - acc: 0.9234 - val_loss: 0.2318 - val_acc: 0.9412\n",
      "Epoch 247/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2323 - acc: 0.9234 - val_loss: 0.2349 - val_acc: 0.9405\n",
      "Epoch 248/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2313 - acc: 0.9241 - val_loss: 0.2301 - val_acc: 0.9412\n",
      "Epoch 249/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2412 - acc: 0.9185 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 250/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2497 - acc: 0.9200 - val_loss: 0.2345 - val_acc: 0.9405\n",
      "Epoch 251/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2466 - acc: 0.9185 - val_loss: 0.2340 - val_acc: 0.9412\n",
      "Epoch 252/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.2365 - acc: 0.9260 - val_loss: 0.2350 - val_acc: 0.9405\n",
      "Epoch 253/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2623 - acc: 0.9122 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 254/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2424 - acc: 0.9208 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 255/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2486 - acc: 0.9159 - val_loss: 0.2333 - val_acc: 0.9412\n",
      "Epoch 256/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2455 - acc: 0.9222 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 257/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.2406 - acc: 0.9196 - val_loss: 0.2326 - val_acc: 0.9412\n",
      "Epoch 258/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.2405 - acc: 0.9200 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 259/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2436 - acc: 0.9241 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 260/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2376 - acc: 0.9196 - val_loss: 0.2349 - val_acc: 0.9405\n",
      "Epoch 261/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2387 - acc: 0.9271 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 262/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2372 - acc: 0.9208 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 263/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2597 - acc: 0.9159 - val_loss: 0.2349 - val_acc: 0.9405\n",
      "Epoch 264/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2450 - acc: 0.9237 - val_loss: 0.2330 - val_acc: 0.9420\n",
      "Epoch 265/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2339 - acc: 0.9260 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "\n",
      "Epoch 00265: loss improved from inf to 0.23394, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-1-000265-0.233939-0.940476.hdf5\n",
      "Epoch 266/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2376 - acc: 0.9170 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 267/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.2481 - acc: 0.9167 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 268/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2499 - acc: 0.9163 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 269/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2487 - acc: 0.9163 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 270/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2523 - acc: 0.9185 - val_loss: 0.2346 - val_acc: 0.9405\n",
      "Epoch 271/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2464 - acc: 0.9193 - val_loss: 0.2346 - val_acc: 0.9405\n",
      "Epoch 272/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2430 - acc: 0.9200 - val_loss: 0.2350 - val_acc: 0.9405\n",
      "Epoch 273/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2438 - acc: 0.9234 - val_loss: 0.2339 - val_acc: 0.9412\n",
      "Epoch 274/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2518 - acc: 0.9234 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 275/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2354 - acc: 0.9222 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 276/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2363 - acc: 0.9267 - val_loss: 0.2350 - val_acc: 0.9405\n",
      "Epoch 277/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2450 - acc: 0.9189 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 278/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2459 - acc: 0.9170 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 279/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2344 - acc: 0.9252 - val_loss: 0.2349 - val_acc: 0.9405\n",
      "Epoch 280/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2364 - acc: 0.9200 - val_loss: 0.2330 - val_acc: 0.9420\n",
      "Epoch 281/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2510 - acc: 0.9204 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 282/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2478 - acc: 0.9208 - val_loss: 0.2350 - val_acc: 0.9405\n",
      "Epoch 283/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2463 - acc: 0.9167 - val_loss: 0.2333 - val_acc: 0.9412\n",
      "Epoch 284/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2542 - acc: 0.9193 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 285/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2446 - acc: 0.9200 - val_loss: 0.2333 - val_acc: 0.9412\n",
      "Epoch 286/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2529 - acc: 0.9170 - val_loss: 0.2350 - val_acc: 0.9405\n",
      "Epoch 287/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2513 - acc: 0.9189 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 288/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2444 - acc: 0.9193 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 289/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2470 - acc: 0.9204 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 290/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2398 - acc: 0.9230 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 291/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2391 - acc: 0.9226 - val_loss: 0.2301 - val_acc: 0.9412\n",
      "Epoch 292/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2511 - acc: 0.9182 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 293/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2350 - acc: 0.9237 - val_loss: 0.2337 - val_acc: 0.9412\n",
      "Epoch 294/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2453 - acc: 0.9208 - val_loss: 0.2342 - val_acc: 0.9412\n",
      "Epoch 295/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2404 - acc: 0.9208 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 296/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2421 - acc: 0.9185 - val_loss: 0.2350 - val_acc: 0.9405\n",
      "Epoch 297/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2425 - acc: 0.9189 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 298/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2432 - acc: 0.9222 - val_loss: 0.2342 - val_acc: 0.9412\n",
      "Epoch 299/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2437 - acc: 0.9170 - val_loss: 0.2346 - val_acc: 0.9405\n",
      "Epoch 300/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2406 - acc: 0.9219 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "\n",
      "Epoch 00300: saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/1-000300-0.240617-0.940476.hdf5\n",
      "Epoch 301/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2450 - acc: 0.9211 - val_loss: 0.2345 - val_acc: 0.9405\n",
      "Epoch 302/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2435 - acc: 0.9230 - val_loss: 0.2228 - val_acc: 0.9412\n",
      "Epoch 303/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2368 - acc: 0.9237 - val_loss: 0.2350 - val_acc: 0.9405\n",
      "Epoch 304/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2375 - acc: 0.9193 - val_loss: 0.2349 - val_acc: 0.9405\n",
      "Epoch 305/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2374 - acc: 0.9241 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 306/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2543 - acc: 0.9178 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 307/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2550 - acc: 0.9196 - val_loss: 0.2342 - val_acc: 0.9412\n",
      "Epoch 308/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2444 - acc: 0.9215 - val_loss: 0.2343 - val_acc: 0.9412\n",
      "Epoch 309/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2428 - acc: 0.9226 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 310/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2500 - acc: 0.9193 - val_loss: 0.2349 - val_acc: 0.9405\n",
      "Epoch 311/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2459 - acc: 0.9178 - val_loss: 0.2323 - val_acc: 0.9412\n",
      "Epoch 312/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2423 - acc: 0.9204 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 313/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2471 - acc: 0.9204 - val_loss: 0.2343 - val_acc: 0.9412\n",
      "Epoch 314/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2388 - acc: 0.9249 - val_loss: 0.2295 - val_acc: 0.9412\n",
      "Epoch 315/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2503 - acc: 0.9189 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 316/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2444 - acc: 0.9204 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 317/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2555 - acc: 0.9204 - val_loss: 0.2349 - val_acc: 0.9405\n",
      "Epoch 318/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2455 - acc: 0.9185 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 319/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2562 - acc: 0.9174 - val_loss: 0.2343 - val_acc: 0.9412\n",
      "Epoch 320/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2560 - acc: 0.9204 - val_loss: 0.2336 - val_acc: 0.9412\n",
      "Epoch 321/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2417 - acc: 0.9263 - val_loss: 0.2339 - val_acc: 0.9412\n",
      "Epoch 322/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2372 - acc: 0.9215 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 323/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2421 - acc: 0.9215 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 324/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2465 - acc: 0.9215 - val_loss: 0.2348 - val_acc: 0.9405\n",
      "Epoch 325/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2458 - acc: 0.9211 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 326/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2346 - acc: 0.9234 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 327/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2417 - acc: 0.9230 - val_loss: 0.2343 - val_acc: 0.9412\n",
      "Epoch 328/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2485 - acc: 0.9141 - val_loss: 0.2343 - val_acc: 0.9412\n",
      "Epoch 329/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2515 - acc: 0.9141 - val_loss: 0.2349 - val_acc: 0.9405\n",
      "Epoch 330/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2524 - acc: 0.9159 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 331/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2356 - acc: 0.9230 - val_loss: 0.2349 - val_acc: 0.9405\n",
      "Epoch 332/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2361 - acc: 0.9208 - val_loss: 0.2349 - val_acc: 0.9405\n",
      "Epoch 333/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2446 - acc: 0.9278 - val_loss: 0.2237 - val_acc: 0.9412\n",
      "Epoch 334/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2468 - acc: 0.9193 - val_loss: 0.2350 - val_acc: 0.9405\n",
      "Epoch 335/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2444 - acc: 0.9245 - val_loss: 0.2346 - val_acc: 0.9405\n",
      "Epoch 336/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2450 - acc: 0.9245 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 337/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2380 - acc: 0.9204 - val_loss: 0.2342 - val_acc: 0.9405\n",
      "Epoch 338/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2294 - acc: 0.9267 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 339/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2345 - acc: 0.9222 - val_loss: 0.2350 - val_acc: 0.9405\n",
      "Epoch 340/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2377 - acc: 0.9204 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 341/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2691 - acc: 0.9156 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 342/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2430 - acc: 0.9215 - val_loss: 0.2349 - val_acc: 0.9405\n",
      "Epoch 343/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2516 - acc: 0.9141 - val_loss: 0.2350 - val_acc: 0.9405\n",
      "Epoch 344/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2478 - acc: 0.9189 - val_loss: 0.2330 - val_acc: 0.9412\n",
      "Epoch 345/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2473 - acc: 0.9148 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 346/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2582 - acc: 0.9174 - val_loss: 0.2341 - val_acc: 0.9412\n",
      "Epoch 347/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2449 - acc: 0.9222 - val_loss: 0.2337 - val_acc: 0.9412\n",
      "Epoch 348/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2408 - acc: 0.9211 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 349/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2416 - acc: 0.9189 - val_loss: 0.2348 - val_acc: 0.9405\n",
      "Epoch 350/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2568 - acc: 0.9204 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 351/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2441 - acc: 0.9170 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 352/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2456 - acc: 0.9196 - val_loss: 0.2342 - val_acc: 0.9412\n",
      "Epoch 353/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2504 - acc: 0.9193 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 354/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2370 - acc: 0.9211 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 355/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2459 - acc: 0.9230 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 356/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2502 - acc: 0.9196 - val_loss: 0.2350 - val_acc: 0.9405\n",
      "Epoch 357/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2426 - acc: 0.9226 - val_loss: 0.2345 - val_acc: 0.9412\n",
      "Epoch 358/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2412 - acc: 0.9282 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 359/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2441 - acc: 0.9237 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 360/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2329 - acc: 0.9245 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 361/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2483 - acc: 0.9256 - val_loss: 0.2343 - val_acc: 0.9405\n",
      "Epoch 362/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2356 - acc: 0.9275 - val_loss: 0.2350 - val_acc: 0.9405\n",
      "Epoch 363/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2358 - acc: 0.9234 - val_loss: 0.2344 - val_acc: 0.9412\n",
      "Epoch 364/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2441 - acc: 0.9204 - val_loss: 0.2349 - val_acc: 0.9405\n",
      "Epoch 365/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2458 - acc: 0.9226 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "\n",
      "Epoch 00365: loss improved from inf to 0.24576, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-1-000365-0.245757-0.940476.hdf5\n",
      "Epoch 366/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2449 - acc: 0.9241 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 367/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2472 - acc: 0.9226 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 368/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2448 - acc: 0.9200 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 369/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2348 - acc: 0.9275 - val_loss: 0.2334 - val_acc: 0.9412\n",
      "\n",
      "Epoch 00369: loss improved from 0.24576 to 0.23475, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-1-000369-0.234751-0.941220.hdf5\n",
      "Epoch 370/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2414 - acc: 0.9256 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 371/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2421 - acc: 0.9241 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 372/1000\n",
      "42/42 [==============================] - 2s 40ms/step - loss: 0.2378 - acc: 0.9215 - val_loss: 0.2353 - val_acc: 0.9405\n",
      "Epoch 373/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2491 - acc: 0.9196 - val_loss: 0.2349 - val_acc: 0.9405\n",
      "Epoch 374/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2368 - acc: 0.9226 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 375/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2496 - acc: 0.9200 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 376/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2486 - acc: 0.9189 - val_loss: 0.2348 - val_acc: 0.9405\n",
      "Epoch 377/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2432 - acc: 0.9219 - val_loss: 0.2349 - val_acc: 0.9405\n",
      "Epoch 378/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2470 - acc: 0.9185 - val_loss: 0.2350 - val_acc: 0.9405\n",
      "Epoch 379/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.2431 - acc: 0.9215 - val_loss: 0.2353 - val_acc: 0.9405\n",
      "Epoch 380/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2385 - acc: 0.9226 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 381/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2579 - acc: 0.9170 - val_loss: 0.2350 - val_acc: 0.9405\n",
      "Epoch 382/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2407 - acc: 0.9219 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 383/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2561 - acc: 0.9196 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 384/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2429 - acc: 0.9211 - val_loss: 0.2340 - val_acc: 0.9412\n",
      "Epoch 385/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2500 - acc: 0.9219 - val_loss: 0.2353 - val_acc: 0.9405\n",
      "Epoch 386/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2475 - acc: 0.9182 - val_loss: 0.2325 - val_acc: 0.9412\n",
      "Epoch 387/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2518 - acc: 0.9193 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 388/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2567 - acc: 0.9167 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 389/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2420 - acc: 0.9222 - val_loss: 0.2301 - val_acc: 0.9420\n",
      "Epoch 390/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2405 - acc: 0.9185 - val_loss: 0.2339 - val_acc: 0.9412\n",
      "Epoch 391/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2442 - acc: 0.9196 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 392/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2504 - acc: 0.9159 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 393/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2458 - acc: 0.9241 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 394/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2473 - acc: 0.9222 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 395/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2458 - acc: 0.9219 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 396/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2567 - acc: 0.9133 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 397/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2323 - acc: 0.9237 - val_loss: 0.2341 - val_acc: 0.9412\n",
      "\n",
      "Epoch 00397: loss improved from 0.23475 to 0.23230, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-1-000397-0.232295-0.941220.hdf5\n",
      "Epoch 398/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2417 - acc: 0.9215 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 399/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2381 - acc: 0.9215 - val_loss: 0.2343 - val_acc: 0.9412\n",
      "Epoch 400/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2389 - acc: 0.9196 - val_loss: 0.2350 - val_acc: 0.9405\n",
      "\n",
      "Epoch 00400: saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/1-000400-0.238927-0.940476.hdf5\n",
      "Epoch 401/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2450 - acc: 0.9204 - val_loss: 0.2351 - val_acc: 0.9405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 402/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2405 - acc: 0.9204 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 403/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2455 - acc: 0.9215 - val_loss: 0.2350 - val_acc: 0.9405\n",
      "Epoch 404/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2325 - acc: 0.9286 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 405/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2599 - acc: 0.9122 - val_loss: 0.2349 - val_acc: 0.9405\n",
      "Epoch 406/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2448 - acc: 0.9204 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 407/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2517 - acc: 0.9219 - val_loss: 0.2349 - val_acc: 0.9405\n",
      "Epoch 408/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2497 - acc: 0.9178 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 409/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2398 - acc: 0.9167 - val_loss: 0.2349 - val_acc: 0.9405\n",
      "Epoch 410/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2472 - acc: 0.9189 - val_loss: 0.2353 - val_acc: 0.9405\n",
      "Epoch 411/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2476 - acc: 0.9215 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 412/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2470 - acc: 0.9178 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 413/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2456 - acc: 0.9234 - val_loss: 0.2333 - val_acc: 0.9412\n",
      "Epoch 414/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2386 - acc: 0.9263 - val_loss: 0.2350 - val_acc: 0.9405\n",
      "Epoch 415/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2421 - acc: 0.9189 - val_loss: 0.2353 - val_acc: 0.9405\n",
      "Epoch 416/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2432 - acc: 0.9219 - val_loss: 0.2344 - val_acc: 0.9412\n",
      "Epoch 417/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2483 - acc: 0.9163 - val_loss: 0.2353 - val_acc: 0.9405\n",
      "Epoch 418/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2386 - acc: 0.9267 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 419/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2349 - acc: 0.9222 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 420/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2422 - acc: 0.9215 - val_loss: 0.2353 - val_acc: 0.9405\n",
      "Epoch 421/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2458 - acc: 0.9234 - val_loss: 0.2347 - val_acc: 0.9405\n",
      "Epoch 422/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2419 - acc: 0.9260 - val_loss: 0.2352 - val_acc: 0.9405\n",
      "Epoch 423/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2446 - acc: 0.9167 - val_loss: 0.2350 - val_acc: 0.9405\n",
      "Epoch 424/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2421 - acc: 0.9185 - val_loss: 0.2349 - val_acc: 0.9405\n",
      "Epoch 425/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2327 - acc: 0.9245 - val_loss: 0.2347 - val_acc: 0.9405\n",
      "Epoch 426/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2493 - acc: 0.9193 - val_loss: 0.2353 - val_acc: 0.9405\n",
      "Epoch 427/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2342 - acc: 0.9237 - val_loss: 0.2347 - val_acc: 0.9405\n",
      "Epoch 428/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2386 - acc: 0.9267 - val_loss: 0.2345 - val_acc: 0.9405\n",
      "Epoch 429/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2537 - acc: 0.9148 - val_loss: 0.2319 - val_acc: 0.9427\n",
      "Epoch 430/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2309 - acc: 0.9304 - val_loss: 0.2340 - val_acc: 0.9412\n",
      "Epoch 431/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2410 - acc: 0.9208 - val_loss: 0.2346 - val_acc: 0.9405\n",
      "Epoch 432/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2486 - acc: 0.9241 - val_loss: 0.2338 - val_acc: 0.9412\n",
      "Epoch 433/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2408 - acc: 0.9237 - val_loss: 0.2353 - val_acc: 0.9405\n",
      "Epoch 434/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2506 - acc: 0.9196 - val_loss: 0.2351 - val_acc: 0.9405\n",
      "Epoch 435/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2452 - acc: 0.9215 - val_loss: 0.2343 - val_acc: 0.9412\n",
      "Epoch 00435: early stopping\n",
      "ModelCheckpoint 已经保存到 ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/1-final.hdf5\n",
      "save in: ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/log/20220201_2000_64_1_3_1.csv\n",
      "time: 0:11:39 s\n",
      "time: 699.0 s\n",
      "average 0.699000 s\n",
      "1 epoch finished\n",
      "--------------------   best   --------------------\n",
      "no_activities: 10\n",
      "\n",
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1348/1348 [==============================] - 1s 573us/step\n",
      "1-milan:\tacc: 94.07%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [0, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 0, 0, 7, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 5, 7, 7, 7, 0, 7, 5, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 2, 7, 4, 2, 7, 7, 2, 2, 7, 7, 0, 7, 7, 7, 7, 7, 7, 2, 7, 7, 7, 2, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 2, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 2, 7, 7, 7, 7, 7, 7, 7, 2, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 2, 7, 7, 7, 7, 7, 7, 7, 7, 2, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 2, 2, 7, 2, 7, 2, 2, 7, 7, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 5, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.982172  0.972713  0.977419       623\n",
      "         Work   0.950000  0.760000  0.844444        25\n",
      "Take_medicine   0.533333  0.800000  0.640000        20\n",
      "        Sleep   0.969697  1.000000  0.984615        32\n",
      "        Relax   0.979167  0.992958  0.986014       142\n",
      "   Leave_Home   0.923077  1.000000  0.960000        72\n",
      "          Eat   0.000000  0.000000  0.000000         8\n",
      "         Cook   0.924324  0.929348  0.926829       184\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        30\n",
      "      Bathing   0.875519  0.995283  0.931567       212\n",
      "\n",
      "     accuracy                       0.940653      1348\n",
      "    macro avg   0.713729  0.745030  0.725089      1348\n",
      " weighted avg   0.918790  0.940653  0.928423      1348\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  26   0   0   4   0   0]\n",
      " [  0  19   0   0   0   3   0   3   0   0]\n",
      " [  0   0   0   0   0   4   2   1   1   0]\n",
      " [  0   0   0  16   0   4   0   0   0   0]\n",
      " [  0   0   0   0 211   0   0   1   0   0]\n",
      " [  0   0   0  11   0 171   0   1   1   0]\n",
      " [  0   0   0   0   0   0  72   0   0   0]\n",
      " [  0   1   0   3   4   3   4 606   1   1]\n",
      " [  0   0   0   0   0   0   0   1 141   0]\n",
      " [  0   0   0   0   0   0   0   0   0  32]]\n",
      "--------------------   final   --------------------\n",
      "no_activities: 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1348/1348 [==============================] - 1s 590us/step\n",
      "1-milan:\tacc: 94.07%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [0, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 0, 0, 7, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 5, 7, 7, 7, 0, 7, 5, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 2, 7, 4, 2, 7, 7, 2, 2, 7, 7, 0, 7, 7, 7, 7, 7, 7, 2, 7, 7, 7, 2, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 2, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 2, 7, 7, 7, 7, 7, 7, 7, 2, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 2, 7, 7, 7, 7, 7, 7, 7, 7, 2, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 2, 2, 7, 2, 7, 2, 2, 7, 7, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 5, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.982172  0.972713  0.977419       623\n",
      "         Work   0.950000  0.760000  0.844444        25\n",
      "Take_medicine   0.533333  0.800000  0.640000        20\n",
      "        Sleep   0.969697  1.000000  0.984615        32\n",
      "        Relax   0.979167  0.992958  0.986014       142\n",
      "   Leave_Home   0.923077  1.000000  0.960000        72\n",
      "          Eat   0.000000  0.000000  0.000000         8\n",
      "         Cook   0.924324  0.929348  0.926829       184\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        30\n",
      "      Bathing   0.875519  0.995283  0.931567       212\n",
      "\n",
      "     accuracy                       0.940653      1348\n",
      "    macro avg   0.713729  0.745030  0.725089      1348\n",
      " weighted avg   0.918790  0.940653  0.928423      1348\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  26   0   0   4   0   0]\n",
      " [  0  19   0   0   0   3   0   3   0   0]\n",
      " [  0   0   0   0   0   4   2   1   1   0]\n",
      " [  0   0   0  16   0   4   0   0   0   0]\n",
      " [  0   0   0   0 211   0   0   1   0   0]\n",
      " [  0   0   0  11   0 171   0   1   1   0]\n",
      " [  0   0   0   0   0   0  72   0   0   0]\n",
      " [  0   1   0   3   4   3   4 606   1   1]\n",
      " [  0   0   0   0   0   0   0   1 141   0]\n",
      " [  0   0   0   0   0   0   0   0   0  32]]\n",
      "no_activities: 10\n",
      "\n",
      "Begin training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 1.4272 - acc: 0.4874 - val_loss: 1.0341 - val_acc: 0.6190\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.9358 - acc: 0.6510 - val_loss: 0.6936 - val_acc: 0.8408\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7578 - acc: 0.7749 - val_loss: 0.5806 - val_acc: 0.8490\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6769 - acc: 0.8065 - val_loss: 0.5213 - val_acc: 0.8490\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6331 - acc: 0.8162 - val_loss: 0.4856 - val_acc: 0.8490\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.5875 - acc: 0.8251 - val_loss: 0.4516 - val_acc: 0.8504\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.5644 - acc: 0.8352 - val_loss: 0.4302 - val_acc: 0.8705\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.5414 - acc: 0.8523 - val_loss: 0.4078 - val_acc: 0.9144\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.5099 - acc: 0.8635 - val_loss: 0.3799 - val_acc: 0.9330\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.4803 - acc: 0.8776 - val_loss: 0.3605 - val_acc: 0.9315\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.4501 - acc: 0.8895 - val_loss: 0.3399 - val_acc: 0.9308\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.4579 - acc: 0.8891 - val_loss: 0.3263 - val_acc: 0.9301\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.4455 - acc: 0.8914 - val_loss: 0.3165 - val_acc: 0.9315\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.4256 - acc: 0.8947 - val_loss: 0.3075 - val_acc: 0.9308\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.4183 - acc: 0.8962 - val_loss: 0.2991 - val_acc: 0.9308\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.4025 - acc: 0.8984 - val_loss: 0.2925 - val_acc: 0.9330\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.3906 - acc: 0.9018 - val_loss: 0.2873 - val_acc: 0.9345\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.3923 - acc: 0.9077 - val_loss: 0.2773 - val_acc: 0.9353\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3887 - acc: 0.9036 - val_loss: 0.2779 - val_acc: 0.9345\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3659 - acc: 0.9129 - val_loss: 0.2696 - val_acc: 0.9353\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.3770 - acc: 0.9111 - val_loss: 0.2668 - val_acc: 0.9382\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3747 - acc: 0.9100 - val_loss: 0.2653 - val_acc: 0.9405\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3596 - acc: 0.9081 - val_loss: 0.2604 - val_acc: 0.9405\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3598 - acc: 0.9089 - val_loss: 0.2566 - val_acc: 0.9412\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3573 - acc: 0.9141 - val_loss: 0.2556 - val_acc: 0.9405\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3568 - acc: 0.9092 - val_loss: 0.2529 - val_acc: 0.9412\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3428 - acc: 0.9122 - val_loss: 0.2513 - val_acc: 0.9412\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3402 - acc: 0.9159 - val_loss: 0.2487 - val_acc: 0.9427\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3363 - acc: 0.9126 - val_loss: 0.2474 - val_acc: 0.9427\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3411 - acc: 0.9167 - val_loss: 0.2441 - val_acc: 0.9420\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3349 - acc: 0.9122 - val_loss: 0.2429 - val_acc: 0.9427\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3190 - acc: 0.9170 - val_loss: 0.2346 - val_acc: 0.9442\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3349 - acc: 0.9118 - val_loss: 0.2389 - val_acc: 0.9427\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3107 - acc: 0.9167 - val_loss: 0.2393 - val_acc: 0.9420\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3319 - acc: 0.9170 - val_loss: 0.2359 - val_acc: 0.9427\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3215 - acc: 0.9144 - val_loss: 0.2364 - val_acc: 0.9420\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3139 - acc: 0.9219 - val_loss: 0.2243 - val_acc: 0.9427\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3188 - acc: 0.9185 - val_loss: 0.2343 - val_acc: 0.9420\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3230 - acc: 0.9208 - val_loss: 0.2314 - val_acc: 0.9427\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3173 - acc: 0.9174 - val_loss: 0.2323 - val_acc: 0.9420\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3100 - acc: 0.9193 - val_loss: 0.2322 - val_acc: 0.9420\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3148 - acc: 0.9159 - val_loss: 0.2303 - val_acc: 0.9427\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3156 - acc: 0.9144 - val_loss: 0.2300 - val_acc: 0.9420\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3164 - acc: 0.9193 - val_loss: 0.2270 - val_acc: 0.9427\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2995 - acc: 0.9185 - val_loss: 0.2286 - val_acc: 0.9420\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3105 - acc: 0.9222 - val_loss: 0.2274 - val_acc: 0.9420\n",
      "Epoch 47/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.3049 - acc: 0.9163 - val_loss: 0.2264 - val_acc: 0.9420\n",
      "Epoch 48/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3010 - acc: 0.9182 - val_loss: 0.2233 - val_acc: 0.9427\n",
      "Epoch 49/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3061 - acc: 0.9170 - val_loss: 0.2242 - val_acc: 0.9420\n",
      "Epoch 50/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3134 - acc: 0.9144 - val_loss: 0.2229 - val_acc: 0.9420\n",
      "Epoch 51/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.3007 - acc: 0.9156 - val_loss: 0.2202 - val_acc: 0.9435\n",
      "Epoch 52/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3111 - acc: 0.9141 - val_loss: 0.2207 - val_acc: 0.9427\n",
      "Epoch 53/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3013 - acc: 0.9159 - val_loss: 0.2211 - val_acc: 0.9449\n",
      "Epoch 54/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2917 - acc: 0.9178 - val_loss: 0.2193 - val_acc: 0.9427\n",
      "Epoch 55/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2865 - acc: 0.9230 - val_loss: 0.2192 - val_acc: 0.9427\n",
      "Epoch 56/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2871 - acc: 0.9204 - val_loss: 0.2170 - val_acc: 0.9435\n",
      "Epoch 57/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2931 - acc: 0.9178 - val_loss: 0.2185 - val_acc: 0.9427\n",
      "Epoch 58/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3097 - acc: 0.9152 - val_loss: 0.2179 - val_acc: 0.9449\n",
      "Epoch 59/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2959 - acc: 0.9226 - val_loss: 0.2175 - val_acc: 0.9449\n",
      "Epoch 60/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2935 - acc: 0.9204 - val_loss: 0.2161 - val_acc: 0.9449\n",
      "Epoch 61/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2858 - acc: 0.9152 - val_loss: 0.2158 - val_acc: 0.9449\n",
      "Epoch 62/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2915 - acc: 0.9163 - val_loss: 0.2149 - val_acc: 0.9449\n",
      "Epoch 63/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2881 - acc: 0.9204 - val_loss: 0.2138 - val_acc: 0.9427\n",
      "Epoch 64/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2993 - acc: 0.9141 - val_loss: 0.2140 - val_acc: 0.9449\n",
      "Epoch 65/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2939 - acc: 0.9219 - val_loss: 0.2136 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00065: loss improved from inf to 0.29386, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-2-000065-0.293856-0.942708.hdf5\n",
      "Epoch 66/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.3005 - acc: 0.9111 - val_loss: 0.2132 - val_acc: 0.9427\n",
      "Epoch 67/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2895 - acc: 0.9193 - val_loss: 0.2136 - val_acc: 0.9427\n",
      "Epoch 68/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2939 - acc: 0.9159 - val_loss: 0.2131 - val_acc: 0.9427\n",
      "Epoch 69/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2909 - acc: 0.9185 - val_loss: 0.2128 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00069: loss improved from 0.29386 to 0.29094, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-2-000069-0.290945-0.942708.hdf5\n",
      "Epoch 70/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2888 - acc: 0.9215 - val_loss: 0.2120 - val_acc: 0.9427\n",
      "Epoch 71/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2835 - acc: 0.9156 - val_loss: 0.2122 - val_acc: 0.9449\n",
      "Epoch 72/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2698 - acc: 0.9219 - val_loss: 0.2116 - val_acc: 0.9427\n",
      "Epoch 73/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2828 - acc: 0.9167 - val_loss: 0.2090 - val_acc: 0.9457\n",
      "\n",
      "Epoch 00073: loss improved from 0.29094 to 0.28284, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-2-000073-0.282841-0.945685.hdf5\n",
      "Epoch 74/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2812 - acc: 0.9211 - val_loss: 0.2112 - val_acc: 0.9427\n",
      "Epoch 75/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2797 - acc: 0.9193 - val_loss: 0.2099 - val_acc: 0.9435\n",
      "Epoch 76/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2682 - acc: 0.9193 - val_loss: 0.2105 - val_acc: 0.9427\n",
      "Epoch 77/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2711 - acc: 0.9226 - val_loss: 0.2084 - val_acc: 0.9457\n",
      "\n",
      "Epoch 00077: loss improved from 0.28284 to 0.27113, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-2-000077-0.271135-0.945685.hdf5\n",
      "Epoch 78/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2923 - acc: 0.9193 - val_loss: 0.2095 - val_acc: 0.9449\n",
      "Epoch 79/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2827 - acc: 0.9222 - val_loss: 0.2075 - val_acc: 0.9457\n",
      "Epoch 80/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2824 - acc: 0.9137 - val_loss: 0.2086 - val_acc: 0.9449\n",
      "Epoch 81/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2830 - acc: 0.9193 - val_loss: 0.2075 - val_acc: 0.9449\n",
      "Epoch 82/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2782 - acc: 0.9230 - val_loss: 0.2078 - val_acc: 0.9449\n",
      "Epoch 83/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2817 - acc: 0.9174 - val_loss: 0.2085 - val_acc: 0.9427\n",
      "Epoch 84/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2842 - acc: 0.9185 - val_loss: 0.2067 - val_acc: 0.9457\n",
      "Epoch 85/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.2806 - acc: 0.9170 - val_loss: 0.2089 - val_acc: 0.9449\n",
      "Epoch 86/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2686 - acc: 0.9226 - val_loss: 0.2078 - val_acc: 0.9449\n",
      "Epoch 87/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2651 - acc: 0.9230 - val_loss: 0.2058 - val_acc: 0.9435\n",
      "Epoch 88/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2873 - acc: 0.9189 - val_loss: 0.2051 - val_acc: 0.9457\n",
      "Epoch 89/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2812 - acc: 0.9185 - val_loss: 0.2003 - val_acc: 0.9464\n",
      "Epoch 90/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2665 - acc: 0.9256 - val_loss: 0.2068 - val_acc: 0.9449\n",
      "Epoch 91/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2778 - acc: 0.9182 - val_loss: 0.2064 - val_acc: 0.9449\n",
      "Epoch 92/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2691 - acc: 0.9215 - val_loss: 0.2056 - val_acc: 0.9449\n",
      "Epoch 93/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2537 - acc: 0.9234 - val_loss: 0.2064 - val_acc: 0.9449\n",
      "\n",
      "Epoch 00093: loss improved from 0.27113 to 0.25372, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-2-000093-0.253717-0.944940.hdf5\n",
      "Epoch 94/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2747 - acc: 0.9196 - val_loss: 0.2058 - val_acc: 0.9457\n",
      "Epoch 95/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2761 - acc: 0.9174 - val_loss: 0.2070 - val_acc: 0.9449\n",
      "Epoch 96/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2705 - acc: 0.9182 - val_loss: 0.2072 - val_acc: 0.9449\n",
      "Epoch 97/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2831 - acc: 0.9185 - val_loss: 0.2066 - val_acc: 0.9449\n",
      "Epoch 98/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2690 - acc: 0.9222 - val_loss: 0.2060 - val_acc: 0.9449\n",
      "Epoch 99/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2791 - acc: 0.9148 - val_loss: 0.2051 - val_acc: 0.9449\n",
      "Epoch 100/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2660 - acc: 0.9182 - val_loss: 0.2053 - val_acc: 0.9449\n",
      "\n",
      "Epoch 00100: saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/2-000100-0.265959-0.944940.hdf5\n",
      "Epoch 101/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2705 - acc: 0.9211 - val_loss: 0.2054 - val_acc: 0.9427\n",
      "Epoch 102/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2703 - acc: 0.9185 - val_loss: 0.2057 - val_acc: 0.9449\n",
      "Epoch 103/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2720 - acc: 0.9208 - val_loss: 0.2056 - val_acc: 0.9427\n",
      "Epoch 104/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2642 - acc: 0.9196 - val_loss: 0.2055 - val_acc: 0.9427\n",
      "Epoch 105/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2682 - acc: 0.9196 - val_loss: 0.2056 - val_acc: 0.9427\n",
      "Epoch 106/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2641 - acc: 0.9185 - val_loss: 0.2056 - val_acc: 0.9427\n",
      "Epoch 107/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2712 - acc: 0.9222 - val_loss: 0.2044 - val_acc: 0.9435\n",
      "Epoch 108/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2624 - acc: 0.9193 - val_loss: 0.2038 - val_acc: 0.9435\n",
      "Epoch 109/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2674 - acc: 0.9245 - val_loss: 0.2020 - val_acc: 0.9464\n",
      "Epoch 110/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2683 - acc: 0.9215 - val_loss: 0.2044 - val_acc: 0.9449\n",
      "Epoch 111/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2524 - acc: 0.9267 - val_loss: 0.2041 - val_acc: 0.9449\n",
      "Epoch 112/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2563 - acc: 0.9271 - val_loss: 0.2038 - val_acc: 0.9449\n",
      "Epoch 113/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2547 - acc: 0.9226 - val_loss: 0.2037 - val_acc: 0.9449\n",
      "Epoch 114/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2697 - acc: 0.9182 - val_loss: 0.2042 - val_acc: 0.9449\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2648 - acc: 0.9245 - val_loss: 0.2023 - val_acc: 0.9457\n",
      "Epoch 116/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2679 - acc: 0.9204 - val_loss: 0.2040 - val_acc: 0.9449\n",
      "Epoch 117/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2596 - acc: 0.9211 - val_loss: 0.2032 - val_acc: 0.9449\n",
      "Epoch 118/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2659 - acc: 0.9219 - val_loss: 0.2032 - val_acc: 0.9449\n",
      "Epoch 119/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2681 - acc: 0.9215 - val_loss: 0.2022 - val_acc: 0.9435\n",
      "Epoch 120/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2652 - acc: 0.9219 - val_loss: 0.2032 - val_acc: 0.9449\n",
      "Epoch 121/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2547 - acc: 0.9252 - val_loss: 0.2029 - val_acc: 0.9449\n",
      "Epoch 122/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2665 - acc: 0.9204 - val_loss: 0.2027 - val_acc: 0.9427\n",
      "Epoch 123/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2591 - acc: 0.9237 - val_loss: 0.2026 - val_acc: 0.9427\n",
      "Epoch 124/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2718 - acc: 0.9230 - val_loss: 0.2025 - val_acc: 0.9427\n",
      "Epoch 125/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2484 - acc: 0.9267 - val_loss: 0.2019 - val_acc: 0.9435\n",
      "Epoch 126/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2510 - acc: 0.9256 - val_loss: 0.1952 - val_acc: 0.9435\n",
      "Epoch 127/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2632 - acc: 0.9200 - val_loss: 0.2018 - val_acc: 0.9427\n",
      "Epoch 128/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2545 - acc: 0.9222 - val_loss: 0.2022 - val_acc: 0.9427\n",
      "Epoch 129/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2518 - acc: 0.9234 - val_loss: 0.2018 - val_acc: 0.9427\n",
      "Epoch 130/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2614 - acc: 0.9241 - val_loss: 0.2016 - val_acc: 0.9427\n",
      "Epoch 131/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2669 - acc: 0.9234 - val_loss: 0.2016 - val_acc: 0.9427\n",
      "Epoch 132/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2612 - acc: 0.9234 - val_loss: 0.2018 - val_acc: 0.9427\n",
      "Epoch 133/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2547 - acc: 0.9278 - val_loss: 0.2016 - val_acc: 0.9427\n",
      "Epoch 134/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2553 - acc: 0.9215 - val_loss: 0.1967 - val_acc: 0.9435\n",
      "Epoch 135/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2591 - acc: 0.9219 - val_loss: 0.2003 - val_acc: 0.9435\n",
      "Epoch 136/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2668 - acc: 0.9204 - val_loss: 0.2019 - val_acc: 0.9427\n",
      "Epoch 137/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2600 - acc: 0.9219 - val_loss: 0.2014 - val_acc: 0.9427\n",
      "Epoch 138/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2605 - acc: 0.9219 - val_loss: 0.2012 - val_acc: 0.9427\n",
      "Epoch 139/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2571 - acc: 0.9226 - val_loss: 0.2007 - val_acc: 0.9427\n",
      "Epoch 140/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2519 - acc: 0.9234 - val_loss: 0.2011 - val_acc: 0.9427\n",
      "Epoch 141/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2507 - acc: 0.9282 - val_loss: 0.2013 - val_acc: 0.9427\n",
      "Epoch 142/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2670 - acc: 0.9208 - val_loss: 0.2002 - val_acc: 0.9435\n",
      "Epoch 143/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2588 - acc: 0.9230 - val_loss: 0.2010 - val_acc: 0.9427\n",
      "Epoch 144/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2586 - acc: 0.9245 - val_loss: 0.1990 - val_acc: 0.9457\n",
      "Epoch 145/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2495 - acc: 0.9301 - val_loss: 0.2002 - val_acc: 0.9449\n",
      "\n",
      "Epoch 00145: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 146/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2492 - acc: 0.9245 - val_loss: 0.1992 - val_acc: 0.9457\n",
      "Epoch 147/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2631 - acc: 0.9230 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 148/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2658 - acc: 0.9219 - val_loss: 0.1984 - val_acc: 0.9457\n",
      "Epoch 149/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2561 - acc: 0.9267 - val_loss: 0.2002 - val_acc: 0.9449\n",
      "Epoch 150/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2535 - acc: 0.9200 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 151/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2491 - acc: 0.9263 - val_loss: 0.2001 - val_acc: 0.9449\n",
      "Epoch 152/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2566 - acc: 0.9271 - val_loss: 0.2001 - val_acc: 0.9449\n",
      "Epoch 153/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2608 - acc: 0.9204 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 154/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2613 - acc: 0.9200 - val_loss: 0.1985 - val_acc: 0.9457\n",
      "Epoch 155/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2468 - acc: 0.9263 - val_loss: 0.1999 - val_acc: 0.9449\n",
      "Epoch 156/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2609 - acc: 0.9208 - val_loss: 0.1986 - val_acc: 0.9457\n",
      "Epoch 157/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2482 - acc: 0.9260 - val_loss: 0.1993 - val_acc: 0.9449\n",
      "Epoch 158/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2544 - acc: 0.9245 - val_loss: 0.2001 - val_acc: 0.9449\n",
      "Epoch 159/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2510 - acc: 0.9234 - val_loss: 0.2000 - val_acc: 0.9449\n",
      "Epoch 160/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2535 - acc: 0.9237 - val_loss: 0.1999 - val_acc: 0.9449\n",
      "Epoch 161/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2475 - acc: 0.9271 - val_loss: 0.1996 - val_acc: 0.9449\n",
      "Epoch 162/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2474 - acc: 0.9226 - val_loss: 0.1993 - val_acc: 0.9449\n",
      "Epoch 163/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2577 - acc: 0.9211 - val_loss: 0.1965 - val_acc: 0.9457\n",
      "Epoch 164/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2637 - acc: 0.9237 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 165/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2440 - acc: 0.9256 - val_loss: 0.1992 - val_acc: 0.9457\n",
      "\n",
      "Epoch 00165: loss improved from inf to 0.24405, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-2-000165-0.244050-0.945685.hdf5\n",
      "Epoch 166/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2553 - acc: 0.9263 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 167/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2417 - acc: 0.9275 - val_loss: 0.2000 - val_acc: 0.9449\n",
      "Epoch 168/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2415 - acc: 0.9267 - val_loss: 0.1987 - val_acc: 0.9457\n",
      "Epoch 169/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2564 - acc: 0.9219 - val_loss: 0.1999 - val_acc: 0.9449\n",
      "Epoch 170/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2495 - acc: 0.9230 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 171/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2473 - acc: 0.9249 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 172/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2469 - acc: 0.9256 - val_loss: 0.1999 - val_acc: 0.9449\n",
      "Epoch 173/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2525 - acc: 0.9256 - val_loss: 0.1998 - val_acc: 0.9449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2435 - acc: 0.9271 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 175/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2473 - acc: 0.9271 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 176/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2535 - acc: 0.9241 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 177/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2581 - acc: 0.9245 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 178/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2601 - acc: 0.9200 - val_loss: 0.1996 - val_acc: 0.9449\n",
      "Epoch 179/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2522 - acc: 0.9271 - val_loss: 0.1999 - val_acc: 0.9449\n",
      "Epoch 180/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2485 - acc: 0.9245 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 181/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2553 - acc: 0.9249 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 182/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2492 - acc: 0.9271 - val_loss: 0.1999 - val_acc: 0.9449\n",
      "Epoch 183/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2593 - acc: 0.9252 - val_loss: 0.1994 - val_acc: 0.9449\n",
      "Epoch 184/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2570 - acc: 0.9241 - val_loss: 0.1999 - val_acc: 0.9449\n",
      "Epoch 185/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2620 - acc: 0.9230 - val_loss: 0.2001 - val_acc: 0.9449\n",
      "Epoch 186/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2498 - acc: 0.9237 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 187/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2517 - acc: 0.9260 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 188/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2455 - acc: 0.9256 - val_loss: 0.1999 - val_acc: 0.9449\n",
      "\n",
      "Epoch 00188: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 189/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2455 - acc: 0.9252 - val_loss: 0.1953 - val_acc: 0.9457\n",
      "Epoch 190/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2482 - acc: 0.9241 - val_loss: 0.1999 - val_acc: 0.9449\n",
      "Epoch 191/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2574 - acc: 0.9241 - val_loss: 0.1999 - val_acc: 0.9449\n",
      "Epoch 192/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2594 - acc: 0.9219 - val_loss: 0.1999 - val_acc: 0.9449\n",
      "Epoch 193/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2522 - acc: 0.9226 - val_loss: 0.1996 - val_acc: 0.9449\n",
      "Epoch 194/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2565 - acc: 0.9260 - val_loss: 0.1999 - val_acc: 0.9449\n",
      "Epoch 195/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2520 - acc: 0.9252 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 196/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2450 - acc: 0.9286 - val_loss: 0.1988 - val_acc: 0.9457\n",
      "Epoch 197/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2449 - acc: 0.9200 - val_loss: 0.1996 - val_acc: 0.9449\n",
      "Epoch 198/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2581 - acc: 0.9226 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 199/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2454 - acc: 0.9226 - val_loss: 0.1999 - val_acc: 0.9449\n",
      "Epoch 200/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2485 - acc: 0.9252 - val_loss: 0.1974 - val_acc: 0.9457\n",
      "\n",
      "Epoch 00200: saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/2-000200-0.248457-0.945685.hdf5\n",
      "Epoch 201/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2500 - acc: 0.9260 - val_loss: 0.1999 - val_acc: 0.9449\n",
      "Epoch 202/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2543 - acc: 0.9241 - val_loss: 0.1999 - val_acc: 0.9449\n",
      "Epoch 203/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2548 - acc: 0.9278 - val_loss: 0.1999 - val_acc: 0.9449\n",
      "Epoch 204/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2566 - acc: 0.9245 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 205/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2578 - acc: 0.9237 - val_loss: 0.1999 - val_acc: 0.9449\n",
      "Epoch 206/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2526 - acc: 0.9237 - val_loss: 0.1999 - val_acc: 0.9449\n",
      "Epoch 207/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2649 - acc: 0.9226 - val_loss: 0.1986 - val_acc: 0.9457\n",
      "Epoch 208/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2459 - acc: 0.9301 - val_loss: 0.1986 - val_acc: 0.9457\n",
      "\n",
      "Epoch 00208: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 209/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2593 - acc: 0.9219 - val_loss: 0.1984 - val_acc: 0.9457\n",
      "Epoch 210/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2514 - acc: 0.9226 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 211/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2453 - acc: 0.9260 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 212/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2514 - acc: 0.9260 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 213/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2539 - acc: 0.9200 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 214/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2511 - acc: 0.9222 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 215/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2546 - acc: 0.9260 - val_loss: 0.1999 - val_acc: 0.9449\n",
      "Epoch 216/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2434 - acc: 0.9271 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 217/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2532 - acc: 0.9219 - val_loss: 0.1990 - val_acc: 0.9449\n",
      "Epoch 218/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2513 - acc: 0.9260 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 219/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2470 - acc: 0.9278 - val_loss: 0.1969 - val_acc: 0.9457\n",
      "Epoch 220/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2592 - acc: 0.9245 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 221/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2532 - acc: 0.9252 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 222/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2506 - acc: 0.9297 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 223/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2589 - acc: 0.9245 - val_loss: 0.1986 - val_acc: 0.9457\n",
      "Epoch 224/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2473 - acc: 0.9263 - val_loss: 0.1973 - val_acc: 0.9457\n",
      "Epoch 225/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2490 - acc: 0.9286 - val_loss: 0.1914 - val_acc: 0.9457\n",
      "Epoch 226/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2657 - acc: 0.9208 - val_loss: 0.1999 - val_acc: 0.9449\n",
      "Epoch 227/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2466 - acc: 0.9308 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 228/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2501 - acc: 0.9267 - val_loss: 0.1990 - val_acc: 0.9449\n",
      "Epoch 229/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2506 - acc: 0.9271 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 230/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2463 - acc: 0.9237 - val_loss: 0.1978 - val_acc: 0.9457\n",
      "Epoch 231/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2521 - acc: 0.9267 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 232/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2530 - acc: 0.9286 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 233/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2558 - acc: 0.9234 - val_loss: 0.1995 - val_acc: 0.9449\n",
      "Epoch 234/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2545 - acc: 0.9234 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 235/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2504 - acc: 0.9230 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 236/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2509 - acc: 0.9260 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 237/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2517 - acc: 0.9267 - val_loss: 0.1995 - val_acc: 0.9449\n",
      "Epoch 238/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2576 - acc: 0.9230 - val_loss: 0.1996 - val_acc: 0.9449\n",
      "Epoch 239/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2543 - acc: 0.9234 - val_loss: 0.1926 - val_acc: 0.9457\n",
      "Epoch 240/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2506 - acc: 0.9249 - val_loss: 0.1961 - val_acc: 0.9464\n",
      "Epoch 241/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2493 - acc: 0.9256 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 242/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2544 - acc: 0.9256 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 243/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2462 - acc: 0.9267 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 244/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2499 - acc: 0.9211 - val_loss: 0.1995 - val_acc: 0.9449\n",
      "Epoch 245/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2535 - acc: 0.9219 - val_loss: 0.1986 - val_acc: 0.9457\n",
      "Epoch 246/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2397 - acc: 0.9301 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 247/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2457 - acc: 0.9234 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 248/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2597 - acc: 0.9234 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 249/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2529 - acc: 0.9252 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 250/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2434 - acc: 0.9289 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 251/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2473 - acc: 0.9282 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 252/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2541 - acc: 0.9256 - val_loss: 0.1977 - val_acc: 0.9464\n",
      "Epoch 253/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2487 - acc: 0.9260 - val_loss: 0.1994 - val_acc: 0.9449\n",
      "Epoch 254/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2557 - acc: 0.9219 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 255/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2491 - acc: 0.9245 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 256/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2583 - acc: 0.9226 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 257/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2518 - acc: 0.9263 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 258/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2572 - acc: 0.9293 - val_loss: 0.1995 - val_acc: 0.9449\n",
      "Epoch 259/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2518 - acc: 0.9200 - val_loss: 0.1989 - val_acc: 0.9457\n",
      "Epoch 260/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2496 - acc: 0.9297 - val_loss: 0.1922 - val_acc: 0.9457\n",
      "Epoch 261/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2412 - acc: 0.9282 - val_loss: 0.1996 - val_acc: 0.9449\n",
      "Epoch 262/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2582 - acc: 0.9234 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 263/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2560 - acc: 0.9256 - val_loss: 0.1993 - val_acc: 0.9449\n",
      "Epoch 264/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2561 - acc: 0.9211 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 265/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2588 - acc: 0.9252 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "\n",
      "Epoch 00265: loss improved from inf to 0.25875, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-2-000265-0.258754-0.944940.hdf5\n",
      "Epoch 266/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2459 - acc: 0.9267 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 267/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2401 - acc: 0.9297 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 268/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2485 - acc: 0.9219 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 269/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2549 - acc: 0.9275 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "\n",
      "Epoch 00269: loss improved from 0.25875 to 0.25485, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-2-000269-0.254852-0.944940.hdf5\n",
      "Epoch 270/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2585 - acc: 0.9222 - val_loss: 0.1996 - val_acc: 0.9449\n",
      "Epoch 271/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2446 - acc: 0.9256 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 272/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2467 - acc: 0.9286 - val_loss: 0.1994 - val_acc: 0.9449\n",
      "Epoch 273/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2535 - acc: 0.9249 - val_loss: 0.1988 - val_acc: 0.9457\n",
      "\n",
      "Epoch 00273: loss improved from 0.25485 to 0.25351, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-2-000273-0.253505-0.945685.hdf5\n",
      "Epoch 274/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2544 - acc: 0.9219 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 275/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2591 - acc: 0.9222 - val_loss: 0.1970 - val_acc: 0.9457\n",
      "Epoch 276/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2521 - acc: 0.9252 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 277/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2537 - acc: 0.9252 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 278/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2470 - acc: 0.9241 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 279/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2444 - acc: 0.9260 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 280/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2524 - acc: 0.9286 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 281/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2490 - acc: 0.9256 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "\n",
      "Epoch 00281: loss improved from 0.25351 to 0.24903, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-2-000281-0.249028-0.944940.hdf5\n",
      "Epoch 282/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2535 - acc: 0.9249 - val_loss: 0.1971 - val_acc: 0.9464\n",
      "Epoch 283/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2559 - acc: 0.9230 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 284/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2655 - acc: 0.9241 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 285/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2490 - acc: 0.9230 - val_loss: 0.1996 - val_acc: 0.9449\n",
      "\n",
      "Epoch 00285: loss improved from 0.24903 to 0.24898, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-2-000285-0.248976-0.944940.hdf5\n",
      "Epoch 286/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2471 - acc: 0.9289 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 287/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2633 - acc: 0.9237 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 288/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2521 - acc: 0.9241 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 289/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2500 - acc: 0.9267 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 290/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2483 - acc: 0.9260 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 291/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2473 - acc: 0.9263 - val_loss: 0.1983 - val_acc: 0.9457\n",
      "Epoch 292/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2502 - acc: 0.9237 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 293/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2475 - acc: 0.9249 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "\n",
      "Epoch 00293: loss improved from 0.24898 to 0.24750, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-2-000293-0.247500-0.944940.hdf5\n",
      "Epoch 294/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2561 - acc: 0.9234 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 295/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2593 - acc: 0.9222 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 296/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2478 - acc: 0.9263 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 297/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2510 - acc: 0.9289 - val_loss: 0.1995 - val_acc: 0.9449\n",
      "Epoch 298/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2494 - acc: 0.9289 - val_loss: 0.1992 - val_acc: 0.9449\n",
      "Epoch 299/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2479 - acc: 0.9278 - val_loss: 0.1987 - val_acc: 0.9457\n",
      "Epoch 300/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2462 - acc: 0.9245 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "\n",
      "Epoch 00300: saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/2-000300-0.246168-0.944940.hdf5\n",
      "Epoch 301/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2625 - acc: 0.9200 - val_loss: 0.1990 - val_acc: 0.9449\n",
      "Epoch 302/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2532 - acc: 0.9282 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 303/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2541 - acc: 0.9241 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 304/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2593 - acc: 0.9249 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 305/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2415 - acc: 0.9304 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 306/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2500 - acc: 0.9271 - val_loss: 0.1921 - val_acc: 0.9457\n",
      "Epoch 307/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2406 - acc: 0.9256 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 308/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2623 - acc: 0.9230 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 309/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2573 - acc: 0.9204 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 310/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2499 - acc: 0.9260 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 311/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2405 - acc: 0.9282 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 312/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2541 - acc: 0.9200 - val_loss: 0.1976 - val_acc: 0.9457\n",
      "Epoch 313/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2510 - acc: 0.9230 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 314/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2452 - acc: 0.9267 - val_loss: 0.1995 - val_acc: 0.9449\n",
      "Epoch 315/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2452 - acc: 0.9241 - val_loss: 0.1985 - val_acc: 0.9457\n",
      "Epoch 316/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2504 - acc: 0.9282 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 317/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2342 - acc: 0.9282 - val_loss: 0.1995 - val_acc: 0.9449\n",
      "Epoch 318/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2649 - acc: 0.9230 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 319/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2405 - acc: 0.9330 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 320/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2516 - acc: 0.9297 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 321/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2430 - acc: 0.9241 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 322/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2546 - acc: 0.9234 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 323/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2504 - acc: 0.9193 - val_loss: 0.1995 - val_acc: 0.9449\n",
      "Epoch 324/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2387 - acc: 0.9278 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 325/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2559 - acc: 0.9222 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 326/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2461 - acc: 0.9286 - val_loss: 0.1978 - val_acc: 0.9457\n",
      "Epoch 327/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2417 - acc: 0.9267 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 328/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2492 - acc: 0.9282 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 329/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2489 - acc: 0.9267 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 330/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2569 - acc: 0.9230 - val_loss: 0.1995 - val_acc: 0.9449\n",
      "Epoch 331/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2590 - acc: 0.9271 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 332/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2551 - acc: 0.9226 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 333/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2524 - acc: 0.9256 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 334/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2611 - acc: 0.9211 - val_loss: 0.1995 - val_acc: 0.9449\n",
      "Epoch 335/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2446 - acc: 0.9286 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 336/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2546 - acc: 0.9226 - val_loss: 0.1981 - val_acc: 0.9457\n",
      "Epoch 337/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2501 - acc: 0.9222 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 338/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2526 - acc: 0.9282 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 339/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2505 - acc: 0.9237 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 340/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2656 - acc: 0.9167 - val_loss: 0.1996 - val_acc: 0.9449\n",
      "Epoch 341/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2472 - acc: 0.9278 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 342/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2411 - acc: 0.9289 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 343/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2427 - acc: 0.9263 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 344/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2620 - acc: 0.9237 - val_loss: 0.1977 - val_acc: 0.9457\n",
      "Epoch 345/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2449 - acc: 0.9263 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 346/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2564 - acc: 0.9211 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 347/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2570 - acc: 0.9252 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 348/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2461 - acc: 0.9271 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 349/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2456 - acc: 0.9275 - val_loss: 0.1986 - val_acc: 0.9457\n",
      "Epoch 350/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2579 - acc: 0.9208 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 351/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2575 - acc: 0.9230 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 352/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2587 - acc: 0.9219 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 353/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2609 - acc: 0.9249 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 354/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2476 - acc: 0.9252 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 355/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2462 - acc: 0.9263 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 356/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2601 - acc: 0.9222 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 357/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2593 - acc: 0.9237 - val_loss: 0.1995 - val_acc: 0.9449\n",
      "Epoch 358/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2493 - acc: 0.9263 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 359/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2504 - acc: 0.9267 - val_loss: 0.1971 - val_acc: 0.9464\n",
      "Epoch 360/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2526 - acc: 0.9222 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 361/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2506 - acc: 0.9267 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 362/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2591 - acc: 0.9241 - val_loss: 0.1996 - val_acc: 0.9449\n",
      "Epoch 363/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2594 - acc: 0.9226 - val_loss: 0.1996 - val_acc: 0.9449\n",
      "Epoch 364/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2474 - acc: 0.9256 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 365/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2469 - acc: 0.9237 - val_loss: 0.1996 - val_acc: 0.9449\n",
      "\n",
      "Epoch 00365: loss improved from inf to 0.24691, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-2-000365-0.246909-0.944940.hdf5\n",
      "Epoch 366/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2555 - acc: 0.9263 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 367/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2493 - acc: 0.9237 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 368/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2452 - acc: 0.9260 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 369/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2532 - acc: 0.9263 - val_loss: 0.1996 - val_acc: 0.9449\n",
      "Epoch 370/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2559 - acc: 0.9241 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 371/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2611 - acc: 0.9256 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 372/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2485 - acc: 0.9237 - val_loss: 0.1922 - val_acc: 0.9457\n",
      "Epoch 373/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2479 - acc: 0.9267 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 374/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2412 - acc: 0.9278 - val_loss: 0.1996 - val_acc: 0.9449\n",
      "Epoch 375/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2491 - acc: 0.9267 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 376/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2602 - acc: 0.9219 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 377/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2506 - acc: 0.9263 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 378/1000\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 0.2588 - acc: 0.9230 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 379/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2487 - acc: 0.9249 - val_loss: 0.1996 - val_acc: 0.9449\n",
      "Epoch 380/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2549 - acc: 0.9278 - val_loss: 0.1983 - val_acc: 0.9457\n",
      "Epoch 381/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2552 - acc: 0.9215 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 382/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.2415 - acc: 0.9245 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 383/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2553 - acc: 0.9297 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 384/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2446 - acc: 0.9278 - val_loss: 0.1981 - val_acc: 0.9457\n",
      "Epoch 385/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2593 - acc: 0.9237 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 386/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2510 - acc: 0.9252 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 387/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2423 - acc: 0.9293 - val_loss: 0.1986 - val_acc: 0.9457\n",
      "Epoch 388/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2439 - acc: 0.9289 - val_loss: 0.1965 - val_acc: 0.9457\n",
      "Epoch 389/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2559 - acc: 0.9196 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 390/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2562 - acc: 0.9230 - val_loss: 0.1989 - val_acc: 0.9449\n",
      "Epoch 391/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2456 - acc: 0.9286 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 392/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2444 - acc: 0.9289 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 393/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2607 - acc: 0.9211 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 394/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2554 - acc: 0.9230 - val_loss: 0.1986 - val_acc: 0.9457\n",
      "Epoch 395/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2657 - acc: 0.9196 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 396/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2599 - acc: 0.9226 - val_loss: 0.1996 - val_acc: 0.9449\n",
      "Epoch 397/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2416 - acc: 0.9263 - val_loss: 0.1995 - val_acc: 0.9449\n",
      "\n",
      "Epoch 00397: loss improved from 0.24691 to 0.24164, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-2-000397-0.241644-0.944940.hdf5\n",
      "Epoch 398/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2574 - acc: 0.9278 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 399/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2643 - acc: 0.9245 - val_loss: 0.1996 - val_acc: 0.9449\n",
      "Epoch 400/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2560 - acc: 0.9222 - val_loss: 0.1976 - val_acc: 0.9457\n",
      "\n",
      "Epoch 00400: saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/2-000400-0.256027-0.945685.hdf5\n",
      "Epoch 401/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2459 - acc: 0.9256 - val_loss: 0.1996 - val_acc: 0.9449\n",
      "Epoch 402/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2428 - acc: 0.9278 - val_loss: 0.1996 - val_acc: 0.9449\n",
      "Epoch 403/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2478 - acc: 0.9271 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 404/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2498 - acc: 0.9263 - val_loss: 0.1990 - val_acc: 0.9449\n",
      "Epoch 405/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2501 - acc: 0.9256 - val_loss: 0.1976 - val_acc: 0.9457\n",
      "Epoch 406/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2623 - acc: 0.9237 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 407/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2526 - acc: 0.9222 - val_loss: 0.1996 - val_acc: 0.9449\n",
      "Epoch 408/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2460 - acc: 0.9245 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 409/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2505 - acc: 0.9211 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 410/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2575 - acc: 0.9271 - val_loss: 0.1974 - val_acc: 0.9464\n",
      "Epoch 411/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2500 - acc: 0.9249 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 412/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2483 - acc: 0.9267 - val_loss: 0.1996 - val_acc: 0.9449\n",
      "Epoch 413/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2485 - acc: 0.9282 - val_loss: 0.1989 - val_acc: 0.9457\n",
      "Epoch 414/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2502 - acc: 0.9245 - val_loss: 0.1995 - val_acc: 0.9449\n",
      "Epoch 415/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2537 - acc: 0.9245 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 416/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2462 - acc: 0.9293 - val_loss: 0.1995 - val_acc: 0.9449\n",
      "Epoch 417/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2530 - acc: 0.9237 - val_loss: 0.1996 - val_acc: 0.9449\n",
      "Epoch 418/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2531 - acc: 0.9230 - val_loss: 0.1986 - val_acc: 0.9457\n",
      "Epoch 419/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2524 - acc: 0.9256 - val_loss: 0.1995 - val_acc: 0.9449\n",
      "Epoch 420/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2468 - acc: 0.9267 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 421/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2432 - acc: 0.9293 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 422/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2513 - acc: 0.9260 - val_loss: 0.1945 - val_acc: 0.9457\n",
      "Epoch 423/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2529 - acc: 0.9245 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 424/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2508 - acc: 0.9282 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 425/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.2611 - acc: 0.9211 - val_loss: 0.1986 - val_acc: 0.9457\n",
      "Epoch 426/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2509 - acc: 0.9237 - val_loss: 0.1890 - val_acc: 0.9464\n",
      "Epoch 427/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2407 - acc: 0.9289 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 428/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2510 - acc: 0.9271 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 429/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2408 - acc: 0.9271 - val_loss: 0.1996 - val_acc: 0.9449\n",
      "Epoch 430/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2518 - acc: 0.9263 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 431/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2436 - acc: 0.9308 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 432/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.2386 - acc: 0.9289 - val_loss: 0.1975 - val_acc: 0.9457\n",
      "Epoch 433/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2479 - acc: 0.9260 - val_loss: 0.1993 - val_acc: 0.9449\n",
      "Epoch 434/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2596 - acc: 0.9252 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 435/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2430 - acc: 0.9289 - val_loss: 0.1981 - val_acc: 0.9457\n",
      "Epoch 436/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2701 - acc: 0.9167 - val_loss: 0.1986 - val_acc: 0.9457\n",
      "Epoch 437/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2516 - acc: 0.9275 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 438/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2522 - acc: 0.9282 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 439/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2478 - acc: 0.9286 - val_loss: 0.1996 - val_acc: 0.9449\n",
      "Epoch 440/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2487 - acc: 0.9267 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 441/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2592 - acc: 0.9234 - val_loss: 0.1996 - val_acc: 0.9449\n",
      "Epoch 442/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2426 - acc: 0.9263 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 443/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2526 - acc: 0.9282 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 444/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2528 - acc: 0.9222 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 445/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2394 - acc: 0.9282 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 446/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2476 - acc: 0.9237 - val_loss: 0.1990 - val_acc: 0.9457\n",
      "Epoch 447/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2367 - acc: 0.9297 - val_loss: 0.1996 - val_acc: 0.9449\n",
      "Epoch 448/1000\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.2485 - acc: 0.9263 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 449/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2587 - acc: 0.9234 - val_loss: 0.1995 - val_acc: 0.9449\n",
      "Epoch 450/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2474 - acc: 0.9271 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 451/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2517 - acc: 0.9282 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 452/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2398 - acc: 0.9252 - val_loss: 0.1996 - val_acc: 0.9449\n",
      "Epoch 453/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2521 - acc: 0.9245 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 454/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2513 - acc: 0.9267 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 455/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2655 - acc: 0.9189 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 456/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2482 - acc: 0.9249 - val_loss: 0.1996 - val_acc: 0.9449\n",
      "Epoch 457/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2584 - acc: 0.9282 - val_loss: 0.1995 - val_acc: 0.9449\n",
      "Epoch 458/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2526 - acc: 0.9256 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 459/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2601 - acc: 0.9245 - val_loss: 0.1986 - val_acc: 0.9457\n",
      "Epoch 460/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2487 - acc: 0.9275 - val_loss: 0.1984 - val_acc: 0.9457\n",
      "Epoch 461/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2577 - acc: 0.9241 - val_loss: 0.1997 - val_acc: 0.9449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 462/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2514 - acc: 0.9245 - val_loss: 0.1983 - val_acc: 0.9457\n",
      "Epoch 463/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2369 - acc: 0.9308 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 464/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2524 - acc: 0.9237 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 465/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2468 - acc: 0.9215 - val_loss: 0.1986 - val_acc: 0.9457\n",
      "\n",
      "Epoch 00465: loss improved from inf to 0.24675, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-2-000465-0.246754-0.945685.hdf5\n",
      "Epoch 466/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2548 - acc: 0.9263 - val_loss: 0.1996 - val_acc: 0.9449\n",
      "Epoch 467/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2501 - acc: 0.9263 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 468/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2511 - acc: 0.9245 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 469/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2479 - acc: 0.9286 - val_loss: 0.1996 - val_acc: 0.9449\n",
      "Epoch 470/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2660 - acc: 0.9222 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 471/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2388 - acc: 0.9297 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 472/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2473 - acc: 0.9275 - val_loss: 0.1986 - val_acc: 0.9457\n",
      "Epoch 473/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2511 - acc: 0.9256 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 474/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2458 - acc: 0.9282 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 475/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2647 - acc: 0.9208 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 476/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2531 - acc: 0.9263 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 477/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2535 - acc: 0.9245 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 478/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2510 - acc: 0.9245 - val_loss: 0.1996 - val_acc: 0.9449\n",
      "Epoch 479/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2568 - acc: 0.9215 - val_loss: 0.1981 - val_acc: 0.9457\n",
      "Epoch 480/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2469 - acc: 0.9289 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 481/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2508 - acc: 0.9275 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 482/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2426 - acc: 0.9278 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 483/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2477 - acc: 0.9263 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 484/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2537 - acc: 0.9245 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 485/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2433 - acc: 0.9256 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "\n",
      "Epoch 00485: loss improved from 0.24675 to 0.24326, saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/Pbest-2-000485-0.243259-0.944940.hdf5\n",
      "Epoch 486/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2556 - acc: 0.9226 - val_loss: 0.1983 - val_acc: 0.9457\n",
      "Epoch 487/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2633 - acc: 0.9185 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 488/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2571 - acc: 0.9196 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 489/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2549 - acc: 0.9267 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 490/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2480 - acc: 0.9208 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 491/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2549 - acc: 0.9226 - val_loss: 0.1987 - val_acc: 0.9457\n",
      "Epoch 492/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2493 - acc: 0.9256 - val_loss: 0.1978 - val_acc: 0.9457\n",
      "Epoch 493/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2561 - acc: 0.9263 - val_loss: 0.1994 - val_acc: 0.9449\n",
      "Epoch 494/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2361 - acc: 0.9312 - val_loss: 0.1996 - val_acc: 0.9449\n",
      "Epoch 495/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2570 - acc: 0.9237 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 496/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2601 - acc: 0.9185 - val_loss: 0.1995 - val_acc: 0.9449\n",
      "Epoch 497/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.2504 - acc: 0.9256 - val_loss: 0.1986 - val_acc: 0.9457\n",
      "Epoch 498/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2484 - acc: 0.9286 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 499/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2453 - acc: 0.9271 - val_loss: 0.1985 - val_acc: 0.9457\n",
      "Epoch 500/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2438 - acc: 0.9256 - val_loss: 0.1922 - val_acc: 0.9457\n",
      "\n",
      "Epoch 00500: saving model to ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/2-000500-0.243847-0.945685.hdf5\n",
      "Epoch 501/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2455 - acc: 0.9263 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 502/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2495 - acc: 0.9249 - val_loss: 0.1983 - val_acc: 0.9457\n",
      "Epoch 503/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2496 - acc: 0.9267 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 504/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2588 - acc: 0.9204 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 505/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2476 - acc: 0.9275 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 506/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2580 - acc: 0.9249 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 507/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2542 - acc: 0.9282 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 508/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2513 - acc: 0.9260 - val_loss: 0.1990 - val_acc: 0.9449\n",
      "Epoch 509/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2484 - acc: 0.9222 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 510/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2455 - acc: 0.9260 - val_loss: 0.1996 - val_acc: 0.9449\n",
      "Epoch 511/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2454 - acc: 0.9342 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 512/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2491 - acc: 0.9260 - val_loss: 0.1978 - val_acc: 0.9457\n",
      "Epoch 513/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2362 - acc: 0.9286 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 514/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2553 - acc: 0.9211 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 515/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.2519 - acc: 0.9204 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 516/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.2386 - acc: 0.9286 - val_loss: 0.1997 - val_acc: 0.9449\n",
      "Epoch 517/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.2486 - acc: 0.9252 - val_loss: 0.1998 - val_acc: 0.9449\n",
      "Epoch 00517: early stopping\n",
      "ModelCheckpoint 已经保存到 ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/weights/2-final.hdf5\n",
      "save in: ../datasets/casas/results/WCNNR/milan/1/20220201_2000_64_1_3_1/log/20220201_2000_64_1_3_1.csv\n",
      "time: 0:13:47 s\n",
      "time: 827.0 s\n",
      "average 0.827000 s\n",
      "2 epoch finished\n",
      "--------------------   best   --------------------\n",
      "no_activities: 10\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1348/1348 [==============================] - 1s 673us/step\n",
      "2-milan:\tacc: 94.51%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [3, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 3, 3, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 7, 0, 0, 0, 0, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 7, 2, 7, 0, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 1, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7, 7, 2, 2, 7, 7, 2, 0, 2, 2, 7, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.966719  0.979133  0.972887       623\n",
      "         Work   0.730769  0.730769  0.730769        26\n",
      "Take_medicine   1.000000  0.450000  0.620690        20\n",
      "        Sleep   0.769231  0.937500  0.845070        32\n",
      "        Relax   0.986207  1.000000  0.993056       143\n",
      "   Leave_Home   1.000000  0.985915  0.992908        71\n",
      "          Eat   0.000000  0.000000  0.000000         7\n",
      "         Cook   0.947917  0.983784  0.965517       185\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        29\n",
      "      Bathing   0.894068  0.995283  0.941964       212\n",
      "\n",
      "     accuracy                       0.945104      1348\n",
      "    macro avg   0.729491  0.706238  0.706286      1348\n",
      " weighted avg   0.921970  0.945104  0.931295      1348\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  25   0   0   1   0   3]\n",
      " [  0  19   0   0   0   1   0   5   0   1]\n",
      " [  0   0   0   0   0   0   0   7   0   0]\n",
      " [  0   0   0   9   0   9   0   2   0   0]\n",
      " [  0   0   0   0 211   0   0   1   0   0]\n",
      " [  0   1   0   0   0 182   0   2   0   0]\n",
      " [  0   0   0   0   0   0  70   1   0   0]\n",
      " [  0   6   0   0   0   0   0 610   2   5]\n",
      " [  0   0   0   0   0   0   0   0 143   0]\n",
      " [  0   0   0   0   0   0   0   2   0  30]]\n",
      "--------------------   final   --------------------\n",
      "no_activities: 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1348/1348 [==============================] - 1s 634us/step\n",
      "2-milan:\tacc: 94.51%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [3, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 3, 3, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 7, 0, 0, 0, 0, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 7, 2, 7, 0, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 1, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7, 7, 2, 2, 7, 7, 2, 0, 2, 2, 7, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.966719  0.979133  0.972887       623\n",
      "         Work   0.730769  0.730769  0.730769        26\n",
      "Take_medicine   1.000000  0.450000  0.620690        20\n",
      "        Sleep   0.769231  0.937500  0.845070        32\n",
      "        Relax   0.986207  1.000000  0.993056       143\n",
      "   Leave_Home   1.000000  0.985915  0.992908        71\n",
      "          Eat   0.000000  0.000000  0.000000         7\n",
      "         Cook   0.947917  0.983784  0.965517       185\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        29\n",
      "      Bathing   0.894068  0.995283  0.941964       212\n",
      "\n",
      "     accuracy                       0.945104      1348\n",
      "    macro avg   0.729491  0.706238  0.706286      1348\n",
      " weighted avg   0.921970  0.945104  0.931295      1348\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  25   0   0   1   0   3]\n",
      " [  0  19   0   0   0   1   0   5   0   1]\n",
      " [  0   0   0   0   0   0   0   7   0   0]\n",
      " [  0   0   0   9   0   9   0   2   0   0]\n",
      " [  0   0   0   0 211   0   0   1   0   0]\n",
      " [  0   1   0   0   0 182   0   2   0   0]\n",
      " [  0   0   0   0   0   0  70   1   0   0]\n",
      " [  0   6   0   0   0   0   0 610   2   5]\n",
      " [  0   0   0   0   0   0   0   0 143   0]\n",
      " [  0   0   0   0   0   0   0   2   0  30]]\n",
      "best: current database: milan \t 94.26% (+/- 0.18%)\n",
      "final: current database: milan \t 94.26% (+/- 0.18%)\n",
      "CPU times: user 33min 21s, sys: 1min 24s, total: 34min 45s\n",
      "Wall time: 37min 14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dict_config_cus['distance_int'] = '1'\n",
    "train_val(dict_config_cus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "scrolled": true
   },
   "source": [
    "```bash\n",
    "best: current database: milan \t 94.26% (+/- 0.18%)\n",
    "final: current database: milan \t 94.26% (+/- 0.18%)\n",
    "CPU times: user 33min 21s, sys: 1min 24s, total: 34min 45s\n",
    "Wall time: 37min 14s\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='constrain_2'>CS_2</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current dataset: milan\n",
      "../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1\n",
      "no_activities: 10\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_28 (InputLayer)        (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_28 (Embedding)     (None, 2000, 64)          172544    \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 2000, 12)          780       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 2000, 12)          0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_28 (Glo (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 18)                234       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 12)                228       \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 10)                130       \n",
      "=================================================================\n",
      "Total params: 173,916\n",
      "Trainable params: 173,916\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Create subdir directory: ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights...\n",
      "Begin training ...\n",
      "Epoch 1/1000\n",
      "42/42 [==============================] - 3s 68ms/step - loss: 1.8495 - acc: 0.4055 - val_loss: 1.5573 - val_acc: 0.4896\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 1.5187 - acc: 0.5268 - val_loss: 1.3833 - val_acc: 0.5908\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.4114 - acc: 0.5584 - val_loss: 1.2850 - val_acc: 0.6012\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.3391 - acc: 0.5714 - val_loss: 1.2200 - val_acc: 0.6138\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.2834 - acc: 0.5833 - val_loss: 1.1693 - val_acc: 0.6153\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.2356 - acc: 0.6008 - val_loss: 1.1203 - val_acc: 0.6399\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.1856 - acc: 0.6138 - val_loss: 1.0707 - val_acc: 0.6622\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.1465 - acc: 0.6328 - val_loss: 1.0229 - val_acc: 0.6801\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.1111 - acc: 0.6391 - val_loss: 0.9922 - val_acc: 0.6868\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0986 - acc: 0.6481 - val_loss: 0.9537 - val_acc: 0.6868\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0572 - acc: 0.6548 - val_loss: 0.9160 - val_acc: 0.7039\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0278 - acc: 0.6722 - val_loss: 0.8975 - val_acc: 0.7128\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 1.0301 - acc: 0.6682 - val_loss: 0.8837 - val_acc: 0.7277\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9766 - acc: 0.6827 - val_loss: 0.8639 - val_acc: 0.7292\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9769 - acc: 0.6741 - val_loss: 0.8493 - val_acc: 0.7321\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9769 - acc: 0.6782 - val_loss: 0.8396 - val_acc: 0.7351\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9632 - acc: 0.6812 - val_loss: 0.8310 - val_acc: 0.7403\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9519 - acc: 0.6875 - val_loss: 0.8243 - val_acc: 0.7418\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.9263 - acc: 0.6931 - val_loss: 0.8067 - val_acc: 0.7507\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9364 - acc: 0.6882 - val_loss: 0.8027 - val_acc: 0.7426\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9239 - acc: 0.6953 - val_loss: 0.7947 - val_acc: 0.7500\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9068 - acc: 0.7076 - val_loss: 0.7839 - val_acc: 0.7552\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9086 - acc: 0.7035 - val_loss: 0.7810 - val_acc: 0.7545\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8973 - acc: 0.7102 - val_loss: 0.7743 - val_acc: 0.7560\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8991 - acc: 0.7005 - val_loss: 0.7693 - val_acc: 0.7478\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.8848 - acc: 0.7013 - val_loss: 0.7652 - val_acc: 0.7582\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8943 - acc: 0.6998 - val_loss: 0.7643 - val_acc: 0.7597\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8858 - acc: 0.7087 - val_loss: 0.7599 - val_acc: 0.7574\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9018 - acc: 0.7020 - val_loss: 0.7596 - val_acc: 0.7582\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8871 - acc: 0.6968 - val_loss: 0.7585 - val_acc: 0.7574\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8759 - acc: 0.7054 - val_loss: 0.7494 - val_acc: 0.7589\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8605 - acc: 0.7091 - val_loss: 0.7524 - val_acc: 0.7537\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8863 - acc: 0.7031 - val_loss: 0.7489 - val_acc: 0.7537\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8613 - acc: 0.7020 - val_loss: 0.7439 - val_acc: 0.7567\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.8475 - acc: 0.7165 - val_loss: 0.7415 - val_acc: 0.7574\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8423 - acc: 0.7243 - val_loss: 0.7355 - val_acc: 0.7582\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8435 - acc: 0.7124 - val_loss: 0.7343 - val_acc: 0.7552\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8486 - acc: 0.7094 - val_loss: 0.7315 - val_acc: 0.7582\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.8305 - acc: 0.7210 - val_loss: 0.7312 - val_acc: 0.7582\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8471 - acc: 0.7065 - val_loss: 0.7270 - val_acc: 0.7597\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8538 - acc: 0.7109 - val_loss: 0.7271 - val_acc: 0.7649\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.8224 - acc: 0.7180 - val_loss: 0.7245 - val_acc: 0.7560\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8471 - acc: 0.7046 - val_loss: 0.7208 - val_acc: 0.7619\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8285 - acc: 0.7173 - val_loss: 0.7203 - val_acc: 0.7619\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8239 - acc: 0.7128 - val_loss: 0.7169 - val_acc: 0.7619\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8021 - acc: 0.7318 - val_loss: 0.7166 - val_acc: 0.7619\n",
      "Epoch 47/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8137 - acc: 0.7139 - val_loss: 0.7143 - val_acc: 0.7604\n",
      "Epoch 48/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8239 - acc: 0.7173 - val_loss: 0.7160 - val_acc: 0.7612\n",
      "Epoch 49/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8177 - acc: 0.7277 - val_loss: 0.7131 - val_acc: 0.7626\n",
      "Epoch 50/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8181 - acc: 0.7195 - val_loss: 0.7089 - val_acc: 0.7649\n",
      "Epoch 51/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8068 - acc: 0.7143 - val_loss: 0.7111 - val_acc: 0.7634\n",
      "Epoch 52/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8210 - acc: 0.7247 - val_loss: 0.7100 - val_acc: 0.7634\n",
      "Epoch 53/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.8279 - acc: 0.7106 - val_loss: 0.7085 - val_acc: 0.7664\n",
      "Epoch 54/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8026 - acc: 0.7243 - val_loss: 0.7061 - val_acc: 0.7664\n",
      "Epoch 55/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8239 - acc: 0.7083 - val_loss: 0.7036 - val_acc: 0.7626\n",
      "Epoch 56/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8099 - acc: 0.7117 - val_loss: 0.7035 - val_acc: 0.7626\n",
      "Epoch 57/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8042 - acc: 0.7269 - val_loss: 0.7035 - val_acc: 0.7634\n",
      "Epoch 58/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8025 - acc: 0.7206 - val_loss: 0.7010 - val_acc: 0.7649\n",
      "Epoch 59/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8138 - acc: 0.7169 - val_loss: 0.7008 - val_acc: 0.7641\n",
      "Epoch 60/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7925 - acc: 0.7135 - val_loss: 0.6996 - val_acc: 0.7619\n",
      "Epoch 61/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7939 - acc: 0.7281 - val_loss: 0.6943 - val_acc: 0.7589\n",
      "Epoch 62/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7919 - acc: 0.7266 - val_loss: 0.6958 - val_acc: 0.7634\n",
      "Epoch 63/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8006 - acc: 0.7154 - val_loss: 0.6941 - val_acc: 0.7649\n",
      "Epoch 64/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7861 - acc: 0.7266 - val_loss: 0.6923 - val_acc: 0.7641\n",
      "Epoch 65/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7939 - acc: 0.7173 - val_loss: 0.6951 - val_acc: 0.7634\n",
      "\n",
      "Epoch 00065: loss improved from inf to 0.79391, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-0-000065-0.793909-0.763393.hdf5\n",
      "Epoch 66/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7839 - acc: 0.7243 - val_loss: 0.6900 - val_acc: 0.7664\n",
      "Epoch 67/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8010 - acc: 0.7184 - val_loss: 0.6911 - val_acc: 0.7671\n",
      "Epoch 68/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7928 - acc: 0.7180 - val_loss: 0.6908 - val_acc: 0.7634\n",
      "Epoch 69/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7861 - acc: 0.7266 - val_loss: 0.6909 - val_acc: 0.7649\n",
      "\n",
      "Epoch 00069: loss improved from 0.79391 to 0.78612, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-0-000069-0.786123-0.764881.hdf5\n",
      "Epoch 70/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7964 - acc: 0.7139 - val_loss: 0.6898 - val_acc: 0.7664\n",
      "Epoch 71/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7675 - acc: 0.7266 - val_loss: 0.6880 - val_acc: 0.7701\n",
      "Epoch 72/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7833 - acc: 0.7228 - val_loss: 0.6874 - val_acc: 0.7723\n",
      "Epoch 73/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7953 - acc: 0.7154 - val_loss: 0.6882 - val_acc: 0.7679\n",
      "Epoch 74/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7916 - acc: 0.7143 - val_loss: 0.6848 - val_acc: 0.7649\n",
      "Epoch 75/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7858 - acc: 0.7206 - val_loss: 0.6848 - val_acc: 0.7664\n",
      "Epoch 76/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7699 - acc: 0.7325 - val_loss: 0.6847 - val_acc: 0.7649\n",
      "Epoch 77/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7866 - acc: 0.7132 - val_loss: 0.6844 - val_acc: 0.7612\n",
      "Epoch 78/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7940 - acc: 0.7247 - val_loss: 0.6795 - val_acc: 0.7634\n",
      "Epoch 79/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7646 - acc: 0.7214 - val_loss: 0.6829 - val_acc: 0.7619\n",
      "Epoch 80/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7876 - acc: 0.7169 - val_loss: 0.6798 - val_acc: 0.7671\n",
      "Epoch 81/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7846 - acc: 0.7214 - val_loss: 0.6810 - val_acc: 0.7619\n",
      "\n",
      "Epoch 00081: loss improved from 0.78612 to 0.78463, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-0-000081-0.784631-0.761905.hdf5\n",
      "Epoch 82/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7662 - acc: 0.7340 - val_loss: 0.6780 - val_acc: 0.7664\n",
      "Epoch 83/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7716 - acc: 0.7273 - val_loss: 0.6769 - val_acc: 0.7686\n",
      "Epoch 84/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7734 - acc: 0.7277 - val_loss: 0.6794 - val_acc: 0.7641\n",
      "Epoch 85/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7751 - acc: 0.7199 - val_loss: 0.6803 - val_acc: 0.7701\n",
      "\n",
      "Epoch 00085: loss improved from 0.78463 to 0.77511, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-0-000085-0.775109-0.770089.hdf5\n",
      "Epoch 86/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7753 - acc: 0.7240 - val_loss: 0.6791 - val_acc: 0.7626\n",
      "Epoch 87/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7622 - acc: 0.7288 - val_loss: 0.6780 - val_acc: 0.7701\n",
      "Epoch 88/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7732 - acc: 0.7217 - val_loss: 0.6779 - val_acc: 0.7731\n",
      "Epoch 89/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7695 - acc: 0.7158 - val_loss: 0.6787 - val_acc: 0.7723\n",
      "\n",
      "Epoch 00089: loss improved from 0.77511 to 0.76952, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-0-000089-0.769516-0.772321.hdf5\n",
      "Epoch 90/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7870 - acc: 0.7210 - val_loss: 0.6769 - val_acc: 0.7664\n",
      "Epoch 91/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7737 - acc: 0.7143 - val_loss: 0.6772 - val_acc: 0.7746\n",
      "Epoch 92/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7710 - acc: 0.7228 - val_loss: 0.6753 - val_acc: 0.7716\n",
      "Epoch 93/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7609 - acc: 0.7325 - val_loss: 0.6736 - val_acc: 0.7664\n",
      "\n",
      "Epoch 00093: loss improved from 0.76952 to 0.76091, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-0-000093-0.760910-0.766369.hdf5\n",
      "Epoch 94/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7753 - acc: 0.7251 - val_loss: 0.6772 - val_acc: 0.7634\n",
      "Epoch 95/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7686 - acc: 0.7254 - val_loss: 0.6751 - val_acc: 0.7716\n",
      "Epoch 96/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7653 - acc: 0.7303 - val_loss: 0.6749 - val_acc: 0.7701\n",
      "Epoch 97/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7412 - acc: 0.7385 - val_loss: 0.6713 - val_acc: 0.7716\n",
      "\n",
      "Epoch 00097: loss improved from 0.76091 to 0.74115, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-0-000097-0.741153-0.771577.hdf5\n",
      "Epoch 98/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7502 - acc: 0.7318 - val_loss: 0.6691 - val_acc: 0.7723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7681 - acc: 0.7336 - val_loss: 0.6730 - val_acc: 0.7693\n",
      "Epoch 100/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7580 - acc: 0.7247 - val_loss: 0.6707 - val_acc: 0.7723\n",
      "\n",
      "Epoch 00100: saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/0-000100-0.758024-0.772321.hdf5\n",
      "Epoch 101/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7500 - acc: 0.7299 - val_loss: 0.6711 - val_acc: 0.7753\n",
      "Epoch 102/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7628 - acc: 0.7281 - val_loss: 0.6698 - val_acc: 0.7768\n",
      "Epoch 103/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7591 - acc: 0.7232 - val_loss: 0.6708 - val_acc: 0.7753\n",
      "Epoch 104/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7526 - acc: 0.7321 - val_loss: 0.6693 - val_acc: 0.7753\n",
      "Epoch 105/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7660 - acc: 0.7258 - val_loss: 0.6719 - val_acc: 0.7738\n",
      "Epoch 106/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7506 - acc: 0.7381 - val_loss: 0.6716 - val_acc: 0.7746\n",
      "Epoch 107/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7542 - acc: 0.7355 - val_loss: 0.6696 - val_acc: 0.7738\n",
      "Epoch 108/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7471 - acc: 0.7336 - val_loss: 0.6684 - val_acc: 0.7701\n",
      "Epoch 109/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7511 - acc: 0.7314 - val_loss: 0.6677 - val_acc: 0.7746\n",
      "Epoch 110/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7534 - acc: 0.7236 - val_loss: 0.6655 - val_acc: 0.7723\n",
      "Epoch 111/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7375 - acc: 0.7359 - val_loss: 0.6680 - val_acc: 0.7716\n",
      "Epoch 112/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7452 - acc: 0.7314 - val_loss: 0.6661 - val_acc: 0.7768\n",
      "Epoch 113/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7509 - acc: 0.7314 - val_loss: 0.6598 - val_acc: 0.7768\n",
      "Epoch 114/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7542 - acc: 0.7258 - val_loss: 0.6658 - val_acc: 0.7746\n",
      "Epoch 115/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7448 - acc: 0.7225 - val_loss: 0.6638 - val_acc: 0.7775\n",
      "Epoch 116/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7416 - acc: 0.7385 - val_loss: 0.6656 - val_acc: 0.7783\n",
      "Epoch 117/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7432 - acc: 0.7347 - val_loss: 0.6638 - val_acc: 0.7783\n",
      "Epoch 118/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7282 - acc: 0.7388 - val_loss: 0.6664 - val_acc: 0.7753\n",
      "Epoch 119/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7445 - acc: 0.7336 - val_loss: 0.6671 - val_acc: 0.7738\n",
      "Epoch 120/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7379 - acc: 0.7403 - val_loss: 0.6660 - val_acc: 0.7746\n",
      "Epoch 121/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7357 - acc: 0.7318 - val_loss: 0.6646 - val_acc: 0.7753\n",
      "Epoch 122/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7438 - acc: 0.7281 - val_loss: 0.6641 - val_acc: 0.7753\n",
      "Epoch 123/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7234 - acc: 0.7414 - val_loss: 0.6618 - val_acc: 0.7768\n",
      "Epoch 124/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7418 - acc: 0.7340 - val_loss: 0.6639 - val_acc: 0.7746\n",
      "Epoch 125/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7376 - acc: 0.7321 - val_loss: 0.6612 - val_acc: 0.7760\n",
      "Epoch 126/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7478 - acc: 0.7314 - val_loss: 0.6589 - val_acc: 0.7753\n",
      "Epoch 127/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7312 - acc: 0.7359 - val_loss: 0.6637 - val_acc: 0.7731\n",
      "Epoch 128/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7439 - acc: 0.7292 - val_loss: 0.6596 - val_acc: 0.7738\n",
      "Epoch 129/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7525 - acc: 0.7310 - val_loss: 0.6608 - val_acc: 0.7746\n",
      "Epoch 130/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7259 - acc: 0.7351 - val_loss: 0.6594 - val_acc: 0.7775\n",
      "Epoch 131/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7449 - acc: 0.7333 - val_loss: 0.6602 - val_acc: 0.7775\n",
      "Epoch 132/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7130 - acc: 0.7422 - val_loss: 0.6618 - val_acc: 0.7746\n",
      "Epoch 133/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7359 - acc: 0.7351 - val_loss: 0.6610 - val_acc: 0.7753\n",
      "Epoch 134/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7293 - acc: 0.7414 - val_loss: 0.6588 - val_acc: 0.7768\n",
      "Epoch 135/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7352 - acc: 0.7314 - val_loss: 0.6598 - val_acc: 0.7746\n",
      "Epoch 136/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7180 - acc: 0.7377 - val_loss: 0.6559 - val_acc: 0.7760\n",
      "Epoch 137/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7369 - acc: 0.7377 - val_loss: 0.6544 - val_acc: 0.7768\n",
      "Epoch 138/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7194 - acc: 0.7299 - val_loss: 0.6547 - val_acc: 0.7753\n",
      "Epoch 139/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7216 - acc: 0.7284 - val_loss: 0.6589 - val_acc: 0.7753\n",
      "Epoch 140/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7315 - acc: 0.7392 - val_loss: 0.6589 - val_acc: 0.7753\n",
      "Epoch 141/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7224 - acc: 0.7362 - val_loss: 0.6602 - val_acc: 0.7753\n",
      "Epoch 142/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7434 - acc: 0.7314 - val_loss: 0.6576 - val_acc: 0.7753\n",
      "Epoch 143/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7265 - acc: 0.7392 - val_loss: 0.6569 - val_acc: 0.7760\n",
      "Epoch 144/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7325 - acc: 0.7362 - val_loss: 0.6562 - val_acc: 0.7783\n",
      "Epoch 145/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7325 - acc: 0.7366 - val_loss: 0.6561 - val_acc: 0.7783\n",
      "Epoch 146/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7270 - acc: 0.7370 - val_loss: 0.6553 - val_acc: 0.7768\n",
      "Epoch 147/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7243 - acc: 0.7281 - val_loss: 0.6549 - val_acc: 0.7783\n",
      "Epoch 148/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7441 - acc: 0.7251 - val_loss: 0.6547 - val_acc: 0.7775\n",
      "Epoch 149/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7174 - acc: 0.7269 - val_loss: 0.6565 - val_acc: 0.7783\n",
      "Epoch 150/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7373 - acc: 0.7295 - val_loss: 0.6545 - val_acc: 0.7798\n",
      "Epoch 151/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7295 - acc: 0.7351 - val_loss: 0.6540 - val_acc: 0.7775\n",
      "Epoch 152/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7233 - acc: 0.7333 - val_loss: 0.6556 - val_acc: 0.7775\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 153/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7286 - acc: 0.7344 - val_loss: 0.6537 - val_acc: 0.7775\n",
      "Epoch 154/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7351 - acc: 0.7295 - val_loss: 0.6522 - val_acc: 0.7798\n",
      "Epoch 155/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7282 - acc: 0.7362 - val_loss: 0.6556 - val_acc: 0.7775\n",
      "Epoch 156/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7206 - acc: 0.7362 - val_loss: 0.6562 - val_acc: 0.7775\n",
      "Epoch 157/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7201 - acc: 0.7381 - val_loss: 0.6544 - val_acc: 0.7790\n",
      "Epoch 158/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7191 - acc: 0.7321 - val_loss: 0.6547 - val_acc: 0.7790\n",
      "Epoch 159/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7159 - acc: 0.7362 - val_loss: 0.6524 - val_acc: 0.7812\n",
      "Epoch 160/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7314 - acc: 0.7374 - val_loss: 0.6538 - val_acc: 0.7790\n",
      "Epoch 161/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7177 - acc: 0.7448 - val_loss: 0.6511 - val_acc: 0.7805\n",
      "Epoch 162/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7253 - acc: 0.7344 - val_loss: 0.6547 - val_acc: 0.7775\n",
      "Epoch 163/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7402 - acc: 0.7321 - val_loss: 0.6531 - val_acc: 0.7805\n",
      "Epoch 164/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7243 - acc: 0.7377 - val_loss: 0.6542 - val_acc: 0.7790\n",
      "Epoch 165/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7092 - acc: 0.7400 - val_loss: 0.6548 - val_acc: 0.7783\n",
      "\n",
      "Epoch 00165: loss improved from inf to 0.70920, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-0-000165-0.709198-0.778274.hdf5\n",
      "Epoch 166/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7398 - acc: 0.7221 - val_loss: 0.6506 - val_acc: 0.7798\n",
      "Epoch 167/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7028 - acc: 0.7459 - val_loss: 0.6534 - val_acc: 0.7783\n",
      "Epoch 168/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7114 - acc: 0.7396 - val_loss: 0.6515 - val_acc: 0.7798\n",
      "Epoch 169/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7237 - acc: 0.7299 - val_loss: 0.6521 - val_acc: 0.7798\n",
      "Epoch 170/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7226 - acc: 0.7347 - val_loss: 0.6526 - val_acc: 0.7805\n",
      "Epoch 171/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7126 - acc: 0.7418 - val_loss: 0.6528 - val_acc: 0.7790\n",
      "Epoch 172/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7133 - acc: 0.7340 - val_loss: 0.6540 - val_acc: 0.7783\n",
      "Epoch 173/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7279 - acc: 0.7351 - val_loss: 0.6466 - val_acc: 0.7805\n",
      "Epoch 174/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7095 - acc: 0.7396 - val_loss: 0.6527 - val_acc: 0.7775\n",
      "Epoch 175/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7155 - acc: 0.7366 - val_loss: 0.6512 - val_acc: 0.7790\n",
      "Epoch 176/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7192 - acc: 0.7411 - val_loss: 0.6536 - val_acc: 0.7783\n",
      "Epoch 177/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7255 - acc: 0.7392 - val_loss: 0.6529 - val_acc: 0.7790\n",
      "Epoch 178/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7146 - acc: 0.7440 - val_loss: 0.6537 - val_acc: 0.7783\n",
      "Epoch 179/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7007 - acc: 0.7448 - val_loss: 0.6509 - val_acc: 0.7798\n",
      "Epoch 180/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7086 - acc: 0.7422 - val_loss: 0.6534 - val_acc: 0.7775\n",
      "Epoch 181/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7070 - acc: 0.7437 - val_loss: 0.6498 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00181: loss improved from 0.70920 to 0.70699, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-0-000181-0.706988-0.779018.hdf5\n",
      "Epoch 182/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7032 - acc: 0.7370 - val_loss: 0.6511 - val_acc: 0.7783\n",
      "Epoch 183/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7177 - acc: 0.7381 - val_loss: 0.6524 - val_acc: 0.7783\n",
      "Epoch 184/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7223 - acc: 0.7340 - val_loss: 0.6505 - val_acc: 0.7790\n",
      "Epoch 185/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7356 - acc: 0.7347 - val_loss: 0.6522 - val_acc: 0.7783\n",
      "Epoch 186/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7225 - acc: 0.7377 - val_loss: 0.6527 - val_acc: 0.7790\n",
      "Epoch 187/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7097 - acc: 0.7418 - val_loss: 0.6514 - val_acc: 0.7783\n",
      "Epoch 188/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7296 - acc: 0.7318 - val_loss: 0.6517 - val_acc: 0.7790\n",
      "Epoch 189/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7177 - acc: 0.7426 - val_loss: 0.6484 - val_acc: 0.7798\n",
      "Epoch 190/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7136 - acc: 0.7374 - val_loss: 0.6525 - val_acc: 0.7798\n",
      "Epoch 191/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7345 - acc: 0.7344 - val_loss: 0.6461 - val_acc: 0.7798\n",
      "Epoch 192/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7175 - acc: 0.7366 - val_loss: 0.6487 - val_acc: 0.7805\n",
      "Epoch 193/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7250 - acc: 0.7299 - val_loss: 0.6510 - val_acc: 0.7798\n",
      "Epoch 194/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7316 - acc: 0.7314 - val_loss: 0.6432 - val_acc: 0.7798\n",
      "Epoch 195/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7169 - acc: 0.7374 - val_loss: 0.6521 - val_acc: 0.7783\n",
      "Epoch 196/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7145 - acc: 0.7411 - val_loss: 0.6509 - val_acc: 0.7790\n",
      "Epoch 197/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7236 - acc: 0.7310 - val_loss: 0.6484 - val_acc: 0.7798\n",
      "Epoch 198/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7231 - acc: 0.7284 - val_loss: 0.6527 - val_acc: 0.7783\n",
      "Epoch 199/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7123 - acc: 0.7418 - val_loss: 0.6495 - val_acc: 0.7798\n",
      "\n",
      "Epoch 00199: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 200/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7083 - acc: 0.7470 - val_loss: 0.6502 - val_acc: 0.7798\n",
      "\n",
      "Epoch 00200: saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/0-000200-0.708332-0.779762.hdf5\n",
      "Epoch 201/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7151 - acc: 0.7359 - val_loss: 0.6512 - val_acc: 0.7783\n",
      "Epoch 202/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7298 - acc: 0.7329 - val_loss: 0.6528 - val_acc: 0.7783\n",
      "Epoch 203/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7164 - acc: 0.7388 - val_loss: 0.6497 - val_acc: 0.7790\n",
      "Epoch 204/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7109 - acc: 0.7396 - val_loss: 0.6531 - val_acc: 0.7783\n",
      "Epoch 205/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7076 - acc: 0.7414 - val_loss: 0.6523 - val_acc: 0.7790\n",
      "Epoch 206/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7247 - acc: 0.7429 - val_loss: 0.6512 - val_acc: 0.7798\n",
      "Epoch 207/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7171 - acc: 0.7299 - val_loss: 0.6519 - val_acc: 0.7790\n",
      "Epoch 208/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7225 - acc: 0.7396 - val_loss: 0.6521 - val_acc: 0.7790\n",
      "Epoch 209/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7253 - acc: 0.7310 - val_loss: 0.6489 - val_acc: 0.7805\n",
      "Epoch 210/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7191 - acc: 0.7347 - val_loss: 0.6534 - val_acc: 0.7783\n",
      "Epoch 211/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7215 - acc: 0.7385 - val_loss: 0.6518 - val_acc: 0.7798\n",
      "Epoch 212/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7018 - acc: 0.7444 - val_loss: 0.6504 - val_acc: 0.7790\n",
      "Epoch 213/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7472 - acc: 0.7366 - val_loss: 0.6504 - val_acc: 0.7798\n",
      "Epoch 214/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7088 - acc: 0.7429 - val_loss: 0.6499 - val_acc: 0.7798\n",
      "Epoch 215/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7169 - acc: 0.7448 - val_loss: 0.6528 - val_acc: 0.7783\n",
      "Epoch 216/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7211 - acc: 0.7388 - val_loss: 0.6493 - val_acc: 0.7798\n",
      "Epoch 217/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7172 - acc: 0.7392 - val_loss: 0.6517 - val_acc: 0.7790\n",
      "Epoch 218/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7081 - acc: 0.7385 - val_loss: 0.6512 - val_acc: 0.7790\n",
      "Epoch 219/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7182 - acc: 0.7418 - val_loss: 0.6527 - val_acc: 0.7783\n",
      "\n",
      "Epoch 00219: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 220/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7174 - acc: 0.7385 - val_loss: 0.6506 - val_acc: 0.7798\n",
      "Epoch 221/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7126 - acc: 0.7388 - val_loss: 0.6500 - val_acc: 0.7798\n",
      "Epoch 222/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7079 - acc: 0.7351 - val_loss: 0.6518 - val_acc: 0.7790\n",
      "Epoch 223/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7340 - acc: 0.7329 - val_loss: 0.6495 - val_acc: 0.7798\n",
      "Epoch 224/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7099 - acc: 0.7422 - val_loss: 0.6519 - val_acc: 0.7798\n",
      "Epoch 225/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7146 - acc: 0.7366 - val_loss: 0.6524 - val_acc: 0.7790\n",
      "Epoch 226/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7275 - acc: 0.7355 - val_loss: 0.6488 - val_acc: 0.7798\n",
      "Epoch 227/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7145 - acc: 0.7359 - val_loss: 0.6520 - val_acc: 0.7790\n",
      "Epoch 228/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7188 - acc: 0.7347 - val_loss: 0.6457 - val_acc: 0.7805\n",
      "Epoch 229/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7149 - acc: 0.7385 - val_loss: 0.6520 - val_acc: 0.7790\n",
      "Epoch 230/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7039 - acc: 0.7478 - val_loss: 0.6475 - val_acc: 0.7790\n",
      "Epoch 231/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7147 - acc: 0.7459 - val_loss: 0.6530 - val_acc: 0.7783\n",
      "Epoch 232/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7144 - acc: 0.7377 - val_loss: 0.6502 - val_acc: 0.7790\n",
      "Epoch 233/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7246 - acc: 0.7433 - val_loss: 0.6516 - val_acc: 0.7783\n",
      "Epoch 234/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7226 - acc: 0.7400 - val_loss: 0.6517 - val_acc: 0.7798\n",
      "Epoch 235/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7306 - acc: 0.7288 - val_loss: 0.6512 - val_acc: 0.7798\n",
      "Epoch 236/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7196 - acc: 0.7344 - val_loss: 0.6513 - val_acc: 0.7790\n",
      "Epoch 237/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7173 - acc: 0.7422 - val_loss: 0.6499 - val_acc: 0.7805\n",
      "Epoch 238/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7245 - acc: 0.7344 - val_loss: 0.6520 - val_acc: 0.7790\n",
      "Epoch 239/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7313 - acc: 0.7347 - val_loss: 0.6526 - val_acc: 0.7783\n",
      "Epoch 240/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7185 - acc: 0.7444 - val_loss: 0.6524 - val_acc: 0.7783\n",
      "Epoch 241/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7109 - acc: 0.7403 - val_loss: 0.6520 - val_acc: 0.7798\n",
      "Epoch 242/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7370 - acc: 0.7414 - val_loss: 0.6515 - val_acc: 0.7790\n",
      "Epoch 243/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7142 - acc: 0.7344 - val_loss: 0.6529 - val_acc: 0.7783\n",
      "Epoch 244/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7118 - acc: 0.7370 - val_loss: 0.6508 - val_acc: 0.7798\n",
      "Epoch 245/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7246 - acc: 0.7392 - val_loss: 0.6531 - val_acc: 0.7783\n",
      "Epoch 246/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7281 - acc: 0.7388 - val_loss: 0.6498 - val_acc: 0.7798\n",
      "Epoch 247/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7186 - acc: 0.7333 - val_loss: 0.6514 - val_acc: 0.7790\n",
      "Epoch 248/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7290 - acc: 0.7310 - val_loss: 0.6518 - val_acc: 0.7790\n",
      "Epoch 249/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7186 - acc: 0.7422 - val_loss: 0.6506 - val_acc: 0.7798\n",
      "Epoch 250/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7282 - acc: 0.7344 - val_loss: 0.6522 - val_acc: 0.7783\n",
      "Epoch 251/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7095 - acc: 0.7440 - val_loss: 0.6520 - val_acc: 0.7790\n",
      "Epoch 252/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7187 - acc: 0.7414 - val_loss: 0.6508 - val_acc: 0.7790\n",
      "Epoch 253/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7163 - acc: 0.7433 - val_loss: 0.6475 - val_acc: 0.7790\n",
      "Epoch 254/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7059 - acc: 0.7426 - val_loss: 0.6518 - val_acc: 0.7790\n",
      "Epoch 255/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7219 - acc: 0.7374 - val_loss: 0.6521 - val_acc: 0.7783\n",
      "Epoch 256/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7155 - acc: 0.7396 - val_loss: 0.6477 - val_acc: 0.7805\n",
      "Epoch 257/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7184 - acc: 0.7377 - val_loss: 0.6524 - val_acc: 0.7790\n",
      "Epoch 258/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7215 - acc: 0.7396 - val_loss: 0.6484 - val_acc: 0.7798\n",
      "Epoch 259/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7205 - acc: 0.7407 - val_loss: 0.6519 - val_acc: 0.7790\n",
      "Epoch 260/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7191 - acc: 0.7530 - val_loss: 0.6480 - val_acc: 0.7798\n",
      "Epoch 261/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7119 - acc: 0.7347 - val_loss: 0.6511 - val_acc: 0.7790\n",
      "Epoch 262/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7099 - acc: 0.7437 - val_loss: 0.6524 - val_acc: 0.7790\n",
      "Epoch 263/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7267 - acc: 0.7392 - val_loss: 0.6512 - val_acc: 0.7790\n",
      "Epoch 264/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7261 - acc: 0.7347 - val_loss: 0.6527 - val_acc: 0.7783\n",
      "Epoch 265/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7327 - acc: 0.7314 - val_loss: 0.6527 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00265: loss improved from inf to 0.73269, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-0-000265-0.732686-0.779018.hdf5\n",
      "Epoch 266/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7242 - acc: 0.7400 - val_loss: 0.6505 - val_acc: 0.7805\n",
      "Epoch 267/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7143 - acc: 0.7414 - val_loss: 0.6427 - val_acc: 0.7805\n",
      "Epoch 268/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7107 - acc: 0.7366 - val_loss: 0.6527 - val_acc: 0.7783\n",
      "Epoch 269/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7083 - acc: 0.7444 - val_loss: 0.6514 - val_acc: 0.7798\n",
      "\n",
      "Epoch 00269: loss improved from 0.73269 to 0.70831, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-0-000269-0.708307-0.779762.hdf5\n",
      "Epoch 270/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7117 - acc: 0.7329 - val_loss: 0.6473 - val_acc: 0.7805\n",
      "Epoch 271/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7191 - acc: 0.7385 - val_loss: 0.6513 - val_acc: 0.7790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 272/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7039 - acc: 0.7481 - val_loss: 0.6485 - val_acc: 0.7790\n",
      "Epoch 273/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7195 - acc: 0.7284 - val_loss: 0.6529 - val_acc: 0.7783\n",
      "Epoch 274/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7107 - acc: 0.7418 - val_loss: 0.6497 - val_acc: 0.7790\n",
      "Epoch 275/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7171 - acc: 0.7388 - val_loss: 0.6513 - val_acc: 0.7790\n",
      "Epoch 276/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7255 - acc: 0.7344 - val_loss: 0.6472 - val_acc: 0.7798\n",
      "Epoch 277/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7172 - acc: 0.7470 - val_loss: 0.6525 - val_acc: 0.7783\n",
      "Epoch 278/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7197 - acc: 0.7351 - val_loss: 0.6480 - val_acc: 0.7798\n",
      "Epoch 279/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7075 - acc: 0.7392 - val_loss: 0.6466 - val_acc: 0.7798\n",
      "Epoch 280/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7215 - acc: 0.7392 - val_loss: 0.6490 - val_acc: 0.7790\n",
      "Epoch 281/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7151 - acc: 0.7385 - val_loss: 0.6530 - val_acc: 0.7783\n",
      "Epoch 282/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7166 - acc: 0.7351 - val_loss: 0.6485 - val_acc: 0.7798\n",
      "Epoch 283/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7120 - acc: 0.7340 - val_loss: 0.6524 - val_acc: 0.7783\n",
      "Epoch 284/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7227 - acc: 0.7359 - val_loss: 0.6524 - val_acc: 0.7783\n",
      "Epoch 285/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7282 - acc: 0.7396 - val_loss: 0.6501 - val_acc: 0.7790\n",
      "Epoch 286/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7183 - acc: 0.7359 - val_loss: 0.6501 - val_acc: 0.7798\n",
      "Epoch 287/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7267 - acc: 0.7396 - val_loss: 0.6488 - val_acc: 0.7790\n",
      "Epoch 288/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7226 - acc: 0.7392 - val_loss: 0.6517 - val_acc: 0.7790\n",
      "Epoch 289/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6997 - acc: 0.7481 - val_loss: 0.6494 - val_acc: 0.7798\n",
      "\n",
      "Epoch 00289: loss improved from 0.70831 to 0.69968, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-0-000289-0.699679-0.779762.hdf5\n",
      "Epoch 290/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7086 - acc: 0.7392 - val_loss: 0.6526 - val_acc: 0.7783\n",
      "Epoch 291/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7315 - acc: 0.7340 - val_loss: 0.6497 - val_acc: 0.7805\n",
      "Epoch 292/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7175 - acc: 0.7381 - val_loss: 0.6527 - val_acc: 0.7783\n",
      "Epoch 293/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7039 - acc: 0.7374 - val_loss: 0.6514 - val_acc: 0.7790\n",
      "Epoch 294/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7140 - acc: 0.7426 - val_loss: 0.6505 - val_acc: 0.7798\n",
      "Epoch 295/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7104 - acc: 0.7340 - val_loss: 0.6528 - val_acc: 0.7783\n",
      "Epoch 296/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7275 - acc: 0.7288 - val_loss: 0.6485 - val_acc: 0.7798\n",
      "Epoch 297/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7135 - acc: 0.7426 - val_loss: 0.6479 - val_acc: 0.7805\n",
      "Epoch 298/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7164 - acc: 0.7359 - val_loss: 0.6521 - val_acc: 0.7790\n",
      "Epoch 299/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7148 - acc: 0.7355 - val_loss: 0.6522 - val_acc: 0.7783\n",
      "Epoch 300/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7219 - acc: 0.7374 - val_loss: 0.6516 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00300: saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/0-000300-0.721926-0.779018.hdf5\n",
      "Epoch 301/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7091 - acc: 0.7396 - val_loss: 0.6532 - val_acc: 0.7783\n",
      "Epoch 302/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7143 - acc: 0.7433 - val_loss: 0.6525 - val_acc: 0.7783\n",
      "Epoch 303/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7063 - acc: 0.7407 - val_loss: 0.6506 - val_acc: 0.7790\n",
      "Epoch 304/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7166 - acc: 0.7444 - val_loss: 0.6525 - val_acc: 0.7783\n",
      "Epoch 305/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7080 - acc: 0.7459 - val_loss: 0.6520 - val_acc: 0.7790\n",
      "Epoch 306/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7334 - acc: 0.7295 - val_loss: 0.6512 - val_acc: 0.7790\n",
      "Epoch 307/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7165 - acc: 0.7344 - val_loss: 0.6514 - val_acc: 0.7783\n",
      "Epoch 308/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7139 - acc: 0.7474 - val_loss: 0.6448 - val_acc: 0.7790\n",
      "Epoch 309/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7106 - acc: 0.7362 - val_loss: 0.6525 - val_acc: 0.7783\n",
      "Epoch 310/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7129 - acc: 0.7351 - val_loss: 0.6519 - val_acc: 0.7790\n",
      "Epoch 311/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7251 - acc: 0.7359 - val_loss: 0.6494 - val_acc: 0.7805\n",
      "Epoch 312/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7081 - acc: 0.7437 - val_loss: 0.6484 - val_acc: 0.7798\n",
      "Epoch 313/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7229 - acc: 0.7336 - val_loss: 0.6530 - val_acc: 0.7783\n",
      "Epoch 314/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7228 - acc: 0.7295 - val_loss: 0.6521 - val_acc: 0.7783\n",
      "Epoch 315/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6993 - acc: 0.7485 - val_loss: 0.6512 - val_acc: 0.7798\n",
      "Epoch 316/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7129 - acc: 0.7422 - val_loss: 0.6504 - val_acc: 0.7790\n",
      "Epoch 317/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7120 - acc: 0.7351 - val_loss: 0.6515 - val_acc: 0.7798\n",
      "Epoch 318/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7128 - acc: 0.7333 - val_loss: 0.6518 - val_acc: 0.7790\n",
      "Epoch 319/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7092 - acc: 0.7400 - val_loss: 0.6530 - val_acc: 0.7783\n",
      "Epoch 320/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7071 - acc: 0.7381 - val_loss: 0.6480 - val_acc: 0.7798\n",
      "Epoch 321/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7277 - acc: 0.7340 - val_loss: 0.6516 - val_acc: 0.7790\n",
      "Epoch 322/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7235 - acc: 0.7366 - val_loss: 0.6528 - val_acc: 0.7783\n",
      "Epoch 323/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7442 - acc: 0.7362 - val_loss: 0.6499 - val_acc: 0.7798\n",
      "Epoch 324/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7069 - acc: 0.7485 - val_loss: 0.6507 - val_acc: 0.7798\n",
      "Epoch 325/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7086 - acc: 0.7403 - val_loss: 0.6531 - val_acc: 0.7783\n",
      "Epoch 326/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7226 - acc: 0.7374 - val_loss: 0.6514 - val_acc: 0.7790\n",
      "Epoch 327/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7052 - acc: 0.7400 - val_loss: 0.6501 - val_acc: 0.7798\n",
      "Epoch 328/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7204 - acc: 0.7381 - val_loss: 0.6494 - val_acc: 0.7798\n",
      "Epoch 329/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7175 - acc: 0.7396 - val_loss: 0.6516 - val_acc: 0.7790\n",
      "Epoch 330/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7135 - acc: 0.7426 - val_loss: 0.6521 - val_acc: 0.7783\n",
      "Epoch 331/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7401 - acc: 0.7310 - val_loss: 0.6506 - val_acc: 0.7798\n",
      "Epoch 332/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7174 - acc: 0.7340 - val_loss: 0.6506 - val_acc: 0.7798\n",
      "Epoch 333/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7121 - acc: 0.7467 - val_loss: 0.6489 - val_acc: 0.7798\n",
      "Epoch 334/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7101 - acc: 0.7459 - val_loss: 0.6490 - val_acc: 0.7790\n",
      "Epoch 335/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7163 - acc: 0.7411 - val_loss: 0.6507 - val_acc: 0.7790\n",
      "Epoch 336/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7200 - acc: 0.7374 - val_loss: 0.6489 - val_acc: 0.7798\n",
      "Epoch 337/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7152 - acc: 0.7381 - val_loss: 0.6513 - val_acc: 0.7783\n",
      "Epoch 338/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7175 - acc: 0.7359 - val_loss: 0.6530 - val_acc: 0.7783\n",
      "Epoch 339/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7222 - acc: 0.7385 - val_loss: 0.6485 - val_acc: 0.7798\n",
      "Epoch 340/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7294 - acc: 0.7303 - val_loss: 0.6475 - val_acc: 0.7798\n",
      "Epoch 341/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7169 - acc: 0.7377 - val_loss: 0.6474 - val_acc: 0.7790\n",
      "Epoch 342/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7136 - acc: 0.7400 - val_loss: 0.6521 - val_acc: 0.7790\n",
      "Epoch 343/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7084 - acc: 0.7381 - val_loss: 0.6516 - val_acc: 0.7790\n",
      "Epoch 344/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7257 - acc: 0.7303 - val_loss: 0.6527 - val_acc: 0.7783\n",
      "Epoch 345/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7165 - acc: 0.7377 - val_loss: 0.6527 - val_acc: 0.7783\n",
      "Epoch 346/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7127 - acc: 0.7377 - val_loss: 0.6529 - val_acc: 0.7783\n",
      "Epoch 347/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7058 - acc: 0.7400 - val_loss: 0.6509 - val_acc: 0.7790\n",
      "Epoch 348/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7233 - acc: 0.7374 - val_loss: 0.6529 - val_acc: 0.7783\n",
      "Epoch 349/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7099 - acc: 0.7396 - val_loss: 0.6521 - val_acc: 0.7783\n",
      "Epoch 350/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7136 - acc: 0.7407 - val_loss: 0.6528 - val_acc: 0.7783\n",
      "Epoch 351/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7142 - acc: 0.7377 - val_loss: 0.6521 - val_acc: 0.7783\n",
      "Epoch 352/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7192 - acc: 0.7374 - val_loss: 0.6528 - val_acc: 0.7783\n",
      "Epoch 353/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7147 - acc: 0.7366 - val_loss: 0.6524 - val_acc: 0.7790\n",
      "Epoch 354/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7210 - acc: 0.7422 - val_loss: 0.6509 - val_acc: 0.7790\n",
      "Epoch 355/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7019 - acc: 0.7426 - val_loss: 0.6523 - val_acc: 0.7790\n",
      "Epoch 356/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7204 - acc: 0.7340 - val_loss: 0.6525 - val_acc: 0.7783\n",
      "Epoch 357/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7117 - acc: 0.7403 - val_loss: 0.6530 - val_acc: 0.7783\n",
      "Epoch 358/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7127 - acc: 0.7407 - val_loss: 0.6503 - val_acc: 0.7798\n",
      "Epoch 359/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7181 - acc: 0.7333 - val_loss: 0.6504 - val_acc: 0.7798\n",
      "Epoch 360/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7090 - acc: 0.7355 - val_loss: 0.6505 - val_acc: 0.7798\n",
      "Epoch 361/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7266 - acc: 0.7340 - val_loss: 0.6528 - val_acc: 0.7783\n",
      "Epoch 362/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7118 - acc: 0.7414 - val_loss: 0.6525 - val_acc: 0.7783\n",
      "Epoch 363/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7129 - acc: 0.7299 - val_loss: 0.6510 - val_acc: 0.7790\n",
      "Epoch 364/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7208 - acc: 0.7411 - val_loss: 0.6517 - val_acc: 0.7790\n",
      "Epoch 365/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7170 - acc: 0.7388 - val_loss: 0.6527 - val_acc: 0.7783\n",
      "\n",
      "Epoch 00365: loss improved from inf to 0.71697, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-0-000365-0.716968-0.778274.hdf5\n",
      "Epoch 366/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7151 - acc: 0.7426 - val_loss: 0.6517 - val_acc: 0.7790\n",
      "Epoch 367/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7231 - acc: 0.7359 - val_loss: 0.6520 - val_acc: 0.7783\n",
      "Epoch 368/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7135 - acc: 0.7377 - val_loss: 0.6504 - val_acc: 0.7798\n",
      "Epoch 369/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7206 - acc: 0.7362 - val_loss: 0.6523 - val_acc: 0.7790\n",
      "Epoch 370/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7180 - acc: 0.7362 - val_loss: 0.6513 - val_acc: 0.7790\n",
      "Epoch 371/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7254 - acc: 0.7370 - val_loss: 0.6506 - val_acc: 0.7798\n",
      "Epoch 372/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7175 - acc: 0.7325 - val_loss: 0.6511 - val_acc: 0.7790\n",
      "Epoch 373/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7120 - acc: 0.7467 - val_loss: 0.6528 - val_acc: 0.7783\n",
      "\n",
      "Epoch 00373: loss improved from 0.71697 to 0.71202, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-0-000373-0.712022-0.778274.hdf5\n",
      "Epoch 374/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7209 - acc: 0.7370 - val_loss: 0.6516 - val_acc: 0.7790\n",
      "Epoch 375/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7165 - acc: 0.7411 - val_loss: 0.6525 - val_acc: 0.7783\n",
      "Epoch 376/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7079 - acc: 0.7407 - val_loss: 0.6513 - val_acc: 0.7790\n",
      "Epoch 377/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7272 - acc: 0.7318 - val_loss: 0.6523 - val_acc: 0.7783\n",
      "Epoch 378/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7013 - acc: 0.7474 - val_loss: 0.6498 - val_acc: 0.7798\n",
      "Epoch 379/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7061 - acc: 0.7340 - val_loss: 0.6525 - val_acc: 0.7783\n",
      "Epoch 380/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7348 - acc: 0.7336 - val_loss: 0.6512 - val_acc: 0.7783\n",
      "Epoch 381/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7136 - acc: 0.7426 - val_loss: 0.6501 - val_acc: 0.7805\n",
      "Epoch 382/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7218 - acc: 0.7370 - val_loss: 0.6508 - val_acc: 0.7798\n",
      "Epoch 383/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7173 - acc: 0.7273 - val_loss: 0.6507 - val_acc: 0.7798\n",
      "Epoch 384/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7160 - acc: 0.7433 - val_loss: 0.6496 - val_acc: 0.7798\n",
      "Epoch 385/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7184 - acc: 0.7310 - val_loss: 0.6525 - val_acc: 0.7783\n",
      "Epoch 386/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7166 - acc: 0.7355 - val_loss: 0.6506 - val_acc: 0.7790\n",
      "Epoch 387/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7133 - acc: 0.7478 - val_loss: 0.6513 - val_acc: 0.7790\n",
      "Epoch 388/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7211 - acc: 0.7318 - val_loss: 0.6517 - val_acc: 0.7783\n",
      "Epoch 389/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7138 - acc: 0.7426 - val_loss: 0.6518 - val_acc: 0.7790\n",
      "Epoch 390/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7132 - acc: 0.7351 - val_loss: 0.6519 - val_acc: 0.7783\n",
      "Epoch 391/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7177 - acc: 0.7400 - val_loss: 0.6523 - val_acc: 0.7783\n",
      "Epoch 392/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7183 - acc: 0.7385 - val_loss: 0.6515 - val_acc: 0.7790\n",
      "Epoch 393/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7212 - acc: 0.7362 - val_loss: 0.6510 - val_acc: 0.7790\n",
      "Epoch 394/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7353 - acc: 0.7266 - val_loss: 0.6498 - val_acc: 0.7798\n",
      "Epoch 395/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7155 - acc: 0.7388 - val_loss: 0.6481 - val_acc: 0.7805\n",
      "Epoch 396/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7005 - acc: 0.7381 - val_loss: 0.6505 - val_acc: 0.7790\n",
      "Epoch 397/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7044 - acc: 0.7444 - val_loss: 0.6504 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00397: loss improved from 0.71202 to 0.70439, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-0-000397-0.704391-0.779018.hdf5\n",
      "Epoch 398/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7273 - acc: 0.7303 - val_loss: 0.6517 - val_acc: 0.7790\n",
      "Epoch 399/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7086 - acc: 0.7463 - val_loss: 0.6525 - val_acc: 0.7783\n",
      "Epoch 400/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7110 - acc: 0.7418 - val_loss: 0.6526 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00400: saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/0-000400-0.710972-0.779018.hdf5\n",
      "Epoch 401/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7186 - acc: 0.7400 - val_loss: 0.6522 - val_acc: 0.7783\n",
      "Epoch 402/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7344 - acc: 0.7243 - val_loss: 0.6508 - val_acc: 0.7790\n",
      "Epoch 403/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7169 - acc: 0.7411 - val_loss: 0.6469 - val_acc: 0.7798\n",
      "Epoch 404/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7264 - acc: 0.7359 - val_loss: 0.6520 - val_acc: 0.7783\n",
      "Epoch 405/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7131 - acc: 0.7377 - val_loss: 0.6517 - val_acc: 0.7783\n",
      "Epoch 406/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7185 - acc: 0.7392 - val_loss: 0.6519 - val_acc: 0.7783\n",
      "Epoch 407/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7215 - acc: 0.7344 - val_loss: 0.6492 - val_acc: 0.7805\n",
      "Epoch 408/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7109 - acc: 0.7444 - val_loss: 0.6501 - val_acc: 0.7790\n",
      "Epoch 409/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7122 - acc: 0.7470 - val_loss: 0.6517 - val_acc: 0.7790\n",
      "Epoch 410/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7280 - acc: 0.7281 - val_loss: 0.6519 - val_acc: 0.7783\n",
      "Epoch 411/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7206 - acc: 0.7381 - val_loss: 0.6522 - val_acc: 0.7783\n",
      "Epoch 412/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7066 - acc: 0.7374 - val_loss: 0.6483 - val_acc: 0.7798\n",
      "Epoch 413/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7055 - acc: 0.7485 - val_loss: 0.6522 - val_acc: 0.7783\n",
      "Epoch 414/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7245 - acc: 0.7351 - val_loss: 0.6508 - val_acc: 0.7790\n",
      "Epoch 415/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7311 - acc: 0.7307 - val_loss: 0.6492 - val_acc: 0.7790\n",
      "Epoch 416/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7140 - acc: 0.7325 - val_loss: 0.6522 - val_acc: 0.7783\n",
      "Epoch 417/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7071 - acc: 0.7422 - val_loss: 0.6507 - val_acc: 0.7790\n",
      "Epoch 418/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7097 - acc: 0.7455 - val_loss: 0.6523 - val_acc: 0.7790\n",
      "Epoch 419/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7105 - acc: 0.7385 - val_loss: 0.6517 - val_acc: 0.7783\n",
      "Epoch 420/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7112 - acc: 0.7433 - val_loss: 0.6506 - val_acc: 0.7790\n",
      "Epoch 421/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7153 - acc: 0.7392 - val_loss: 0.6517 - val_acc: 0.7790\n",
      "Epoch 422/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7256 - acc: 0.7359 - val_loss: 0.6520 - val_acc: 0.7790\n",
      "Epoch 423/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7079 - acc: 0.7403 - val_loss: 0.6508 - val_acc: 0.7798\n",
      "Epoch 424/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7223 - acc: 0.7284 - val_loss: 0.6517 - val_acc: 0.7790\n",
      "Epoch 425/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7224 - acc: 0.7307 - val_loss: 0.6517 - val_acc: 0.7790\n",
      "Epoch 426/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7097 - acc: 0.7426 - val_loss: 0.6514 - val_acc: 0.7790\n",
      "Epoch 427/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7157 - acc: 0.7388 - val_loss: 0.6520 - val_acc: 0.7790\n",
      "Epoch 428/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7097 - acc: 0.7344 - val_loss: 0.6529 - val_acc: 0.7783\n",
      "Epoch 429/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7035 - acc: 0.7481 - val_loss: 0.6526 - val_acc: 0.7783\n",
      "Epoch 430/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7104 - acc: 0.7433 - val_loss: 0.6514 - val_acc: 0.7790\n",
      "Epoch 431/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6989 - acc: 0.7448 - val_loss: 0.6530 - val_acc: 0.7783\n",
      "Epoch 432/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7034 - acc: 0.7478 - val_loss: 0.6516 - val_acc: 0.7783\n",
      "Epoch 433/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6908 - acc: 0.7448 - val_loss: 0.6523 - val_acc: 0.7783\n",
      "Epoch 434/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7377 - acc: 0.7325 - val_loss: 0.6508 - val_acc: 0.7790\n",
      "Epoch 435/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7099 - acc: 0.7504 - val_loss: 0.6519 - val_acc: 0.7783\n",
      "Epoch 436/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7161 - acc: 0.7418 - val_loss: 0.6510 - val_acc: 0.7798\n",
      "Epoch 437/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7174 - acc: 0.7388 - val_loss: 0.6499 - val_acc: 0.7798\n",
      "Epoch 438/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7375 - acc: 0.7333 - val_loss: 0.6470 - val_acc: 0.7805\n",
      "Epoch 439/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7028 - acc: 0.7440 - val_loss: 0.6472 - val_acc: 0.7798\n",
      "Epoch 440/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7194 - acc: 0.7370 - val_loss: 0.6517 - val_acc: 0.7790\n",
      "Epoch 441/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7088 - acc: 0.7336 - val_loss: 0.6494 - val_acc: 0.7790\n",
      "Epoch 442/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7128 - acc: 0.7440 - val_loss: 0.6525 - val_acc: 0.7783\n",
      "Epoch 443/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7371 - acc: 0.7329 - val_loss: 0.6502 - val_acc: 0.7798\n",
      "Epoch 444/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7184 - acc: 0.7440 - val_loss: 0.6491 - val_acc: 0.7798\n",
      "Epoch 445/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7150 - acc: 0.7392 - val_loss: 0.6528 - val_acc: 0.7783\n",
      "Epoch 446/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7119 - acc: 0.7429 - val_loss: 0.6519 - val_acc: 0.7783\n",
      "Epoch 447/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7170 - acc: 0.7366 - val_loss: 0.6519 - val_acc: 0.7790\n",
      "Epoch 448/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7139 - acc: 0.7403 - val_loss: 0.6514 - val_acc: 0.7790\n",
      "Epoch 449/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7236 - acc: 0.7329 - val_loss: 0.6518 - val_acc: 0.7783\n",
      "Epoch 450/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7183 - acc: 0.7385 - val_loss: 0.6521 - val_acc: 0.7783\n",
      "Epoch 451/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7252 - acc: 0.7351 - val_loss: 0.6504 - val_acc: 0.7790\n",
      "Epoch 452/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7160 - acc: 0.7385 - val_loss: 0.6500 - val_acc: 0.7798\n",
      "Epoch 453/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7289 - acc: 0.7400 - val_loss: 0.6506 - val_acc: 0.7790\n",
      "Epoch 454/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7226 - acc: 0.7325 - val_loss: 0.6525 - val_acc: 0.7783\n",
      "Epoch 455/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7213 - acc: 0.7362 - val_loss: 0.6515 - val_acc: 0.7790\n",
      "Epoch 456/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7220 - acc: 0.7370 - val_loss: 0.6508 - val_acc: 0.7798\n",
      "Epoch 457/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7037 - acc: 0.7448 - val_loss: 0.6522 - val_acc: 0.7783\n",
      "Epoch 458/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7101 - acc: 0.7422 - val_loss: 0.6522 - val_acc: 0.7783\n",
      "Epoch 459/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7040 - acc: 0.7515 - val_loss: 0.6526 - val_acc: 0.7783\n",
      "Epoch 460/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7178 - acc: 0.7355 - val_loss: 0.6518 - val_acc: 0.7783\n",
      "Epoch 461/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7205 - acc: 0.7377 - val_loss: 0.6530 - val_acc: 0.7783\n",
      "Epoch 462/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7115 - acc: 0.7396 - val_loss: 0.6521 - val_acc: 0.7790\n",
      "Epoch 463/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7220 - acc: 0.7344 - val_loss: 0.6517 - val_acc: 0.7790\n",
      "Epoch 464/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7008 - acc: 0.7455 - val_loss: 0.6506 - val_acc: 0.7798\n",
      "Epoch 465/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7143 - acc: 0.7392 - val_loss: 0.6508 - val_acc: 0.7798\n",
      "\n",
      "Epoch 00465: loss improved from inf to 0.71430, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-0-000465-0.714302-0.779762.hdf5\n",
      "Epoch 466/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7042 - acc: 0.7489 - val_loss: 0.6527 - val_acc: 0.7783\n",
      "Epoch 467/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7033 - acc: 0.7526 - val_loss: 0.6501 - val_acc: 0.7798\n",
      "Epoch 468/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7205 - acc: 0.7407 - val_loss: 0.6509 - val_acc: 0.7798\n",
      "Epoch 469/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7314 - acc: 0.7336 - val_loss: 0.6509 - val_acc: 0.7790\n",
      "Epoch 470/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7287 - acc: 0.7362 - val_loss: 0.6508 - val_acc: 0.7790\n",
      "Epoch 471/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7285 - acc: 0.7284 - val_loss: 0.6499 - val_acc: 0.7790\n",
      "Epoch 472/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7115 - acc: 0.7400 - val_loss: 0.6515 - val_acc: 0.7783\n",
      "Epoch 473/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7151 - acc: 0.7381 - val_loss: 0.6504 - val_acc: 0.7798\n",
      "Epoch 474/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6998 - acc: 0.7467 - val_loss: 0.6500 - val_acc: 0.7798\n",
      "Epoch 475/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7115 - acc: 0.7429 - val_loss: 0.6439 - val_acc: 0.7798\n",
      "Epoch 476/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7188 - acc: 0.7418 - val_loss: 0.6528 - val_acc: 0.7783\n",
      "Epoch 477/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7148 - acc: 0.7411 - val_loss: 0.6524 - val_acc: 0.7783\n",
      "Epoch 478/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7066 - acc: 0.7519 - val_loss: 0.6527 - val_acc: 0.7783\n",
      "Epoch 479/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7354 - acc: 0.7385 - val_loss: 0.6524 - val_acc: 0.7783\n",
      "Epoch 480/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7246 - acc: 0.7344 - val_loss: 0.6502 - val_acc: 0.7790\n",
      "Epoch 481/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7200 - acc: 0.7411 - val_loss: 0.6478 - val_acc: 0.7812\n",
      "Epoch 482/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7250 - acc: 0.7396 - val_loss: 0.6512 - val_acc: 0.7798\n",
      "Epoch 483/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7100 - acc: 0.7396 - val_loss: 0.6520 - val_acc: 0.7790\n",
      "Epoch 484/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7232 - acc: 0.7277 - val_loss: 0.6513 - val_acc: 0.7790\n",
      "Epoch 485/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7199 - acc: 0.7355 - val_loss: 0.6511 - val_acc: 0.7790\n",
      "Epoch 486/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7142 - acc: 0.7295 - val_loss: 0.6487 - val_acc: 0.7798\n",
      "Epoch 487/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7182 - acc: 0.7463 - val_loss: 0.6512 - val_acc: 0.7790\n",
      "Epoch 488/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7179 - acc: 0.7340 - val_loss: 0.6523 - val_acc: 0.7783\n",
      "Epoch 489/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7169 - acc: 0.7470 - val_loss: 0.6484 - val_acc: 0.7798\n",
      "Epoch 490/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7192 - acc: 0.7381 - val_loss: 0.6516 - val_acc: 0.7783\n",
      "Epoch 491/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7138 - acc: 0.7347 - val_loss: 0.6528 - val_acc: 0.7783\n",
      "Epoch 492/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7100 - acc: 0.7411 - val_loss: 0.6512 - val_acc: 0.7790\n",
      "Epoch 493/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7099 - acc: 0.7437 - val_loss: 0.6498 - val_acc: 0.7798\n",
      "\n",
      "Epoch 00493: loss improved from 0.71430 to 0.70988, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-0-000493-0.709876-0.779762.hdf5\n",
      "Epoch 494/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7207 - acc: 0.7374 - val_loss: 0.6519 - val_acc: 0.7790\n",
      "Epoch 495/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7221 - acc: 0.7385 - val_loss: 0.6519 - val_acc: 0.7790\n",
      "Epoch 496/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7200 - acc: 0.7321 - val_loss: 0.6506 - val_acc: 0.7798\n",
      "Epoch 497/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7215 - acc: 0.7400 - val_loss: 0.6510 - val_acc: 0.7790\n",
      "Epoch 498/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7176 - acc: 0.7374 - val_loss: 0.6502 - val_acc: 0.7790\n",
      "Epoch 499/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7245 - acc: 0.7388 - val_loss: 0.6488 - val_acc: 0.7798\n",
      "Epoch 500/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7111 - acc: 0.7381 - val_loss: 0.6519 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00500: saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/0-000500-0.711115-0.779018.hdf5\n",
      "Epoch 501/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7197 - acc: 0.7321 - val_loss: 0.6527 - val_acc: 0.7783\n",
      "Epoch 502/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7191 - acc: 0.7388 - val_loss: 0.6514 - val_acc: 0.7790\n",
      "Epoch 503/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7225 - acc: 0.7403 - val_loss: 0.6512 - val_acc: 0.7783\n",
      "Epoch 504/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7199 - acc: 0.7347 - val_loss: 0.6526 - val_acc: 0.7783\n",
      "Epoch 505/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7069 - acc: 0.7414 - val_loss: 0.6527 - val_acc: 0.7783\n",
      "Epoch 506/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7196 - acc: 0.7329 - val_loss: 0.6523 - val_acc: 0.7783\n",
      "Epoch 507/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6988 - acc: 0.7478 - val_loss: 0.6520 - val_acc: 0.7783\n",
      "Epoch 508/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6979 - acc: 0.7493 - val_loss: 0.6526 - val_acc: 0.7783\n",
      "Epoch 509/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7112 - acc: 0.7418 - val_loss: 0.6523 - val_acc: 0.7783\n",
      "Epoch 510/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7020 - acc: 0.7440 - val_loss: 0.6523 - val_acc: 0.7783\n",
      "Epoch 511/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7236 - acc: 0.7370 - val_loss: 0.6511 - val_acc: 0.7790\n",
      "Epoch 512/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7243 - acc: 0.7381 - val_loss: 0.6493 - val_acc: 0.7798\n",
      "Epoch 513/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7142 - acc: 0.7370 - val_loss: 0.6507 - val_acc: 0.7790\n",
      "Epoch 514/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7199 - acc: 0.7374 - val_loss: 0.6503 - val_acc: 0.7790\n",
      "Epoch 515/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7098 - acc: 0.7452 - val_loss: 0.6490 - val_acc: 0.7798\n",
      "Epoch 516/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7123 - acc: 0.7437 - val_loss: 0.6522 - val_acc: 0.7783\n",
      "Epoch 517/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7261 - acc: 0.7333 - val_loss: 0.6525 - val_acc: 0.7783\n",
      "Epoch 518/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7086 - acc: 0.7463 - val_loss: 0.6485 - val_acc: 0.7805\n",
      "Epoch 519/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7104 - acc: 0.7407 - val_loss: 0.6499 - val_acc: 0.7790\n",
      "Epoch 520/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7139 - acc: 0.7474 - val_loss: 0.6527 - val_acc: 0.7783\n",
      "Epoch 521/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7159 - acc: 0.7422 - val_loss: 0.6522 - val_acc: 0.7783\n",
      "Epoch 522/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7213 - acc: 0.7381 - val_loss: 0.6505 - val_acc: 0.7798\n",
      "Epoch 523/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7250 - acc: 0.7381 - val_loss: 0.6487 - val_acc: 0.7798\n",
      "Epoch 524/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7147 - acc: 0.7381 - val_loss: 0.6518 - val_acc: 0.7790\n",
      "Epoch 525/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7108 - acc: 0.7452 - val_loss: 0.6507 - val_acc: 0.7790\n",
      "Epoch 526/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7150 - acc: 0.7463 - val_loss: 0.6454 - val_acc: 0.7805\n",
      "Epoch 527/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7165 - acc: 0.7336 - val_loss: 0.6511 - val_acc: 0.7798\n",
      "Epoch 528/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7245 - acc: 0.7303 - val_loss: 0.6521 - val_acc: 0.7783\n",
      "Epoch 529/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7216 - acc: 0.7403 - val_loss: 0.6521 - val_acc: 0.7783\n",
      "Epoch 530/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7152 - acc: 0.7370 - val_loss: 0.6503 - val_acc: 0.7790\n",
      "Epoch 531/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7007 - acc: 0.7418 - val_loss: 0.6506 - val_acc: 0.7790\n",
      "Epoch 532/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7016 - acc: 0.7411 - val_loss: 0.6502 - val_acc: 0.7790\n",
      "Epoch 533/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7222 - acc: 0.7310 - val_loss: 0.6489 - val_acc: 0.7798\n",
      "Epoch 534/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7265 - acc: 0.7396 - val_loss: 0.6514 - val_acc: 0.7790\n",
      "Epoch 535/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7157 - acc: 0.7403 - val_loss: 0.6512 - val_acc: 0.7790\n",
      "Epoch 536/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7181 - acc: 0.7366 - val_loss: 0.6501 - val_acc: 0.7790\n",
      "Epoch 537/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7270 - acc: 0.7385 - val_loss: 0.6427 - val_acc: 0.7798\n",
      "Epoch 538/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7068 - acc: 0.7452 - val_loss: 0.6511 - val_acc: 0.7790\n",
      "Epoch 539/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7232 - acc: 0.7370 - val_loss: 0.6423 - val_acc: 0.7798\n",
      "Epoch 540/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7122 - acc: 0.7452 - val_loss: 0.6485 - val_acc: 0.7798\n",
      "Epoch 541/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7261 - acc: 0.7295 - val_loss: 0.6484 - val_acc: 0.7790\n",
      "Epoch 542/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7118 - acc: 0.7388 - val_loss: 0.6519 - val_acc: 0.7790\n",
      "Epoch 543/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7229 - acc: 0.7340 - val_loss: 0.6485 - val_acc: 0.7790\n",
      "Epoch 544/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7193 - acc: 0.7403 - val_loss: 0.6491 - val_acc: 0.7798\n",
      "Epoch 545/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7151 - acc: 0.7455 - val_loss: 0.6515 - val_acc: 0.7783\n",
      "Epoch 546/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7172 - acc: 0.7411 - val_loss: 0.6523 - val_acc: 0.7783\n",
      "Epoch 547/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7217 - acc: 0.7407 - val_loss: 0.6520 - val_acc: 0.7783\n",
      "Epoch 548/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7144 - acc: 0.7377 - val_loss: 0.6497 - val_acc: 0.7798\n",
      "Epoch 549/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6983 - acc: 0.7433 - val_loss: 0.6506 - val_acc: 0.7798\n",
      "Epoch 550/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7187 - acc: 0.7288 - val_loss: 0.6519 - val_acc: 0.7783\n",
      "Epoch 551/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7157 - acc: 0.7429 - val_loss: 0.6512 - val_acc: 0.7798\n",
      "Epoch 552/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6966 - acc: 0.7418 - val_loss: 0.6510 - val_acc: 0.7790\n",
      "Epoch 553/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7123 - acc: 0.7344 - val_loss: 0.6512 - val_acc: 0.7790\n",
      "Epoch 554/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7208 - acc: 0.7448 - val_loss: 0.6515 - val_acc: 0.7798\n",
      "Epoch 555/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7231 - acc: 0.7374 - val_loss: 0.6513 - val_acc: 0.7790\n",
      "Epoch 556/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7211 - acc: 0.7377 - val_loss: 0.6527 - val_acc: 0.7783\n",
      "Epoch 557/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7266 - acc: 0.7396 - val_loss: 0.6511 - val_acc: 0.7790\n",
      "Epoch 558/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7234 - acc: 0.7314 - val_loss: 0.6515 - val_acc: 0.7790\n",
      "Epoch 559/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7092 - acc: 0.7418 - val_loss: 0.6521 - val_acc: 0.7783\n",
      "Epoch 560/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6958 - acc: 0.7433 - val_loss: 0.6497 - val_acc: 0.7798\n",
      "Epoch 561/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7142 - acc: 0.7400 - val_loss: 0.6501 - val_acc: 0.7798\n",
      "Epoch 562/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7182 - acc: 0.7396 - val_loss: 0.6502 - val_acc: 0.7790\n",
      "Epoch 563/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7249 - acc: 0.7321 - val_loss: 0.6516 - val_acc: 0.7790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 564/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7208 - acc: 0.7444 - val_loss: 0.6487 - val_acc: 0.7798\n",
      "Epoch 565/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7088 - acc: 0.7470 - val_loss: 0.6489 - val_acc: 0.7798\n",
      "\n",
      "Epoch 00565: loss improved from inf to 0.70877, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-0-000565-0.708773-0.779762.hdf5\n",
      "Epoch 566/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7221 - acc: 0.7340 - val_loss: 0.6518 - val_acc: 0.7790\n",
      "Epoch 567/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7051 - acc: 0.7414 - val_loss: 0.6529 - val_acc: 0.7783\n",
      "Epoch 568/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7051 - acc: 0.7414 - val_loss: 0.6501 - val_acc: 0.7798\n",
      "Epoch 569/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7261 - acc: 0.7340 - val_loss: 0.6518 - val_acc: 0.7783\n",
      "Epoch 570/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7250 - acc: 0.7351 - val_loss: 0.6505 - val_acc: 0.7798\n",
      "Epoch 571/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7110 - acc: 0.7392 - val_loss: 0.6521 - val_acc: 0.7783\n",
      "Epoch 572/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7150 - acc: 0.7400 - val_loss: 0.6484 - val_acc: 0.7798\n",
      "Epoch 573/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7066 - acc: 0.7463 - val_loss: 0.6505 - val_acc: 0.7798\n",
      "\n",
      "Epoch 00573: loss improved from 0.70877 to 0.70659, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-0-000573-0.706594-0.779762.hdf5\n",
      "Epoch 574/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7139 - acc: 0.7396 - val_loss: 0.6504 - val_acc: 0.7790\n",
      "Epoch 575/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7211 - acc: 0.7414 - val_loss: 0.6497 - val_acc: 0.7798\n",
      "Epoch 576/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7097 - acc: 0.7437 - val_loss: 0.6516 - val_acc: 0.7790\n",
      "Epoch 577/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7165 - acc: 0.7377 - val_loss: 0.6510 - val_acc: 0.7798\n",
      "Epoch 578/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7050 - acc: 0.7388 - val_loss: 0.6512 - val_acc: 0.7790\n",
      "Epoch 579/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7202 - acc: 0.7359 - val_loss: 0.6516 - val_acc: 0.7790\n",
      "Epoch 580/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7202 - acc: 0.7359 - val_loss: 0.6525 - val_acc: 0.7783\n",
      "Epoch 581/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7161 - acc: 0.7351 - val_loss: 0.6498 - val_acc: 0.7805\n",
      "Epoch 582/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7202 - acc: 0.7321 - val_loss: 0.6516 - val_acc: 0.7790\n",
      "Epoch 583/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7120 - acc: 0.7385 - val_loss: 0.6526 - val_acc: 0.7783\n",
      "Epoch 584/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7130 - acc: 0.7377 - val_loss: 0.6509 - val_acc: 0.7798\n",
      "Epoch 585/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7190 - acc: 0.7448 - val_loss: 0.6476 - val_acc: 0.7790\n",
      "Epoch 586/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7236 - acc: 0.7284 - val_loss: 0.6511 - val_acc: 0.7790\n",
      "Epoch 587/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7261 - acc: 0.7288 - val_loss: 0.6506 - val_acc: 0.7798\n",
      "Epoch 588/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7189 - acc: 0.7355 - val_loss: 0.6516 - val_acc: 0.7790\n",
      "Epoch 589/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7019 - acc: 0.7418 - val_loss: 0.6502 - val_acc: 0.7798\n",
      "\n",
      "Epoch 00589: loss improved from 0.70659 to 0.70193, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-0-000589-0.701932-0.779762.hdf5\n",
      "Epoch 590/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7074 - acc: 0.7377 - val_loss: 0.6513 - val_acc: 0.7790\n",
      "Epoch 591/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7128 - acc: 0.7422 - val_loss: 0.6516 - val_acc: 0.7790\n",
      "Epoch 592/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7197 - acc: 0.7426 - val_loss: 0.6504 - val_acc: 0.7790\n",
      "Epoch 593/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7280 - acc: 0.7433 - val_loss: 0.6506 - val_acc: 0.7790\n",
      "Epoch 594/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7286 - acc: 0.7362 - val_loss: 0.6526 - val_acc: 0.7783\n",
      "Epoch 595/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7253 - acc: 0.7325 - val_loss: 0.6510 - val_acc: 0.7783\n",
      "Epoch 596/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7111 - acc: 0.7318 - val_loss: 0.6502 - val_acc: 0.7798\n",
      "Epoch 597/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7039 - acc: 0.7366 - val_loss: 0.6529 - val_acc: 0.7783\n",
      "Epoch 598/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7140 - acc: 0.7366 - val_loss: 0.6514 - val_acc: 0.7798\n",
      "Epoch 599/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7252 - acc: 0.7411 - val_loss: 0.6485 - val_acc: 0.7798\n",
      "Epoch 600/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7267 - acc: 0.7325 - val_loss: 0.6515 - val_acc: 0.7783\n",
      "\n",
      "Epoch 00600: saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/0-000600-0.726745-0.778274.hdf5\n",
      "Epoch 601/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7222 - acc: 0.7411 - val_loss: 0.6515 - val_acc: 0.7790\n",
      "Epoch 602/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7252 - acc: 0.7370 - val_loss: 0.6515 - val_acc: 0.7790\n",
      "Epoch 603/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7013 - acc: 0.7519 - val_loss: 0.6504 - val_acc: 0.7790\n",
      "Epoch 604/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7115 - acc: 0.7411 - val_loss: 0.6517 - val_acc: 0.7790\n",
      "Epoch 605/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7297 - acc: 0.7295 - val_loss: 0.6520 - val_acc: 0.7783\n",
      "Epoch 606/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7160 - acc: 0.7362 - val_loss: 0.6502 - val_acc: 0.7790\n",
      "Epoch 607/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7117 - acc: 0.7377 - val_loss: 0.6518 - val_acc: 0.7783\n",
      "Epoch 608/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7162 - acc: 0.7374 - val_loss: 0.6505 - val_acc: 0.7798\n",
      "Epoch 609/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7138 - acc: 0.7440 - val_loss: 0.6500 - val_acc: 0.7790\n",
      "Epoch 610/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7209 - acc: 0.7433 - val_loss: 0.6497 - val_acc: 0.7805\n",
      "Epoch 611/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6970 - acc: 0.7429 - val_loss: 0.6501 - val_acc: 0.7798\n",
      "Epoch 612/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7201 - acc: 0.7366 - val_loss: 0.6485 - val_acc: 0.7798\n",
      "Epoch 613/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7143 - acc: 0.7411 - val_loss: 0.6504 - val_acc: 0.7790\n",
      "Epoch 614/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7275 - acc: 0.7459 - val_loss: 0.6515 - val_acc: 0.7783\n",
      "Epoch 615/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7157 - acc: 0.7359 - val_loss: 0.6523 - val_acc: 0.7790\n",
      "Epoch 616/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7255 - acc: 0.7340 - val_loss: 0.6511 - val_acc: 0.7798\n",
      "Epoch 617/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6935 - acc: 0.7567 - val_loss: 0.6513 - val_acc: 0.7790\n",
      "Epoch 618/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7175 - acc: 0.7433 - val_loss: 0.6510 - val_acc: 0.7790\n",
      "Epoch 619/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7010 - acc: 0.7444 - val_loss: 0.6517 - val_acc: 0.7783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 620/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7228 - acc: 0.7385 - val_loss: 0.6521 - val_acc: 0.7783\n",
      "Epoch 621/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7112 - acc: 0.7440 - val_loss: 0.6503 - val_acc: 0.7790\n",
      "Epoch 622/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7057 - acc: 0.7485 - val_loss: 0.6489 - val_acc: 0.7805\n",
      "Epoch 623/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7194 - acc: 0.7370 - val_loss: 0.6501 - val_acc: 0.7790\n",
      "Epoch 624/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7180 - acc: 0.7426 - val_loss: 0.6527 - val_acc: 0.7783\n",
      "Epoch 625/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7163 - acc: 0.7347 - val_loss: 0.6519 - val_acc: 0.7783\n",
      "Epoch 626/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7076 - acc: 0.7448 - val_loss: 0.6501 - val_acc: 0.7790\n",
      "Epoch 627/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7362 - acc: 0.7403 - val_loss: 0.6511 - val_acc: 0.7783\n",
      "Epoch 628/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7120 - acc: 0.7396 - val_loss: 0.6509 - val_acc: 0.7790\n",
      "Epoch 629/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7180 - acc: 0.7426 - val_loss: 0.6516 - val_acc: 0.7783\n",
      "Epoch 630/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7136 - acc: 0.7411 - val_loss: 0.6490 - val_acc: 0.7798\n",
      "Epoch 631/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7355 - acc: 0.7325 - val_loss: 0.6483 - val_acc: 0.7805\n",
      "Epoch 632/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7177 - acc: 0.7370 - val_loss: 0.6460 - val_acc: 0.7805\n",
      "Epoch 633/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7095 - acc: 0.7392 - val_loss: 0.6495 - val_acc: 0.7790\n",
      "Epoch 00633: early stopping\n",
      "ModelCheckpoint 已经保存到 ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/0-final.hdf5\n",
      "Create subdir directory: ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/log...\n",
      "save in: ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/log/20220201_2000_64_1_3_1.csv\n",
      "time: 0:16:52 s\n",
      "time: 1012.0 s\n",
      "average 1.012000 s\n",
      "0 epoch finished\n",
      "--------------------   best   --------------------\n",
      "no_activities: 10\n",
      "\n",
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1349/1349 [==============================] - 1s 654us/step\n",
      "0-milan:\tacc: 77.91%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [3, 9, 9, 9, 9, 9, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 2, 2, 2, 2, 2, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 0, 9, 9, 9, 7, 9, 0, 9, 9, 9, 0, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 9, 9, 9, 9, 0, 9, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 0, 7, 9, 9, 9, 9, 7, 9, 0, 9, 9, 9, 9, 9, 0, 7, 0, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 0, 7, 7, 7, 7, 7, 7, 0, 0, 7, 0, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 4, 0, 7, 7, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 4, 7, 7, 0, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 4, 7, 0, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 4, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 0, 0, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 0, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 0, 5, 5, 5, 5, 5, 7, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 0, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 7, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 3, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 7, 2, 2, 7, 7, 2, 2, 7, 2, 0, 0, 0, 0, 0, 0, 7, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 9, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 0, 7, 0, 0, 7, 0, 4, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 7, 0, 4, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 9, 7, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 4, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 7, 0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 4, 4, 4, 4, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 0, 7, 4, 4, 4, 4, 0, 4, 4, 0, 0, 4, 4, 0, 0, 4, 0, 4, 4, 0, 4, 0, 0, 0, 4, 7, 4, 4, 4, 0, 0, 4, 0, 4, 4, 4, 4, 0, 4, 4, 0, 4, 4, 4, 4, 4, 4, 0, 4, 4, 0, 0, 4, 0, 0, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 0, 0, 4, 4, 4, 4, 4, 4, 4, 0, 0, 4, 4, 4, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 3, 0, 3, 0, 0, 3, 3, 0, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 9, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 4]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.752343  0.902087  0.820438       623\n",
      "         Work   1.000000  0.153846  0.266667        26\n",
      "Take_medicine   1.000000  0.800000  0.888889        20\n",
      "        Sleep   0.750000  0.281250  0.409091        32\n",
      "        Relax   0.723404  0.475524  0.573840       143\n",
      "   Leave_Home   0.925373  0.873239  0.898551        71\n",
      "          Eat   0.000000  0.000000  0.000000         7\n",
      "         Cook   0.802083  0.832432  0.816976       185\n",
      "Bed_to_toilet   1.000000  0.033333  0.064516        30\n",
      "      Bathing   0.810185  0.825472  0.817757       212\n",
      "\n",
      "     accuracy                       0.779096      1349\n",
      "    macro avg   0.776339  0.517718  0.555672      1349\n",
      " weighted avg   0.784286  0.779096  0.757029      1349\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  1   0   0   0  28   0   0   0   0   1]\n",
      " [  0   4   0   0   0   1   0  21   0   0]\n",
      " [  0   0   0   0   0   1   0   6   0   0]\n",
      " [  0   0   0  16   0   4   0   0   0   0]\n",
      " [  0   0   0   0 175   4   0  32   0   1]\n",
      " [  0   0   0   0   0 154   0  26   5   0]\n",
      " [  0   0   0   0   0   2  62   6   1   0]\n",
      " [  0   0   0   0  11  24   5 562  20   1]\n",
      " [  0   0   0   0   0   2   0  73  68   0]\n",
      " [  0   0   0   0   2   0   0  21   0   9]]\n",
      "--------------------   final   --------------------\n",
      "no_activities: 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1349/1349 [==============================] - 1s 729us/step\n",
      "0-milan:\tacc: 77.91%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [3, 9, 9, 9, 9, 9, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 2, 2, 2, 2, 2, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 0, 9, 9, 9, 7, 9, 0, 9, 9, 9, 0, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 9, 9, 9, 9, 0, 9, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 0, 7, 9, 9, 9, 9, 7, 9, 0, 9, 9, 9, 9, 9, 0, 7, 0, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 0, 7, 7, 7, 7, 7, 7, 0, 0, 7, 0, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 4, 0, 7, 7, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 4, 7, 7, 0, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 4, 7, 0, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 4, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 0, 0, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 0, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 0, 5, 5, 5, 5, 5, 7, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 0, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 7, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 3, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 7, 2, 2, 7, 7, 2, 2, 7, 2, 0, 0, 0, 0, 0, 0, 7, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 9, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 0, 7, 0, 0, 7, 0, 4, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 7, 0, 4, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 9, 7, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 4, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 7, 0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 4, 4, 4, 4, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 0, 7, 4, 4, 4, 4, 0, 4, 4, 0, 0, 4, 4, 0, 0, 4, 0, 4, 4, 0, 4, 0, 0, 0, 4, 7, 4, 4, 4, 0, 0, 4, 0, 4, 4, 4, 4, 0, 4, 4, 0, 4, 4, 4, 4, 4, 4, 0, 4, 4, 0, 0, 4, 0, 0, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 0, 0, 4, 4, 4, 4, 4, 4, 4, 0, 0, 4, 4, 4, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 3, 0, 3, 0, 0, 3, 3, 0, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 9, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 4]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.752343  0.902087  0.820438       623\n",
      "         Work   1.000000  0.153846  0.266667        26\n",
      "Take_medicine   1.000000  0.800000  0.888889        20\n",
      "        Sleep   0.750000  0.281250  0.409091        32\n",
      "        Relax   0.723404  0.475524  0.573840       143\n",
      "   Leave_Home   0.925373  0.873239  0.898551        71\n",
      "          Eat   0.000000  0.000000  0.000000         7\n",
      "         Cook   0.802083  0.832432  0.816976       185\n",
      "Bed_to_toilet   1.000000  0.033333  0.064516        30\n",
      "      Bathing   0.810185  0.825472  0.817757       212\n",
      "\n",
      "     accuracy                       0.779096      1349\n",
      "    macro avg   0.776339  0.517718  0.555672      1349\n",
      " weighted avg   0.784286  0.779096  0.757029      1349\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  1   0   0   0  28   0   0   0   0   1]\n",
      " [  0   4   0   0   0   1   0  21   0   0]\n",
      " [  0   0   0   0   0   1   0   6   0   0]\n",
      " [  0   0   0  16   0   4   0   0   0   0]\n",
      " [  0   0   0   0 175   4   0  32   0   1]\n",
      " [  0   0   0   0   0 154   0  26   5   0]\n",
      " [  0   0   0   0   0   2  62   6   1   0]\n",
      " [  0   0   0   0  11  24   5 562  20   1]\n",
      " [  0   0   0   0   0   2   0  73  68   0]\n",
      " [  0   0   0   0   2   0   0  21   0   9]]\n",
      "no_activities: 10\n",
      "\n",
      "Begin training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 1.7799 - acc: 0.3850 - val_loss: 1.5105 - val_acc: 0.4628\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.4682 - acc: 0.5108 - val_loss: 1.2980 - val_acc: 0.5878\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.3104 - acc: 0.5662 - val_loss: 1.1330 - val_acc: 0.6540\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.2174 - acc: 0.6034 - val_loss: 1.0378 - val_acc: 0.6935\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.1529 - acc: 0.6209 - val_loss: 0.9629 - val_acc: 0.6949\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.0800 - acc: 0.6410 - val_loss: 0.9269 - val_acc: 0.7039\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.0514 - acc: 0.6473 - val_loss: 0.8861 - val_acc: 0.7121\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0127 - acc: 0.6562 - val_loss: 0.8617 - val_acc: 0.7121\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0047 - acc: 0.6682 - val_loss: 0.8552 - val_acc: 0.7121\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9754 - acc: 0.6652 - val_loss: 0.8417 - val_acc: 0.7195\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.9569 - acc: 0.6760 - val_loss: 0.8346 - val_acc: 0.7143\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9578 - acc: 0.6719 - val_loss: 0.8205 - val_acc: 0.7217\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9306 - acc: 0.6823 - val_loss: 0.8140 - val_acc: 0.7254\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.9330 - acc: 0.6760 - val_loss: 0.8068 - val_acc: 0.7269\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9255 - acc: 0.6923 - val_loss: 0.7952 - val_acc: 0.7307\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9141 - acc: 0.6882 - val_loss: 0.7821 - val_acc: 0.7463\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9121 - acc: 0.6920 - val_loss: 0.7825 - val_acc: 0.7463\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9109 - acc: 0.6845 - val_loss: 0.7792 - val_acc: 0.7500\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9047 - acc: 0.6912 - val_loss: 0.7707 - val_acc: 0.7582\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8944 - acc: 0.6935 - val_loss: 0.7620 - val_acc: 0.7656\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8832 - acc: 0.7031 - val_loss: 0.7581 - val_acc: 0.7701\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8795 - acc: 0.6908 - val_loss: 0.7535 - val_acc: 0.7708\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8587 - acc: 0.7087 - val_loss: 0.7451 - val_acc: 0.7790\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8799 - acc: 0.7072 - val_loss: 0.7445 - val_acc: 0.7768\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8604 - acc: 0.7076 - val_loss: 0.7361 - val_acc: 0.7775\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8514 - acc: 0.7158 - val_loss: 0.7331 - val_acc: 0.7738\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8405 - acc: 0.7195 - val_loss: 0.7258 - val_acc: 0.7790\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8504 - acc: 0.7109 - val_loss: 0.7267 - val_acc: 0.7723\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.8288 - acc: 0.7236 - val_loss: 0.7222 - val_acc: 0.7738\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8403 - acc: 0.7124 - val_loss: 0.7169 - val_acc: 0.7783\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8424 - acc: 0.7121 - val_loss: 0.7152 - val_acc: 0.7820\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8377 - acc: 0.7232 - val_loss: 0.7121 - val_acc: 0.7827\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8204 - acc: 0.7195 - val_loss: 0.7118 - val_acc: 0.7790\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8209 - acc: 0.7307 - val_loss: 0.7067 - val_acc: 0.7805\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8251 - acc: 0.7202 - val_loss: 0.7081 - val_acc: 0.7783\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8248 - acc: 0.7180 - val_loss: 0.7064 - val_acc: 0.7812\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8092 - acc: 0.7199 - val_loss: 0.7003 - val_acc: 0.7812\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8264 - acc: 0.7117 - val_loss: 0.6956 - val_acc: 0.7790\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8093 - acc: 0.7232 - val_loss: 0.6997 - val_acc: 0.7798\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8027 - acc: 0.7225 - val_loss: 0.6947 - val_acc: 0.7842\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8027 - acc: 0.7225 - val_loss: 0.6950 - val_acc: 0.7798\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.8221 - acc: 0.7254 - val_loss: 0.6916 - val_acc: 0.7835\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7990 - acc: 0.7277 - val_loss: 0.6906 - val_acc: 0.7835\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8037 - acc: 0.7310 - val_loss: 0.6880 - val_acc: 0.7850\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8102 - acc: 0.7262 - val_loss: 0.6858 - val_acc: 0.7865\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7879 - acc: 0.7359 - val_loss: 0.6866 - val_acc: 0.7827\n",
      "Epoch 47/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8043 - acc: 0.7251 - val_loss: 0.6827 - val_acc: 0.7842\n",
      "Epoch 48/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8030 - acc: 0.7236 - val_loss: 0.6847 - val_acc: 0.7805\n",
      "Epoch 49/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7912 - acc: 0.7392 - val_loss: 0.6844 - val_acc: 0.7850\n",
      "Epoch 50/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7893 - acc: 0.7321 - val_loss: 0.6828 - val_acc: 0.7812\n",
      "Epoch 51/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7893 - acc: 0.7269 - val_loss: 0.6792 - val_acc: 0.7820\n",
      "Epoch 52/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7869 - acc: 0.7210 - val_loss: 0.6782 - val_acc: 0.7820\n",
      "Epoch 53/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7968 - acc: 0.7202 - val_loss: 0.6753 - val_acc: 0.7879\n",
      "Epoch 54/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7933 - acc: 0.7191 - val_loss: 0.6810 - val_acc: 0.7798\n",
      "Epoch 55/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7671 - acc: 0.7307 - val_loss: 0.6765 - val_acc: 0.7798\n",
      "Epoch 56/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7802 - acc: 0.7281 - val_loss: 0.6762 - val_acc: 0.7798\n",
      "Epoch 57/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7880 - acc: 0.7307 - val_loss: 0.6698 - val_acc: 0.7887\n",
      "Epoch 58/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7780 - acc: 0.7351 - val_loss: 0.6727 - val_acc: 0.7842\n",
      "Epoch 59/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7873 - acc: 0.7329 - val_loss: 0.6706 - val_acc: 0.7872\n",
      "Epoch 60/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7816 - acc: 0.7333 - val_loss: 0.6721 - val_acc: 0.7835\n",
      "Epoch 61/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7662 - acc: 0.7347 - val_loss: 0.6719 - val_acc: 0.7790\n",
      "Epoch 62/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7657 - acc: 0.7452 - val_loss: 0.6661 - val_acc: 0.7842\n",
      "Epoch 63/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7570 - acc: 0.7396 - val_loss: 0.6688 - val_acc: 0.7820\n",
      "Epoch 64/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7480 - acc: 0.7426 - val_loss: 0.6640 - val_acc: 0.7835\n",
      "Epoch 65/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7721 - acc: 0.7381 - val_loss: 0.6678 - val_acc: 0.7812\n",
      "\n",
      "Epoch 00065: loss improved from inf to 0.77212, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-1-000065-0.772116-0.781250.hdf5\n",
      "Epoch 66/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7618 - acc: 0.7396 - val_loss: 0.6608 - val_acc: 0.7820\n",
      "Epoch 67/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7658 - acc: 0.7325 - val_loss: 0.6601 - val_acc: 0.7820\n",
      "Epoch 68/1000\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 0.7726 - acc: 0.7426 - val_loss: 0.6628 - val_acc: 0.7783\n",
      "Epoch 69/1000\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 0.7762 - acc: 0.7262 - val_loss: 0.6612 - val_acc: 0.7820\n",
      "Epoch 70/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7658 - acc: 0.7314 - val_loss: 0.6597 - val_acc: 0.7827\n",
      "Epoch 71/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7535 - acc: 0.7481 - val_loss: 0.6605 - val_acc: 0.7812\n",
      "Epoch 72/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7522 - acc: 0.7314 - val_loss: 0.6595 - val_acc: 0.7812\n",
      "Epoch 73/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7711 - acc: 0.7351 - val_loss: 0.6609 - val_acc: 0.7820\n",
      "\n",
      "Epoch 00073: loss improved from 0.77212 to 0.77113, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-1-000073-0.771132-0.781994.hdf5\n",
      "Epoch 74/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7653 - acc: 0.7329 - val_loss: 0.6573 - val_acc: 0.7835\n",
      "Epoch 75/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7410 - acc: 0.7500 - val_loss: 0.6557 - val_acc: 0.7842\n",
      "Epoch 76/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7705 - acc: 0.7288 - val_loss: 0.6583 - val_acc: 0.7805\n",
      "Epoch 77/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7328 - acc: 0.7474 - val_loss: 0.6589 - val_acc: 0.7798\n",
      "\n",
      "Epoch 00077: loss improved from 0.77113 to 0.73284, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-1-000077-0.732836-0.779762.hdf5\n",
      "Epoch 78/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7745 - acc: 0.7351 - val_loss: 0.6570 - val_acc: 0.7805\n",
      "Epoch 79/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7360 - acc: 0.7411 - val_loss: 0.6561 - val_acc: 0.7827\n",
      "Epoch 80/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7678 - acc: 0.7381 - val_loss: 0.6543 - val_acc: 0.7842\n",
      "Epoch 81/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7378 - acc: 0.7474 - val_loss: 0.6535 - val_acc: 0.7835\n",
      "Epoch 82/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7417 - acc: 0.7485 - val_loss: 0.6560 - val_acc: 0.7827\n",
      "Epoch 83/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7464 - acc: 0.7474 - val_loss: 0.6517 - val_acc: 0.7857\n",
      "Epoch 84/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7509 - acc: 0.7407 - val_loss: 0.6505 - val_acc: 0.7835\n",
      "Epoch 85/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7511 - acc: 0.7362 - val_loss: 0.6536 - val_acc: 0.7827\n",
      "Epoch 86/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7471 - acc: 0.7463 - val_loss: 0.6504 - val_acc: 0.7812\n",
      "Epoch 87/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7533 - acc: 0.7318 - val_loss: 0.6508 - val_acc: 0.7850\n",
      "Epoch 88/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7386 - acc: 0.7414 - val_loss: 0.6497 - val_acc: 0.7827\n",
      "Epoch 89/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7422 - acc: 0.7347 - val_loss: 0.6522 - val_acc: 0.7820\n",
      "Epoch 90/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7620 - acc: 0.7388 - val_loss: 0.6484 - val_acc: 0.7857\n",
      "Epoch 91/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7399 - acc: 0.7411 - val_loss: 0.6506 - val_acc: 0.7857\n",
      "Epoch 92/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7406 - acc: 0.7396 - val_loss: 0.6475 - val_acc: 0.7842\n",
      "Epoch 93/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7244 - acc: 0.7515 - val_loss: 0.6485 - val_acc: 0.7827\n",
      "\n",
      "Epoch 00093: loss improved from 0.73284 to 0.72443, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-1-000093-0.724428-0.782738.hdf5\n",
      "Epoch 94/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7252 - acc: 0.7493 - val_loss: 0.6457 - val_acc: 0.7812\n",
      "Epoch 95/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7262 - acc: 0.7493 - val_loss: 0.6431 - val_acc: 0.7850\n",
      "Epoch 96/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7348 - acc: 0.7444 - val_loss: 0.6428 - val_acc: 0.7850\n",
      "Epoch 97/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7425 - acc: 0.7437 - val_loss: 0.6475 - val_acc: 0.7842\n",
      "Epoch 98/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7373 - acc: 0.7414 - val_loss: 0.6432 - val_acc: 0.7820\n",
      "Epoch 99/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7489 - acc: 0.7344 - val_loss: 0.6424 - val_acc: 0.7857\n",
      "Epoch 100/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7239 - acc: 0.7496 - val_loss: 0.6421 - val_acc: 0.7842\n",
      "\n",
      "Epoch 00100: saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/1-000100-0.723856-0.784226.hdf5\n",
      "Epoch 101/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7199 - acc: 0.7560 - val_loss: 0.6428 - val_acc: 0.7827\n",
      "Epoch 102/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7325 - acc: 0.7459 - val_loss: 0.6428 - val_acc: 0.7842\n",
      "Epoch 103/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7254 - acc: 0.7433 - val_loss: 0.6433 - val_acc: 0.7835\n",
      "Epoch 104/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7319 - acc: 0.7355 - val_loss: 0.6398 - val_acc: 0.7857\n",
      "Epoch 105/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7275 - acc: 0.7463 - val_loss: 0.6397 - val_acc: 0.7827\n",
      "Epoch 106/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7250 - acc: 0.7403 - val_loss: 0.6403 - val_acc: 0.7835\n",
      "Epoch 107/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7396 - acc: 0.7388 - val_loss: 0.6369 - val_acc: 0.7857\n",
      "Epoch 108/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7170 - acc: 0.7414 - val_loss: 0.6401 - val_acc: 0.7805\n",
      "Epoch 109/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7108 - acc: 0.7541 - val_loss: 0.6394 - val_acc: 0.7835\n",
      "Epoch 110/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7282 - acc: 0.7563 - val_loss: 0.6408 - val_acc: 0.7820\n",
      "Epoch 111/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7542 - acc: 0.7344 - val_loss: 0.6400 - val_acc: 0.7805\n",
      "Epoch 112/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7061 - acc: 0.7470 - val_loss: 0.6384 - val_acc: 0.7850\n",
      "Epoch 113/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7323 - acc: 0.7426 - val_loss: 0.6381 - val_acc: 0.7850\n",
      "Epoch 114/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7176 - acc: 0.7396 - val_loss: 0.6381 - val_acc: 0.7850\n",
      "Epoch 115/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7259 - acc: 0.7418 - val_loss: 0.6368 - val_acc: 0.7835\n",
      "Epoch 116/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7201 - acc: 0.7493 - val_loss: 0.6387 - val_acc: 0.7865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7176 - acc: 0.7507 - val_loss: 0.6359 - val_acc: 0.7842\n",
      "Epoch 118/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7026 - acc: 0.7519 - val_loss: 0.6343 - val_acc: 0.7857\n",
      "Epoch 119/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7198 - acc: 0.7437 - val_loss: 0.6396 - val_acc: 0.7850\n",
      "Epoch 120/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7145 - acc: 0.7500 - val_loss: 0.6364 - val_acc: 0.7842\n",
      "Epoch 121/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7121 - acc: 0.7548 - val_loss: 0.6354 - val_acc: 0.7842\n",
      "Epoch 122/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7171 - acc: 0.7485 - val_loss: 0.6340 - val_acc: 0.7857\n",
      "Epoch 123/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7125 - acc: 0.7522 - val_loss: 0.6335 - val_acc: 0.7827\n",
      "Epoch 124/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7322 - acc: 0.7481 - val_loss: 0.6375 - val_acc: 0.7805\n",
      "Epoch 125/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7059 - acc: 0.7411 - val_loss: 0.6375 - val_acc: 0.7842\n",
      "Epoch 126/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7190 - acc: 0.7552 - val_loss: 0.6352 - val_acc: 0.7820\n",
      "Epoch 127/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7007 - acc: 0.7530 - val_loss: 0.6334 - val_acc: 0.7835\n",
      "Epoch 128/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7104 - acc: 0.7507 - val_loss: 0.6328 - val_acc: 0.7835\n",
      "Epoch 129/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7082 - acc: 0.7522 - val_loss: 0.6336 - val_acc: 0.7812\n",
      "Epoch 130/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7029 - acc: 0.7526 - val_loss: 0.6334 - val_acc: 0.7850\n",
      "Epoch 131/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7192 - acc: 0.7526 - val_loss: 0.6347 - val_acc: 0.7835\n",
      "Epoch 132/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7119 - acc: 0.7496 - val_loss: 0.6337 - val_acc: 0.7812\n",
      "Epoch 133/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7149 - acc: 0.7496 - val_loss: 0.6278 - val_acc: 0.7865\n",
      "Epoch 134/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7094 - acc: 0.7511 - val_loss: 0.6317 - val_acc: 0.7835\n",
      "Epoch 135/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7051 - acc: 0.7533 - val_loss: 0.6299 - val_acc: 0.7850\n",
      "Epoch 136/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7052 - acc: 0.7530 - val_loss: 0.6299 - val_acc: 0.7865\n",
      "Epoch 137/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7157 - acc: 0.7481 - val_loss: 0.6309 - val_acc: 0.7857\n",
      "Epoch 138/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7062 - acc: 0.7489 - val_loss: 0.6300 - val_acc: 0.7820\n",
      "Epoch 139/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7102 - acc: 0.7478 - val_loss: 0.6303 - val_acc: 0.7820\n",
      "Epoch 140/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7089 - acc: 0.7530 - val_loss: 0.6299 - val_acc: 0.7820\n",
      "Epoch 141/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7083 - acc: 0.7459 - val_loss: 0.6255 - val_acc: 0.7842\n",
      "Epoch 142/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7036 - acc: 0.7481 - val_loss: 0.6291 - val_acc: 0.7812\n",
      "Epoch 143/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7236 - acc: 0.7500 - val_loss: 0.6300 - val_acc: 0.7775\n",
      "Epoch 144/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7014 - acc: 0.7504 - val_loss: 0.6266 - val_acc: 0.7827\n",
      "Epoch 145/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7183 - acc: 0.7400 - val_loss: 0.6270 - val_acc: 0.7879\n",
      "Epoch 146/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7117 - acc: 0.7586 - val_loss: 0.6277 - val_acc: 0.7827\n",
      "Epoch 147/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7009 - acc: 0.7526 - val_loss: 0.6267 - val_acc: 0.7827\n",
      "\n",
      "Epoch 00147: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 148/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6967 - acc: 0.7478 - val_loss: 0.6248 - val_acc: 0.7827\n",
      "Epoch 149/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6944 - acc: 0.7548 - val_loss: 0.6252 - val_acc: 0.7835\n",
      "Epoch 150/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7020 - acc: 0.7455 - val_loss: 0.6268 - val_acc: 0.7820\n",
      "Epoch 151/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7100 - acc: 0.7496 - val_loss: 0.6292 - val_acc: 0.7812\n",
      "Epoch 152/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6918 - acc: 0.7556 - val_loss: 0.6294 - val_acc: 0.7812\n",
      "Epoch 153/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6930 - acc: 0.7522 - val_loss: 0.6260 - val_acc: 0.7827\n",
      "Epoch 154/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7124 - acc: 0.7455 - val_loss: 0.6288 - val_acc: 0.7812\n",
      "Epoch 155/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6886 - acc: 0.7541 - val_loss: 0.6236 - val_acc: 0.7850\n",
      "Epoch 156/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7000 - acc: 0.7537 - val_loss: 0.6284 - val_acc: 0.7820\n",
      "Epoch 157/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6968 - acc: 0.7530 - val_loss: 0.6287 - val_acc: 0.7827\n",
      "Epoch 158/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7066 - acc: 0.7526 - val_loss: 0.6272 - val_acc: 0.7820\n",
      "Epoch 159/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6961 - acc: 0.7500 - val_loss: 0.6272 - val_acc: 0.7827\n",
      "Epoch 160/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6991 - acc: 0.7634 - val_loss: 0.6264 - val_acc: 0.7842\n",
      "Epoch 161/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6939 - acc: 0.7634 - val_loss: 0.6267 - val_acc: 0.7835\n",
      "Epoch 162/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7135 - acc: 0.7426 - val_loss: 0.6271 - val_acc: 0.7820\n",
      "Epoch 163/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7012 - acc: 0.7582 - val_loss: 0.6266 - val_acc: 0.7820\n",
      "Epoch 164/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7274 - acc: 0.7429 - val_loss: 0.6267 - val_acc: 0.7827\n",
      "Epoch 165/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7057 - acc: 0.7440 - val_loss: 0.6264 - val_acc: 0.7827\n",
      "\n",
      "Epoch 00165: loss improved from inf to 0.70570, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-1-000165-0.705703-0.782738.hdf5\n",
      "Epoch 166/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7063 - acc: 0.7459 - val_loss: 0.6276 - val_acc: 0.7820\n",
      "Epoch 167/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7123 - acc: 0.7571 - val_loss: 0.6275 - val_acc: 0.7827\n",
      "Epoch 168/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7082 - acc: 0.7560 - val_loss: 0.6280 - val_acc: 0.7827\n",
      "Epoch 169/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7016 - acc: 0.7533 - val_loss: 0.6248 - val_acc: 0.7835\n",
      "\n",
      "Epoch 00169: loss improved from 0.70570 to 0.70157, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-1-000169-0.701565-0.783482.hdf5\n",
      "Epoch 170/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6956 - acc: 0.7548 - val_loss: 0.6260 - val_acc: 0.7827\n",
      "Epoch 171/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6933 - acc: 0.7467 - val_loss: 0.6272 - val_acc: 0.7820\n",
      "Epoch 172/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7178 - acc: 0.7437 - val_loss: 0.6261 - val_acc: 0.7827\n",
      "Epoch 173/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6885 - acc: 0.7515 - val_loss: 0.6279 - val_acc: 0.7820\n",
      "\n",
      "Epoch 00173: loss improved from 0.70157 to 0.68846, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-1-000173-0.688461-0.781994.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7044 - acc: 0.7470 - val_loss: 0.6266 - val_acc: 0.7827\n",
      "Epoch 175/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6834 - acc: 0.7604 - val_loss: 0.6223 - val_acc: 0.7835\n",
      "Epoch 176/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7068 - acc: 0.7485 - val_loss: 0.6255 - val_acc: 0.7820\n",
      "Epoch 177/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7023 - acc: 0.7563 - val_loss: 0.6243 - val_acc: 0.7835\n",
      "Epoch 178/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6935 - acc: 0.7537 - val_loss: 0.6237 - val_acc: 0.7835\n",
      "Epoch 179/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6948 - acc: 0.7567 - val_loss: 0.6247 - val_acc: 0.7835\n",
      "Epoch 180/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7044 - acc: 0.7455 - val_loss: 0.6259 - val_acc: 0.7820\n",
      "Epoch 181/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6724 - acc: 0.7589 - val_loss: 0.6263 - val_acc: 0.7820\n",
      "\n",
      "Epoch 00181: loss improved from 0.68846 to 0.67241, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-1-000181-0.672411-0.781994.hdf5\n",
      "Epoch 182/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7047 - acc: 0.7459 - val_loss: 0.6264 - val_acc: 0.7820\n",
      "Epoch 183/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7014 - acc: 0.7467 - val_loss: 0.6229 - val_acc: 0.7827\n",
      "Epoch 184/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7111 - acc: 0.7511 - val_loss: 0.6253 - val_acc: 0.7820\n",
      "Epoch 185/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6991 - acc: 0.7541 - val_loss: 0.6251 - val_acc: 0.7820\n",
      "Epoch 186/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7009 - acc: 0.7515 - val_loss: 0.6262 - val_acc: 0.7820\n",
      "Epoch 187/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6933 - acc: 0.7556 - val_loss: 0.6249 - val_acc: 0.7827\n",
      "Epoch 188/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6962 - acc: 0.7589 - val_loss: 0.6225 - val_acc: 0.7827\n",
      "Epoch 189/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6933 - acc: 0.7526 - val_loss: 0.6225 - val_acc: 0.7820\n",
      "Epoch 190/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7126 - acc: 0.7500 - val_loss: 0.6271 - val_acc: 0.7812\n",
      "Epoch 191/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6949 - acc: 0.7563 - val_loss: 0.6246 - val_acc: 0.7820\n",
      "Epoch 192/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6980 - acc: 0.7574 - val_loss: 0.6265 - val_acc: 0.7812\n",
      "Epoch 193/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6995 - acc: 0.7470 - val_loss: 0.6262 - val_acc: 0.7820\n",
      "Epoch 194/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7069 - acc: 0.7537 - val_loss: 0.6264 - val_acc: 0.7812\n",
      "Epoch 195/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7029 - acc: 0.7489 - val_loss: 0.6256 - val_acc: 0.7820\n",
      "Epoch 196/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7088 - acc: 0.7467 - val_loss: 0.6267 - val_acc: 0.7812\n",
      "Epoch 197/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6858 - acc: 0.7589 - val_loss: 0.6268 - val_acc: 0.7812\n",
      "Epoch 198/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6952 - acc: 0.7522 - val_loss: 0.6240 - val_acc: 0.7842\n",
      "Epoch 199/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7050 - acc: 0.7530 - val_loss: 0.6237 - val_acc: 0.7827\n",
      "Epoch 200/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6997 - acc: 0.7496 - val_loss: 0.6255 - val_acc: 0.7820\n",
      "\n",
      "Epoch 00200: saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/1-000200-0.699692-0.781994.hdf5\n",
      "Epoch 201/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6934 - acc: 0.7556 - val_loss: 0.6241 - val_acc: 0.7827\n",
      "\n",
      "Epoch 00201: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 202/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7047 - acc: 0.7478 - val_loss: 0.6152 - val_acc: 0.7827\n",
      "Epoch 203/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7072 - acc: 0.7504 - val_loss: 0.6253 - val_acc: 0.7827\n",
      "Epoch 204/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7041 - acc: 0.7496 - val_loss: 0.6247 - val_acc: 0.7827\n",
      "Epoch 205/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7038 - acc: 0.7526 - val_loss: 0.6243 - val_acc: 0.7827\n",
      "Epoch 206/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6906 - acc: 0.7522 - val_loss: 0.6251 - val_acc: 0.7820\n",
      "Epoch 207/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7056 - acc: 0.7440 - val_loss: 0.6245 - val_acc: 0.7827\n",
      "Epoch 208/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6861 - acc: 0.7574 - val_loss: 0.6258 - val_acc: 0.7820\n",
      "Epoch 209/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6751 - acc: 0.7571 - val_loss: 0.6239 - val_acc: 0.7835\n",
      "Epoch 210/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6953 - acc: 0.7519 - val_loss: 0.6256 - val_acc: 0.7820\n",
      "Epoch 211/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6948 - acc: 0.7493 - val_loss: 0.6262 - val_acc: 0.7820\n",
      "Epoch 212/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6921 - acc: 0.7537 - val_loss: 0.6259 - val_acc: 0.7820\n",
      "Epoch 213/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6879 - acc: 0.7556 - val_loss: 0.6261 - val_acc: 0.7820\n",
      "Epoch 214/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7003 - acc: 0.7489 - val_loss: 0.6262 - val_acc: 0.7820\n",
      "Epoch 215/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6903 - acc: 0.7522 - val_loss: 0.6246 - val_acc: 0.7835\n",
      "Epoch 216/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6973 - acc: 0.7526 - val_loss: 0.6236 - val_acc: 0.7827\n",
      "Epoch 217/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7125 - acc: 0.7470 - val_loss: 0.6228 - val_acc: 0.7842\n",
      "Epoch 218/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6821 - acc: 0.7597 - val_loss: 0.6254 - val_acc: 0.7820\n",
      "Epoch 219/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.6776 - acc: 0.7519 - val_loss: 0.6251 - val_acc: 0.7827\n",
      "Epoch 220/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6933 - acc: 0.7604 - val_loss: 0.6245 - val_acc: 0.7827\n",
      "Epoch 221/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6925 - acc: 0.7537 - val_loss: 0.6258 - val_acc: 0.7820\n",
      "\n",
      "Epoch 00221: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 222/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6912 - acc: 0.7545 - val_loss: 0.6244 - val_acc: 0.7827\n",
      "Epoch 223/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7025 - acc: 0.7444 - val_loss: 0.6247 - val_acc: 0.7835\n",
      "Epoch 224/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6874 - acc: 0.7619 - val_loss: 0.6254 - val_acc: 0.7827\n",
      "Epoch 225/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7085 - acc: 0.7467 - val_loss: 0.6233 - val_acc: 0.7835\n",
      "Epoch 226/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6981 - acc: 0.7586 - val_loss: 0.6250 - val_acc: 0.7827\n",
      "Epoch 227/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6990 - acc: 0.7448 - val_loss: 0.6263 - val_acc: 0.7820\n",
      "Epoch 228/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6997 - acc: 0.7556 - val_loss: 0.6225 - val_acc: 0.7835\n",
      "Epoch 229/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7007 - acc: 0.7556 - val_loss: 0.6254 - val_acc: 0.7827\n",
      "Epoch 230/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6969 - acc: 0.7567 - val_loss: 0.6245 - val_acc: 0.7827\n",
      "Epoch 231/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7069 - acc: 0.7433 - val_loss: 0.6251 - val_acc: 0.7827\n",
      "Epoch 232/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6884 - acc: 0.7578 - val_loss: 0.6244 - val_acc: 0.7827\n",
      "Epoch 233/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6948 - acc: 0.7556 - val_loss: 0.6264 - val_acc: 0.7820\n",
      "Epoch 234/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7005 - acc: 0.7489 - val_loss: 0.6260 - val_acc: 0.7820\n",
      "Epoch 235/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6994 - acc: 0.7589 - val_loss: 0.6244 - val_acc: 0.7835\n",
      "Epoch 236/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6994 - acc: 0.7504 - val_loss: 0.6258 - val_acc: 0.7820\n",
      "Epoch 237/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6932 - acc: 0.7563 - val_loss: 0.6250 - val_acc: 0.7827\n",
      "Epoch 238/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6849 - acc: 0.7541 - val_loss: 0.6254 - val_acc: 0.7827\n",
      "Epoch 239/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6974 - acc: 0.7560 - val_loss: 0.6251 - val_acc: 0.7820\n",
      "Epoch 240/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7046 - acc: 0.7556 - val_loss: 0.6262 - val_acc: 0.7820\n",
      "Epoch 241/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6932 - acc: 0.7519 - val_loss: 0.6261 - val_acc: 0.7820\n",
      "Epoch 242/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6897 - acc: 0.7526 - val_loss: 0.6257 - val_acc: 0.7820\n",
      "Epoch 243/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6747 - acc: 0.7641 - val_loss: 0.6260 - val_acc: 0.7820\n",
      "Epoch 244/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6963 - acc: 0.7530 - val_loss: 0.6247 - val_acc: 0.7827\n",
      "Epoch 245/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6853 - acc: 0.7571 - val_loss: 0.6258 - val_acc: 0.7820\n",
      "Epoch 246/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6802 - acc: 0.7556 - val_loss: 0.6233 - val_acc: 0.7827\n",
      "Epoch 247/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7024 - acc: 0.7593 - val_loss: 0.6255 - val_acc: 0.7820\n",
      "Epoch 248/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6934 - acc: 0.7537 - val_loss: 0.6237 - val_acc: 0.7827\n",
      "Epoch 249/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6878 - acc: 0.7526 - val_loss: 0.6220 - val_acc: 0.7842\n",
      "Epoch 250/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7010 - acc: 0.7459 - val_loss: 0.6262 - val_acc: 0.7820\n",
      "Epoch 251/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6939 - acc: 0.7504 - val_loss: 0.6251 - val_acc: 0.7827\n",
      "Epoch 252/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6871 - acc: 0.7593 - val_loss: 0.6263 - val_acc: 0.7820\n",
      "Epoch 253/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6881 - acc: 0.7593 - val_loss: 0.6238 - val_acc: 0.7827\n",
      "Epoch 254/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6937 - acc: 0.7522 - val_loss: 0.6247 - val_acc: 0.7827\n",
      "Epoch 255/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6831 - acc: 0.7608 - val_loss: 0.6249 - val_acc: 0.7827\n",
      "Epoch 256/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7052 - acc: 0.7500 - val_loss: 0.6258 - val_acc: 0.7820\n",
      "Epoch 257/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6898 - acc: 0.7593 - val_loss: 0.6239 - val_acc: 0.7835\n",
      "Epoch 258/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7018 - acc: 0.7533 - val_loss: 0.6248 - val_acc: 0.7827\n",
      "Epoch 259/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6972 - acc: 0.7548 - val_loss: 0.6228 - val_acc: 0.7835\n",
      "Epoch 260/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6845 - acc: 0.7582 - val_loss: 0.6222 - val_acc: 0.7835\n",
      "Epoch 261/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6875 - acc: 0.7582 - val_loss: 0.6263 - val_acc: 0.7820\n",
      "Epoch 262/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6959 - acc: 0.7548 - val_loss: 0.6249 - val_acc: 0.7827\n",
      "Epoch 263/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6833 - acc: 0.7567 - val_loss: 0.6254 - val_acc: 0.7827\n",
      "Epoch 264/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6880 - acc: 0.7515 - val_loss: 0.6249 - val_acc: 0.7820\n",
      "Epoch 265/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7002 - acc: 0.7515 - val_loss: 0.6248 - val_acc: 0.7827\n",
      "\n",
      "Epoch 00265: loss improved from inf to 0.70019, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-1-000265-0.700188-0.782738.hdf5\n",
      "Epoch 266/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6948 - acc: 0.7470 - val_loss: 0.6250 - val_acc: 0.7827\n",
      "Epoch 267/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6916 - acc: 0.7541 - val_loss: 0.6263 - val_acc: 0.7820\n",
      "Epoch 268/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6880 - acc: 0.7571 - val_loss: 0.6259 - val_acc: 0.7820\n",
      "Epoch 269/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6897 - acc: 0.7560 - val_loss: 0.6242 - val_acc: 0.7827\n",
      "\n",
      "Epoch 00269: loss improved from 0.70019 to 0.68970, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-1-000269-0.689701-0.782738.hdf5\n",
      "Epoch 270/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6848 - acc: 0.7489 - val_loss: 0.6260 - val_acc: 0.7820\n",
      "Epoch 271/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7007 - acc: 0.7537 - val_loss: 0.6248 - val_acc: 0.7827\n",
      "Epoch 272/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7052 - acc: 0.7504 - val_loss: 0.6261 - val_acc: 0.7820\n",
      "Epoch 273/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6860 - acc: 0.7567 - val_loss: 0.6250 - val_acc: 0.7820\n",
      "\n",
      "Epoch 00273: loss improved from 0.68970 to 0.68597, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-1-000273-0.685968-0.781994.hdf5\n",
      "Epoch 274/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6929 - acc: 0.7552 - val_loss: 0.6248 - val_acc: 0.7835\n",
      "Epoch 275/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6999 - acc: 0.7571 - val_loss: 0.6251 - val_acc: 0.7827\n",
      "Epoch 276/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6999 - acc: 0.7563 - val_loss: 0.6243 - val_acc: 0.7820\n",
      "Epoch 277/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6870 - acc: 0.7701 - val_loss: 0.6239 - val_acc: 0.7827\n",
      "Epoch 278/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6882 - acc: 0.7567 - val_loss: 0.6248 - val_acc: 0.7827\n",
      "Epoch 279/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6912 - acc: 0.7519 - val_loss: 0.6255 - val_acc: 0.7820\n",
      "Epoch 280/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6966 - acc: 0.7571 - val_loss: 0.6253 - val_acc: 0.7820\n",
      "Epoch 281/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6894 - acc: 0.7541 - val_loss: 0.6240 - val_acc: 0.7827\n",
      "Epoch 282/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7001 - acc: 0.7533 - val_loss: 0.6119 - val_acc: 0.7835\n",
      "Epoch 283/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6820 - acc: 0.7560 - val_loss: 0.6222 - val_acc: 0.7850\n",
      "Epoch 284/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6974 - acc: 0.7537 - val_loss: 0.6216 - val_acc: 0.7827\n",
      "Epoch 285/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6911 - acc: 0.7589 - val_loss: 0.6259 - val_acc: 0.7820\n",
      "Epoch 286/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6887 - acc: 0.7530 - val_loss: 0.6254 - val_acc: 0.7820\n",
      "Epoch 287/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6923 - acc: 0.7489 - val_loss: 0.6235 - val_acc: 0.7827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 288/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6968 - acc: 0.7634 - val_loss: 0.6243 - val_acc: 0.7827\n",
      "Epoch 289/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6832 - acc: 0.7574 - val_loss: 0.6216 - val_acc: 0.7835\n",
      "\n",
      "Epoch 00289: loss improved from 0.68597 to 0.68320, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-1-000289-0.683204-0.783482.hdf5\n",
      "Epoch 290/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6996 - acc: 0.7519 - val_loss: 0.6258 - val_acc: 0.7820\n",
      "Epoch 291/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7032 - acc: 0.7519 - val_loss: 0.6240 - val_acc: 0.7827\n",
      "Epoch 292/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.6983 - acc: 0.7444 - val_loss: 0.6262 - val_acc: 0.7820\n",
      "Epoch 293/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6976 - acc: 0.7526 - val_loss: 0.6261 - val_acc: 0.7820\n",
      "Epoch 294/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6892 - acc: 0.7574 - val_loss: 0.6236 - val_acc: 0.7835\n",
      "Epoch 295/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7013 - acc: 0.7552 - val_loss: 0.6257 - val_acc: 0.7820\n",
      "Epoch 296/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6967 - acc: 0.7448 - val_loss: 0.6249 - val_acc: 0.7827\n",
      "Epoch 297/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6878 - acc: 0.7500 - val_loss: 0.6260 - val_acc: 0.7820\n",
      "Epoch 298/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6866 - acc: 0.7560 - val_loss: 0.6248 - val_acc: 0.7820\n",
      "Epoch 299/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6855 - acc: 0.7519 - val_loss: 0.6255 - val_acc: 0.7820\n",
      "Epoch 300/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6890 - acc: 0.7526 - val_loss: 0.6258 - val_acc: 0.7820\n",
      "\n",
      "Epoch 00300: saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/1-000300-0.689027-0.781994.hdf5\n",
      "Epoch 301/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7003 - acc: 0.7489 - val_loss: 0.6260 - val_acc: 0.7820\n",
      "Epoch 302/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6959 - acc: 0.7519 - val_loss: 0.6263 - val_acc: 0.7820\n",
      "Epoch 303/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6867 - acc: 0.7556 - val_loss: 0.6262 - val_acc: 0.7820\n",
      "Epoch 304/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7054 - acc: 0.7433 - val_loss: 0.6226 - val_acc: 0.7835\n",
      "Epoch 305/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6942 - acc: 0.7533 - val_loss: 0.6255 - val_acc: 0.7820\n",
      "Epoch 306/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6937 - acc: 0.7452 - val_loss: 0.6253 - val_acc: 0.7820\n",
      "Epoch 307/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7059 - acc: 0.7493 - val_loss: 0.6260 - val_acc: 0.7820\n",
      "Epoch 308/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6950 - acc: 0.7574 - val_loss: 0.6239 - val_acc: 0.7835\n",
      "Epoch 309/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6988 - acc: 0.7496 - val_loss: 0.6263 - val_acc: 0.7820\n",
      "Epoch 310/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6842 - acc: 0.7578 - val_loss: 0.6248 - val_acc: 0.7827\n",
      "Epoch 311/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7023 - acc: 0.7548 - val_loss: 0.6249 - val_acc: 0.7827\n",
      "Epoch 312/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6960 - acc: 0.7500 - val_loss: 0.6259 - val_acc: 0.7820\n",
      "Epoch 313/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6956 - acc: 0.7589 - val_loss: 0.6198 - val_acc: 0.7835\n",
      "Epoch 314/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6878 - acc: 0.7600 - val_loss: 0.6250 - val_acc: 0.7827\n",
      "Epoch 315/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6705 - acc: 0.7526 - val_loss: 0.6245 - val_acc: 0.7827\n",
      "Epoch 316/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7084 - acc: 0.7500 - val_loss: 0.6260 - val_acc: 0.7820\n",
      "Epoch 317/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6976 - acc: 0.7493 - val_loss: 0.6252 - val_acc: 0.7827\n",
      "Epoch 318/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6801 - acc: 0.7545 - val_loss: 0.6235 - val_acc: 0.7835\n",
      "Epoch 319/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6971 - acc: 0.7563 - val_loss: 0.6259 - val_acc: 0.7820\n",
      "Epoch 320/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7022 - acc: 0.7467 - val_loss: 0.6246 - val_acc: 0.7827\n",
      "Epoch 321/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7099 - acc: 0.7437 - val_loss: 0.6253 - val_acc: 0.7827\n",
      "Epoch 322/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6809 - acc: 0.7571 - val_loss: 0.6262 - val_acc: 0.7820\n",
      "Epoch 323/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7095 - acc: 0.7478 - val_loss: 0.6251 - val_acc: 0.7827\n",
      "Epoch 324/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6825 - acc: 0.7563 - val_loss: 0.6259 - val_acc: 0.7820\n",
      "Epoch 325/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6989 - acc: 0.7563 - val_loss: 0.6253 - val_acc: 0.7820\n",
      "Epoch 326/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7088 - acc: 0.7545 - val_loss: 0.6258 - val_acc: 0.7820\n",
      "Epoch 327/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7062 - acc: 0.7470 - val_loss: 0.6245 - val_acc: 0.7835\n",
      "Epoch 328/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6867 - acc: 0.7556 - val_loss: 0.6236 - val_acc: 0.7835\n",
      "Epoch 329/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6877 - acc: 0.7552 - val_loss: 0.6254 - val_acc: 0.7820\n",
      "Epoch 330/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6960 - acc: 0.7563 - val_loss: 0.6253 - val_acc: 0.7820\n",
      "Epoch 331/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6893 - acc: 0.7448 - val_loss: 0.6236 - val_acc: 0.7835\n",
      "Epoch 332/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6802 - acc: 0.7615 - val_loss: 0.6257 - val_acc: 0.7820\n",
      "Epoch 333/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6852 - acc: 0.7615 - val_loss: 0.6260 - val_acc: 0.7820\n",
      "Epoch 334/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7008 - acc: 0.7541 - val_loss: 0.6262 - val_acc: 0.7820\n",
      "Epoch 335/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7063 - acc: 0.7511 - val_loss: 0.6247 - val_acc: 0.7827\n",
      "Epoch 336/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6869 - acc: 0.7522 - val_loss: 0.6259 - val_acc: 0.7820\n",
      "Epoch 337/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6963 - acc: 0.7522 - val_loss: 0.6248 - val_acc: 0.7827\n",
      "Epoch 338/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7083 - acc: 0.7489 - val_loss: 0.6251 - val_acc: 0.7827\n",
      "Epoch 339/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7001 - acc: 0.7552 - val_loss: 0.6245 - val_acc: 0.7827\n",
      "Epoch 340/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6950 - acc: 0.7556 - val_loss: 0.6253 - val_acc: 0.7820\n",
      "Epoch 341/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7033 - acc: 0.7600 - val_loss: 0.6253 - val_acc: 0.7827\n",
      "Epoch 342/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6999 - acc: 0.7489 - val_loss: 0.6239 - val_acc: 0.7835\n",
      "Epoch 343/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7000 - acc: 0.7530 - val_loss: 0.6254 - val_acc: 0.7827\n",
      "Epoch 344/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6984 - acc: 0.7507 - val_loss: 0.6251 - val_acc: 0.7827\n",
      "Epoch 345/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7034 - acc: 0.7481 - val_loss: 0.6242 - val_acc: 0.7827\n",
      "Epoch 346/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 36ms/step - loss: 0.6869 - acc: 0.7604 - val_loss: 0.6204 - val_acc: 0.7827\n",
      "Epoch 347/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6998 - acc: 0.7481 - val_loss: 0.6258 - val_acc: 0.7820\n",
      "Epoch 348/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7038 - acc: 0.7467 - val_loss: 0.6263 - val_acc: 0.7820\n",
      "Epoch 349/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6981 - acc: 0.7593 - val_loss: 0.6241 - val_acc: 0.7835\n",
      "Epoch 350/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6844 - acc: 0.7667 - val_loss: 0.6250 - val_acc: 0.7820\n",
      "Epoch 351/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6977 - acc: 0.7571 - val_loss: 0.6254 - val_acc: 0.7820\n",
      "Epoch 352/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6913 - acc: 0.7560 - val_loss: 0.6235 - val_acc: 0.7827\n",
      "Epoch 353/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6887 - acc: 0.7574 - val_loss: 0.6255 - val_acc: 0.7827\n",
      "Epoch 354/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6951 - acc: 0.7526 - val_loss: 0.6236 - val_acc: 0.7827\n",
      "Epoch 355/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7124 - acc: 0.7493 - val_loss: 0.6254 - val_acc: 0.7827\n",
      "Epoch 356/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6949 - acc: 0.7496 - val_loss: 0.6212 - val_acc: 0.7827\n",
      "Epoch 357/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7165 - acc: 0.7522 - val_loss: 0.6246 - val_acc: 0.7827\n",
      "Epoch 358/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6897 - acc: 0.7541 - val_loss: 0.6243 - val_acc: 0.7835\n",
      "Epoch 359/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6910 - acc: 0.7522 - val_loss: 0.6235 - val_acc: 0.7827\n",
      "Epoch 360/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6912 - acc: 0.7496 - val_loss: 0.6263 - val_acc: 0.7820\n",
      "Epoch 361/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6848 - acc: 0.7571 - val_loss: 0.6256 - val_acc: 0.7820\n",
      "Epoch 362/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6952 - acc: 0.7582 - val_loss: 0.6253 - val_acc: 0.7827\n",
      "Epoch 363/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6997 - acc: 0.7545 - val_loss: 0.6256 - val_acc: 0.7820\n",
      "Epoch 364/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6916 - acc: 0.7478 - val_loss: 0.6260 - val_acc: 0.7820\n",
      "Epoch 365/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7008 - acc: 0.7533 - val_loss: 0.6246 - val_acc: 0.7827\n",
      "\n",
      "Epoch 00365: loss improved from inf to 0.70083, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-1-000365-0.700826-0.782738.hdf5\n",
      "Epoch 366/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6820 - acc: 0.7567 - val_loss: 0.6247 - val_acc: 0.7827\n",
      "Epoch 367/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6870 - acc: 0.7511 - val_loss: 0.6251 - val_acc: 0.7827\n",
      "Epoch 368/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7079 - acc: 0.7526 - val_loss: 0.6233 - val_acc: 0.7827\n",
      "Epoch 369/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6958 - acc: 0.7463 - val_loss: 0.6256 - val_acc: 0.7820\n",
      "\n",
      "Epoch 00369: loss improved from 0.70083 to 0.69584, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-1-000369-0.695842-0.781994.hdf5\n",
      "Epoch 370/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6939 - acc: 0.7496 - val_loss: 0.6240 - val_acc: 0.7835\n",
      "Epoch 371/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6957 - acc: 0.7522 - val_loss: 0.6237 - val_acc: 0.7827\n",
      "Epoch 372/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6900 - acc: 0.7600 - val_loss: 0.6254 - val_acc: 0.7820\n",
      "Epoch 373/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6992 - acc: 0.7478 - val_loss: 0.6205 - val_acc: 0.7835\n",
      "Epoch 374/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6993 - acc: 0.7481 - val_loss: 0.6255 - val_acc: 0.7820\n",
      "Epoch 375/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7139 - acc: 0.7586 - val_loss: 0.6259 - val_acc: 0.7820\n",
      "Epoch 376/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6798 - acc: 0.7511 - val_loss: 0.6235 - val_acc: 0.7835\n",
      "Epoch 377/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6925 - acc: 0.7537 - val_loss: 0.6238 - val_acc: 0.7827\n",
      "\n",
      "Epoch 00377: loss improved from 0.69584 to 0.69250, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-1-000377-0.692497-0.782738.hdf5\n",
      "Epoch 378/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6932 - acc: 0.7604 - val_loss: 0.6258 - val_acc: 0.7820\n",
      "Epoch 379/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7103 - acc: 0.7463 - val_loss: 0.6198 - val_acc: 0.7835\n",
      "Epoch 380/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6914 - acc: 0.7537 - val_loss: 0.6155 - val_acc: 0.7842\n",
      "Epoch 381/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7062 - acc: 0.7541 - val_loss: 0.6234 - val_acc: 0.7835\n",
      "Epoch 382/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6945 - acc: 0.7597 - val_loss: 0.6223 - val_acc: 0.7835\n",
      "Epoch 383/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6866 - acc: 0.7615 - val_loss: 0.6257 - val_acc: 0.7820\n",
      "Epoch 384/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6877 - acc: 0.7519 - val_loss: 0.6254 - val_acc: 0.7820\n",
      "Epoch 385/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6908 - acc: 0.7638 - val_loss: 0.6261 - val_acc: 0.7820\n",
      "\n",
      "Epoch 00385: loss improved from 0.69250 to 0.69076, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-1-000385-0.690762-0.781994.hdf5\n",
      "Epoch 386/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6997 - acc: 0.7489 - val_loss: 0.6234 - val_acc: 0.7827\n",
      "Epoch 387/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6852 - acc: 0.7481 - val_loss: 0.6248 - val_acc: 0.7827\n",
      "Epoch 388/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6966 - acc: 0.7470 - val_loss: 0.6249 - val_acc: 0.7827\n",
      "Epoch 389/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6975 - acc: 0.7541 - val_loss: 0.6248 - val_acc: 0.7827\n",
      "Epoch 390/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7011 - acc: 0.7586 - val_loss: 0.6209 - val_acc: 0.7842\n",
      "Epoch 391/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6840 - acc: 0.7667 - val_loss: 0.6248 - val_acc: 0.7827\n",
      "Epoch 392/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6928 - acc: 0.7563 - val_loss: 0.6256 - val_acc: 0.7820\n",
      "Epoch 393/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6867 - acc: 0.7545 - val_loss: 0.6244 - val_acc: 0.7827\n",
      "\n",
      "Epoch 00393: loss improved from 0.69076 to 0.68666, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-1-000393-0.686663-0.782738.hdf5\n",
      "Epoch 394/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6980 - acc: 0.7478 - val_loss: 0.6260 - val_acc: 0.7820\n",
      "Epoch 395/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6983 - acc: 0.7533 - val_loss: 0.6250 - val_acc: 0.7827\n",
      "Epoch 396/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7003 - acc: 0.7552 - val_loss: 0.6256 - val_acc: 0.7827\n",
      "Epoch 397/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7068 - acc: 0.7515 - val_loss: 0.6239 - val_acc: 0.7827\n",
      "Epoch 398/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6869 - acc: 0.7578 - val_loss: 0.6249 - val_acc: 0.7827\n",
      "Epoch 399/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6900 - acc: 0.7552 - val_loss: 0.6254 - val_acc: 0.7820\n",
      "Epoch 400/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6932 - acc: 0.7493 - val_loss: 0.6252 - val_acc: 0.7820\n",
      "\n",
      "Epoch 00400: saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/1-000400-0.693158-0.781994.hdf5\n",
      "Epoch 401/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6905 - acc: 0.7545 - val_loss: 0.6249 - val_acc: 0.7820\n",
      "Epoch 402/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7052 - acc: 0.7537 - val_loss: 0.6168 - val_acc: 0.7842\n",
      "Epoch 403/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6958 - acc: 0.7522 - val_loss: 0.6258 - val_acc: 0.7820\n",
      "Epoch 404/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6953 - acc: 0.7545 - val_loss: 0.6131 - val_acc: 0.7842\n",
      "Epoch 405/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6978 - acc: 0.7448 - val_loss: 0.6243 - val_acc: 0.7827\n",
      "Epoch 406/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6961 - acc: 0.7474 - val_loss: 0.6255 - val_acc: 0.7820\n",
      "Epoch 407/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6921 - acc: 0.7474 - val_loss: 0.6237 - val_acc: 0.7835\n",
      "Epoch 408/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7124 - acc: 0.7507 - val_loss: 0.6253 - val_acc: 0.7820\n",
      "Epoch 409/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6960 - acc: 0.7574 - val_loss: 0.6219 - val_acc: 0.7835\n",
      "Epoch 410/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7074 - acc: 0.7612 - val_loss: 0.6256 - val_acc: 0.7820\n",
      "Epoch 411/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6989 - acc: 0.7548 - val_loss: 0.6224 - val_acc: 0.7835\n",
      "Epoch 412/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7072 - acc: 0.7545 - val_loss: 0.6252 - val_acc: 0.7827\n",
      "Epoch 413/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7021 - acc: 0.7519 - val_loss: 0.6248 - val_acc: 0.7827\n",
      "Epoch 414/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6937 - acc: 0.7478 - val_loss: 0.6242 - val_acc: 0.7827\n",
      "Epoch 415/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6824 - acc: 0.7530 - val_loss: 0.6215 - val_acc: 0.7835\n",
      "Epoch 416/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7015 - acc: 0.7504 - val_loss: 0.6250 - val_acc: 0.7827\n",
      "Epoch 417/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.6957 - acc: 0.7574 - val_loss: 0.6259 - val_acc: 0.7820\n",
      "Epoch 418/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7012 - acc: 0.7519 - val_loss: 0.6249 - val_acc: 0.7827\n",
      "Epoch 419/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6960 - acc: 0.7474 - val_loss: 0.6243 - val_acc: 0.7827\n",
      "Epoch 420/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6970 - acc: 0.7530 - val_loss: 0.6244 - val_acc: 0.7827\n",
      "Epoch 421/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6850 - acc: 0.7589 - val_loss: 0.6246 - val_acc: 0.7835\n",
      "Epoch 422/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6926 - acc: 0.7533 - val_loss: 0.6250 - val_acc: 0.7827\n",
      "Epoch 423/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6988 - acc: 0.7481 - val_loss: 0.6258 - val_acc: 0.7820\n",
      "Epoch 424/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7045 - acc: 0.7496 - val_loss: 0.6227 - val_acc: 0.7835\n",
      "Epoch 425/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6868 - acc: 0.7455 - val_loss: 0.6237 - val_acc: 0.7827\n",
      "Epoch 426/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6893 - acc: 0.7593 - val_loss: 0.6215 - val_acc: 0.7827\n",
      "Epoch 427/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7032 - acc: 0.7504 - val_loss: 0.6254 - val_acc: 0.7820\n",
      "Epoch 428/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6924 - acc: 0.7485 - val_loss: 0.6235 - val_acc: 0.7827\n",
      "Epoch 429/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7022 - acc: 0.7560 - val_loss: 0.6244 - val_acc: 0.7835\n",
      "Epoch 430/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6928 - acc: 0.7541 - val_loss: 0.6247 - val_acc: 0.7827\n",
      "Epoch 431/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6954 - acc: 0.7526 - val_loss: 0.6259 - val_acc: 0.7820\n",
      "Epoch 432/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6976 - acc: 0.7560 - val_loss: 0.6258 - val_acc: 0.7820\n",
      "Epoch 433/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6869 - acc: 0.7500 - val_loss: 0.6241 - val_acc: 0.7827\n",
      "Epoch 434/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7052 - acc: 0.7589 - val_loss: 0.6248 - val_acc: 0.7827\n",
      "Epoch 435/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6884 - acc: 0.7563 - val_loss: 0.6259 - val_acc: 0.7820\n",
      "Epoch 436/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6794 - acc: 0.7626 - val_loss: 0.6254 - val_acc: 0.7820\n",
      "Epoch 437/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6923 - acc: 0.7533 - val_loss: 0.6256 - val_acc: 0.7820\n",
      "Epoch 438/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7088 - acc: 0.7459 - val_loss: 0.6228 - val_acc: 0.7827\n",
      "Epoch 439/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6967 - acc: 0.7496 - val_loss: 0.6253 - val_acc: 0.7827\n",
      "Epoch 440/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6924 - acc: 0.7552 - val_loss: 0.6250 - val_acc: 0.7827\n",
      "Epoch 441/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6952 - acc: 0.7437 - val_loss: 0.6221 - val_acc: 0.7842\n",
      "Epoch 442/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6928 - acc: 0.7545 - val_loss: 0.6245 - val_acc: 0.7827\n",
      "Epoch 443/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6884 - acc: 0.7519 - val_loss: 0.6261 - val_acc: 0.7820\n",
      "Epoch 444/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7011 - acc: 0.7444 - val_loss: 0.6234 - val_acc: 0.7842\n",
      "Epoch 445/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7074 - acc: 0.7485 - val_loss: 0.6254 - val_acc: 0.7820\n",
      "Epoch 446/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6915 - acc: 0.7493 - val_loss: 0.6252 - val_acc: 0.7820\n",
      "Epoch 447/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6818 - acc: 0.7563 - val_loss: 0.6240 - val_acc: 0.7827\n",
      "Epoch 448/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7054 - acc: 0.7448 - val_loss: 0.6246 - val_acc: 0.7827\n",
      "Epoch 449/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6941 - acc: 0.7548 - val_loss: 0.6230 - val_acc: 0.7827\n",
      "Epoch 450/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6987 - acc: 0.7522 - val_loss: 0.6254 - val_acc: 0.7820\n",
      "Epoch 451/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6934 - acc: 0.7563 - val_loss: 0.6247 - val_acc: 0.7827\n",
      "Epoch 452/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6975 - acc: 0.7485 - val_loss: 0.6257 - val_acc: 0.7820\n",
      "Epoch 453/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6996 - acc: 0.7571 - val_loss: 0.6225 - val_acc: 0.7835\n",
      "Epoch 454/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7102 - acc: 0.7526 - val_loss: 0.6258 - val_acc: 0.7820\n",
      "Epoch 455/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6876 - acc: 0.7496 - val_loss: 0.6243 - val_acc: 0.7827\n",
      "Epoch 456/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6958 - acc: 0.7496 - val_loss: 0.6243 - val_acc: 0.7835\n",
      "Epoch 457/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6977 - acc: 0.7560 - val_loss: 0.6259 - val_acc: 0.7820\n",
      "Epoch 458/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6929 - acc: 0.7545 - val_loss: 0.6249 - val_acc: 0.7820\n",
      "Epoch 459/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6857 - acc: 0.7574 - val_loss: 0.6254 - val_acc: 0.7820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 460/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6988 - acc: 0.7552 - val_loss: 0.6254 - val_acc: 0.7820\n",
      "Epoch 461/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6900 - acc: 0.7530 - val_loss: 0.6253 - val_acc: 0.7827\n",
      "Epoch 462/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6850 - acc: 0.7552 - val_loss: 0.6222 - val_acc: 0.7842\n",
      "Epoch 463/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6853 - acc: 0.7511 - val_loss: 0.6247 - val_acc: 0.7827\n",
      "Epoch 464/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7024 - acc: 0.7533 - val_loss: 0.6209 - val_acc: 0.7842\n",
      "Epoch 465/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6814 - acc: 0.7541 - val_loss: 0.6246 - val_acc: 0.7827\n",
      "\n",
      "Epoch 00465: loss improved from inf to 0.68141, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-1-000465-0.681410-0.782738.hdf5\n",
      "Epoch 466/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6971 - acc: 0.7563 - val_loss: 0.6240 - val_acc: 0.7827\n",
      "Epoch 467/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6942 - acc: 0.7455 - val_loss: 0.6251 - val_acc: 0.7820\n",
      "Epoch 468/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6913 - acc: 0.7541 - val_loss: 0.6244 - val_acc: 0.7827\n",
      "Epoch 469/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6909 - acc: 0.7604 - val_loss: 0.6255 - val_acc: 0.7820\n",
      "Epoch 470/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6932 - acc: 0.7489 - val_loss: 0.6252 - val_acc: 0.7827\n",
      "Epoch 471/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6922 - acc: 0.7563 - val_loss: 0.6229 - val_acc: 0.7835\n",
      "Epoch 472/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6978 - acc: 0.7530 - val_loss: 0.6261 - val_acc: 0.7820\n",
      "Epoch 473/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6859 - acc: 0.7526 - val_loss: 0.6249 - val_acc: 0.7827\n",
      "Epoch 474/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6871 - acc: 0.7645 - val_loss: 0.6255 - val_acc: 0.7820\n",
      "Epoch 475/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6865 - acc: 0.7578 - val_loss: 0.6253 - val_acc: 0.7820\n",
      "Epoch 476/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6844 - acc: 0.7582 - val_loss: 0.6250 - val_acc: 0.7820\n",
      "Epoch 477/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6813 - acc: 0.7582 - val_loss: 0.6236 - val_acc: 0.7827\n",
      "\n",
      "Epoch 00477: loss improved from 0.68141 to 0.68129, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-1-000477-0.681286-0.782738.hdf5\n",
      "Epoch 478/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6892 - acc: 0.7556 - val_loss: 0.6249 - val_acc: 0.7820\n",
      "Epoch 479/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6910 - acc: 0.7586 - val_loss: 0.6238 - val_acc: 0.7827\n",
      "Epoch 480/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7157 - acc: 0.7537 - val_loss: 0.6224 - val_acc: 0.7827\n",
      "Epoch 481/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7033 - acc: 0.7463 - val_loss: 0.6256 - val_acc: 0.7820\n",
      "Epoch 482/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7034 - acc: 0.7571 - val_loss: 0.6251 - val_acc: 0.7827\n",
      "Epoch 483/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6917 - acc: 0.7522 - val_loss: 0.6243 - val_acc: 0.7827\n",
      "Epoch 484/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6894 - acc: 0.7593 - val_loss: 0.6253 - val_acc: 0.7820\n",
      "Epoch 485/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7030 - acc: 0.7519 - val_loss: 0.6251 - val_acc: 0.7827\n",
      "Epoch 486/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6884 - acc: 0.7593 - val_loss: 0.6229 - val_acc: 0.7842\n",
      "Epoch 487/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6913 - acc: 0.7615 - val_loss: 0.6237 - val_acc: 0.7835\n",
      "Epoch 488/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6951 - acc: 0.7504 - val_loss: 0.6218 - val_acc: 0.7835\n",
      "Epoch 489/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6938 - acc: 0.7530 - val_loss: 0.6225 - val_acc: 0.7827\n",
      "Epoch 490/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7077 - acc: 0.7481 - val_loss: 0.6244 - val_acc: 0.7827\n",
      "Epoch 491/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6862 - acc: 0.7552 - val_loss: 0.6250 - val_acc: 0.7820\n",
      "Epoch 492/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6915 - acc: 0.7560 - val_loss: 0.6247 - val_acc: 0.7827\n",
      "Epoch 493/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6971 - acc: 0.7511 - val_loss: 0.6245 - val_acc: 0.7820\n",
      "Epoch 494/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6921 - acc: 0.7578 - val_loss: 0.6241 - val_acc: 0.7827\n",
      "Epoch 495/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6816 - acc: 0.7597 - val_loss: 0.6240 - val_acc: 0.7827\n",
      "Epoch 496/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6891 - acc: 0.7530 - val_loss: 0.6260 - val_acc: 0.7820\n",
      "Epoch 497/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6960 - acc: 0.7556 - val_loss: 0.6243 - val_acc: 0.7827\n",
      "Epoch 498/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7073 - acc: 0.7459 - val_loss: 0.6244 - val_acc: 0.7827\n",
      "Epoch 499/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7080 - acc: 0.7522 - val_loss: 0.6257 - val_acc: 0.7820\n",
      "Epoch 500/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6916 - acc: 0.7619 - val_loss: 0.6228 - val_acc: 0.7827\n",
      "\n",
      "Epoch 00500: saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/1-000500-0.691629-0.782738.hdf5\n",
      "Epoch 501/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6830 - acc: 0.7608 - val_loss: 0.6228 - val_acc: 0.7827\n",
      "Epoch 502/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7121 - acc: 0.7385 - val_loss: 0.6252 - val_acc: 0.7827\n",
      "Epoch 503/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7051 - acc: 0.7459 - val_loss: 0.6255 - val_acc: 0.7820\n",
      "Epoch 504/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6922 - acc: 0.7537 - val_loss: 0.6253 - val_acc: 0.7827\n",
      "Epoch 505/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6863 - acc: 0.7589 - val_loss: 0.6257 - val_acc: 0.7820\n",
      "Epoch 506/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7019 - acc: 0.7537 - val_loss: 0.6241 - val_acc: 0.7835\n",
      "Epoch 507/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6839 - acc: 0.7552 - val_loss: 0.6239 - val_acc: 0.7835\n",
      "Epoch 508/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6881 - acc: 0.7485 - val_loss: 0.6249 - val_acc: 0.7827\n",
      "Epoch 509/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6887 - acc: 0.7526 - val_loss: 0.6250 - val_acc: 0.7827\n",
      "Epoch 510/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6871 - acc: 0.7582 - val_loss: 0.6239 - val_acc: 0.7835\n",
      "Epoch 511/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6981 - acc: 0.7485 - val_loss: 0.6253 - val_acc: 0.7820\n",
      "Epoch 512/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6892 - acc: 0.7515 - val_loss: 0.6255 - val_acc: 0.7820\n",
      "Epoch 513/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6903 - acc: 0.7530 - val_loss: 0.6238 - val_acc: 0.7827\n",
      "Epoch 514/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6961 - acc: 0.7493 - val_loss: 0.6261 - val_acc: 0.7820\n",
      "Epoch 515/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6844 - acc: 0.7519 - val_loss: 0.6258 - val_acc: 0.7820\n",
      "Epoch 00515: early stopping\n",
      "ModelCheckpoint 已经保存到 ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/1-final.hdf5\n",
      "save in: ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/log/20220201_2000_64_1_3_1.csv\n",
      "time: 0:13:38 s\n",
      "time: 818.0 s\n",
      "average 0.818000 s\n",
      "1 epoch finished\n",
      "--------------------   best   --------------------\n",
      "no_activities: 10\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1348/1348 [==============================] - 1s 801us/step\n",
      "1-milan:\tacc: 78.26%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 4, 7, 4, 4, 1, 0, 0, 1, 4, 0, 0, 7, 7, 7, 4, 0, 0, 0, 0, 2, 2, 2, 2, 2, 7, 7, 2, 9, 9, 9, 9, 9, 9, 9, 9, 4, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 0, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9, 0, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 4, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 4, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 0, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 7, 7, 7, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 0, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 5, 7, 7, 7, 2, 2, 7, 0, 7, 2, 2, 0, 0, 7, 0, 1, 0, 4, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 7, 5, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 7, 9, 4, 0, 7, 0, 0, 0, 7, 0, 0, 9, 0, 0, 0, 0, 5, 0, 4, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 7, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 4, 0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 7, 0, 9, 0, 0, 0, 0, 0, 4, 0, 4, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 7, 0, 0, 0, 0, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 7, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 7, 0, 9, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 7, 0, 0, 0, 4, 0, 4, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 0, 0, 0, 0, 4, 0, 7, 0, 5, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 7, 0, 9, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 0, 0, 7, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 7, 4, 4, 4, 4, 0, 7, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 7, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 9, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 9, 0, 9, 9, 9, 0, 0, 9, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 4, 0, 0, 4, 4, 4, 7, 0, 0, 0, 7, 4, 4, 0, 9, 0, 9, 0, 0, 4, 4, 4, 0, 0, 9, 0, 0, 4, 0, 0, 0]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.814199  0.865169  0.838911       623\n",
      "         Work   0.666667  0.080000  0.142857        25\n",
      "Take_medicine   0.833333  0.500000  0.625000        20\n",
      "        Sleep   0.000000  0.000000  0.000000        32\n",
      "        Relax   0.671533  0.647887  0.659498       142\n",
      "   Leave_Home   0.897059  0.847222  0.871429        72\n",
      "          Eat   0.000000  0.000000  0.000000         8\n",
      "         Cook   0.714912  0.885870  0.791262       184\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        30\n",
      "      Bathing   0.789916  0.886792  0.835556       212\n",
      "\n",
      "     accuracy                       0.782641      1348\n",
      "    macro avg   0.538762  0.471294  0.476451      1348\n",
      " weighted avg   0.741492  0.782641  0.755070      1348\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  28   0   0   2   0   0]\n",
      " [  0   2   0   0   0   2   0  15   6   0]\n",
      " [  0   0   0   0   0   3   0   4   1   0]\n",
      " [  0   0   0  10   0   8   1   1   0   0]\n",
      " [  0   0   0   0 188   3   0  20   1   0]\n",
      " [  0   0   0   0   0 163   0  19   2   0]\n",
      " [  0   0   0   2   1   8  61   0   0   0]\n",
      " [  0   1   0   0  10  32   6 539  35   0]\n",
      " [  0   0   0   0   3   9   0  38  92   0]\n",
      " [  0   0   0   0   8   0   0  24   0   0]]\n",
      "--------------------   final   --------------------\n",
      "no_activities: 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1348/1348 [==============================] - 1s 800us/step\n",
      "1-milan:\tacc: 78.26%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 4, 7, 4, 4, 1, 0, 0, 1, 4, 0, 0, 7, 7, 7, 4, 0, 0, 0, 0, 2, 2, 2, 2, 2, 7, 7, 2, 9, 9, 9, 9, 9, 9, 9, 9, 4, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 0, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9, 0, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 4, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 4, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 0, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 5, 5, 5, 7, 7, 7, 5, 5, 5, 7, 5, 5, 7, 5, 5, 5, 5, 5, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 0, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 5, 7, 7, 7, 2, 2, 7, 0, 7, 2, 2, 0, 0, 7, 0, 1, 0, 4, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 7, 5, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 7, 9, 4, 0, 7, 0, 0, 0, 7, 0, 0, 9, 0, 0, 0, 0, 5, 0, 4, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 7, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 4, 0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 7, 0, 9, 0, 0, 0, 0, 0, 4, 0, 4, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 7, 0, 0, 0, 0, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 7, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 7, 0, 9, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 7, 0, 0, 0, 4, 0, 4, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 0, 0, 0, 0, 4, 0, 7, 0, 5, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 7, 0, 9, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 4, 4, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 0, 0, 7, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 7, 4, 4, 4, 4, 0, 7, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 7, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 9, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 9, 0, 9, 9, 9, 0, 0, 9, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 4, 0, 0, 4, 4, 4, 7, 0, 0, 0, 7, 4, 4, 0, 9, 0, 9, 0, 0, 4, 4, 4, 0, 0, 9, 0, 0, 4, 0, 0, 0]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.814199  0.865169  0.838911       623\n",
      "         Work   0.666667  0.080000  0.142857        25\n",
      "Take_medicine   0.833333  0.500000  0.625000        20\n",
      "        Sleep   0.000000  0.000000  0.000000        32\n",
      "        Relax   0.671533  0.647887  0.659498       142\n",
      "   Leave_Home   0.897059  0.847222  0.871429        72\n",
      "          Eat   0.000000  0.000000  0.000000         8\n",
      "         Cook   0.714912  0.885870  0.791262       184\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        30\n",
      "      Bathing   0.789916  0.886792  0.835556       212\n",
      "\n",
      "     accuracy                       0.782641      1348\n",
      "    macro avg   0.538762  0.471294  0.476451      1348\n",
      " weighted avg   0.741492  0.782641  0.755070      1348\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  28   0   0   2   0   0]\n",
      " [  0   2   0   0   0   2   0  15   6   0]\n",
      " [  0   0   0   0   0   3   0   4   1   0]\n",
      " [  0   0   0  10   0   8   1   1   0   0]\n",
      " [  0   0   0   0 188   3   0  20   1   0]\n",
      " [  0   0   0   0   0 163   0  19   2   0]\n",
      " [  0   0   0   2   1   8  61   0   0   0]\n",
      " [  0   1   0   0  10  32   6 539  35   0]\n",
      " [  0   0   0   0   3   9   0  38  92   0]\n",
      " [  0   0   0   0   8   0   0  24   0   0]]\n",
      "no_activities: 10\n",
      "\n",
      "Begin training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "42/42 [==============================] - 3s 72ms/step - loss: 1.6581 - acc: 0.4676 - val_loss: 1.4047 - val_acc: 0.5052\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.3832 - acc: 0.5618 - val_loss: 1.1978 - val_acc: 0.6562\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.2606 - acc: 0.5934 - val_loss: 1.1202 - val_acc: 0.6488\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.1879 - acc: 0.6187 - val_loss: 1.0668 - val_acc: 0.6503\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.1390 - acc: 0.6254 - val_loss: 1.0217 - val_acc: 0.6496\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0883 - acc: 0.6313 - val_loss: 0.9792 - val_acc: 0.6533\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0467 - acc: 0.6410 - val_loss: 0.9390 - val_acc: 0.6763\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0309 - acc: 0.6577 - val_loss: 0.9137 - val_acc: 0.6830\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9887 - acc: 0.6693 - val_loss: 0.8840 - val_acc: 0.7068\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9763 - acc: 0.6756 - val_loss: 0.8601 - val_acc: 0.7232\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9470 - acc: 0.6864 - val_loss: 0.8366 - val_acc: 0.7217\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9371 - acc: 0.7024 - val_loss: 0.8214 - val_acc: 0.7292\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9074 - acc: 0.7098 - val_loss: 0.7996 - val_acc: 0.7396\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9062 - acc: 0.7109 - val_loss: 0.7818 - val_acc: 0.7537\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9077 - acc: 0.7031 - val_loss: 0.7727 - val_acc: 0.7485\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8676 - acc: 0.7184 - val_loss: 0.7561 - val_acc: 0.7530\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8464 - acc: 0.7221 - val_loss: 0.7460 - val_acc: 0.7567\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8643 - acc: 0.7128 - val_loss: 0.7353 - val_acc: 0.7574\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8397 - acc: 0.7232 - val_loss: 0.7269 - val_acc: 0.7641\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8389 - acc: 0.7217 - val_loss: 0.7181 - val_acc: 0.7671\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8194 - acc: 0.7225 - val_loss: 0.7139 - val_acc: 0.7589\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.8133 - acc: 0.7347 - val_loss: 0.7020 - val_acc: 0.7619\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8094 - acc: 0.7355 - val_loss: 0.6990 - val_acc: 0.7589\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7993 - acc: 0.7299 - val_loss: 0.6926 - val_acc: 0.7664\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7942 - acc: 0.7251 - val_loss: 0.6863 - val_acc: 0.7693\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.8052 - acc: 0.7366 - val_loss: 0.6808 - val_acc: 0.7664\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8086 - acc: 0.7228 - val_loss: 0.6794 - val_acc: 0.7626\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7862 - acc: 0.7299 - val_loss: 0.6759 - val_acc: 0.7634\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7930 - acc: 0.7258 - val_loss: 0.6740 - val_acc: 0.7664\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7703 - acc: 0.7426 - val_loss: 0.6698 - val_acc: 0.7671\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7935 - acc: 0.7225 - val_loss: 0.6652 - val_acc: 0.7664\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7722 - acc: 0.7426 - val_loss: 0.6606 - val_acc: 0.7701\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7724 - acc: 0.7314 - val_loss: 0.6599 - val_acc: 0.7701\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7690 - acc: 0.7359 - val_loss: 0.6575 - val_acc: 0.7693\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7736 - acc: 0.7321 - val_loss: 0.6546 - val_acc: 0.7731\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7706 - acc: 0.7411 - val_loss: 0.6518 - val_acc: 0.7723\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7765 - acc: 0.7388 - val_loss: 0.6539 - val_acc: 0.7693\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7683 - acc: 0.7310 - val_loss: 0.6498 - val_acc: 0.7716\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7812 - acc: 0.7247 - val_loss: 0.6522 - val_acc: 0.7701\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7589 - acc: 0.7411 - val_loss: 0.6516 - val_acc: 0.7723\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7411 - acc: 0.7496 - val_loss: 0.6448 - val_acc: 0.7775\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7491 - acc: 0.7374 - val_loss: 0.6433 - val_acc: 0.7753\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7472 - acc: 0.7470 - val_loss: 0.6452 - val_acc: 0.7746\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7447 - acc: 0.7422 - val_loss: 0.6414 - val_acc: 0.7753\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7659 - acc: 0.7374 - val_loss: 0.6458 - val_acc: 0.7753\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7451 - acc: 0.7422 - val_loss: 0.6416 - val_acc: 0.7753\n",
      "Epoch 47/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7651 - acc: 0.7396 - val_loss: 0.6401 - val_acc: 0.7731\n",
      "Epoch 48/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7370 - acc: 0.7429 - val_loss: 0.6348 - val_acc: 0.7768\n",
      "Epoch 49/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7455 - acc: 0.7429 - val_loss: 0.6329 - val_acc: 0.7812\n",
      "Epoch 50/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7507 - acc: 0.7422 - val_loss: 0.6367 - val_acc: 0.7760\n",
      "Epoch 51/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7411 - acc: 0.7455 - val_loss: 0.6323 - val_acc: 0.7753\n",
      "Epoch 52/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7397 - acc: 0.7504 - val_loss: 0.6309 - val_acc: 0.7768\n",
      "Epoch 53/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7423 - acc: 0.7448 - val_loss: 0.6297 - val_acc: 0.7790\n",
      "Epoch 54/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7440 - acc: 0.7455 - val_loss: 0.6310 - val_acc: 0.7798\n",
      "Epoch 55/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7271 - acc: 0.7533 - val_loss: 0.6304 - val_acc: 0.7790\n",
      "Epoch 56/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7289 - acc: 0.7493 - val_loss: 0.6273 - val_acc: 0.7731\n",
      "Epoch 57/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7363 - acc: 0.7452 - val_loss: 0.6228 - val_acc: 0.7760\n",
      "Epoch 58/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7393 - acc: 0.7463 - val_loss: 0.6259 - val_acc: 0.7768\n",
      "Epoch 59/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7277 - acc: 0.7422 - val_loss: 0.6260 - val_acc: 0.7775\n",
      "Epoch 60/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7203 - acc: 0.7522 - val_loss: 0.6247 - val_acc: 0.7812\n",
      "Epoch 61/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7197 - acc: 0.7452 - val_loss: 0.6217 - val_acc: 0.7812\n",
      "Epoch 62/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7315 - acc: 0.7459 - val_loss: 0.6212 - val_acc: 0.7827\n",
      "Epoch 63/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7319 - acc: 0.7403 - val_loss: 0.6218 - val_acc: 0.7790\n",
      "Epoch 64/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7300 - acc: 0.7496 - val_loss: 0.6187 - val_acc: 0.7820\n",
      "Epoch 65/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7235 - acc: 0.7448 - val_loss: 0.6185 - val_acc: 0.7798\n",
      "\n",
      "Epoch 00065: loss improved from inf to 0.72351, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-2-000065-0.723508-0.779762.hdf5\n",
      "Epoch 66/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7149 - acc: 0.7478 - val_loss: 0.6216 - val_acc: 0.7790\n",
      "Epoch 67/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7021 - acc: 0.7608 - val_loss: 0.6158 - val_acc: 0.7790\n",
      "Epoch 68/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7202 - acc: 0.7489 - val_loss: 0.6153 - val_acc: 0.7827\n",
      "Epoch 69/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7072 - acc: 0.7597 - val_loss: 0.6132 - val_acc: 0.7805\n",
      "\n",
      "Epoch 00069: loss improved from 0.72351 to 0.70722, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-2-000069-0.707216-0.780506.hdf5\n",
      "Epoch 70/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7044 - acc: 0.7552 - val_loss: 0.6123 - val_acc: 0.7805\n",
      "Epoch 71/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7062 - acc: 0.7541 - val_loss: 0.6126 - val_acc: 0.7790\n",
      "Epoch 72/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7225 - acc: 0.7459 - val_loss: 0.6132 - val_acc: 0.7820\n",
      "Epoch 73/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7146 - acc: 0.7507 - val_loss: 0.6122 - val_acc: 0.7827\n",
      "Epoch 74/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7164 - acc: 0.7440 - val_loss: 0.6115 - val_acc: 0.7805\n",
      "Epoch 75/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6986 - acc: 0.7597 - val_loss: 0.6088 - val_acc: 0.7805\n",
      "Epoch 76/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7142 - acc: 0.7548 - val_loss: 0.6101 - val_acc: 0.7820\n",
      "Epoch 77/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7047 - acc: 0.7507 - val_loss: 0.6096 - val_acc: 0.7820\n",
      "\n",
      "Epoch 00077: loss improved from 0.70722 to 0.70470, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-2-000077-0.704701-0.781994.hdf5\n",
      "Epoch 78/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7228 - acc: 0.7504 - val_loss: 0.6103 - val_acc: 0.7865\n",
      "Epoch 79/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7166 - acc: 0.7560 - val_loss: 0.5985 - val_acc: 0.7842\n",
      "Epoch 80/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7115 - acc: 0.7452 - val_loss: 0.6114 - val_acc: 0.7812\n",
      "Epoch 81/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7092 - acc: 0.7493 - val_loss: 0.6056 - val_acc: 0.7827\n",
      "Epoch 82/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7097 - acc: 0.7522 - val_loss: 0.6080 - val_acc: 0.7835\n",
      "Epoch 83/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7122 - acc: 0.7582 - val_loss: 0.6061 - val_acc: 0.7857\n",
      "Epoch 84/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6970 - acc: 0.7563 - val_loss: 0.6040 - val_acc: 0.7842\n",
      "Epoch 85/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7161 - acc: 0.7422 - val_loss: 0.6056 - val_acc: 0.7835\n",
      "Epoch 86/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7121 - acc: 0.7567 - val_loss: 0.6062 - val_acc: 0.7805\n",
      "Epoch 87/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7059 - acc: 0.7474 - val_loss: 0.6082 - val_acc: 0.7827\n",
      "Epoch 88/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7045 - acc: 0.7574 - val_loss: 0.6045 - val_acc: 0.7842\n",
      "Epoch 89/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7112 - acc: 0.7530 - val_loss: 0.6067 - val_acc: 0.7827\n",
      "Epoch 90/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6989 - acc: 0.7586 - val_loss: 0.6054 - val_acc: 0.7827\n",
      "Epoch 91/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7028 - acc: 0.7556 - val_loss: 0.6045 - val_acc: 0.7835\n",
      "Epoch 92/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7132 - acc: 0.7496 - val_loss: 0.6037 - val_acc: 0.7887\n",
      "Epoch 93/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6884 - acc: 0.7612 - val_loss: 0.6037 - val_acc: 0.7879\n",
      "\n",
      "Epoch 00093: loss improved from 0.70470 to 0.68845, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-2-000093-0.688450-0.787946.hdf5\n",
      "Epoch 94/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7012 - acc: 0.7548 - val_loss: 0.6025 - val_acc: 0.7879\n",
      "Epoch 95/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7151 - acc: 0.7485 - val_loss: 0.6025 - val_acc: 0.7879\n",
      "Epoch 96/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6960 - acc: 0.7526 - val_loss: 0.6003 - val_acc: 0.7865\n",
      "Epoch 97/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.6850 - acc: 0.7530 - val_loss: 0.6012 - val_acc: 0.7879\n",
      "\n",
      "Epoch 00097: loss improved from 0.68845 to 0.68499, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-2-000097-0.684992-0.787946.hdf5\n",
      "Epoch 98/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6928 - acc: 0.7638 - val_loss: 0.5990 - val_acc: 0.7872\n",
      "Epoch 99/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6943 - acc: 0.7556 - val_loss: 0.5997 - val_acc: 0.7894\n",
      "Epoch 100/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7046 - acc: 0.7519 - val_loss: 0.6021 - val_acc: 0.7879\n",
      "\n",
      "Epoch 00100: saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/2-000100-0.704560-0.787946.hdf5\n",
      "Epoch 101/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7118 - acc: 0.7548 - val_loss: 0.6023 - val_acc: 0.7865\n",
      "Epoch 102/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6958 - acc: 0.7600 - val_loss: 0.5956 - val_acc: 0.7865\n",
      "Epoch 103/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7008 - acc: 0.7593 - val_loss: 0.5993 - val_acc: 0.7879\n",
      "Epoch 104/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6989 - acc: 0.7470 - val_loss: 0.5999 - val_acc: 0.7872\n",
      "Epoch 105/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7038 - acc: 0.7556 - val_loss: 0.5994 - val_acc: 0.7879\n",
      "Epoch 106/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6903 - acc: 0.7567 - val_loss: 0.5997 - val_acc: 0.7850\n",
      "Epoch 107/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6937 - acc: 0.7560 - val_loss: 0.5964 - val_acc: 0.7850\n",
      "Epoch 108/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6857 - acc: 0.7615 - val_loss: 0.5989 - val_acc: 0.7865\n",
      "Epoch 109/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6826 - acc: 0.7623 - val_loss: 0.5982 - val_acc: 0.7887\n",
      "Epoch 110/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7026 - acc: 0.7481 - val_loss: 0.5999 - val_acc: 0.7887\n",
      "Epoch 111/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6844 - acc: 0.7656 - val_loss: 0.5978 - val_acc: 0.7917\n",
      "Epoch 112/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7059 - acc: 0.7571 - val_loss: 0.5971 - val_acc: 0.7872\n",
      "Epoch 113/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6810 - acc: 0.7705 - val_loss: 0.5956 - val_acc: 0.7887\n",
      "Epoch 114/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6877 - acc: 0.7686 - val_loss: 0.5962 - val_acc: 0.7902\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6889 - acc: 0.7619 - val_loss: 0.5973 - val_acc: 0.7872\n",
      "Epoch 116/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6912 - acc: 0.7500 - val_loss: 0.5966 - val_acc: 0.7872\n",
      "Epoch 117/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6957 - acc: 0.7574 - val_loss: 0.5972 - val_acc: 0.7865\n",
      "Epoch 118/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6949 - acc: 0.7560 - val_loss: 0.5968 - val_acc: 0.7887\n",
      "Epoch 119/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6844 - acc: 0.7560 - val_loss: 0.5968 - val_acc: 0.7872\n",
      "Epoch 120/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6877 - acc: 0.7604 - val_loss: 0.5972 - val_acc: 0.7879\n",
      "Epoch 121/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6966 - acc: 0.7481 - val_loss: 0.5974 - val_acc: 0.7879\n",
      "Epoch 122/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6883 - acc: 0.7612 - val_loss: 0.5941 - val_acc: 0.7879\n",
      "Epoch 123/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6876 - acc: 0.7641 - val_loss: 0.5972 - val_acc: 0.7894\n",
      "Epoch 124/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6814 - acc: 0.7615 - val_loss: 0.5968 - val_acc: 0.7872\n",
      "Epoch 125/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7034 - acc: 0.7586 - val_loss: 0.5937 - val_acc: 0.7909\n",
      "Epoch 126/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6884 - acc: 0.7560 - val_loss: 0.5943 - val_acc: 0.7894\n",
      "Epoch 127/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6848 - acc: 0.7638 - val_loss: 0.5964 - val_acc: 0.7902\n",
      "Epoch 128/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6883 - acc: 0.7630 - val_loss: 0.5932 - val_acc: 0.7932\n",
      "Epoch 129/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6969 - acc: 0.7571 - val_loss: 0.5965 - val_acc: 0.7924\n",
      "Epoch 130/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6796 - acc: 0.7567 - val_loss: 0.5930 - val_acc: 0.7894\n",
      "Epoch 131/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6787 - acc: 0.7630 - val_loss: 0.5905 - val_acc: 0.7902\n",
      "Epoch 132/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6753 - acc: 0.7626 - val_loss: 0.5935 - val_acc: 0.7909\n",
      "Epoch 133/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6840 - acc: 0.7615 - val_loss: 0.5948 - val_acc: 0.7917\n",
      "Epoch 134/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6727 - acc: 0.7634 - val_loss: 0.5925 - val_acc: 0.7909\n",
      "Epoch 135/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6916 - acc: 0.7574 - val_loss: 0.5930 - val_acc: 0.7879\n",
      "Epoch 136/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6979 - acc: 0.7567 - val_loss: 0.5940 - val_acc: 0.7909\n",
      "Epoch 137/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6832 - acc: 0.7608 - val_loss: 0.5939 - val_acc: 0.7917\n",
      "Epoch 138/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6801 - acc: 0.7630 - val_loss: 0.5924 - val_acc: 0.7909\n",
      "Epoch 139/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6836 - acc: 0.7623 - val_loss: 0.5932 - val_acc: 0.7902\n",
      "Epoch 140/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6967 - acc: 0.7630 - val_loss: 0.5937 - val_acc: 0.7924\n",
      "Epoch 141/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6830 - acc: 0.7623 - val_loss: 0.5941 - val_acc: 0.7946\n",
      "Epoch 142/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6860 - acc: 0.7645 - val_loss: 0.5949 - val_acc: 0.7939\n",
      "Epoch 143/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6817 - acc: 0.7582 - val_loss: 0.5892 - val_acc: 0.7939\n",
      "Epoch 144/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6876 - acc: 0.7582 - val_loss: 0.5933 - val_acc: 0.7909\n",
      "Epoch 145/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6763 - acc: 0.7608 - val_loss: 0.5923 - val_acc: 0.7917\n",
      "Epoch 146/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6808 - acc: 0.7738 - val_loss: 0.5919 - val_acc: 0.7909\n",
      "Epoch 147/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6823 - acc: 0.7653 - val_loss: 0.5897 - val_acc: 0.7924\n",
      "Epoch 148/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6764 - acc: 0.7608 - val_loss: 0.5905 - val_acc: 0.7894\n",
      "Epoch 149/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6715 - acc: 0.7697 - val_loss: 0.5904 - val_acc: 0.7932\n",
      "Epoch 150/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6910 - acc: 0.7556 - val_loss: 0.5907 - val_acc: 0.7879\n",
      "Epoch 151/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6767 - acc: 0.7571 - val_loss: 0.5905 - val_acc: 0.7917\n",
      "Epoch 152/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6644 - acc: 0.7653 - val_loss: 0.5906 - val_acc: 0.7909\n",
      "Epoch 153/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6669 - acc: 0.7630 - val_loss: 0.5871 - val_acc: 0.7939\n",
      "Epoch 154/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6743 - acc: 0.7593 - val_loss: 0.5860 - val_acc: 0.7939\n",
      "Epoch 155/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6632 - acc: 0.7660 - val_loss: 0.5875 - val_acc: 0.7909\n",
      "Epoch 156/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6814 - acc: 0.7582 - val_loss: 0.5883 - val_acc: 0.7939\n",
      "Epoch 157/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6772 - acc: 0.7686 - val_loss: 0.5859 - val_acc: 0.7924\n",
      "Epoch 158/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6780 - acc: 0.7664 - val_loss: 0.5885 - val_acc: 0.7894\n",
      "Epoch 159/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6852 - acc: 0.7586 - val_loss: 0.5876 - val_acc: 0.7932\n",
      "Epoch 160/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6581 - acc: 0.7634 - val_loss: 0.5886 - val_acc: 0.7924\n",
      "Epoch 161/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6837 - acc: 0.7608 - val_loss: 0.5888 - val_acc: 0.7946\n",
      "Epoch 162/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6859 - acc: 0.7563 - val_loss: 0.5854 - val_acc: 0.7902\n",
      "Epoch 163/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6728 - acc: 0.7623 - val_loss: 0.5854 - val_acc: 0.7939\n",
      "Epoch 164/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6711 - acc: 0.7671 - val_loss: 0.5866 - val_acc: 0.7902\n",
      "Epoch 165/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6687 - acc: 0.7679 - val_loss: 0.5875 - val_acc: 0.7887\n",
      "\n",
      "Epoch 00165: loss improved from inf to 0.66866, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-2-000165-0.668665-0.788690.hdf5\n",
      "Epoch 166/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6752 - acc: 0.7719 - val_loss: 0.5874 - val_acc: 0.7946\n",
      "Epoch 167/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6658 - acc: 0.7679 - val_loss: 0.5754 - val_acc: 0.7946\n",
      "Epoch 168/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6682 - acc: 0.7734 - val_loss: 0.5855 - val_acc: 0.7932\n",
      "Epoch 169/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6770 - acc: 0.7615 - val_loss: 0.5880 - val_acc: 0.7924\n",
      "Epoch 170/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6789 - acc: 0.7623 - val_loss: 0.5874 - val_acc: 0.7954\n",
      "Epoch 171/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6791 - acc: 0.7615 - val_loss: 0.5861 - val_acc: 0.7939\n",
      "Epoch 172/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6581 - acc: 0.7697 - val_loss: 0.5863 - val_acc: 0.7961\n",
      "Epoch 173/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6692 - acc: 0.7612 - val_loss: 0.5855 - val_acc: 0.7961\n",
      "Epoch 174/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6689 - acc: 0.7630 - val_loss: 0.5850 - val_acc: 0.7946\n",
      "Epoch 175/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6620 - acc: 0.7675 - val_loss: 0.5859 - val_acc: 0.7924\n",
      "Epoch 176/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6713 - acc: 0.7671 - val_loss: 0.5868 - val_acc: 0.7887\n",
      "Epoch 177/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6892 - acc: 0.7586 - val_loss: 0.5848 - val_acc: 0.7909\n",
      "Epoch 178/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6760 - acc: 0.7615 - val_loss: 0.5883 - val_acc: 0.7924\n",
      "Epoch 179/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6666 - acc: 0.7686 - val_loss: 0.5856 - val_acc: 0.7902\n",
      "Epoch 180/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6810 - acc: 0.7645 - val_loss: 0.5827 - val_acc: 0.7909\n",
      "\n",
      "Epoch 00180: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 181/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6681 - acc: 0.7612 - val_loss: 0.5852 - val_acc: 0.7932\n",
      "\n",
      "Epoch 00181: loss improved from 0.66866 to 0.66813, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-2-000181-0.668128-0.793155.hdf5\n",
      "Epoch 182/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6552 - acc: 0.7723 - val_loss: 0.5865 - val_acc: 0.7902\n",
      "Epoch 183/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6608 - acc: 0.7705 - val_loss: 0.5850 - val_acc: 0.7894\n",
      "Epoch 184/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6610 - acc: 0.7656 - val_loss: 0.5855 - val_acc: 0.7924\n",
      "Epoch 185/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6654 - acc: 0.7731 - val_loss: 0.5832 - val_acc: 0.7932\n",
      "\n",
      "Epoch 00185: loss improved from 0.66813 to 0.66537, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-2-000185-0.665375-0.793155.hdf5\n",
      "Epoch 186/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6530 - acc: 0.7719 - val_loss: 0.5851 - val_acc: 0.7879\n",
      "Epoch 187/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6863 - acc: 0.7615 - val_loss: 0.5845 - val_acc: 0.7909\n",
      "Epoch 188/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6665 - acc: 0.7705 - val_loss: 0.5859 - val_acc: 0.7894\n",
      "Epoch 189/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6759 - acc: 0.7619 - val_loss: 0.5848 - val_acc: 0.7924\n",
      "Epoch 190/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6652 - acc: 0.7723 - val_loss: 0.5863 - val_acc: 0.7902\n",
      "Epoch 191/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6698 - acc: 0.7686 - val_loss: 0.5849 - val_acc: 0.7887\n",
      "Epoch 192/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6637 - acc: 0.7623 - val_loss: 0.5857 - val_acc: 0.7894\n",
      "Epoch 193/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6541 - acc: 0.7634 - val_loss: 0.5836 - val_acc: 0.7924\n",
      "\n",
      "Epoch 00193: loss improved from 0.66537 to 0.65405, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-2-000193-0.654054-0.792411.hdf5\n",
      "Epoch 194/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6695 - acc: 0.7667 - val_loss: 0.5862 - val_acc: 0.7909\n",
      "Epoch 195/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6727 - acc: 0.7574 - val_loss: 0.5848 - val_acc: 0.7917\n",
      "Epoch 196/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6741 - acc: 0.7645 - val_loss: 0.5846 - val_acc: 0.7917\n",
      "Epoch 197/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6727 - acc: 0.7638 - val_loss: 0.5742 - val_acc: 0.7909\n",
      "Epoch 198/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6601 - acc: 0.7675 - val_loss: 0.5860 - val_acc: 0.7887\n",
      "Epoch 199/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6488 - acc: 0.7697 - val_loss: 0.5833 - val_acc: 0.7909\n",
      "Epoch 200/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6694 - acc: 0.7679 - val_loss: 0.5845 - val_acc: 0.7909\n",
      "\n",
      "Epoch 00200: saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/2-000200-0.669403-0.790923.hdf5\n",
      "Epoch 201/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6568 - acc: 0.7638 - val_loss: 0.5831 - val_acc: 0.7909\n",
      "Epoch 202/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6720 - acc: 0.7630 - val_loss: 0.5828 - val_acc: 0.7924\n",
      "Epoch 203/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6517 - acc: 0.7719 - val_loss: 0.5848 - val_acc: 0.7909\n",
      "Epoch 204/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6809 - acc: 0.7634 - val_loss: 0.5858 - val_acc: 0.7894\n",
      "Epoch 205/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6639 - acc: 0.7649 - val_loss: 0.5843 - val_acc: 0.7924\n",
      "Epoch 206/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6681 - acc: 0.7716 - val_loss: 0.5846 - val_acc: 0.7917\n",
      "Epoch 207/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6726 - acc: 0.7556 - val_loss: 0.5847 - val_acc: 0.7917\n",
      "Epoch 208/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6615 - acc: 0.7623 - val_loss: 0.5851 - val_acc: 0.7932\n",
      "Epoch 209/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.6688 - acc: 0.7679 - val_loss: 0.5825 - val_acc: 0.7917\n",
      "Epoch 210/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6579 - acc: 0.7686 - val_loss: 0.5840 - val_acc: 0.7917\n",
      "Epoch 211/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6547 - acc: 0.7749 - val_loss: 0.5846 - val_acc: 0.7909\n",
      "Epoch 212/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6698 - acc: 0.7708 - val_loss: 0.5803 - val_acc: 0.7924\n",
      "Epoch 213/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6786 - acc: 0.7586 - val_loss: 0.5847 - val_acc: 0.7909\n",
      "Epoch 214/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6778 - acc: 0.7656 - val_loss: 0.5844 - val_acc: 0.7909\n",
      "Epoch 215/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.6600 - acc: 0.7653 - val_loss: 0.5859 - val_acc: 0.7902\n",
      "Epoch 216/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.6787 - acc: 0.7612 - val_loss: 0.5853 - val_acc: 0.7924\n",
      "Epoch 217/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6681 - acc: 0.7593 - val_loss: 0.5845 - val_acc: 0.7917\n",
      "Epoch 218/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6492 - acc: 0.7772 - val_loss: 0.5827 - val_acc: 0.7924\n",
      "Epoch 219/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6729 - acc: 0.7630 - val_loss: 0.5860 - val_acc: 0.7909\n",
      "\n",
      "Epoch 00219: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 220/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6651 - acc: 0.7679 - val_loss: 0.5862 - val_acc: 0.7917\n",
      "Epoch 221/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6566 - acc: 0.7690 - val_loss: 0.5855 - val_acc: 0.7909\n",
      "Epoch 222/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6514 - acc: 0.7798 - val_loss: 0.5854 - val_acc: 0.7909\n",
      "Epoch 223/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6541 - acc: 0.7686 - val_loss: 0.5818 - val_acc: 0.7924\n",
      "Epoch 224/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6396 - acc: 0.7816 - val_loss: 0.5829 - val_acc: 0.7917\n",
      "Epoch 225/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6587 - acc: 0.7690 - val_loss: 0.5847 - val_acc: 0.7902\n",
      "Epoch 226/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6581 - acc: 0.7649 - val_loss: 0.5821 - val_acc: 0.7894\n",
      "Epoch 227/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6432 - acc: 0.7667 - val_loss: 0.5856 - val_acc: 0.7894\n",
      "Epoch 228/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6725 - acc: 0.7682 - val_loss: 0.5842 - val_acc: 0.7902\n",
      "Epoch 229/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6745 - acc: 0.7578 - val_loss: 0.5852 - val_acc: 0.7894\n",
      "Epoch 230/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6566 - acc: 0.7783 - val_loss: 0.5843 - val_acc: 0.7894\n",
      "Epoch 231/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6750 - acc: 0.7693 - val_loss: 0.5849 - val_acc: 0.7902\n",
      "Epoch 232/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6661 - acc: 0.7656 - val_loss: 0.5841 - val_acc: 0.7902\n",
      "Epoch 233/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6641 - acc: 0.7716 - val_loss: 0.5838 - val_acc: 0.7902\n",
      "Epoch 234/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.6703 - acc: 0.7653 - val_loss: 0.5827 - val_acc: 0.7902\n",
      "Epoch 235/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.6568 - acc: 0.7645 - val_loss: 0.5848 - val_acc: 0.7887\n",
      "Epoch 236/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6717 - acc: 0.7656 - val_loss: 0.5857 - val_acc: 0.7887\n",
      "Epoch 237/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.6643 - acc: 0.7697 - val_loss: 0.5846 - val_acc: 0.7894\n",
      "Epoch 238/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6576 - acc: 0.7772 - val_loss: 0.5836 - val_acc: 0.7894\n",
      "Epoch 239/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6602 - acc: 0.7571 - val_loss: 0.5837 - val_acc: 0.7894\n",
      "Epoch 240/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.6700 - acc: 0.7667 - val_loss: 0.5834 - val_acc: 0.7902\n",
      "Epoch 241/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6527 - acc: 0.7727 - val_loss: 0.5858 - val_acc: 0.7887\n",
      "Epoch 242/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6673 - acc: 0.7645 - val_loss: 0.5848 - val_acc: 0.7887\n",
      "Epoch 243/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6632 - acc: 0.7645 - val_loss: 0.5832 - val_acc: 0.7894\n",
      "Epoch 244/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6644 - acc: 0.7664 - val_loss: 0.5839 - val_acc: 0.7902\n",
      "\n",
      "Epoch 00244: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 245/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6633 - acc: 0.7589 - val_loss: 0.5846 - val_acc: 0.7887\n",
      "Epoch 246/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6649 - acc: 0.7719 - val_loss: 0.5857 - val_acc: 0.7887\n",
      "Epoch 247/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6724 - acc: 0.7567 - val_loss: 0.5825 - val_acc: 0.7902\n",
      "Epoch 248/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6642 - acc: 0.7697 - val_loss: 0.5838 - val_acc: 0.7902\n",
      "Epoch 249/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6698 - acc: 0.7708 - val_loss: 0.5840 - val_acc: 0.7894\n",
      "Epoch 250/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6560 - acc: 0.7723 - val_loss: 0.5855 - val_acc: 0.7887\n",
      "Epoch 251/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6751 - acc: 0.7578 - val_loss: 0.5830 - val_acc: 0.7902\n",
      "Epoch 252/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6715 - acc: 0.7597 - val_loss: 0.5840 - val_acc: 0.7894\n",
      "Epoch 253/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6607 - acc: 0.7705 - val_loss: 0.5826 - val_acc: 0.7894\n",
      "Epoch 254/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6638 - acc: 0.7653 - val_loss: 0.5834 - val_acc: 0.7902\n",
      "Epoch 255/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6600 - acc: 0.7705 - val_loss: 0.5845 - val_acc: 0.7894\n",
      "Epoch 256/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6638 - acc: 0.7600 - val_loss: 0.5830 - val_acc: 0.7902\n",
      "Epoch 257/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6743 - acc: 0.7600 - val_loss: 0.5857 - val_acc: 0.7887\n",
      "Epoch 258/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6553 - acc: 0.7634 - val_loss: 0.5842 - val_acc: 0.7894\n",
      "Epoch 259/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6649 - acc: 0.7645 - val_loss: 0.5839 - val_acc: 0.7894\n",
      "Epoch 260/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6498 - acc: 0.7615 - val_loss: 0.5835 - val_acc: 0.7902\n",
      "Epoch 261/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6649 - acc: 0.7645 - val_loss: 0.5850 - val_acc: 0.7887\n",
      "Epoch 262/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6741 - acc: 0.7608 - val_loss: 0.5858 - val_acc: 0.7887\n",
      "Epoch 263/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6477 - acc: 0.7719 - val_loss: 0.5856 - val_acc: 0.7887\n",
      "Epoch 264/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6699 - acc: 0.7634 - val_loss: 0.5846 - val_acc: 0.7894\n",
      "Epoch 265/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6729 - acc: 0.7641 - val_loss: 0.5844 - val_acc: 0.7894\n",
      "\n",
      "Epoch 00265: loss improved from inf to 0.67292, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-2-000265-0.672917-0.789435.hdf5\n",
      "Epoch 266/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6631 - acc: 0.7682 - val_loss: 0.5852 - val_acc: 0.7887\n",
      "Epoch 267/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6754 - acc: 0.7623 - val_loss: 0.5841 - val_acc: 0.7894\n",
      "Epoch 268/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6627 - acc: 0.7638 - val_loss: 0.5841 - val_acc: 0.7894\n",
      "Epoch 269/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6538 - acc: 0.7653 - val_loss: 0.5840 - val_acc: 0.7894\n",
      "\n",
      "Epoch 00269: loss improved from 0.67292 to 0.65375, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-2-000269-0.653755-0.789435.hdf5\n",
      "Epoch 270/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6800 - acc: 0.7582 - val_loss: 0.5849 - val_acc: 0.7887\n",
      "Epoch 271/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6537 - acc: 0.7708 - val_loss: 0.5833 - val_acc: 0.7894\n",
      "Epoch 272/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6603 - acc: 0.7693 - val_loss: 0.5834 - val_acc: 0.7894\n",
      "Epoch 273/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6559 - acc: 0.7693 - val_loss: 0.5847 - val_acc: 0.7894\n",
      "Epoch 274/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6752 - acc: 0.7626 - val_loss: 0.5832 - val_acc: 0.7909\n",
      "Epoch 275/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.6549 - acc: 0.7727 - val_loss: 0.5846 - val_acc: 0.7894\n",
      "Epoch 276/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6680 - acc: 0.7682 - val_loss: 0.5845 - val_acc: 0.7894\n",
      "Epoch 277/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6601 - acc: 0.7667 - val_loss: 0.5844 - val_acc: 0.7894\n",
      "Epoch 278/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6740 - acc: 0.7612 - val_loss: 0.5849 - val_acc: 0.7887\n",
      "Epoch 279/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6539 - acc: 0.7716 - val_loss: 0.5843 - val_acc: 0.7894\n",
      "Epoch 280/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6618 - acc: 0.7675 - val_loss: 0.5853 - val_acc: 0.7887\n",
      "Epoch 281/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6746 - acc: 0.7615 - val_loss: 0.5854 - val_acc: 0.7887\n",
      "Epoch 282/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6694 - acc: 0.7664 - val_loss: 0.5844 - val_acc: 0.7894\n",
      "Epoch 283/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6696 - acc: 0.7645 - val_loss: 0.5847 - val_acc: 0.7894\n",
      "Epoch 284/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6559 - acc: 0.7753 - val_loss: 0.5828 - val_acc: 0.7894\n",
      "Epoch 285/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6642 - acc: 0.7701 - val_loss: 0.5824 - val_acc: 0.7894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6696 - acc: 0.7638 - val_loss: 0.5844 - val_acc: 0.7887\n",
      "Epoch 287/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6697 - acc: 0.7693 - val_loss: 0.5856 - val_acc: 0.7887\n",
      "Epoch 288/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6672 - acc: 0.7697 - val_loss: 0.5823 - val_acc: 0.7894\n",
      "Epoch 289/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6679 - acc: 0.7664 - val_loss: 0.5846 - val_acc: 0.7887\n",
      "Epoch 290/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6741 - acc: 0.7597 - val_loss: 0.5832 - val_acc: 0.7902\n",
      "Epoch 291/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6625 - acc: 0.7708 - val_loss: 0.5687 - val_acc: 0.7917\n",
      "Epoch 292/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6671 - acc: 0.7630 - val_loss: 0.5815 - val_acc: 0.7894\n",
      "Epoch 293/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6788 - acc: 0.7563 - val_loss: 0.5844 - val_acc: 0.7894\n",
      "Epoch 294/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6688 - acc: 0.7593 - val_loss: 0.5833 - val_acc: 0.7902\n",
      "Epoch 295/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6592 - acc: 0.7667 - val_loss: 0.5846 - val_acc: 0.7894\n",
      "Epoch 296/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6747 - acc: 0.7686 - val_loss: 0.5848 - val_acc: 0.7894\n",
      "Epoch 297/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6605 - acc: 0.7574 - val_loss: 0.5859 - val_acc: 0.7887\n",
      "Epoch 298/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6679 - acc: 0.7600 - val_loss: 0.5833 - val_acc: 0.7902\n",
      "Epoch 299/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6602 - acc: 0.7734 - val_loss: 0.5843 - val_acc: 0.7894\n",
      "Epoch 300/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6602 - acc: 0.7731 - val_loss: 0.5851 - val_acc: 0.7887\n",
      "\n",
      "Epoch 00300: saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/2-000300-0.660220-0.788690.hdf5\n",
      "Epoch 301/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6522 - acc: 0.7749 - val_loss: 0.5835 - val_acc: 0.7894\n",
      "Epoch 302/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6753 - acc: 0.7604 - val_loss: 0.5845 - val_acc: 0.7894\n",
      "Epoch 303/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6699 - acc: 0.7582 - val_loss: 0.5844 - val_acc: 0.7902\n",
      "Epoch 304/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6635 - acc: 0.7675 - val_loss: 0.5838 - val_acc: 0.7902\n",
      "Epoch 305/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6803 - acc: 0.7574 - val_loss: 0.5841 - val_acc: 0.7894\n",
      "Epoch 306/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.6506 - acc: 0.7757 - val_loss: 0.5829 - val_acc: 0.7902\n",
      "Epoch 307/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6638 - acc: 0.7686 - val_loss: 0.5830 - val_acc: 0.7894\n",
      "Epoch 308/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6657 - acc: 0.7675 - val_loss: 0.5853 - val_acc: 0.7887\n",
      "Epoch 309/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6667 - acc: 0.7649 - val_loss: 0.5850 - val_acc: 0.7894\n",
      "Epoch 310/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6665 - acc: 0.7690 - val_loss: 0.5832 - val_acc: 0.7894\n",
      "Epoch 311/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6780 - acc: 0.7563 - val_loss: 0.5853 - val_acc: 0.7887\n",
      "Epoch 312/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6646 - acc: 0.7723 - val_loss: 0.5853 - val_acc: 0.7887\n",
      "Epoch 313/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6712 - acc: 0.7623 - val_loss: 0.5848 - val_acc: 0.7894\n",
      "Epoch 314/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6717 - acc: 0.7552 - val_loss: 0.5857 - val_acc: 0.7887\n",
      "Epoch 315/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6643 - acc: 0.7697 - val_loss: 0.5858 - val_acc: 0.7887\n",
      "Epoch 316/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6612 - acc: 0.7716 - val_loss: 0.5801 - val_acc: 0.7902\n",
      "Epoch 317/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6652 - acc: 0.7664 - val_loss: 0.5843 - val_acc: 0.7894\n",
      "Epoch 318/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6584 - acc: 0.7649 - val_loss: 0.5815 - val_acc: 0.7902\n",
      "Epoch 319/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6734 - acc: 0.7667 - val_loss: 0.5827 - val_acc: 0.7902\n",
      "Epoch 320/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6626 - acc: 0.7716 - val_loss: 0.5838 - val_acc: 0.7894\n",
      "Epoch 321/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6770 - acc: 0.7660 - val_loss: 0.5850 - val_acc: 0.7887\n",
      "Epoch 322/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6534 - acc: 0.7712 - val_loss: 0.5835 - val_acc: 0.7902\n",
      "Epoch 323/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6621 - acc: 0.7600 - val_loss: 0.5833 - val_acc: 0.7902\n",
      "Epoch 324/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6550 - acc: 0.7705 - val_loss: 0.5850 - val_acc: 0.7887\n",
      "Epoch 325/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6723 - acc: 0.7686 - val_loss: 0.5855 - val_acc: 0.7887\n",
      "Epoch 326/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.6638 - acc: 0.7705 - val_loss: 0.5857 - val_acc: 0.7887\n",
      "Epoch 327/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6768 - acc: 0.7634 - val_loss: 0.5849 - val_acc: 0.7887\n",
      "Epoch 328/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6774 - acc: 0.7519 - val_loss: 0.5828 - val_acc: 0.7902\n",
      "Epoch 329/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6643 - acc: 0.7615 - val_loss: 0.5831 - val_acc: 0.7894\n",
      "Epoch 330/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6720 - acc: 0.7667 - val_loss: 0.5850 - val_acc: 0.7887\n",
      "Epoch 331/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6727 - acc: 0.7634 - val_loss: 0.5846 - val_acc: 0.7894\n",
      "Epoch 332/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6683 - acc: 0.7798 - val_loss: 0.5843 - val_acc: 0.7894\n",
      "Epoch 333/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6603 - acc: 0.7675 - val_loss: 0.5847 - val_acc: 0.7887\n",
      "Epoch 334/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6690 - acc: 0.7671 - val_loss: 0.5849 - val_acc: 0.7887\n",
      "Epoch 335/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6782 - acc: 0.7645 - val_loss: 0.5847 - val_acc: 0.7887\n",
      "Epoch 336/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6583 - acc: 0.7634 - val_loss: 0.5840 - val_acc: 0.7894\n",
      "Epoch 337/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6742 - acc: 0.7630 - val_loss: 0.5838 - val_acc: 0.7902\n",
      "Epoch 338/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6693 - acc: 0.7656 - val_loss: 0.5849 - val_acc: 0.7887\n",
      "Epoch 339/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6619 - acc: 0.7686 - val_loss: 0.5833 - val_acc: 0.7894\n",
      "Epoch 340/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6769 - acc: 0.7619 - val_loss: 0.5851 - val_acc: 0.7887\n",
      "Epoch 341/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6645 - acc: 0.7723 - val_loss: 0.5831 - val_acc: 0.7909\n",
      "Epoch 342/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6770 - acc: 0.7690 - val_loss: 0.5845 - val_acc: 0.7894\n",
      "Epoch 343/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6701 - acc: 0.7716 - val_loss: 0.5841 - val_acc: 0.7902\n",
      "Epoch 344/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6647 - acc: 0.7645 - val_loss: 0.5849 - val_acc: 0.7894\n",
      "Epoch 345/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6809 - acc: 0.7582 - val_loss: 0.5841 - val_acc: 0.7894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 346/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6631 - acc: 0.7697 - val_loss: 0.5822 - val_acc: 0.7894\n",
      "Epoch 347/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6560 - acc: 0.7727 - val_loss: 0.5799 - val_acc: 0.7894\n",
      "Epoch 348/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6713 - acc: 0.7638 - val_loss: 0.5850 - val_acc: 0.7887\n",
      "Epoch 349/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6565 - acc: 0.7712 - val_loss: 0.5839 - val_acc: 0.7902\n",
      "Epoch 350/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6647 - acc: 0.7645 - val_loss: 0.5847 - val_acc: 0.7894\n",
      "Epoch 351/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6805 - acc: 0.7552 - val_loss: 0.5852 - val_acc: 0.7894\n",
      "Epoch 352/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6577 - acc: 0.7723 - val_loss: 0.5852 - val_acc: 0.7887\n",
      "Epoch 353/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6607 - acc: 0.7719 - val_loss: 0.5837 - val_acc: 0.7894\n",
      "Epoch 354/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6780 - acc: 0.7682 - val_loss: 0.5845 - val_acc: 0.7894\n",
      "Epoch 355/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6540 - acc: 0.7682 - val_loss: 0.5839 - val_acc: 0.7894\n",
      "Epoch 356/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6603 - acc: 0.7719 - val_loss: 0.5837 - val_acc: 0.7894\n",
      "Epoch 357/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6765 - acc: 0.7556 - val_loss: 0.5853 - val_acc: 0.7887\n",
      "Epoch 358/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6755 - acc: 0.7586 - val_loss: 0.5803 - val_acc: 0.7902\n",
      "Epoch 359/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6561 - acc: 0.7719 - val_loss: 0.5855 - val_acc: 0.7887\n",
      "Epoch 360/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6653 - acc: 0.7612 - val_loss: 0.5832 - val_acc: 0.7902\n",
      "Epoch 361/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6606 - acc: 0.7664 - val_loss: 0.5845 - val_acc: 0.7894\n",
      "Epoch 362/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6659 - acc: 0.7682 - val_loss: 0.5854 - val_acc: 0.7887\n",
      "Epoch 363/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6597 - acc: 0.7779 - val_loss: 0.5858 - val_acc: 0.7887\n",
      "Epoch 364/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6478 - acc: 0.7638 - val_loss: 0.5850 - val_acc: 0.7887\n",
      "Epoch 365/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6615 - acc: 0.7671 - val_loss: 0.5855 - val_acc: 0.7887\n",
      "\n",
      "Epoch 00365: loss improved from inf to 0.66153, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-2-000365-0.661528-0.788690.hdf5\n",
      "Epoch 366/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6515 - acc: 0.7742 - val_loss: 0.5823 - val_acc: 0.7902\n",
      "Epoch 367/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6667 - acc: 0.7671 - val_loss: 0.5846 - val_acc: 0.7894\n",
      "Epoch 368/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6605 - acc: 0.7671 - val_loss: 0.5827 - val_acc: 0.7902\n",
      "Epoch 369/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6604 - acc: 0.7734 - val_loss: 0.5854 - val_acc: 0.7887\n",
      "\n",
      "Epoch 00369: loss improved from 0.66153 to 0.66044, saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/Pbest-2-000369-0.660441-0.788690.hdf5\n",
      "Epoch 370/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6461 - acc: 0.7734 - val_loss: 0.5852 - val_acc: 0.7887\n",
      "Epoch 371/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6689 - acc: 0.7649 - val_loss: 0.5850 - val_acc: 0.7894\n",
      "Epoch 372/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6548 - acc: 0.7716 - val_loss: 0.5847 - val_acc: 0.7894\n",
      "Epoch 373/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6726 - acc: 0.7653 - val_loss: 0.5849 - val_acc: 0.7894\n",
      "Epoch 374/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6571 - acc: 0.7708 - val_loss: 0.5835 - val_acc: 0.7902\n",
      "Epoch 375/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6625 - acc: 0.7719 - val_loss: 0.5840 - val_acc: 0.7894\n",
      "Epoch 376/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6702 - acc: 0.7690 - val_loss: 0.5836 - val_acc: 0.7894\n",
      "Epoch 377/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6653 - acc: 0.7667 - val_loss: 0.5842 - val_acc: 0.7894\n",
      "Epoch 378/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6571 - acc: 0.7671 - val_loss: 0.5845 - val_acc: 0.7887\n",
      "Epoch 379/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6839 - acc: 0.7548 - val_loss: 0.5850 - val_acc: 0.7887\n",
      "Epoch 380/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6516 - acc: 0.7705 - val_loss: 0.5842 - val_acc: 0.7887\n",
      "Epoch 381/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6695 - acc: 0.7630 - val_loss: 0.5844 - val_acc: 0.7894\n",
      "Epoch 382/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6683 - acc: 0.7608 - val_loss: 0.5815 - val_acc: 0.7909\n",
      "Epoch 383/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6760 - acc: 0.7615 - val_loss: 0.5854 - val_acc: 0.7887\n",
      "Epoch 384/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6693 - acc: 0.7701 - val_loss: 0.5825 - val_acc: 0.7909\n",
      "Epoch 385/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6608 - acc: 0.7664 - val_loss: 0.5848 - val_acc: 0.7887\n",
      "Epoch 386/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6517 - acc: 0.7708 - val_loss: 0.5856 - val_acc: 0.7887\n",
      "Epoch 387/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6548 - acc: 0.7749 - val_loss: 0.5852 - val_acc: 0.7887\n",
      "Epoch 388/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6712 - acc: 0.7693 - val_loss: 0.5831 - val_acc: 0.7894\n",
      "Epoch 389/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6617 - acc: 0.7690 - val_loss: 0.5842 - val_acc: 0.7902\n",
      "Epoch 390/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6576 - acc: 0.7693 - val_loss: 0.5834 - val_acc: 0.7894\n",
      "Epoch 391/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6517 - acc: 0.7649 - val_loss: 0.5839 - val_acc: 0.7894\n",
      "Epoch 392/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6566 - acc: 0.7690 - val_loss: 0.5846 - val_acc: 0.7894\n",
      "Epoch 393/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6800 - acc: 0.7664 - val_loss: 0.5839 - val_acc: 0.7894\n",
      "Epoch 394/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6597 - acc: 0.7667 - val_loss: 0.5849 - val_acc: 0.7894\n",
      "Epoch 395/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6706 - acc: 0.7630 - val_loss: 0.5856 - val_acc: 0.7887\n",
      "Epoch 396/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6699 - acc: 0.7649 - val_loss: 0.5843 - val_acc: 0.7887\n",
      "Epoch 397/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6855 - acc: 0.7630 - val_loss: 0.5852 - val_acc: 0.7887\n",
      "Epoch 398/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6602 - acc: 0.7626 - val_loss: 0.5839 - val_acc: 0.7902\n",
      "Epoch 399/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.6720 - acc: 0.7593 - val_loss: 0.5857 - val_acc: 0.7887\n",
      "Epoch 400/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.6528 - acc: 0.7701 - val_loss: 0.5857 - val_acc: 0.7887\n",
      "\n",
      "Epoch 00400: saving model to ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/2-000400-0.652790-0.788690.hdf5\n",
      "Epoch 401/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6606 - acc: 0.7641 - val_loss: 0.5844 - val_acc: 0.7894\n",
      "Epoch 402/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6584 - acc: 0.7675 - val_loss: 0.5846 - val_acc: 0.7894\n",
      "Epoch 403/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6659 - acc: 0.7679 - val_loss: 0.5857 - val_acc: 0.7887\n",
      "Epoch 404/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6684 - acc: 0.7660 - val_loss: 0.5849 - val_acc: 0.7887\n",
      "Epoch 405/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6556 - acc: 0.7686 - val_loss: 0.5819 - val_acc: 0.7902\n",
      "Epoch 406/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6737 - acc: 0.7653 - val_loss: 0.5857 - val_acc: 0.7887\n",
      "Epoch 407/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6702 - acc: 0.7682 - val_loss: 0.5845 - val_acc: 0.7894\n",
      "Epoch 408/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6604 - acc: 0.7653 - val_loss: 0.5847 - val_acc: 0.7894\n",
      "Epoch 409/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6714 - acc: 0.7664 - val_loss: 0.5853 - val_acc: 0.7887\n",
      "Epoch 410/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6824 - acc: 0.7641 - val_loss: 0.5853 - val_acc: 0.7887\n",
      "Epoch 411/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6812 - acc: 0.7560 - val_loss: 0.5837 - val_acc: 0.7894\n",
      "Epoch 412/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6758 - acc: 0.7679 - val_loss: 0.5855 - val_acc: 0.7887\n",
      "Epoch 413/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6554 - acc: 0.7790 - val_loss: 0.5821 - val_acc: 0.7909\n",
      "Epoch 414/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6683 - acc: 0.7612 - val_loss: 0.5840 - val_acc: 0.7902\n",
      "Epoch 415/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6584 - acc: 0.7653 - val_loss: 0.5852 - val_acc: 0.7887\n",
      "Epoch 416/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6709 - acc: 0.7600 - val_loss: 0.5853 - val_acc: 0.7887\n",
      "Epoch 417/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6596 - acc: 0.7719 - val_loss: 0.5845 - val_acc: 0.7894\n",
      "Epoch 418/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6522 - acc: 0.7719 - val_loss: 0.5855 - val_acc: 0.7887\n",
      "Epoch 419/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6644 - acc: 0.7712 - val_loss: 0.5841 - val_acc: 0.7894\n",
      "Epoch 420/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6763 - acc: 0.7556 - val_loss: 0.5833 - val_acc: 0.7902\n",
      "Epoch 421/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6751 - acc: 0.7582 - val_loss: 0.5843 - val_acc: 0.7887\n",
      "Epoch 422/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6642 - acc: 0.7634 - val_loss: 0.5856 - val_acc: 0.7887\n",
      "Epoch 423/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6575 - acc: 0.7719 - val_loss: 0.5822 - val_acc: 0.7902\n",
      "Epoch 424/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6734 - acc: 0.7615 - val_loss: 0.5838 - val_acc: 0.7894\n",
      "Epoch 00424: early stopping\n",
      "ModelCheckpoint 已经保存到 ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/weights/2-final.hdf5\n",
      "save in: ../datasets/casas/results/WCNNR/milan/2/20220201_2000_64_1_3_1/log/20220201_2000_64_1_3_1.csv\n",
      "time: 0:11:10 s\n",
      "time: 670.0 s\n",
      "average 0.670000 s\n",
      "2 epoch finished\n",
      "--------------------   best   --------------------\n",
      "no_activities: 10\n",
      "\n",
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1348/1348 [==============================] - 1s 865us/step\n",
      "2-milan:\tacc: 78.86%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 3, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 5, 0, 0, 7, 0, 7, 2, 7, 0, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 7, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 0, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 0, 0, 4, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 4, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 4, 7, 7, 7, 7, 7, 4, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 0, 7, 7, 7, 7, 4, 7, 2, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 0, 9, 3, 3, 9, 9, 3, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 3, 9, 9, 9, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 9, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7, 2, 7, 7, 2, 2, 2, 7, 2, 0, 2, 2, 2, 7, 0, 0, 9, 0, 0, 7, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 4, 0, 0, 7, 9, 0, 0, 0, 0, 4, 0, 0, 3, 0, 9, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 7, 0, 0, 0, 0, 0, 9, 9, 0, 7, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7, 0, 7, 0, 0, 0, 5, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 4, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 4, 0, 9, 0, 0, 0, 0, 0, 0, 7, 0, 5, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 4, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 7, 4, 4, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 4, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 5, 4, 0, 0, 4, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 4, 4, 0, 4, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 0, 0, 4, 0, 4, 4, 4, 0, 4, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 0, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 7, 4, 4, 0, 3, 0, 3, 0, 3, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 9, 9, 0, 0, 0, 9, 3, 0, 0, 3, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 4, 4, 4, 4, 0, 0, 7, 0, 0, 4, 0, 4, 4, 4, 0, 4, 0, 0, 0, 0, 3, 0]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.791849  0.873194  0.830534       623\n",
      "         Work   0.000000  0.000000  0.000000        26\n",
      "Take_medicine   0.916667  0.550000  0.687500        20\n",
      "        Sleep   0.476190  0.312500  0.377358        32\n",
      "        Relax   0.732283  0.650350  0.688889       143\n",
      "   Leave_Home   0.866667  0.915493  0.890411        71\n",
      "          Eat   0.000000  0.000000  0.000000         7\n",
      "         Cook   0.816327  0.864865  0.839895       185\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        29\n",
      "      Bathing   0.782609  0.849057  0.814480       212\n",
      "\n",
      "     accuracy                       0.788576      1348\n",
      "    macro avg   0.538259  0.501546  0.512907      1348\n",
      " weighted avg   0.749315  0.788576  0.766342      1348\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  27   0   0   1   0   1]\n",
      " [  0   0   0   0   1   0   0  20   5   0]\n",
      " [  0   0   0   0   0   2   1   4   0   0]\n",
      " [  0   0   0  11   0   7   0   2   0   0]\n",
      " [  0   0   0   0 180   2   0  26   0   4]\n",
      " [  0   0   0   1   0 160   0  18   6   0]\n",
      " [  0   0   0   0   0   0  65   6   0   0]\n",
      " [  0   0   0   0  19  23   9 544  23   5]\n",
      " [  0   0   0   0   0   2   0  47  93   1]\n",
      " [  0   0   0   0   3   0   0  19   0  10]]\n",
      "--------------------   final   --------------------\n",
      "no_activities: 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1348/1348 [==============================] - 1s 923us/step\n",
      "2-milan:\tacc: 78.93%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 3, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 7, 0, 0, 0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 4, 4, 0, 4, 0, 0, 4, 0, 0, 0, 0, 7, 0, 5, 0, 0, 7, 0, 7, 2, 2, 0, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 0, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 0, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 0, 0, 4, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 4, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 4, 7, 0, 7, 7, 7, 4, 7, 0, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 0, 7, 7, 7, 7, 4, 7, 2, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 0, 9, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 0, 9, 3, 3, 9, 9, 3, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 3, 9, 9, 9, 9, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7, 2, 7, 7, 2, 2, 2, 7, 2, 0, 2, 2, 2, 7, 0, 0, 9, 0, 0, 7, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 4, 0, 0, 7, 9, 0, 0, 0, 0, 4, 0, 0, 3, 0, 9, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 7, 0, 0, 0, 0, 0, 9, 9, 0, 7, 0, 0, 0, 0, 0, 0, 7, 4, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7, 0, 0, 0, 5, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 0, 4, 0, 0, 0, 0, 4, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 4, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 5, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 7, 4, 4, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 9, 0, 0, 0, 0, 4, 7, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 5, 4, 0, 0, 4, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 7, 4, 4, 4, 4, 4, 0, 0, 4, 4, 4, 0, 4, 4, 4, 4, 0, 4, 4, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 4, 4, 0, 4, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 5, 0, 0, 4, 4, 4, 0, 4, 4, 4, 0, 4, 4, 0, 4, 4, 0, 4, 4, 4, 5, 4, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 0, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 7, 4, 4, 0, 3, 0, 3, 0, 3, 3, 0, 0, 0, 3, 0, 3, 0, 0, 0, 3, 0, 0, 0, 3, 9, 9, 0, 0, 0, 3, 3, 0, 0, 3, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 4, 4, 4, 4, 0, 0, 7, 0, 0, 4, 0, 4, 4, 4, 0, 4, 0, 0, 0, 0, 3, 0]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.792151  0.874799  0.831426       623\n",
      "         Work   0.000000  0.000000  0.000000        26\n",
      "Take_medicine   0.923077  0.600000  0.727273        20\n",
      "        Sleep   0.480000  0.375000  0.421053        32\n",
      "        Relax   0.720000  0.629371  0.671642       143\n",
      "   Leave_Home   0.848101  0.943662  0.893333        71\n",
      "          Eat   0.000000  0.000000  0.000000         7\n",
      "         Cook   0.813472  0.848649  0.830688       185\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        29\n",
      "      Bathing   0.804444  0.853774  0.828375       212\n",
      "\n",
      "     accuracy                       0.789318      1348\n",
      "    macro avg   0.538125  0.512525  0.520379      1348\n",
      " weighted avg   0.750402  0.789318  0.767628      1348\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  27   0   0   1   0   1]\n",
      " [  0   0   0   0   0   1   0  19   6   0]\n",
      " [  0   0   0   0   0   2   1   4   0   0]\n",
      " [  0   0   0  12   0   6   0   2   0   0]\n",
      " [  0   0   0   0 181   0   0  27   0   4]\n",
      " [  0   0   0   1   0 157   0  21   6   0]\n",
      " [  0   0   0   0   0   0  67   4   0   0]\n",
      " [  0   0   0   0  15  24   9 545  23   7]\n",
      " [  0   0   0   0   0   3   2  47  90   1]\n",
      " [  0   0   0   0   2   0   0  18   0  12]]\n",
      "best: current database: milan \t 78.34% (+/- 0.39%)\n",
      "final: current database: milan \t 78.37% (+/- 0.42%)\n",
      "CPU times: user 37min 41s, sys: 1min 34s, total: 39min 16s\n",
      "Wall time: 41min 56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dict_config_cus['distance_int'] = '2'\n",
    "train_val(dict_config_cus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "scrolled": true
   },
   "source": [
    "```bash\n",
    "best: current database: milan \t 78.34% (+/- 0.39%)\n",
    "final: current database: milan \t 78.37% (+/- 0.42%)\n",
    "CPU times: user 37min 41s, sys: 1min 34s, total: 39min 16s\n",
    "Wall time: 41min 56s\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='constrain_3'>CS_3</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current dataset: milan\n",
      "../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1\n",
      "no_activities: 10\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_37 (InputLayer)        (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_37 (Embedding)     (None, 2000, 64)          172544    \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 2000, 12)          780       \n",
      "_________________________________________________________________\n",
      "activation_109 (Activation)  (None, 2000, 12)          0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_37 (Glo (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 18)                234       \n",
      "_________________________________________________________________\n",
      "activation_110 (Activation)  (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 12)                228       \n",
      "_________________________________________________________________\n",
      "activation_111 (Activation)  (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 10)                130       \n",
      "=================================================================\n",
      "Total params: 173,916\n",
      "Trainable params: 173,916\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Create subdir directory: ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights...\n",
      "Begin training ...\n",
      "Epoch 1/1000\n",
      "42/42 [==============================] - 3s 74ms/step - loss: 1.7963 - acc: 0.4487 - val_loss: 1.4360 - val_acc: 0.5811\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.4384 - acc: 0.5640 - val_loss: 1.2332 - val_acc: 0.6302\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.2831 - acc: 0.6324 - val_loss: 1.0933 - val_acc: 0.6830\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.1802 - acc: 0.6611 - val_loss: 1.0161 - val_acc: 0.7106\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.1296 - acc: 0.6678 - val_loss: 0.9581 - val_acc: 0.7128\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0767 - acc: 0.6793 - val_loss: 0.9153 - val_acc: 0.7232\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0662 - acc: 0.6633 - val_loss: 0.8944 - val_acc: 0.7463\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0253 - acc: 0.6916 - val_loss: 0.8735 - val_acc: 0.7493\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9869 - acc: 0.6957 - val_loss: 0.8550 - val_acc: 0.7455\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9725 - acc: 0.7109 - val_loss: 0.8334 - val_acc: 0.7552\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9565 - acc: 0.7072 - val_loss: 0.8181 - val_acc: 0.7530\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9636 - acc: 0.7054 - val_loss: 0.8082 - val_acc: 0.7604\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9413 - acc: 0.7139 - val_loss: 0.7879 - val_acc: 0.7582\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9187 - acc: 0.7247 - val_loss: 0.7902 - val_acc: 0.7537\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8789 - acc: 0.7437 - val_loss: 0.7651 - val_acc: 0.7612\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8950 - acc: 0.7321 - val_loss: 0.7545 - val_acc: 0.7597\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8878 - acc: 0.7277 - val_loss: 0.7496 - val_acc: 0.7589\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8710 - acc: 0.7247 - val_loss: 0.7462 - val_acc: 0.7626\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.8777 - acc: 0.7362 - val_loss: 0.7375 - val_acc: 0.7641\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8547 - acc: 0.7355 - val_loss: 0.7252 - val_acc: 0.7671\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8580 - acc: 0.7295 - val_loss: 0.7231 - val_acc: 0.7679\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8570 - acc: 0.7310 - val_loss: 0.7181 - val_acc: 0.7664\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8630 - acc: 0.7318 - val_loss: 0.7112 - val_acc: 0.7671\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8591 - acc: 0.7258 - val_loss: 0.7047 - val_acc: 0.7708\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8438 - acc: 0.7310 - val_loss: 0.7027 - val_acc: 0.7701\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8295 - acc: 0.7418 - val_loss: 0.6979 - val_acc: 0.7716\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.8340 - acc: 0.7362 - val_loss: 0.6922 - val_acc: 0.7693\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8080 - acc: 0.7359 - val_loss: 0.6883 - val_acc: 0.7723\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8205 - acc: 0.7347 - val_loss: 0.6873 - val_acc: 0.7693\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8165 - acc: 0.7448 - val_loss: 0.6811 - val_acc: 0.7708\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8267 - acc: 0.7251 - val_loss: 0.6836 - val_acc: 0.7679\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8166 - acc: 0.7377 - val_loss: 0.6808 - val_acc: 0.7693\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8140 - acc: 0.7414 - val_loss: 0.6772 - val_acc: 0.7708\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.8131 - acc: 0.7385 - val_loss: 0.6731 - val_acc: 0.7723\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7973 - acc: 0.7414 - val_loss: 0.6709 - val_acc: 0.7693\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8010 - acc: 0.7414 - val_loss: 0.6657 - val_acc: 0.7708\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7967 - acc: 0.7381 - val_loss: 0.6653 - val_acc: 0.7723\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7991 - acc: 0.7392 - val_loss: 0.6592 - val_acc: 0.7701\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7868 - acc: 0.7526 - val_loss: 0.6628 - val_acc: 0.7701\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7919 - acc: 0.7429 - val_loss: 0.6592 - val_acc: 0.7731\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7793 - acc: 0.7388 - val_loss: 0.6571 - val_acc: 0.7716\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7996 - acc: 0.7307 - val_loss: 0.6573 - val_acc: 0.7716\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7891 - acc: 0.7396 - val_loss: 0.6582 - val_acc: 0.7723\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7877 - acc: 0.7377 - val_loss: 0.6632 - val_acc: 0.7701\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7865 - acc: 0.7418 - val_loss: 0.6548 - val_acc: 0.7746\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7783 - acc: 0.7407 - val_loss: 0.6562 - val_acc: 0.7723\n",
      "Epoch 47/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7801 - acc: 0.7463 - val_loss: 0.6586 - val_acc: 0.7708\n",
      "Epoch 48/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7721 - acc: 0.7385 - val_loss: 0.6548 - val_acc: 0.7701\n",
      "Epoch 49/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7806 - acc: 0.7433 - val_loss: 0.6534 - val_acc: 0.7723\n",
      "Epoch 50/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7918 - acc: 0.7318 - val_loss: 0.6504 - val_acc: 0.7746\n",
      "Epoch 51/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7789 - acc: 0.7519 - val_loss: 0.6521 - val_acc: 0.7701\n",
      "Epoch 52/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7835 - acc: 0.7381 - val_loss: 0.6514 - val_acc: 0.7723\n",
      "Epoch 53/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7765 - acc: 0.7440 - val_loss: 0.6517 - val_acc: 0.7693\n",
      "Epoch 54/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7733 - acc: 0.7452 - val_loss: 0.6511 - val_acc: 0.7708\n",
      "Epoch 55/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7753 - acc: 0.7440 - val_loss: 0.6474 - val_acc: 0.7738\n",
      "Epoch 56/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7546 - acc: 0.7470 - val_loss: 0.6470 - val_acc: 0.7731\n",
      "Epoch 57/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7571 - acc: 0.7493 - val_loss: 0.6444 - val_acc: 0.7753\n",
      "Epoch 58/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7540 - acc: 0.7507 - val_loss: 0.6461 - val_acc: 0.7701\n",
      "Epoch 59/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7698 - acc: 0.7355 - val_loss: 0.6413 - val_acc: 0.7738\n",
      "Epoch 60/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7563 - acc: 0.7489 - val_loss: 0.6408 - val_acc: 0.7783\n",
      "Epoch 61/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7600 - acc: 0.7470 - val_loss: 0.6407 - val_acc: 0.7746\n",
      "Epoch 62/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7429 - acc: 0.7515 - val_loss: 0.6400 - val_acc: 0.7753\n",
      "Epoch 63/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7551 - acc: 0.7541 - val_loss: 0.6402 - val_acc: 0.7775\n",
      "Epoch 64/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7660 - acc: 0.7533 - val_loss: 0.6397 - val_acc: 0.7798\n",
      "Epoch 65/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7631 - acc: 0.7511 - val_loss: 0.6392 - val_acc: 0.7693\n",
      "\n",
      "Epoch 00065: loss improved from inf to 0.76308, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-0-000065-0.763085-0.769345.hdf5\n",
      "Epoch 66/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7562 - acc: 0.7481 - val_loss: 0.6361 - val_acc: 0.7760\n",
      "Epoch 67/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7764 - acc: 0.7440 - val_loss: 0.6389 - val_acc: 0.7753\n",
      "Epoch 68/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7575 - acc: 0.7426 - val_loss: 0.6372 - val_acc: 0.7768\n",
      "Epoch 69/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7469 - acc: 0.7459 - val_loss: 0.6321 - val_acc: 0.7775\n",
      "\n",
      "Epoch 00069: loss improved from 0.76308 to 0.74685, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-0-000069-0.746852-0.777530.hdf5\n",
      "Epoch 70/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7394 - acc: 0.7548 - val_loss: 0.6385 - val_acc: 0.7738\n",
      "Epoch 71/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7625 - acc: 0.7452 - val_loss: 0.6393 - val_acc: 0.7716\n",
      "Epoch 72/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7422 - acc: 0.7545 - val_loss: 0.6348 - val_acc: 0.7738\n",
      "Epoch 73/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7677 - acc: 0.7489 - val_loss: 0.6367 - val_acc: 0.7738\n",
      "Epoch 74/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7581 - acc: 0.7470 - val_loss: 0.6375 - val_acc: 0.7731\n",
      "Epoch 75/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7570 - acc: 0.7545 - val_loss: 0.6356 - val_acc: 0.7760\n",
      "Epoch 76/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7433 - acc: 0.7537 - val_loss: 0.6333 - val_acc: 0.7768\n",
      "Epoch 77/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7456 - acc: 0.7515 - val_loss: 0.6336 - val_acc: 0.7738\n",
      "\n",
      "Epoch 00077: loss improved from 0.74685 to 0.74561, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-0-000077-0.745612-0.773810.hdf5\n",
      "Epoch 78/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7447 - acc: 0.7444 - val_loss: 0.6322 - val_acc: 0.7753\n",
      "Epoch 79/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7506 - acc: 0.7459 - val_loss: 0.6347 - val_acc: 0.7768\n",
      "Epoch 80/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7615 - acc: 0.7403 - val_loss: 0.6315 - val_acc: 0.7775\n",
      "Epoch 81/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7447 - acc: 0.7504 - val_loss: 0.6333 - val_acc: 0.7746\n",
      "\n",
      "Epoch 00081: loss improved from 0.74561 to 0.74467, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-0-000081-0.744671-0.774554.hdf5\n",
      "Epoch 82/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7431 - acc: 0.7530 - val_loss: 0.6290 - val_acc: 0.7783\n",
      "Epoch 83/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7549 - acc: 0.7533 - val_loss: 0.6324 - val_acc: 0.7760\n",
      "Epoch 84/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7450 - acc: 0.7541 - val_loss: 0.6343 - val_acc: 0.7731\n",
      "Epoch 85/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7322 - acc: 0.7507 - val_loss: 0.6327 - val_acc: 0.7760\n",
      "\n",
      "Epoch 00085: loss improved from 0.74467 to 0.73221, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-0-000085-0.732211-0.776042.hdf5\n",
      "Epoch 86/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7399 - acc: 0.7519 - val_loss: 0.6316 - val_acc: 0.7746\n",
      "Epoch 87/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7393 - acc: 0.7526 - val_loss: 0.6302 - val_acc: 0.7775\n",
      "Epoch 88/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7315 - acc: 0.7560 - val_loss: 0.6309 - val_acc: 0.7708\n",
      "Epoch 89/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7426 - acc: 0.7511 - val_loss: 0.6261 - val_acc: 0.7731\n",
      "Epoch 90/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7397 - acc: 0.7545 - val_loss: 0.6246 - val_acc: 0.7746\n",
      "Epoch 91/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7361 - acc: 0.7478 - val_loss: 0.6276 - val_acc: 0.7738\n",
      "Epoch 92/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7528 - acc: 0.7455 - val_loss: 0.6301 - val_acc: 0.7746\n",
      "Epoch 93/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7282 - acc: 0.7481 - val_loss: 0.6275 - val_acc: 0.7746\n",
      "\n",
      "Epoch 00093: loss improved from 0.73221 to 0.72817, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-0-000093-0.728169-0.774554.hdf5\n",
      "Epoch 94/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7340 - acc: 0.7537 - val_loss: 0.6293 - val_acc: 0.7731\n",
      "Epoch 95/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7466 - acc: 0.7533 - val_loss: 0.6283 - val_acc: 0.7738\n",
      "Epoch 96/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7278 - acc: 0.7537 - val_loss: 0.6268 - val_acc: 0.7731\n",
      "Epoch 97/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7310 - acc: 0.7589 - val_loss: 0.6260 - val_acc: 0.7723\n",
      "Epoch 98/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7301 - acc: 0.7574 - val_loss: 0.6268 - val_acc: 0.7775\n",
      "Epoch 99/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7376 - acc: 0.7507 - val_loss: 0.6260 - val_acc: 0.7775\n",
      "Epoch 100/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7328 - acc: 0.7600 - val_loss: 0.6220 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00100: saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/0-000100-0.732848-0.779018.hdf5\n",
      "Epoch 101/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7239 - acc: 0.7493 - val_loss: 0.6226 - val_acc: 0.7783\n",
      "Epoch 102/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7346 - acc: 0.7481 - val_loss: 0.6236 - val_acc: 0.7746\n",
      "Epoch 103/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7327 - acc: 0.7452 - val_loss: 0.6223 - val_acc: 0.7746\n",
      "Epoch 104/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7157 - acc: 0.7571 - val_loss: 0.6217 - val_acc: 0.7783\n",
      "Epoch 105/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7388 - acc: 0.7489 - val_loss: 0.6228 - val_acc: 0.7768\n",
      "Epoch 106/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7308 - acc: 0.7470 - val_loss: 0.6206 - val_acc: 0.7775\n",
      "Epoch 107/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7246 - acc: 0.7582 - val_loss: 0.6216 - val_acc: 0.7790\n",
      "Epoch 108/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7278 - acc: 0.7548 - val_loss: 0.6183 - val_acc: 0.7783\n",
      "Epoch 109/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7514 - acc: 0.7455 - val_loss: 0.6195 - val_acc: 0.7790\n",
      "Epoch 110/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7302 - acc: 0.7489 - val_loss: 0.6188 - val_acc: 0.7760\n",
      "Epoch 111/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7164 - acc: 0.7597 - val_loss: 0.6220 - val_acc: 0.7738\n",
      "Epoch 112/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7188 - acc: 0.7567 - val_loss: 0.6195 - val_acc: 0.7783\n",
      "Epoch 113/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7315 - acc: 0.7556 - val_loss: 0.6212 - val_acc: 0.7783\n",
      "Epoch 114/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7266 - acc: 0.7504 - val_loss: 0.6219 - val_acc: 0.7731\n",
      "Epoch 115/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7180 - acc: 0.7586 - val_loss: 0.6204 - val_acc: 0.7738\n",
      "Epoch 116/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7343 - acc: 0.7533 - val_loss: 0.6205 - val_acc: 0.7746\n",
      "Epoch 117/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7334 - acc: 0.7455 - val_loss: 0.6183 - val_acc: 0.7798\n",
      "Epoch 118/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7237 - acc: 0.7578 - val_loss: 0.6203 - val_acc: 0.7731\n",
      "Epoch 119/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7370 - acc: 0.7496 - val_loss: 0.6187 - val_acc: 0.7790\n",
      "Epoch 120/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7168 - acc: 0.7604 - val_loss: 0.6159 - val_acc: 0.7775\n",
      "Epoch 121/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7166 - acc: 0.7586 - val_loss: 0.6192 - val_acc: 0.7731\n",
      "Epoch 122/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7242 - acc: 0.7541 - val_loss: 0.6179 - val_acc: 0.7768\n",
      "Epoch 123/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7318 - acc: 0.7522 - val_loss: 0.6167 - val_acc: 0.7760\n",
      "Epoch 124/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7149 - acc: 0.7593 - val_loss: 0.6198 - val_acc: 0.7723\n",
      "Epoch 125/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7108 - acc: 0.7589 - val_loss: 0.6190 - val_acc: 0.7731\n",
      "Epoch 126/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7089 - acc: 0.7574 - val_loss: 0.6194 - val_acc: 0.7731\n",
      "Epoch 127/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7216 - acc: 0.7522 - val_loss: 0.6176 - val_acc: 0.7760\n",
      "Epoch 128/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7225 - acc: 0.7593 - val_loss: 0.6151 - val_acc: 0.7746\n",
      "Epoch 129/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7105 - acc: 0.7556 - val_loss: 0.6166 - val_acc: 0.7783\n",
      "Epoch 130/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7282 - acc: 0.7519 - val_loss: 0.6145 - val_acc: 0.7760\n",
      "Epoch 131/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7047 - acc: 0.7649 - val_loss: 0.6156 - val_acc: 0.7753\n",
      "Epoch 132/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7360 - acc: 0.7403 - val_loss: 0.6167 - val_acc: 0.7783\n",
      "Epoch 133/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7199 - acc: 0.7541 - val_loss: 0.6149 - val_acc: 0.7760\n",
      "Epoch 134/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7285 - acc: 0.7515 - val_loss: 0.6136 - val_acc: 0.7731\n",
      "Epoch 135/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7290 - acc: 0.7452 - val_loss: 0.6164 - val_acc: 0.7723\n",
      "Epoch 136/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7189 - acc: 0.7623 - val_loss: 0.6184 - val_acc: 0.7783\n",
      "Epoch 137/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7113 - acc: 0.7478 - val_loss: 0.6164 - val_acc: 0.7768\n",
      "Epoch 138/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7191 - acc: 0.7571 - val_loss: 0.6138 - val_acc: 0.7775\n",
      "Epoch 139/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7152 - acc: 0.7563 - val_loss: 0.6118 - val_acc: 0.7798\n",
      "Epoch 140/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7112 - acc: 0.7593 - val_loss: 0.6150 - val_acc: 0.7760\n",
      "Epoch 141/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7150 - acc: 0.7463 - val_loss: 0.6119 - val_acc: 0.7775\n",
      "Epoch 142/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7221 - acc: 0.7474 - val_loss: 0.6129 - val_acc: 0.7790\n",
      "Epoch 143/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7044 - acc: 0.7582 - val_loss: 0.6105 - val_acc: 0.7738\n",
      "Epoch 144/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7224 - acc: 0.7500 - val_loss: 0.6167 - val_acc: 0.7731\n",
      "Epoch 145/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7073 - acc: 0.7563 - val_loss: 0.6170 - val_acc: 0.7716\n",
      "Epoch 146/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7001 - acc: 0.7600 - val_loss: 0.6127 - val_acc: 0.7775\n",
      "Epoch 147/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7242 - acc: 0.7507 - val_loss: 0.6148 - val_acc: 0.7783\n",
      "Epoch 148/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7111 - acc: 0.7537 - val_loss: 0.6138 - val_acc: 0.7790\n",
      "Epoch 149/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7050 - acc: 0.7552 - val_loss: 0.6144 - val_acc: 0.7753\n",
      "Epoch 150/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7133 - acc: 0.7600 - val_loss: 0.6143 - val_acc: 0.7760\n",
      "Epoch 151/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7017 - acc: 0.7615 - val_loss: 0.6106 - val_acc: 0.7746\n",
      "Epoch 152/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7250 - acc: 0.7507 - val_loss: 0.6130 - val_acc: 0.7716\n",
      "Epoch 153/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7144 - acc: 0.7630 - val_loss: 0.6099 - val_acc: 0.7738\n",
      "Epoch 154/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7126 - acc: 0.7537 - val_loss: 0.6100 - val_acc: 0.7723\n",
      "Epoch 155/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7103 - acc: 0.7586 - val_loss: 0.6137 - val_acc: 0.7716\n",
      "Epoch 156/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7273 - acc: 0.7478 - val_loss: 0.6129 - val_acc: 0.7753\n",
      "Epoch 157/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7098 - acc: 0.7574 - val_loss: 0.6137 - val_acc: 0.7760\n",
      "Epoch 158/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7159 - acc: 0.7571 - val_loss: 0.6117 - val_acc: 0.7775\n",
      "Epoch 159/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7180 - acc: 0.7522 - val_loss: 0.6110 - val_acc: 0.7805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7104 - acc: 0.7541 - val_loss: 0.6119 - val_acc: 0.7783\n",
      "Epoch 161/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7114 - acc: 0.7582 - val_loss: 0.6128 - val_acc: 0.7775\n",
      "Epoch 162/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6891 - acc: 0.7578 - val_loss: 0.6137 - val_acc: 0.7775\n",
      "Epoch 163/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7181 - acc: 0.7526 - val_loss: 0.6129 - val_acc: 0.7746\n",
      "Epoch 164/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7042 - acc: 0.7638 - val_loss: 0.6125 - val_acc: 0.7775\n",
      "Epoch 165/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7153 - acc: 0.7537 - val_loss: 0.6087 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00165: loss improved from inf to 0.71530, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-0-000165-0.715304-0.779018.hdf5\n",
      "Epoch 166/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7066 - acc: 0.7574 - val_loss: 0.6125 - val_acc: 0.7716\n",
      "Epoch 167/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7069 - acc: 0.7515 - val_loss: 0.6095 - val_acc: 0.7753\n",
      "Epoch 168/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7040 - acc: 0.7578 - val_loss: 0.6110 - val_acc: 0.7723\n",
      "Epoch 169/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7081 - acc: 0.7522 - val_loss: 0.6120 - val_acc: 0.7746\n",
      "\n",
      "Epoch 00169: loss improved from 0.71530 to 0.70812, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-0-000169-0.708118-0.774554.hdf5\n",
      "Epoch 170/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7039 - acc: 0.7560 - val_loss: 0.6096 - val_acc: 0.7753\n",
      "Epoch 171/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7127 - acc: 0.7522 - val_loss: 0.6106 - val_acc: 0.7768\n",
      "Epoch 172/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7024 - acc: 0.7593 - val_loss: 0.6108 - val_acc: 0.7768\n",
      "Epoch 173/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6874 - acc: 0.7623 - val_loss: 0.6118 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00173: loss improved from 0.70812 to 0.68736, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-0-000173-0.687363-0.779018.hdf5\n",
      "Epoch 174/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7092 - acc: 0.7545 - val_loss: 0.6126 - val_acc: 0.7790\n",
      "Epoch 175/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7108 - acc: 0.7593 - val_loss: 0.6088 - val_acc: 0.7775\n",
      "Epoch 176/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7086 - acc: 0.7567 - val_loss: 0.6104 - val_acc: 0.7768\n",
      "Epoch 177/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7024 - acc: 0.7560 - val_loss: 0.6083 - val_acc: 0.7812\n",
      "Epoch 178/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7161 - acc: 0.7519 - val_loss: 0.6103 - val_acc: 0.7775\n",
      "Epoch 179/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6943 - acc: 0.7619 - val_loss: 0.6086 - val_acc: 0.7775\n",
      "Epoch 180/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7010 - acc: 0.7467 - val_loss: 0.6067 - val_acc: 0.7790\n",
      "Epoch 181/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7282 - acc: 0.7470 - val_loss: 0.6068 - val_acc: 0.7783\n",
      "Epoch 182/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7055 - acc: 0.7593 - val_loss: 0.6100 - val_acc: 0.7768\n",
      "Epoch 183/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6955 - acc: 0.7619 - val_loss: 0.6110 - val_acc: 0.7783\n",
      "Epoch 184/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7112 - acc: 0.7500 - val_loss: 0.6069 - val_acc: 0.7798\n",
      "Epoch 185/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7006 - acc: 0.7552 - val_loss: 0.6083 - val_acc: 0.7790\n",
      "Epoch 186/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7129 - acc: 0.7541 - val_loss: 0.6093 - val_acc: 0.7798\n",
      "Epoch 187/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6919 - acc: 0.7634 - val_loss: 0.6085 - val_acc: 0.7746\n",
      "Epoch 188/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6951 - acc: 0.7563 - val_loss: 0.6047 - val_acc: 0.7805\n",
      "Epoch 189/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6953 - acc: 0.7623 - val_loss: 0.6067 - val_acc: 0.7812\n",
      "Epoch 190/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7144 - acc: 0.7545 - val_loss: 0.6081 - val_acc: 0.7812\n",
      "Epoch 191/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7134 - acc: 0.7500 - val_loss: 0.6082 - val_acc: 0.7820\n",
      "Epoch 192/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7034 - acc: 0.7608 - val_loss: 0.6077 - val_acc: 0.7783\n",
      "Epoch 193/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7184 - acc: 0.7533 - val_loss: 0.6076 - val_acc: 0.7783\n",
      "\n",
      "Epoch 00193: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 194/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7074 - acc: 0.7444 - val_loss: 0.6089 - val_acc: 0.7790\n",
      "Epoch 195/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6865 - acc: 0.7693 - val_loss: 0.6074 - val_acc: 0.7783\n",
      "Epoch 196/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6933 - acc: 0.7634 - val_loss: 0.6081 - val_acc: 0.7783\n",
      "Epoch 197/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6904 - acc: 0.7537 - val_loss: 0.6013 - val_acc: 0.7798\n",
      "Epoch 198/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6917 - acc: 0.7604 - val_loss: 0.6076 - val_acc: 0.7798\n",
      "Epoch 199/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7018 - acc: 0.7526 - val_loss: 0.6089 - val_acc: 0.7783\n",
      "Epoch 200/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6973 - acc: 0.7623 - val_loss: 0.6070 - val_acc: 0.7775\n",
      "\n",
      "Epoch 00200: saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/0-000200-0.697251-0.777530.hdf5\n",
      "Epoch 201/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7048 - acc: 0.7493 - val_loss: 0.6043 - val_acc: 0.7790\n",
      "Epoch 202/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6978 - acc: 0.7634 - val_loss: 0.6067 - val_acc: 0.7768\n",
      "Epoch 203/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7047 - acc: 0.7604 - val_loss: 0.6084 - val_acc: 0.7760\n",
      "Epoch 204/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7126 - acc: 0.7526 - val_loss: 0.6060 - val_acc: 0.7775\n",
      "Epoch 205/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6976 - acc: 0.7604 - val_loss: 0.6090 - val_acc: 0.7760\n",
      "Epoch 206/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7026 - acc: 0.7563 - val_loss: 0.6087 - val_acc: 0.7775\n",
      "Epoch 207/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7032 - acc: 0.7545 - val_loss: 0.6073 - val_acc: 0.7775\n",
      "Epoch 208/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6942 - acc: 0.7563 - val_loss: 0.6076 - val_acc: 0.7768\n",
      "Epoch 209/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6794 - acc: 0.7634 - val_loss: 0.6059 - val_acc: 0.7783\n",
      "Epoch 210/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6968 - acc: 0.7574 - val_loss: 0.6079 - val_acc: 0.7783\n",
      "Epoch 211/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7022 - acc: 0.7626 - val_loss: 0.6091 - val_acc: 0.7768\n",
      "Epoch 212/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6903 - acc: 0.7634 - val_loss: 0.6089 - val_acc: 0.7768\n",
      "Epoch 213/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6918 - acc: 0.7597 - val_loss: 0.6079 - val_acc: 0.7775\n",
      "Epoch 214/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7002 - acc: 0.7604 - val_loss: 0.6072 - val_acc: 0.7783\n",
      "Epoch 215/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6977 - acc: 0.7563 - val_loss: 0.6035 - val_acc: 0.7783\n",
      "Epoch 216/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6980 - acc: 0.7597 - val_loss: 0.6078 - val_acc: 0.7768\n",
      "Epoch 217/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6913 - acc: 0.7593 - val_loss: 0.6074 - val_acc: 0.7775\n",
      "Epoch 218/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6902 - acc: 0.7571 - val_loss: 0.6082 - val_acc: 0.7783\n",
      "Epoch 219/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6907 - acc: 0.7582 - val_loss: 0.6075 - val_acc: 0.7775\n",
      "Epoch 220/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6938 - acc: 0.7578 - val_loss: 0.6075 - val_acc: 0.7783\n",
      "Epoch 221/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7128 - acc: 0.7552 - val_loss: 0.6033 - val_acc: 0.7775\n",
      "Epoch 222/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7049 - acc: 0.7541 - val_loss: 0.6080 - val_acc: 0.7768\n",
      "Epoch 223/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6948 - acc: 0.7615 - val_loss: 0.6055 - val_acc: 0.7783\n",
      "Epoch 224/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7069 - acc: 0.7556 - val_loss: 0.6090 - val_acc: 0.7775\n",
      "Epoch 225/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6972 - acc: 0.7582 - val_loss: 0.6084 - val_acc: 0.7775\n",
      "Epoch 226/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6929 - acc: 0.7545 - val_loss: 0.6065 - val_acc: 0.7790\n",
      "Epoch 227/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7072 - acc: 0.7626 - val_loss: 0.6077 - val_acc: 0.7783\n",
      "Epoch 228/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7051 - acc: 0.7630 - val_loss: 0.6049 - val_acc: 0.7790\n",
      "Epoch 229/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6864 - acc: 0.7649 - val_loss: 0.6071 - val_acc: 0.7775\n",
      "\n",
      "Epoch 00229: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 230/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7069 - acc: 0.7574 - val_loss: 0.6072 - val_acc: 0.7783\n",
      "Epoch 231/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7084 - acc: 0.7608 - val_loss: 0.6071 - val_acc: 0.7775\n",
      "Epoch 232/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7006 - acc: 0.7589 - val_loss: 0.6076 - val_acc: 0.7768\n",
      "Epoch 233/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7081 - acc: 0.7571 - val_loss: 0.6046 - val_acc: 0.7775\n",
      "Epoch 234/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7061 - acc: 0.7586 - val_loss: 0.6070 - val_acc: 0.7783\n",
      "Epoch 235/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6834 - acc: 0.7630 - val_loss: 0.6065 - val_acc: 0.7790\n",
      "Epoch 236/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6948 - acc: 0.7604 - val_loss: 0.6070 - val_acc: 0.7783\n",
      "Epoch 237/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7060 - acc: 0.7556 - val_loss: 0.6063 - val_acc: 0.7798\n",
      "Epoch 238/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7008 - acc: 0.7630 - val_loss: 0.6077 - val_acc: 0.7775\n",
      "Epoch 239/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6963 - acc: 0.7571 - val_loss: 0.6056 - val_acc: 0.7790\n",
      "Epoch 240/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7099 - acc: 0.7537 - val_loss: 0.6080 - val_acc: 0.7775\n",
      "Epoch 241/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7035 - acc: 0.7619 - val_loss: 0.6060 - val_acc: 0.7783\n",
      "Epoch 242/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6929 - acc: 0.7604 - val_loss: 0.6050 - val_acc: 0.7798\n",
      "Epoch 243/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7061 - acc: 0.7571 - val_loss: 0.6009 - val_acc: 0.7812\n",
      "Epoch 244/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6979 - acc: 0.7571 - val_loss: 0.6073 - val_acc: 0.7790\n",
      "Epoch 245/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7015 - acc: 0.7586 - val_loss: 0.6058 - val_acc: 0.7798\n",
      "Epoch 246/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7014 - acc: 0.7563 - val_loss: 0.6061 - val_acc: 0.7790\n",
      "Epoch 247/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6808 - acc: 0.7634 - val_loss: 0.6023 - val_acc: 0.7798\n",
      "Epoch 248/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6925 - acc: 0.7586 - val_loss: 0.6082 - val_acc: 0.7768\n",
      "Epoch 249/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7059 - acc: 0.7493 - val_loss: 0.6071 - val_acc: 0.7760\n",
      "\n",
      "Epoch 00249: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 250/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7012 - acc: 0.7574 - val_loss: 0.6059 - val_acc: 0.7775\n",
      "Epoch 251/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7056 - acc: 0.7574 - val_loss: 0.6075 - val_acc: 0.7760\n",
      "Epoch 252/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7007 - acc: 0.7556 - val_loss: 0.6071 - val_acc: 0.7768\n",
      "Epoch 253/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6972 - acc: 0.7697 - val_loss: 0.6063 - val_acc: 0.7768\n",
      "Epoch 254/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7236 - acc: 0.7504 - val_loss: 0.6053 - val_acc: 0.7775\n",
      "Epoch 255/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6938 - acc: 0.7604 - val_loss: 0.6051 - val_acc: 0.7790\n",
      "Epoch 256/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6998 - acc: 0.7522 - val_loss: 0.6071 - val_acc: 0.7768\n",
      "Epoch 257/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6916 - acc: 0.7571 - val_loss: 0.6082 - val_acc: 0.7775\n",
      "Epoch 258/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6898 - acc: 0.7653 - val_loss: 0.6059 - val_acc: 0.7783\n",
      "Epoch 259/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6993 - acc: 0.7597 - val_loss: 0.6077 - val_acc: 0.7775\n",
      "Epoch 260/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6900 - acc: 0.7545 - val_loss: 0.6050 - val_acc: 0.7790\n",
      "Epoch 261/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6993 - acc: 0.7515 - val_loss: 0.6074 - val_acc: 0.7783\n",
      "Epoch 262/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7083 - acc: 0.7593 - val_loss: 0.6083 - val_acc: 0.7775\n",
      "Epoch 263/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7065 - acc: 0.7600 - val_loss: 0.6072 - val_acc: 0.7783\n",
      "Epoch 264/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6964 - acc: 0.7593 - val_loss: 0.6076 - val_acc: 0.7775\n",
      "Epoch 265/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6875 - acc: 0.7574 - val_loss: 0.6039 - val_acc: 0.7798\n",
      "\n",
      "Epoch 00265: loss improved from inf to 0.68746, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-0-000265-0.687458-0.779762.hdf5\n",
      "Epoch 266/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6993 - acc: 0.7537 - val_loss: 0.6054 - val_acc: 0.7790\n",
      "Epoch 267/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6918 - acc: 0.7615 - val_loss: 0.6051 - val_acc: 0.7790\n",
      "Epoch 268/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6929 - acc: 0.7578 - val_loss: 0.6064 - val_acc: 0.7783\n",
      "Epoch 269/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6936 - acc: 0.7578 - val_loss: 0.6050 - val_acc: 0.7783\n",
      "Epoch 270/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6954 - acc: 0.7571 - val_loss: 0.6046 - val_acc: 0.7783\n",
      "Epoch 271/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.6882 - acc: 0.7630 - val_loss: 0.6066 - val_acc: 0.7783\n",
      "Epoch 272/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6917 - acc: 0.7630 - val_loss: 0.6059 - val_acc: 0.7790\n",
      "Epoch 273/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 32ms/step - loss: 0.6928 - acc: 0.7626 - val_loss: 0.6052 - val_acc: 0.7783\n",
      "Epoch 274/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7006 - acc: 0.7556 - val_loss: 0.6064 - val_acc: 0.7783\n",
      "Epoch 275/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7170 - acc: 0.7530 - val_loss: 0.6047 - val_acc: 0.7790\n",
      "Epoch 276/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6949 - acc: 0.7593 - val_loss: 0.6078 - val_acc: 0.7775\n",
      "Epoch 277/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6988 - acc: 0.7604 - val_loss: 0.6049 - val_acc: 0.7798\n",
      "Epoch 278/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7025 - acc: 0.7548 - val_loss: 0.6069 - val_acc: 0.7783\n",
      "Epoch 279/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6985 - acc: 0.7556 - val_loss: 0.6072 - val_acc: 0.7783\n",
      "Epoch 280/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.6890 - acc: 0.7679 - val_loss: 0.6078 - val_acc: 0.7775\n",
      "Epoch 281/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7089 - acc: 0.7507 - val_loss: 0.6063 - val_acc: 0.7783\n",
      "Epoch 282/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6920 - acc: 0.7619 - val_loss: 0.6078 - val_acc: 0.7783\n",
      "Epoch 283/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7024 - acc: 0.7574 - val_loss: 0.6075 - val_acc: 0.7783\n",
      "Epoch 284/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6939 - acc: 0.7567 - val_loss: 0.6078 - val_acc: 0.7760\n",
      "Epoch 285/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6900 - acc: 0.7597 - val_loss: 0.6008 - val_acc: 0.7798\n",
      "Epoch 286/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7033 - acc: 0.7582 - val_loss: 0.6054 - val_acc: 0.7783\n",
      "Epoch 287/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6959 - acc: 0.7660 - val_loss: 0.6062 - val_acc: 0.7775\n",
      "Epoch 288/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7045 - acc: 0.7563 - val_loss: 0.6074 - val_acc: 0.7768\n",
      "Epoch 289/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6952 - acc: 0.7634 - val_loss: 0.6040 - val_acc: 0.7790\n",
      "Epoch 290/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6943 - acc: 0.7597 - val_loss: 0.6062 - val_acc: 0.7775\n",
      "Epoch 291/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7011 - acc: 0.7545 - val_loss: 0.6078 - val_acc: 0.7760\n",
      "Epoch 292/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7061 - acc: 0.7600 - val_loss: 0.6077 - val_acc: 0.7760\n",
      "Epoch 293/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6900 - acc: 0.7615 - val_loss: 0.6045 - val_acc: 0.7768\n",
      "Epoch 294/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6894 - acc: 0.7589 - val_loss: 0.6070 - val_acc: 0.7768\n",
      "Epoch 295/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6982 - acc: 0.7582 - val_loss: 0.6059 - val_acc: 0.7768\n",
      "Epoch 296/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6971 - acc: 0.7571 - val_loss: 0.6049 - val_acc: 0.7775\n",
      "Epoch 297/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7175 - acc: 0.7526 - val_loss: 0.6063 - val_acc: 0.7768\n",
      "Epoch 298/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6975 - acc: 0.7574 - val_loss: 0.6048 - val_acc: 0.7783\n",
      "Epoch 299/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6873 - acc: 0.7586 - val_loss: 0.6072 - val_acc: 0.7760\n",
      "Epoch 300/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6989 - acc: 0.7552 - val_loss: 0.6074 - val_acc: 0.7760\n",
      "\n",
      "Epoch 00300: saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/0-000300-0.698853-0.776042.hdf5\n",
      "Epoch 301/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6977 - acc: 0.7560 - val_loss: 0.6052 - val_acc: 0.7775\n",
      "Epoch 302/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6905 - acc: 0.7567 - val_loss: 0.6045 - val_acc: 0.7783\n",
      "Epoch 303/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6988 - acc: 0.7589 - val_loss: 0.6074 - val_acc: 0.7768\n",
      "Epoch 304/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6885 - acc: 0.7623 - val_loss: 0.6071 - val_acc: 0.7775\n",
      "Epoch 305/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6995 - acc: 0.7649 - val_loss: 0.6078 - val_acc: 0.7768\n",
      "Epoch 306/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6906 - acc: 0.7619 - val_loss: 0.6069 - val_acc: 0.7775\n",
      "Epoch 307/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6889 - acc: 0.7589 - val_loss: 0.6084 - val_acc: 0.7768\n",
      "Epoch 308/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7107 - acc: 0.7548 - val_loss: 0.6078 - val_acc: 0.7768\n",
      "Epoch 309/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6945 - acc: 0.7582 - val_loss: 0.6065 - val_acc: 0.7783\n",
      "Epoch 310/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6959 - acc: 0.7619 - val_loss: 0.6076 - val_acc: 0.7768\n",
      "Epoch 311/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7057 - acc: 0.7597 - val_loss: 0.6070 - val_acc: 0.7775\n",
      "Epoch 312/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7015 - acc: 0.7586 - val_loss: 0.6026 - val_acc: 0.7790\n",
      "Epoch 313/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6994 - acc: 0.7645 - val_loss: 0.6084 - val_acc: 0.7768\n",
      "Epoch 314/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6891 - acc: 0.7626 - val_loss: 0.6065 - val_acc: 0.7775\n",
      "Epoch 315/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7006 - acc: 0.7634 - val_loss: 0.6068 - val_acc: 0.7775\n",
      "Epoch 316/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6837 - acc: 0.7612 - val_loss: 0.6081 - val_acc: 0.7768\n",
      "Epoch 317/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6974 - acc: 0.7571 - val_loss: 0.6058 - val_acc: 0.7783\n",
      "Epoch 318/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6876 - acc: 0.7623 - val_loss: 0.6081 - val_acc: 0.7768\n",
      "Epoch 319/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7059 - acc: 0.7560 - val_loss: 0.6077 - val_acc: 0.7768\n",
      "Epoch 320/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6876 - acc: 0.7574 - val_loss: 0.6065 - val_acc: 0.7790\n",
      "Epoch 321/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6944 - acc: 0.7615 - val_loss: 0.6069 - val_acc: 0.7790\n",
      "Epoch 322/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6879 - acc: 0.7556 - val_loss: 0.6048 - val_acc: 0.7798\n",
      "Epoch 323/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6899 - acc: 0.7630 - val_loss: 0.6057 - val_acc: 0.7790\n",
      "Epoch 324/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6962 - acc: 0.7578 - val_loss: 0.6065 - val_acc: 0.7790\n",
      "Epoch 325/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6809 - acc: 0.7653 - val_loss: 0.6066 - val_acc: 0.7783\n",
      "Epoch 326/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7010 - acc: 0.7526 - val_loss: 0.6066 - val_acc: 0.7783\n",
      "Epoch 327/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7048 - acc: 0.7496 - val_loss: 0.6077 - val_acc: 0.7775\n",
      "Epoch 328/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7100 - acc: 0.7582 - val_loss: 0.6080 - val_acc: 0.7775\n",
      "Epoch 329/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6917 - acc: 0.7686 - val_loss: 0.6068 - val_acc: 0.7783\n",
      "Epoch 330/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6731 - acc: 0.7675 - val_loss: 0.6052 - val_acc: 0.7790\n",
      "Epoch 331/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6933 - acc: 0.7630 - val_loss: 0.6071 - val_acc: 0.7783\n",
      "Epoch 332/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6962 - acc: 0.7533 - val_loss: 0.6009 - val_acc: 0.7805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 333/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7080 - acc: 0.7545 - val_loss: 0.6044 - val_acc: 0.7798\n",
      "Epoch 334/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7207 - acc: 0.7489 - val_loss: 0.6056 - val_acc: 0.7798\n",
      "Epoch 335/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6842 - acc: 0.7630 - val_loss: 0.6082 - val_acc: 0.7783\n",
      "Epoch 336/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6946 - acc: 0.7634 - val_loss: 0.6080 - val_acc: 0.7775\n",
      "Epoch 337/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7034 - acc: 0.7567 - val_loss: 0.6067 - val_acc: 0.7790\n",
      "Epoch 338/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7063 - acc: 0.7589 - val_loss: 0.6072 - val_acc: 0.7790\n",
      "Epoch 339/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6983 - acc: 0.7574 - val_loss: 0.6078 - val_acc: 0.7783\n",
      "Epoch 340/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7073 - acc: 0.7571 - val_loss: 0.6069 - val_acc: 0.7790\n",
      "Epoch 341/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7033 - acc: 0.7507 - val_loss: 0.6077 - val_acc: 0.7783\n",
      "Epoch 342/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7052 - acc: 0.7597 - val_loss: 0.6054 - val_acc: 0.7790\n",
      "Epoch 343/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6939 - acc: 0.7574 - val_loss: 0.6075 - val_acc: 0.7790\n",
      "Epoch 344/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7020 - acc: 0.7537 - val_loss: 0.6055 - val_acc: 0.7798\n",
      "Epoch 345/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.6952 - acc: 0.7597 - val_loss: 0.6069 - val_acc: 0.7798\n",
      "Epoch 346/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7037 - acc: 0.7545 - val_loss: 0.6074 - val_acc: 0.7783\n",
      "Epoch 347/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6983 - acc: 0.7582 - val_loss: 0.6059 - val_acc: 0.7798\n",
      "Epoch 348/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6918 - acc: 0.7578 - val_loss: 0.6046 - val_acc: 0.7805\n",
      "Epoch 349/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6776 - acc: 0.7641 - val_loss: 0.6056 - val_acc: 0.7812\n",
      "Epoch 350/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6975 - acc: 0.7552 - val_loss: 0.6064 - val_acc: 0.7798\n",
      "Epoch 351/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7078 - acc: 0.7485 - val_loss: 0.6078 - val_acc: 0.7790\n",
      "Epoch 352/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7015 - acc: 0.7634 - val_loss: 0.6069 - val_acc: 0.7790\n",
      "Epoch 353/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7019 - acc: 0.7589 - val_loss: 0.6071 - val_acc: 0.7798\n",
      "Epoch 354/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6777 - acc: 0.7705 - val_loss: 0.6081 - val_acc: 0.7790\n",
      "Epoch 355/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7093 - acc: 0.7571 - val_loss: 0.6065 - val_acc: 0.7798\n",
      "Epoch 356/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7013 - acc: 0.7478 - val_loss: 0.6066 - val_acc: 0.7798\n",
      "Epoch 357/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7024 - acc: 0.7560 - val_loss: 0.6072 - val_acc: 0.7790\n",
      "Epoch 358/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6964 - acc: 0.7593 - val_loss: 0.6064 - val_acc: 0.7790\n",
      "Epoch 359/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7017 - acc: 0.7582 - val_loss: 0.6066 - val_acc: 0.7798\n",
      "Epoch 360/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7118 - acc: 0.7504 - val_loss: 0.6075 - val_acc: 0.7790\n",
      "Epoch 361/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6855 - acc: 0.7641 - val_loss: 0.6062 - val_acc: 0.7798\n",
      "Epoch 362/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6895 - acc: 0.7708 - val_loss: 0.6076 - val_acc: 0.7783\n",
      "Epoch 363/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7121 - acc: 0.7485 - val_loss: 0.6065 - val_acc: 0.7798\n",
      "Epoch 364/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6985 - acc: 0.7582 - val_loss: 0.6086 - val_acc: 0.7783\n",
      "Epoch 365/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6904 - acc: 0.7578 - val_loss: 0.6061 - val_acc: 0.7783\n",
      "\n",
      "Epoch 00365: loss improved from inf to 0.69038, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-0-000365-0.690385-0.778274.hdf5\n",
      "Epoch 366/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6941 - acc: 0.7522 - val_loss: 0.6070 - val_acc: 0.7783\n",
      "Epoch 367/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6858 - acc: 0.7630 - val_loss: 0.6049 - val_acc: 0.7798\n",
      "Epoch 368/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7042 - acc: 0.7533 - val_loss: 0.6075 - val_acc: 0.7783\n",
      "Epoch 369/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6894 - acc: 0.7626 - val_loss: 0.6050 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00369: loss improved from 0.69038 to 0.68938, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-0-000369-0.689378-0.779018.hdf5\n",
      "Epoch 370/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7025 - acc: 0.7556 - val_loss: 0.6053 - val_acc: 0.7783\n",
      "Epoch 371/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6966 - acc: 0.7578 - val_loss: 0.6050 - val_acc: 0.7790\n",
      "Epoch 372/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6964 - acc: 0.7541 - val_loss: 0.6057 - val_acc: 0.7783\n",
      "Epoch 373/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7060 - acc: 0.7552 - val_loss: 0.6075 - val_acc: 0.7783\n",
      "Epoch 374/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7037 - acc: 0.7615 - val_loss: 0.6069 - val_acc: 0.7783\n",
      "Epoch 375/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7007 - acc: 0.7608 - val_loss: 0.6061 - val_acc: 0.7790\n",
      "Epoch 376/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6981 - acc: 0.7530 - val_loss: 0.6081 - val_acc: 0.7775\n",
      "Epoch 377/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7046 - acc: 0.7541 - val_loss: 0.6081 - val_acc: 0.7775\n",
      "Epoch 378/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6934 - acc: 0.7530 - val_loss: 0.6078 - val_acc: 0.7783\n",
      "Epoch 379/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6943 - acc: 0.7589 - val_loss: 0.6072 - val_acc: 0.7783\n",
      "Epoch 380/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6875 - acc: 0.7690 - val_loss: 0.6056 - val_acc: 0.7783\n",
      "Epoch 381/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6844 - acc: 0.7589 - val_loss: 0.6054 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00381: loss improved from 0.68938 to 0.68438, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-0-000381-0.684383-0.779018.hdf5\n",
      "Epoch 382/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7061 - acc: 0.7571 - val_loss: 0.6058 - val_acc: 0.7783\n",
      "Epoch 383/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6946 - acc: 0.7541 - val_loss: 0.6042 - val_acc: 0.7790\n",
      "Epoch 384/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6939 - acc: 0.7615 - val_loss: 0.6084 - val_acc: 0.7775\n",
      "Epoch 385/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7092 - acc: 0.7586 - val_loss: 0.6066 - val_acc: 0.7783\n",
      "Epoch 386/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6861 - acc: 0.7690 - val_loss: 0.6066 - val_acc: 0.7783\n",
      "Epoch 387/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7116 - acc: 0.7496 - val_loss: 0.6070 - val_acc: 0.7783\n",
      "Epoch 388/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7027 - acc: 0.7522 - val_loss: 0.6075 - val_acc: 0.7783\n",
      "Epoch 389/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7038 - acc: 0.7612 - val_loss: 0.6061 - val_acc: 0.7783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 390/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7002 - acc: 0.7526 - val_loss: 0.6065 - val_acc: 0.7783\n",
      "Epoch 391/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7029 - acc: 0.7552 - val_loss: 0.6071 - val_acc: 0.7775\n",
      "Epoch 392/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6939 - acc: 0.7604 - val_loss: 0.6077 - val_acc: 0.7775\n",
      "Epoch 393/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6822 - acc: 0.7690 - val_loss: 0.6072 - val_acc: 0.7783\n",
      "\n",
      "Epoch 00393: loss improved from 0.68438 to 0.68221, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-0-000393-0.682208-0.778274.hdf5\n",
      "Epoch 394/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6914 - acc: 0.7489 - val_loss: 0.6064 - val_acc: 0.7790\n",
      "Epoch 395/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7004 - acc: 0.7533 - val_loss: 0.6082 - val_acc: 0.7775\n",
      "Epoch 396/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6961 - acc: 0.7578 - val_loss: 0.6033 - val_acc: 0.7790\n",
      "Epoch 397/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6859 - acc: 0.7612 - val_loss: 0.6060 - val_acc: 0.7790\n",
      "Epoch 398/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7022 - acc: 0.7582 - val_loss: 0.6072 - val_acc: 0.7775\n",
      "Epoch 399/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6986 - acc: 0.7634 - val_loss: 0.6077 - val_acc: 0.7775\n",
      "Epoch 400/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7102 - acc: 0.7630 - val_loss: 0.6073 - val_acc: 0.7783\n",
      "\n",
      "Epoch 00400: saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/0-000400-0.710153-0.778274.hdf5\n",
      "Epoch 401/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6950 - acc: 0.7567 - val_loss: 0.6063 - val_acc: 0.7783\n",
      "Epoch 402/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6939 - acc: 0.7567 - val_loss: 0.6039 - val_acc: 0.7790\n",
      "Epoch 403/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6961 - acc: 0.7586 - val_loss: 0.6033 - val_acc: 0.7805\n",
      "Epoch 404/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6926 - acc: 0.7560 - val_loss: 0.6051 - val_acc: 0.7790\n",
      "Epoch 405/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6910 - acc: 0.7578 - val_loss: 0.6068 - val_acc: 0.7783\n",
      "Epoch 406/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6896 - acc: 0.7593 - val_loss: 0.6072 - val_acc: 0.7768\n",
      "Epoch 407/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6950 - acc: 0.7593 - val_loss: 0.6080 - val_acc: 0.7760\n",
      "Epoch 408/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7046 - acc: 0.7578 - val_loss: 0.6066 - val_acc: 0.7790\n",
      "Epoch 409/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6987 - acc: 0.7608 - val_loss: 0.6068 - val_acc: 0.7783\n",
      "Epoch 410/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6847 - acc: 0.7593 - val_loss: 0.6067 - val_acc: 0.7768\n",
      "Epoch 411/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7004 - acc: 0.7619 - val_loss: 0.6075 - val_acc: 0.7768\n",
      "Epoch 412/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6741 - acc: 0.7660 - val_loss: 0.6011 - val_acc: 0.7790\n",
      "Epoch 413/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7097 - acc: 0.7496 - val_loss: 0.6068 - val_acc: 0.7768\n",
      "Epoch 414/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6953 - acc: 0.7574 - val_loss: 0.6080 - val_acc: 0.7760\n",
      "Epoch 415/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7000 - acc: 0.7578 - val_loss: 0.6070 - val_acc: 0.7768\n",
      "Epoch 416/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6998 - acc: 0.7574 - val_loss: 0.6068 - val_acc: 0.7768\n",
      "Epoch 417/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6827 - acc: 0.7530 - val_loss: 0.6033 - val_acc: 0.7775\n",
      "Epoch 418/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7055 - acc: 0.7563 - val_loss: 0.6059 - val_acc: 0.7775\n",
      "Epoch 419/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6980 - acc: 0.7560 - val_loss: 0.6069 - val_acc: 0.7768\n",
      "Epoch 420/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6900 - acc: 0.7623 - val_loss: 0.6071 - val_acc: 0.7768\n",
      "Epoch 421/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7050 - acc: 0.7537 - val_loss: 0.6066 - val_acc: 0.7768\n",
      "Epoch 422/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6923 - acc: 0.7649 - val_loss: 0.6054 - val_acc: 0.7768\n",
      "Epoch 423/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7008 - acc: 0.7578 - val_loss: 0.6086 - val_acc: 0.7760\n",
      "Epoch 424/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6951 - acc: 0.7615 - val_loss: 0.6073 - val_acc: 0.7768\n",
      "Epoch 425/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7029 - acc: 0.7481 - val_loss: 0.6066 - val_acc: 0.7775\n",
      "Epoch 426/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7080 - acc: 0.7548 - val_loss: 0.6064 - val_acc: 0.7783\n",
      "Epoch 427/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6964 - acc: 0.7511 - val_loss: 0.6070 - val_acc: 0.7775\n",
      "Epoch 428/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7036 - acc: 0.7522 - val_loss: 0.6076 - val_acc: 0.7783\n",
      "Epoch 429/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7026 - acc: 0.7560 - val_loss: 0.6044 - val_acc: 0.7798\n",
      "Epoch 430/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6949 - acc: 0.7653 - val_loss: 0.6047 - val_acc: 0.7783\n",
      "Epoch 431/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6953 - acc: 0.7604 - val_loss: 0.6074 - val_acc: 0.7775\n",
      "Epoch 432/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7025 - acc: 0.7571 - val_loss: 0.6070 - val_acc: 0.7783\n",
      "Epoch 433/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6829 - acc: 0.7619 - val_loss: 0.6059 - val_acc: 0.7790\n",
      "Epoch 434/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6998 - acc: 0.7504 - val_loss: 0.6054 - val_acc: 0.7783\n",
      "Epoch 435/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6890 - acc: 0.7679 - val_loss: 0.6078 - val_acc: 0.7775\n",
      "Epoch 436/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6957 - acc: 0.7612 - val_loss: 0.6068 - val_acc: 0.7783\n",
      "Epoch 437/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6960 - acc: 0.7600 - val_loss: 0.6056 - val_acc: 0.7783\n",
      "Epoch 438/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6951 - acc: 0.7537 - val_loss: 0.6053 - val_acc: 0.7790\n",
      "Epoch 439/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6803 - acc: 0.7649 - val_loss: 0.6079 - val_acc: 0.7775\n",
      "Epoch 440/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6982 - acc: 0.7519 - val_loss: 0.6072 - val_acc: 0.7783\n",
      "Epoch 441/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7006 - acc: 0.7496 - val_loss: 0.6066 - val_acc: 0.7790\n",
      "Epoch 442/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6961 - acc: 0.7582 - val_loss: 0.6059 - val_acc: 0.7783\n",
      "Epoch 443/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7048 - acc: 0.7548 - val_loss: 0.6079 - val_acc: 0.7775\n",
      "Epoch 444/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6970 - acc: 0.7548 - val_loss: 0.6072 - val_acc: 0.7783\n",
      "Epoch 445/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6997 - acc: 0.7574 - val_loss: 0.6076 - val_acc: 0.7783\n",
      "Epoch 446/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6985 - acc: 0.7612 - val_loss: 0.6056 - val_acc: 0.7798\n",
      "Epoch 447/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7052 - acc: 0.7582 - val_loss: 0.6069 - val_acc: 0.7783\n",
      "Epoch 448/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6997 - acc: 0.7574 - val_loss: 0.6081 - val_acc: 0.7775\n",
      "Epoch 449/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6992 - acc: 0.7567 - val_loss: 0.6071 - val_acc: 0.7783\n",
      "Epoch 450/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6922 - acc: 0.7615 - val_loss: 0.6071 - val_acc: 0.7783\n",
      "Epoch 451/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7025 - acc: 0.7522 - val_loss: 0.6084 - val_acc: 0.7775\n",
      "Epoch 452/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7109 - acc: 0.7504 - val_loss: 0.6071 - val_acc: 0.7783\n",
      "Epoch 453/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6936 - acc: 0.7619 - val_loss: 0.6069 - val_acc: 0.7775\n",
      "Epoch 454/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6958 - acc: 0.7582 - val_loss: 0.6071 - val_acc: 0.7783\n",
      "Epoch 455/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7030 - acc: 0.7589 - val_loss: 0.6072 - val_acc: 0.7783\n",
      "Epoch 456/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6904 - acc: 0.7638 - val_loss: 0.6031 - val_acc: 0.7790\n",
      "Epoch 457/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7019 - acc: 0.7571 - val_loss: 0.6046 - val_acc: 0.7790\n",
      "Epoch 458/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7096 - acc: 0.7515 - val_loss: 0.6044 - val_acc: 0.7798\n",
      "Epoch 459/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7056 - acc: 0.7526 - val_loss: 0.6075 - val_acc: 0.7775\n",
      "Epoch 460/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6981 - acc: 0.7586 - val_loss: 0.6078 - val_acc: 0.7775\n",
      "Epoch 461/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6896 - acc: 0.7630 - val_loss: 0.6068 - val_acc: 0.7783\n",
      "Epoch 462/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6890 - acc: 0.7574 - val_loss: 0.6074 - val_acc: 0.7760\n",
      "Epoch 463/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6828 - acc: 0.7582 - val_loss: 0.6043 - val_acc: 0.7783\n",
      "Epoch 464/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7042 - acc: 0.7519 - val_loss: 0.6072 - val_acc: 0.7768\n",
      "Epoch 465/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6914 - acc: 0.7649 - val_loss: 0.6083 - val_acc: 0.7760\n",
      "\n",
      "Epoch 00465: loss improved from inf to 0.69139, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-0-000465-0.691391-0.776042.hdf5\n",
      "Epoch 466/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7170 - acc: 0.7481 - val_loss: 0.6050 - val_acc: 0.7775\n",
      "Epoch 467/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7011 - acc: 0.7630 - val_loss: 0.6078 - val_acc: 0.7768\n",
      "Epoch 468/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6855 - acc: 0.7653 - val_loss: 0.6081 - val_acc: 0.7760\n",
      "Epoch 469/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6933 - acc: 0.7675 - val_loss: 0.6071 - val_acc: 0.7768\n",
      "Epoch 470/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6783 - acc: 0.7582 - val_loss: 0.6073 - val_acc: 0.7768\n",
      "Epoch 471/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7095 - acc: 0.7533 - val_loss: 0.6079 - val_acc: 0.7760\n",
      "Epoch 472/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6801 - acc: 0.7660 - val_loss: 0.6081 - val_acc: 0.7760\n",
      "Epoch 473/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7124 - acc: 0.7522 - val_loss: 0.6075 - val_acc: 0.7768\n",
      "Epoch 474/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7074 - acc: 0.7567 - val_loss: 0.6073 - val_acc: 0.7760\n",
      "Epoch 475/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6885 - acc: 0.7560 - val_loss: 0.6075 - val_acc: 0.7768\n",
      "Epoch 476/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7038 - acc: 0.7571 - val_loss: 0.6049 - val_acc: 0.7775\n",
      "Epoch 477/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6948 - acc: 0.7593 - val_loss: 0.6075 - val_acc: 0.7760\n",
      "Epoch 478/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6961 - acc: 0.7571 - val_loss: 0.6073 - val_acc: 0.7768\n",
      "Epoch 479/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6941 - acc: 0.7578 - val_loss: 0.6068 - val_acc: 0.7768\n",
      "Epoch 480/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6975 - acc: 0.7608 - val_loss: 0.6047 - val_acc: 0.7775\n",
      "Epoch 481/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6833 - acc: 0.7574 - val_loss: 0.6073 - val_acc: 0.7768\n",
      "\n",
      "Epoch 00481: loss improved from 0.69139 to 0.68330, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-0-000481-0.683301-0.776786.hdf5\n",
      "Epoch 482/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6783 - acc: 0.7638 - val_loss: 0.6056 - val_acc: 0.7775\n",
      "Epoch 483/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7098 - acc: 0.7541 - val_loss: 0.6065 - val_acc: 0.7768\n",
      "Epoch 484/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7000 - acc: 0.7586 - val_loss: 0.6068 - val_acc: 0.7768\n",
      "Epoch 485/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6977 - acc: 0.7604 - val_loss: 0.6080 - val_acc: 0.7760\n",
      "Epoch 486/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7006 - acc: 0.7552 - val_loss: 0.6060 - val_acc: 0.7768\n",
      "Epoch 487/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6760 - acc: 0.7645 - val_loss: 0.6023 - val_acc: 0.7783\n",
      "Epoch 488/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7040 - acc: 0.7563 - val_loss: 0.6066 - val_acc: 0.7775\n",
      "Epoch 489/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6973 - acc: 0.7600 - val_loss: 0.6058 - val_acc: 0.7768\n",
      "Epoch 490/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7071 - acc: 0.7489 - val_loss: 0.6063 - val_acc: 0.7775\n",
      "Epoch 491/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6932 - acc: 0.7578 - val_loss: 0.6061 - val_acc: 0.7775\n",
      "Epoch 492/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7027 - acc: 0.7612 - val_loss: 0.6062 - val_acc: 0.7783\n",
      "Epoch 493/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7040 - acc: 0.7563 - val_loss: 0.6069 - val_acc: 0.7768\n",
      "Epoch 494/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6903 - acc: 0.7641 - val_loss: 0.6022 - val_acc: 0.7775\n",
      "Epoch 495/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7114 - acc: 0.7537 - val_loss: 0.6082 - val_acc: 0.7760\n",
      "Epoch 496/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7068 - acc: 0.7567 - val_loss: 0.6048 - val_acc: 0.7783\n",
      "Epoch 497/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7001 - acc: 0.7545 - val_loss: 0.6079 - val_acc: 0.7760\n",
      "Epoch 498/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6893 - acc: 0.7619 - val_loss: 0.6061 - val_acc: 0.7783\n",
      "Epoch 499/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6776 - acc: 0.7604 - val_loss: 0.6059 - val_acc: 0.7790\n",
      "Epoch 500/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6956 - acc: 0.7578 - val_loss: 0.6044 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00500: saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/0-000500-0.695557-0.779018.hdf5\n",
      "Epoch 501/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6970 - acc: 0.7615 - val_loss: 0.6072 - val_acc: 0.7790\n",
      "Epoch 502/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7006 - acc: 0.7567 - val_loss: 0.6063 - val_acc: 0.7790\n",
      "Epoch 503/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6968 - acc: 0.7623 - val_loss: 0.6014 - val_acc: 0.7805\n",
      "Epoch 504/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6879 - acc: 0.7552 - val_loss: 0.6066 - val_acc: 0.7790\n",
      "Epoch 505/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7030 - acc: 0.7597 - val_loss: 0.6061 - val_acc: 0.7790\n",
      "Epoch 506/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6889 - acc: 0.7634 - val_loss: 0.6057 - val_acc: 0.7798\n",
      "Epoch 507/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6854 - acc: 0.7641 - val_loss: 0.6067 - val_acc: 0.7790\n",
      "Epoch 508/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6945 - acc: 0.7582 - val_loss: 0.6045 - val_acc: 0.7783\n",
      "Epoch 509/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6835 - acc: 0.7552 - val_loss: 0.6050 - val_acc: 0.7790\n",
      "Epoch 510/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6834 - acc: 0.7671 - val_loss: 0.6076 - val_acc: 0.7783\n",
      "Epoch 511/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6866 - acc: 0.7593 - val_loss: 0.6069 - val_acc: 0.7790\n",
      "Epoch 512/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7032 - acc: 0.7571 - val_loss: 0.6070 - val_acc: 0.7783\n",
      "Epoch 513/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6951 - acc: 0.7597 - val_loss: 0.6078 - val_acc: 0.7790\n",
      "Epoch 514/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6991 - acc: 0.7541 - val_loss: 0.6058 - val_acc: 0.7783\n",
      "Epoch 515/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6850 - acc: 0.7615 - val_loss: 0.6027 - val_acc: 0.7805\n",
      "Epoch 516/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6916 - acc: 0.7578 - val_loss: 0.6056 - val_acc: 0.7783\n",
      "Epoch 517/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6936 - acc: 0.7589 - val_loss: 0.6071 - val_acc: 0.7790\n",
      "Epoch 518/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7061 - acc: 0.7578 - val_loss: 0.6066 - val_acc: 0.7790\n",
      "Epoch 519/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6938 - acc: 0.7574 - val_loss: 0.6017 - val_acc: 0.7798\n",
      "Epoch 520/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7024 - acc: 0.7578 - val_loss: 0.6053 - val_acc: 0.7798\n",
      "Epoch 521/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7129 - acc: 0.7474 - val_loss: 0.6083 - val_acc: 0.7783\n",
      "Epoch 522/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7074 - acc: 0.7504 - val_loss: 0.6069 - val_acc: 0.7790\n",
      "Epoch 523/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6897 - acc: 0.7612 - val_loss: 0.6073 - val_acc: 0.7783\n",
      "Epoch 524/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6931 - acc: 0.7519 - val_loss: 0.6050 - val_acc: 0.7798\n",
      "Epoch 525/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6912 - acc: 0.7634 - val_loss: 0.6082 - val_acc: 0.7783\n",
      "Epoch 526/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6866 - acc: 0.7630 - val_loss: 0.6084 - val_acc: 0.7783\n",
      "Epoch 527/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6967 - acc: 0.7586 - val_loss: 0.6074 - val_acc: 0.7790\n",
      "Epoch 528/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6946 - acc: 0.7679 - val_loss: 0.6074 - val_acc: 0.7783\n",
      "Epoch 529/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7049 - acc: 0.7496 - val_loss: 0.6054 - val_acc: 0.7790\n",
      "Epoch 530/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7060 - acc: 0.7500 - val_loss: 0.6063 - val_acc: 0.7798\n",
      "Epoch 00530: early stopping\n",
      "ModelCheckpoint 已经保存到 ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/0-final.hdf5\n",
      "Create subdir directory: ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/log...\n",
      "save in: ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/log/20220201_2000_64_1_3_1.csv\n",
      "time: 0:14:10 s\n",
      "time: 850.0 s\n",
      "average 0.850000 s\n",
      "0 epoch finished\n",
      "--------------------   best   --------------------\n",
      "no_activities: 10\n",
      "\n",
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1349/1349 [==============================] - 1s 993us/step\n",
      "0-milan:\tacc: 77.76%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [3, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 4, 0, 0, 0, 0, 7, 7, 7, 7, 7, 7, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 4, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 4, 4, 9, 9, 9, 9, 9, 9, 9, 9, 9, 4, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 9, 0, 9, 9, 9, 4, 9, 9, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 0, 7, 7, 7, 7, 7, 7, 0, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 0, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 0, 7, 7, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 0, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 3, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 9, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 4, 0, 4, 4, 0, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 0, 0, 4, 0, 0, 4, 4, 0, 4, 4, 0, 4, 0, 4, 4, 0, 7, 4, 4, 4, 0, 4, 4, 0, 7, 4, 4, 4, 0, 0, 0, 0, 4, 4, 0, 4, 0, 4, 0, 4, 4, 0, 0, 4, 0, 4, 4, 4, 7, 4, 4, 4, 0, 7, 4, 4, 4, 4, 4, 4, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.758256  0.921348  0.831884       623\n",
      "         Work   0.000000  0.000000  0.000000        26\n",
      "Take_medicine   0.000000  0.000000  0.000000        20\n",
      "        Sleep   0.571429  0.125000  0.205128        32\n",
      "        Relax   0.811765  0.482517  0.605263       143\n",
      "   Leave_Home   0.915493  0.915493  0.915493        71\n",
      "          Eat   0.000000  0.000000  0.000000         7\n",
      "         Cook   0.757143  0.859459  0.805063       185\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        30\n",
      "      Bathing   0.812785  0.839623  0.825986       212\n",
      "\n",
      "     accuracy                       0.777613      1349\n",
      "    macro avg   0.462687  0.414344  0.418882      1349\n",
      " weighted avg   0.729536  0.777613  0.741606      1349\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  29   0   0   0   0   1]\n",
      " [  0   0   0   0   0   1   0  25   0   0]\n",
      " [  0   0   0   0   0   2   0   4   1   0]\n",
      " [  0   0   0   0   0  20   0   0   0   0]\n",
      " [  0   0   0   0 178   0   0  28   5   1]\n",
      " [  0   0   0   0   0 159   0  26   0   0]\n",
      " [  0   0   0   0   0   2  65   4   0   0]\n",
      " [  0   0   0   0  11  21   6 574  10   1]\n",
      " [  0   0   0   0   0   5   0  69  69   0]\n",
      " [  0   0   0   0   1   0   0  27   0   4]]\n",
      "--------------------   final   --------------------\n",
      "no_activities: 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1349/1349 [==============================] - 1s 1ms/step\n",
      "0-milan:\tacc: 77.91%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [3, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 4, 0, 0, 0, 0, 7, 7, 7, 7, 7, 7, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 4, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 4, 4, 9, 9, 9, 9, 9, 9, 9, 9, 9, 4, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 9, 0, 9, 9, 9, 4, 9, 9, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 0, 7, 7, 7, 7, 7, 7, 0, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 0, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 0, 7, 7, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 0, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 3, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 9, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 7, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 4, 0, 4, 4, 0, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 0, 0, 4, 0, 0, 4, 4, 0, 4, 4, 0, 4, 0, 4, 4, 0, 7, 4, 4, 4, 0, 4, 4, 0, 7, 4, 4, 4, 0, 0, 0, 0, 4, 4, 0, 4, 0, 4, 0, 4, 4, 0, 0, 4, 0, 4, 4, 4, 7, 4, 4, 4, 0, 7, 4, 4, 4, 4, 4, 4, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.761273  0.921348  0.833696       623\n",
      "         Work   0.000000  0.000000  0.000000        26\n",
      "Take_medicine   0.000000  0.000000  0.000000        20\n",
      "        Sleep   0.571429  0.125000  0.205128        32\n",
      "        Relax   0.795455  0.489510  0.606061       143\n",
      "   Leave_Home   0.914286  0.901408  0.907801        71\n",
      "          Eat   0.000000  0.000000  0.000000         7\n",
      "         Cook   0.763033  0.870270  0.813131       185\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        30\n",
      "      Bathing   0.812785  0.839623  0.825986       212\n",
      "\n",
      "     accuracy                       0.779096      1349\n",
      "    macro avg   0.461826  0.414716  0.419180      1349\n",
      " weighted avg   0.729944  0.779096  0.743229      1349\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  29   0   0   0   0   1]\n",
      " [  0   0   0   0   0   1   0  25   0   0]\n",
      " [  0   0   0   0   0   2   0   4   1   0]\n",
      " [  0   0   0   0   0  20   0   0   0   0]\n",
      " [  0   0   0   0 178   0   0  28   5   1]\n",
      " [  0   0   0   0   0 161   0  24   0   0]\n",
      " [  0   0   0   0   0   2  64   4   1   0]\n",
      " [  0   0   0   0  11  20   6 574  11   1]\n",
      " [  0   0   0   0   0   5   0  68  70   0]\n",
      " [  0   0   0   0   1   0   0  27   0   4]]\n",
      "no_activities: 10\n",
      "\n",
      "Begin training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "42/42 [==============================] - 3s 73ms/step - loss: 1.8214 - acc: 0.4684 - val_loss: 1.3371 - val_acc: 0.5893\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.3522 - acc: 0.5964 - val_loss: 1.1199 - val_acc: 0.6451\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.2310 - acc: 0.6071 - val_loss: 1.0505 - val_acc: 0.6622\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.1692 - acc: 0.6283 - val_loss: 1.0131 - val_acc: 0.6629\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.1413 - acc: 0.6321 - val_loss: 0.9768 - val_acc: 0.6741\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0968 - acc: 0.6443 - val_loss: 0.9528 - val_acc: 0.6935\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.0688 - acc: 0.6611 - val_loss: 0.9407 - val_acc: 0.6935\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.0631 - acc: 0.6559 - val_loss: 0.9233 - val_acc: 0.7039\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 1.0276 - acc: 0.6629 - val_loss: 0.9012 - val_acc: 0.7128\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0351 - acc: 0.6603 - val_loss: 0.8963 - val_acc: 0.6994\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9945 - acc: 0.6685 - val_loss: 0.8831 - val_acc: 0.7121\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9900 - acc: 0.6607 - val_loss: 0.8759 - val_acc: 0.7143\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9843 - acc: 0.6663 - val_loss: 0.8646 - val_acc: 0.7121\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9873 - acc: 0.6693 - val_loss: 0.8592 - val_acc: 0.7121\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9749 - acc: 0.6752 - val_loss: 0.8502 - val_acc: 0.7054\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9758 - acc: 0.6663 - val_loss: 0.8395 - val_acc: 0.7091\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9542 - acc: 0.6775 - val_loss: 0.8349 - val_acc: 0.7076\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9357 - acc: 0.6812 - val_loss: 0.8314 - val_acc: 0.7150\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9242 - acc: 0.6920 - val_loss: 0.8200 - val_acc: 0.7128\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9268 - acc: 0.6912 - val_loss: 0.8116 - val_acc: 0.7247\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9279 - acc: 0.6797 - val_loss: 0.8083 - val_acc: 0.7232\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9189 - acc: 0.6916 - val_loss: 0.8007 - val_acc: 0.7262\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9182 - acc: 0.6868 - val_loss: 0.7961 - val_acc: 0.7225\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9138 - acc: 0.6920 - val_loss: 0.7915 - val_acc: 0.7247\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8964 - acc: 0.6983 - val_loss: 0.7839 - val_acc: 0.7240\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8909 - acc: 0.6935 - val_loss: 0.7816 - val_acc: 0.7217\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8916 - acc: 0.6994 - val_loss: 0.7785 - val_acc: 0.7247\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8684 - acc: 0.7054 - val_loss: 0.7730 - val_acc: 0.7247\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8966 - acc: 0.6905 - val_loss: 0.7708 - val_acc: 0.7262\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8618 - acc: 0.7065 - val_loss: 0.7642 - val_acc: 0.7299\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8834 - acc: 0.7057 - val_loss: 0.7635 - val_acc: 0.7307\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8676 - acc: 0.7061 - val_loss: 0.7606 - val_acc: 0.7351\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8635 - acc: 0.7128 - val_loss: 0.7542 - val_acc: 0.7329\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8637 - acc: 0.7091 - val_loss: 0.7571 - val_acc: 0.7374\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8582 - acc: 0.7109 - val_loss: 0.7526 - val_acc: 0.7374\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8667 - acc: 0.7098 - val_loss: 0.7516 - val_acc: 0.7329\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8661 - acc: 0.7147 - val_loss: 0.7505 - val_acc: 0.7351\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8447 - acc: 0.7083 - val_loss: 0.7504 - val_acc: 0.7336\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8542 - acc: 0.7094 - val_loss: 0.7460 - val_acc: 0.7396\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8571 - acc: 0.7102 - val_loss: 0.7482 - val_acc: 0.7418\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8458 - acc: 0.7087 - val_loss: 0.7421 - val_acc: 0.7344\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8456 - acc: 0.7072 - val_loss: 0.7416 - val_acc: 0.7411\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8563 - acc: 0.7091 - val_loss: 0.7434 - val_acc: 0.7381\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8418 - acc: 0.7065 - val_loss: 0.7405 - val_acc: 0.7411\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8406 - acc: 0.7154 - val_loss: 0.7387 - val_acc: 0.7411\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8364 - acc: 0.7121 - val_loss: 0.7396 - val_acc: 0.7403\n",
      "Epoch 47/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8497 - acc: 0.7042 - val_loss: 0.7393 - val_acc: 0.7374\n",
      "Epoch 48/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8333 - acc: 0.7154 - val_loss: 0.7368 - val_acc: 0.7388\n",
      "Epoch 49/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8443 - acc: 0.7165 - val_loss: 0.7335 - val_acc: 0.7426\n",
      "Epoch 50/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8248 - acc: 0.7199 - val_loss: 0.7319 - val_acc: 0.7411\n",
      "Epoch 51/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8405 - acc: 0.7173 - val_loss: 0.7324 - val_acc: 0.7478\n",
      "Epoch 52/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8255 - acc: 0.7195 - val_loss: 0.7269 - val_acc: 0.7552\n",
      "Epoch 53/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.8296 - acc: 0.7210 - val_loss: 0.7291 - val_acc: 0.7560\n",
      "Epoch 54/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8314 - acc: 0.7258 - val_loss: 0.7278 - val_acc: 0.7582\n",
      "Epoch 55/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8341 - acc: 0.7165 - val_loss: 0.7286 - val_acc: 0.7567\n",
      "Epoch 56/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8250 - acc: 0.7121 - val_loss: 0.7273 - val_acc: 0.7426\n",
      "Epoch 57/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8456 - acc: 0.7054 - val_loss: 0.7270 - val_acc: 0.7530\n",
      "Epoch 58/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8213 - acc: 0.7206 - val_loss: 0.7257 - val_acc: 0.7522\n",
      "Epoch 59/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8161 - acc: 0.7243 - val_loss: 0.7231 - val_acc: 0.7545\n",
      "Epoch 60/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8127 - acc: 0.7269 - val_loss: 0.7239 - val_acc: 0.7537\n",
      "Epoch 61/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8135 - acc: 0.7210 - val_loss: 0.7218 - val_acc: 0.7545\n",
      "Epoch 62/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8095 - acc: 0.7132 - val_loss: 0.7223 - val_acc: 0.7515\n",
      "Epoch 63/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8225 - acc: 0.7180 - val_loss: 0.7209 - val_acc: 0.7574\n",
      "Epoch 64/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8147 - acc: 0.7228 - val_loss: 0.7185 - val_acc: 0.7552\n",
      "Epoch 65/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8302 - acc: 0.7117 - val_loss: 0.7227 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00065: loss improved from inf to 0.83018, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-1-000065-0.830185-0.752232.hdf5\n",
      "Epoch 66/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8311 - acc: 0.7195 - val_loss: 0.7191 - val_acc: 0.7574\n",
      "Epoch 67/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8049 - acc: 0.7240 - val_loss: 0.7213 - val_acc: 0.7567\n",
      "Epoch 68/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8209 - acc: 0.7184 - val_loss: 0.7160 - val_acc: 0.7560\n",
      "Epoch 69/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8183 - acc: 0.7176 - val_loss: 0.7195 - val_acc: 0.7560\n",
      "\n",
      "Epoch 00069: loss improved from 0.83018 to 0.81826, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-1-000069-0.818257-0.755952.hdf5\n",
      "Epoch 70/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8132 - acc: 0.7184 - val_loss: 0.7185 - val_acc: 0.7507\n",
      "Epoch 71/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8217 - acc: 0.7121 - val_loss: 0.7162 - val_acc: 0.7574\n",
      "Epoch 72/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8087 - acc: 0.7254 - val_loss: 0.7167 - val_acc: 0.7552\n",
      "Epoch 73/1000\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.8229 - acc: 0.7191 - val_loss: 0.7165 - val_acc: 0.7560\n",
      "Epoch 74/1000\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.7983 - acc: 0.7232 - val_loss: 0.7152 - val_acc: 0.7560\n",
      "Epoch 75/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.8169 - acc: 0.7184 - val_loss: 0.7164 - val_acc: 0.7552\n",
      "Epoch 76/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.8123 - acc: 0.7184 - val_loss: 0.7154 - val_acc: 0.7545\n",
      "Epoch 77/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.8181 - acc: 0.7128 - val_loss: 0.7148 - val_acc: 0.7552\n",
      "\n",
      "Epoch 00077: loss improved from 0.81826 to 0.81813, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-1-000077-0.818128-0.755208.hdf5\n",
      "Epoch 78/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.8028 - acc: 0.7176 - val_loss: 0.7134 - val_acc: 0.7560\n",
      "Epoch 79/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.8093 - acc: 0.7106 - val_loss: 0.7122 - val_acc: 0.7567\n",
      "Epoch 80/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.8037 - acc: 0.7173 - val_loss: 0.7111 - val_acc: 0.7560\n",
      "Epoch 81/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.8056 - acc: 0.7199 - val_loss: 0.7128 - val_acc: 0.7537\n",
      "\n",
      "Epoch 00081: loss improved from 0.81813 to 0.80561, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-1-000081-0.805609-0.753720.hdf5\n",
      "Epoch 82/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7972 - acc: 0.7214 - val_loss: 0.7118 - val_acc: 0.7574\n",
      "Epoch 83/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.8023 - acc: 0.7206 - val_loss: 0.7066 - val_acc: 0.7560\n",
      "Epoch 84/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8126 - acc: 0.7180 - val_loss: 0.7088 - val_acc: 0.7560\n",
      "Epoch 85/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8220 - acc: 0.7132 - val_loss: 0.7099 - val_acc: 0.7589\n",
      "Epoch 86/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7944 - acc: 0.7340 - val_loss: 0.7099 - val_acc: 0.7545\n",
      "Epoch 87/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7999 - acc: 0.7258 - val_loss: 0.7080 - val_acc: 0.7552\n",
      "Epoch 88/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8043 - acc: 0.7217 - val_loss: 0.7092 - val_acc: 0.7589\n",
      "Epoch 89/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8096 - acc: 0.7150 - val_loss: 0.7026 - val_acc: 0.7582\n",
      "Epoch 90/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7961 - acc: 0.7109 - val_loss: 0.7070 - val_acc: 0.7604\n",
      "Epoch 91/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7972 - acc: 0.7184 - val_loss: 0.7062 - val_acc: 0.7597\n",
      "Epoch 92/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8023 - acc: 0.7221 - val_loss: 0.7076 - val_acc: 0.7597\n",
      "Epoch 93/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7947 - acc: 0.7262 - val_loss: 0.7037 - val_acc: 0.7619\n",
      "\n",
      "Epoch 00093: loss improved from 0.80561 to 0.79474, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-1-000093-0.794743-0.761905.hdf5\n",
      "Epoch 94/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8000 - acc: 0.7262 - val_loss: 0.7053 - val_acc: 0.7582\n",
      "Epoch 95/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7904 - acc: 0.7221 - val_loss: 0.7028 - val_acc: 0.7589\n",
      "Epoch 96/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7938 - acc: 0.7347 - val_loss: 0.7013 - val_acc: 0.7589\n",
      "Epoch 97/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7952 - acc: 0.7266 - val_loss: 0.7011 - val_acc: 0.7597\n",
      "Epoch 98/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7802 - acc: 0.7303 - val_loss: 0.6998 - val_acc: 0.7612\n",
      "Epoch 99/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7875 - acc: 0.7258 - val_loss: 0.7001 - val_acc: 0.7582\n",
      "Epoch 100/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7975 - acc: 0.7258 - val_loss: 0.6993 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00100: saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/1-000100-0.797467-0.757440.hdf5\n",
      "Epoch 101/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8078 - acc: 0.7195 - val_loss: 0.6989 - val_acc: 0.7589\n",
      "Epoch 102/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7900 - acc: 0.7299 - val_loss: 0.6983 - val_acc: 0.7589\n",
      "Epoch 103/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7905 - acc: 0.7232 - val_loss: 0.6970 - val_acc: 0.7567\n",
      "Epoch 104/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7866 - acc: 0.7273 - val_loss: 0.6961 - val_acc: 0.7582\n",
      "Epoch 105/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7872 - acc: 0.7236 - val_loss: 0.6973 - val_acc: 0.7574\n",
      "Epoch 106/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7829 - acc: 0.7325 - val_loss: 0.6912 - val_acc: 0.7574\n",
      "Epoch 107/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7828 - acc: 0.7243 - val_loss: 0.6947 - val_acc: 0.7612\n",
      "Epoch 108/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7694 - acc: 0.7362 - val_loss: 0.6984 - val_acc: 0.7604\n",
      "Epoch 109/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7954 - acc: 0.7225 - val_loss: 0.6974 - val_acc: 0.7574\n",
      "Epoch 110/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7762 - acc: 0.7347 - val_loss: 0.6979 - val_acc: 0.7604\n",
      "Epoch 111/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7747 - acc: 0.7247 - val_loss: 0.6942 - val_acc: 0.7619\n",
      "Epoch 112/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7974 - acc: 0.7169 - val_loss: 0.6980 - val_acc: 0.7589\n",
      "Epoch 113/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7837 - acc: 0.7251 - val_loss: 0.6973 - val_acc: 0.7604\n",
      "Epoch 114/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7712 - acc: 0.7292 - val_loss: 0.6901 - val_acc: 0.7604\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7771 - acc: 0.7251 - val_loss: 0.6936 - val_acc: 0.7619\n",
      "Epoch 116/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7823 - acc: 0.7325 - val_loss: 0.6933 - val_acc: 0.7604\n",
      "Epoch 117/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7801 - acc: 0.7228 - val_loss: 0.6934 - val_acc: 0.7641\n",
      "Epoch 118/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7788 - acc: 0.7236 - val_loss: 0.6937 - val_acc: 0.7582\n",
      "Epoch 119/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7807 - acc: 0.7243 - val_loss: 0.6960 - val_acc: 0.7619\n",
      "Epoch 120/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7748 - acc: 0.7254 - val_loss: 0.6934 - val_acc: 0.7604\n",
      "Epoch 121/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7718 - acc: 0.7269 - val_loss: 0.6939 - val_acc: 0.7589\n",
      "Epoch 122/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7603 - acc: 0.7314 - val_loss: 0.6926 - val_acc: 0.7604\n",
      "Epoch 123/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7732 - acc: 0.7299 - val_loss: 0.6918 - val_acc: 0.7612\n",
      "Epoch 124/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7862 - acc: 0.7321 - val_loss: 0.6915 - val_acc: 0.7619\n",
      "Epoch 125/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7624 - acc: 0.7370 - val_loss: 0.6913 - val_acc: 0.7597\n",
      "Epoch 126/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7699 - acc: 0.7284 - val_loss: 0.6904 - val_acc: 0.7604\n",
      "Epoch 127/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7675 - acc: 0.7426 - val_loss: 0.6912 - val_acc: 0.7619\n",
      "Epoch 128/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7629 - acc: 0.7314 - val_loss: 0.6847 - val_acc: 0.7612\n",
      "Epoch 129/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7648 - acc: 0.7325 - val_loss: 0.6895 - val_acc: 0.7612\n",
      "Epoch 130/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7692 - acc: 0.7303 - val_loss: 0.6850 - val_acc: 0.7626\n",
      "Epoch 131/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7788 - acc: 0.7295 - val_loss: 0.6880 - val_acc: 0.7612\n",
      "Epoch 132/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7660 - acc: 0.7347 - val_loss: 0.6856 - val_acc: 0.7619\n",
      "Epoch 133/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7869 - acc: 0.7232 - val_loss: 0.6864 - val_acc: 0.7597\n",
      "Epoch 134/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7681 - acc: 0.7362 - val_loss: 0.6871 - val_acc: 0.7612\n",
      "Epoch 135/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7711 - acc: 0.7362 - val_loss: 0.6843 - val_acc: 0.7597\n",
      "Epoch 136/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7522 - acc: 0.7381 - val_loss: 0.6837 - val_acc: 0.7597\n",
      "Epoch 137/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7503 - acc: 0.7340 - val_loss: 0.6826 - val_acc: 0.7619\n",
      "Epoch 138/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7662 - acc: 0.7314 - val_loss: 0.6771 - val_acc: 0.7634\n",
      "Epoch 139/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7650 - acc: 0.7362 - val_loss: 0.6783 - val_acc: 0.7634\n",
      "Epoch 140/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7528 - acc: 0.7403 - val_loss: 0.6785 - val_acc: 0.7612\n",
      "Epoch 141/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7765 - acc: 0.7251 - val_loss: 0.6818 - val_acc: 0.7612\n",
      "Epoch 142/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7619 - acc: 0.7414 - val_loss: 0.6817 - val_acc: 0.7604\n",
      "Epoch 143/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7665 - acc: 0.7292 - val_loss: 0.6802 - val_acc: 0.7626\n",
      "Epoch 144/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7597 - acc: 0.7344 - val_loss: 0.6798 - val_acc: 0.7612\n",
      "Epoch 145/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7516 - acc: 0.7381 - val_loss: 0.6806 - val_acc: 0.7641\n",
      "Epoch 146/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7688 - acc: 0.7307 - val_loss: 0.6799 - val_acc: 0.7626\n",
      "Epoch 147/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7642 - acc: 0.7329 - val_loss: 0.6802 - val_acc: 0.7626\n",
      "Epoch 148/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7742 - acc: 0.7281 - val_loss: 0.6784 - val_acc: 0.7619\n",
      "Epoch 149/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7504 - acc: 0.7370 - val_loss: 0.6779 - val_acc: 0.7619\n",
      "Epoch 150/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7681 - acc: 0.7336 - val_loss: 0.6806 - val_acc: 0.7626\n",
      "Epoch 151/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7626 - acc: 0.7277 - val_loss: 0.6766 - val_acc: 0.7634\n",
      "Epoch 152/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7560 - acc: 0.7418 - val_loss: 0.6783 - val_acc: 0.7589\n",
      "Epoch 153/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7617 - acc: 0.7333 - val_loss: 0.6773 - val_acc: 0.7597\n",
      "Epoch 154/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7643 - acc: 0.7355 - val_loss: 0.6788 - val_acc: 0.7604\n",
      "Epoch 155/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7591 - acc: 0.7407 - val_loss: 0.6777 - val_acc: 0.7589\n",
      "Epoch 156/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7656 - acc: 0.7333 - val_loss: 0.6771 - val_acc: 0.7567\n",
      "Epoch 157/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7683 - acc: 0.7284 - val_loss: 0.6744 - val_acc: 0.7619\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 158/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7550 - acc: 0.7403 - val_loss: 0.6730 - val_acc: 0.7634\n",
      "Epoch 159/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7512 - acc: 0.7396 - val_loss: 0.6755 - val_acc: 0.7634\n",
      "Epoch 160/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7801 - acc: 0.7273 - val_loss: 0.6737 - val_acc: 0.7619\n",
      "Epoch 161/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7523 - acc: 0.7388 - val_loss: 0.6772 - val_acc: 0.7619\n",
      "Epoch 162/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7464 - acc: 0.7344 - val_loss: 0.6777 - val_acc: 0.7619\n",
      "Epoch 163/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7727 - acc: 0.7295 - val_loss: 0.6762 - val_acc: 0.7619\n",
      "Epoch 164/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7452 - acc: 0.7396 - val_loss: 0.6761 - val_acc: 0.7626\n",
      "Epoch 165/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7474 - acc: 0.7440 - val_loss: 0.6763 - val_acc: 0.7612\n",
      "\n",
      "Epoch 00165: loss improved from inf to 0.74740, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-1-000165-0.747401-0.761161.hdf5\n",
      "Epoch 166/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7442 - acc: 0.7452 - val_loss: 0.6755 - val_acc: 0.7649\n",
      "Epoch 167/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7582 - acc: 0.7414 - val_loss: 0.6742 - val_acc: 0.7641\n",
      "Epoch 168/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7561 - acc: 0.7344 - val_loss: 0.6757 - val_acc: 0.7634\n",
      "Epoch 169/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7518 - acc: 0.7355 - val_loss: 0.6742 - val_acc: 0.7634\n",
      "Epoch 170/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7562 - acc: 0.7440 - val_loss: 0.6758 - val_acc: 0.7626\n",
      "Epoch 171/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7760 - acc: 0.7321 - val_loss: 0.6729 - val_acc: 0.7634\n",
      "Epoch 172/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7761 - acc: 0.7247 - val_loss: 0.6754 - val_acc: 0.7612\n",
      "Epoch 173/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7578 - acc: 0.7385 - val_loss: 0.6729 - val_acc: 0.7634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7624 - acc: 0.7266 - val_loss: 0.6761 - val_acc: 0.7612\n",
      "Epoch 175/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7568 - acc: 0.7347 - val_loss: 0.6741 - val_acc: 0.7604\n",
      "Epoch 176/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7471 - acc: 0.7519 - val_loss: 0.6776 - val_acc: 0.7597\n",
      "Epoch 177/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7517 - acc: 0.7340 - val_loss: 0.6752 - val_acc: 0.7604\n",
      "Epoch 178/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7365 - acc: 0.7370 - val_loss: 0.6767 - val_acc: 0.7597\n",
      "Epoch 179/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7594 - acc: 0.7281 - val_loss: 0.6742 - val_acc: 0.7612\n",
      "Epoch 180/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7447 - acc: 0.7403 - val_loss: 0.6715 - val_acc: 0.7634\n",
      "Epoch 181/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7624 - acc: 0.7381 - val_loss: 0.6755 - val_acc: 0.7604\n",
      "Epoch 182/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7477 - acc: 0.7381 - val_loss: 0.6757 - val_acc: 0.7604\n",
      "Epoch 183/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7452 - acc: 0.7307 - val_loss: 0.6727 - val_acc: 0.7634\n",
      "Epoch 184/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7447 - acc: 0.7347 - val_loss: 0.6758 - val_acc: 0.7634\n",
      "Epoch 185/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7500 - acc: 0.7403 - val_loss: 0.6745 - val_acc: 0.7626\n",
      "Epoch 186/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7573 - acc: 0.7321 - val_loss: 0.6722 - val_acc: 0.7656\n",
      "Epoch 187/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7472 - acc: 0.7370 - val_loss: 0.6742 - val_acc: 0.7634\n",
      "Epoch 188/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7429 - acc: 0.7377 - val_loss: 0.6702 - val_acc: 0.7649\n",
      "Epoch 189/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7501 - acc: 0.7362 - val_loss: 0.6724 - val_acc: 0.7641\n",
      "Epoch 190/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7647 - acc: 0.7314 - val_loss: 0.6739 - val_acc: 0.7634\n",
      "Epoch 191/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7609 - acc: 0.7269 - val_loss: 0.6755 - val_acc: 0.7626\n",
      "Epoch 192/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7601 - acc: 0.7321 - val_loss: 0.6727 - val_acc: 0.7626\n",
      "Epoch 193/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7467 - acc: 0.7388 - val_loss: 0.6746 - val_acc: 0.7641\n",
      "\n",
      "Epoch 00193: loss improved from 0.74740 to 0.74667, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-1-000193-0.746671-0.764137.hdf5\n",
      "Epoch 194/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7690 - acc: 0.7359 - val_loss: 0.6714 - val_acc: 0.7634\n",
      "Epoch 195/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7500 - acc: 0.7411 - val_loss: 0.6734 - val_acc: 0.7634\n",
      "Epoch 196/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7407 - acc: 0.7426 - val_loss: 0.6756 - val_acc: 0.7626\n",
      "Epoch 197/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7564 - acc: 0.7392 - val_loss: 0.6754 - val_acc: 0.7626\n",
      "Epoch 198/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7639 - acc: 0.7381 - val_loss: 0.6747 - val_acc: 0.7619\n",
      "\n",
      "Epoch 00198: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 199/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7556 - acc: 0.7440 - val_loss: 0.6724 - val_acc: 0.7626\n",
      "Epoch 200/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7604 - acc: 0.7307 - val_loss: 0.6737 - val_acc: 0.7634\n",
      "\n",
      "Epoch 00200: saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/1-000200-0.760430-0.763393.hdf5\n",
      "Epoch 201/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7580 - acc: 0.7381 - val_loss: 0.6749 - val_acc: 0.7619\n",
      "Epoch 202/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7599 - acc: 0.7310 - val_loss: 0.6736 - val_acc: 0.7626\n",
      "Epoch 203/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7479 - acc: 0.7366 - val_loss: 0.6756 - val_acc: 0.7619\n",
      "Epoch 204/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7619 - acc: 0.7266 - val_loss: 0.6726 - val_acc: 0.7626\n",
      "Epoch 205/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7587 - acc: 0.7310 - val_loss: 0.6747 - val_acc: 0.7626\n",
      "Epoch 206/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7509 - acc: 0.7336 - val_loss: 0.6725 - val_acc: 0.7641\n",
      "Epoch 207/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7547 - acc: 0.7385 - val_loss: 0.6733 - val_acc: 0.7626\n",
      "Epoch 208/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7648 - acc: 0.7310 - val_loss: 0.6740 - val_acc: 0.7626\n",
      "Epoch 209/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7536 - acc: 0.7381 - val_loss: 0.6756 - val_acc: 0.7619\n",
      "Epoch 210/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7471 - acc: 0.7314 - val_loss: 0.6748 - val_acc: 0.7619\n",
      "Epoch 211/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7602 - acc: 0.7377 - val_loss: 0.6754 - val_acc: 0.7619\n",
      "Epoch 212/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7453 - acc: 0.7351 - val_loss: 0.6753 - val_acc: 0.7619\n",
      "Epoch 213/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7511 - acc: 0.7362 - val_loss: 0.6749 - val_acc: 0.7619\n",
      "Epoch 214/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7686 - acc: 0.7303 - val_loss: 0.6718 - val_acc: 0.7626\n",
      "Epoch 215/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7459 - acc: 0.7407 - val_loss: 0.6738 - val_acc: 0.7634\n",
      "Epoch 216/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7535 - acc: 0.7359 - val_loss: 0.6750 - val_acc: 0.7619\n",
      "Epoch 217/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7509 - acc: 0.7362 - val_loss: 0.6732 - val_acc: 0.7634\n",
      "Epoch 218/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7593 - acc: 0.7325 - val_loss: 0.6705 - val_acc: 0.7634\n",
      "\n",
      "Epoch 00218: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 219/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7529 - acc: 0.7388 - val_loss: 0.6732 - val_acc: 0.7634\n",
      "Epoch 220/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7375 - acc: 0.7426 - val_loss: 0.6743 - val_acc: 0.7626\n",
      "Epoch 221/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7495 - acc: 0.7359 - val_loss: 0.6715 - val_acc: 0.7634\n",
      "Epoch 222/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7610 - acc: 0.7403 - val_loss: 0.6745 - val_acc: 0.7619\n",
      "Epoch 223/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7532 - acc: 0.7303 - val_loss: 0.6741 - val_acc: 0.7626\n",
      "Epoch 224/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7500 - acc: 0.7325 - val_loss: 0.6746 - val_acc: 0.7619\n",
      "Epoch 225/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7434 - acc: 0.7377 - val_loss: 0.6728 - val_acc: 0.7634\n",
      "Epoch 226/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7563 - acc: 0.7362 - val_loss: 0.6750 - val_acc: 0.7619\n",
      "Epoch 227/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7553 - acc: 0.7396 - val_loss: 0.6725 - val_acc: 0.7626\n",
      "Epoch 228/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7610 - acc: 0.7381 - val_loss: 0.6736 - val_acc: 0.7619\n",
      "Epoch 229/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7622 - acc: 0.7344 - val_loss: 0.6745 - val_acc: 0.7619\n",
      "Epoch 230/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7619 - acc: 0.7266 - val_loss: 0.6740 - val_acc: 0.7626\n",
      "Epoch 231/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7471 - acc: 0.7452 - val_loss: 0.6749 - val_acc: 0.7619\n",
      "Epoch 232/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7551 - acc: 0.7340 - val_loss: 0.6740 - val_acc: 0.7626\n",
      "Epoch 233/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7424 - acc: 0.7377 - val_loss: 0.6748 - val_acc: 0.7619\n",
      "Epoch 234/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7541 - acc: 0.7303 - val_loss: 0.6748 - val_acc: 0.7619\n",
      "Epoch 235/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7416 - acc: 0.7351 - val_loss: 0.6716 - val_acc: 0.7634\n",
      "Epoch 236/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7480 - acc: 0.7370 - val_loss: 0.6755 - val_acc: 0.7619\n",
      "Epoch 237/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7645 - acc: 0.7340 - val_loss: 0.6745 - val_acc: 0.7626\n",
      "Epoch 238/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7632 - acc: 0.7225 - val_loss: 0.6746 - val_acc: 0.7626\n",
      "Epoch 239/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7500 - acc: 0.7403 - val_loss: 0.6722 - val_acc: 0.7641\n",
      "Epoch 240/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7401 - acc: 0.7403 - val_loss: 0.6724 - val_acc: 0.7626\n",
      "Epoch 241/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7572 - acc: 0.7284 - val_loss: 0.6729 - val_acc: 0.7626\n",
      "Epoch 242/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7566 - acc: 0.7359 - val_loss: 0.6728 - val_acc: 0.7626\n",
      "Epoch 243/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7441 - acc: 0.7370 - val_loss: 0.6704 - val_acc: 0.7634\n",
      "Epoch 244/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7420 - acc: 0.7448 - val_loss: 0.6728 - val_acc: 0.7626\n",
      "Epoch 245/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7527 - acc: 0.7381 - val_loss: 0.6745 - val_acc: 0.7619\n",
      "Epoch 246/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7538 - acc: 0.7314 - val_loss: 0.6728 - val_acc: 0.7626\n",
      "Epoch 247/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7581 - acc: 0.7336 - val_loss: 0.6738 - val_acc: 0.7626\n",
      "Epoch 248/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7406 - acc: 0.7355 - val_loss: 0.6747 - val_acc: 0.7619\n",
      "Epoch 249/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7485 - acc: 0.7377 - val_loss: 0.6746 - val_acc: 0.7619\n",
      "Epoch 250/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7505 - acc: 0.7385 - val_loss: 0.6739 - val_acc: 0.7619\n",
      "Epoch 251/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7686 - acc: 0.7336 - val_loss: 0.6721 - val_acc: 0.7634\n",
      "Epoch 252/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7471 - acc: 0.7325 - val_loss: 0.6745 - val_acc: 0.7619\n",
      "Epoch 253/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.7428 - acc: 0.7411 - val_loss: 0.6744 - val_acc: 0.7619\n",
      "Epoch 254/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7434 - acc: 0.7455 - val_loss: 0.6729 - val_acc: 0.7634\n",
      "Epoch 255/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7521 - acc: 0.7266 - val_loss: 0.6741 - val_acc: 0.7626\n",
      "Epoch 256/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7469 - acc: 0.7318 - val_loss: 0.6711 - val_acc: 0.7641\n",
      "Epoch 257/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7522 - acc: 0.7392 - val_loss: 0.6745 - val_acc: 0.7619\n",
      "Epoch 258/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7580 - acc: 0.7318 - val_loss: 0.6740 - val_acc: 0.7626\n",
      "Epoch 259/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7419 - acc: 0.7418 - val_loss: 0.6729 - val_acc: 0.7634\n",
      "Epoch 260/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7459 - acc: 0.7355 - val_loss: 0.6746 - val_acc: 0.7619\n",
      "Epoch 261/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7509 - acc: 0.7388 - val_loss: 0.6737 - val_acc: 0.7626\n",
      "Epoch 262/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7519 - acc: 0.7329 - val_loss: 0.6741 - val_acc: 0.7626\n",
      "Epoch 263/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7511 - acc: 0.7377 - val_loss: 0.6734 - val_acc: 0.7626\n",
      "Epoch 264/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7549 - acc: 0.7325 - val_loss: 0.6721 - val_acc: 0.7626\n",
      "Epoch 265/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7333 - acc: 0.7426 - val_loss: 0.6741 - val_acc: 0.7619\n",
      "\n",
      "Epoch 00265: loss improved from inf to 0.73329, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-1-000265-0.733289-0.761905.hdf5\n",
      "Epoch 266/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7454 - acc: 0.7362 - val_loss: 0.6748 - val_acc: 0.7619\n",
      "Epoch 267/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7504 - acc: 0.7303 - val_loss: 0.6728 - val_acc: 0.7626\n",
      "Epoch 268/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7582 - acc: 0.7347 - val_loss: 0.6724 - val_acc: 0.7626\n",
      "Epoch 269/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7583 - acc: 0.7362 - val_loss: 0.6730 - val_acc: 0.7634\n",
      "Epoch 270/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7624 - acc: 0.7340 - val_loss: 0.6752 - val_acc: 0.7619\n",
      "Epoch 271/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7554 - acc: 0.7325 - val_loss: 0.6753 - val_acc: 0.7619\n",
      "Epoch 272/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7450 - acc: 0.7377 - val_loss: 0.6740 - val_acc: 0.7626\n",
      "Epoch 273/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7472 - acc: 0.7459 - val_loss: 0.6748 - val_acc: 0.7619\n",
      "Epoch 274/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7566 - acc: 0.7351 - val_loss: 0.6750 - val_acc: 0.7619\n",
      "Epoch 275/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7413 - acc: 0.7474 - val_loss: 0.6744 - val_acc: 0.7626\n",
      "Epoch 276/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7508 - acc: 0.7310 - val_loss: 0.6728 - val_acc: 0.7626\n",
      "Epoch 277/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7550 - acc: 0.7340 - val_loss: 0.6746 - val_acc: 0.7619\n",
      "Epoch 278/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7485 - acc: 0.7310 - val_loss: 0.6736 - val_acc: 0.7626\n",
      "Epoch 279/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7475 - acc: 0.7388 - val_loss: 0.6736 - val_acc: 0.7626\n",
      "Epoch 280/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7430 - acc: 0.7340 - val_loss: 0.6723 - val_acc: 0.7634\n",
      "Epoch 281/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7404 - acc: 0.7403 - val_loss: 0.6731 - val_acc: 0.7626\n",
      "Epoch 282/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7638 - acc: 0.7281 - val_loss: 0.6741 - val_acc: 0.7626\n",
      "Epoch 283/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7483 - acc: 0.7377 - val_loss: 0.6698 - val_acc: 0.7641\n",
      "Epoch 284/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7538 - acc: 0.7370 - val_loss: 0.6741 - val_acc: 0.7626\n",
      "Epoch 285/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7711 - acc: 0.7385 - val_loss: 0.6719 - val_acc: 0.7634\n",
      "Epoch 286/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7360 - acc: 0.7362 - val_loss: 0.6740 - val_acc: 0.7626\n",
      "Epoch 287/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7559 - acc: 0.7370 - val_loss: 0.6725 - val_acc: 0.7626\n",
      "Epoch 288/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7493 - acc: 0.7474 - val_loss: 0.6727 - val_acc: 0.7626\n",
      "Epoch 289/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7542 - acc: 0.7381 - val_loss: 0.6710 - val_acc: 0.7634\n",
      "Epoch 290/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7445 - acc: 0.7455 - val_loss: 0.6718 - val_acc: 0.7626\n",
      "Epoch 291/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7424 - acc: 0.7366 - val_loss: 0.6739 - val_acc: 0.7626\n",
      "Epoch 292/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7432 - acc: 0.7381 - val_loss: 0.6735 - val_acc: 0.7626\n",
      "Epoch 293/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7691 - acc: 0.7176 - val_loss: 0.6747 - val_acc: 0.7619\n",
      "Epoch 294/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7457 - acc: 0.7374 - val_loss: 0.6733 - val_acc: 0.7634\n",
      "Epoch 295/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7540 - acc: 0.7299 - val_loss: 0.6734 - val_acc: 0.7634\n",
      "Epoch 296/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7651 - acc: 0.7381 - val_loss: 0.6754 - val_acc: 0.7619\n",
      "Epoch 297/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7337 - acc: 0.7422 - val_loss: 0.6752 - val_acc: 0.7619\n",
      "Epoch 298/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7475 - acc: 0.7377 - val_loss: 0.6745 - val_acc: 0.7626\n",
      "Epoch 299/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7607 - acc: 0.7336 - val_loss: 0.6751 - val_acc: 0.7619\n",
      "Epoch 300/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7516 - acc: 0.7351 - val_loss: 0.6740 - val_acc: 0.7626\n",
      "\n",
      "Epoch 00300: saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/1-000300-0.751568-0.762649.hdf5\n",
      "Epoch 301/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7501 - acc: 0.7321 - val_loss: 0.6741 - val_acc: 0.7626\n",
      "Epoch 302/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7373 - acc: 0.7411 - val_loss: 0.6736 - val_acc: 0.7626\n",
      "Epoch 303/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7483 - acc: 0.7448 - val_loss: 0.6748 - val_acc: 0.7619\n",
      "Epoch 304/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7444 - acc: 0.7400 - val_loss: 0.6731 - val_acc: 0.7626\n",
      "Epoch 305/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7399 - acc: 0.7444 - val_loss: 0.6731 - val_acc: 0.7626\n",
      "Epoch 306/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7602 - acc: 0.7262 - val_loss: 0.6743 - val_acc: 0.7626\n",
      "Epoch 307/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7686 - acc: 0.7251 - val_loss: 0.6744 - val_acc: 0.7626\n",
      "Epoch 308/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7588 - acc: 0.7336 - val_loss: 0.6743 - val_acc: 0.7626\n",
      "Epoch 309/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7543 - acc: 0.7411 - val_loss: 0.6731 - val_acc: 0.7634\n",
      "Epoch 310/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7453 - acc: 0.7336 - val_loss: 0.6744 - val_acc: 0.7619\n",
      "Epoch 311/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7634 - acc: 0.7374 - val_loss: 0.6726 - val_acc: 0.7634\n",
      "Epoch 312/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7392 - acc: 0.7377 - val_loss: 0.6734 - val_acc: 0.7626\n",
      "Epoch 313/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7535 - acc: 0.7269 - val_loss: 0.6742 - val_acc: 0.7626\n",
      "Epoch 314/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7391 - acc: 0.7400 - val_loss: 0.6743 - val_acc: 0.7619\n",
      "Epoch 315/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7460 - acc: 0.7411 - val_loss: 0.6737 - val_acc: 0.7626\n",
      "Epoch 316/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7509 - acc: 0.7437 - val_loss: 0.6752 - val_acc: 0.7619\n",
      "Epoch 317/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7510 - acc: 0.7407 - val_loss: 0.6743 - val_acc: 0.7626\n",
      "Epoch 318/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7391 - acc: 0.7470 - val_loss: 0.6749 - val_acc: 0.7619\n",
      "Epoch 319/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7563 - acc: 0.7347 - val_loss: 0.6747 - val_acc: 0.7619\n",
      "Epoch 320/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7489 - acc: 0.7362 - val_loss: 0.6726 - val_acc: 0.7634\n",
      "Epoch 321/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7523 - acc: 0.7385 - val_loss: 0.6744 - val_acc: 0.7626\n",
      "Epoch 322/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7413 - acc: 0.7344 - val_loss: 0.6735 - val_acc: 0.7626\n",
      "Epoch 323/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7577 - acc: 0.7336 - val_loss: 0.6721 - val_acc: 0.7634\n",
      "Epoch 324/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7594 - acc: 0.7299 - val_loss: 0.6728 - val_acc: 0.7634\n",
      "Epoch 325/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7541 - acc: 0.7292 - val_loss: 0.6682 - val_acc: 0.7641\n",
      "Epoch 326/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7465 - acc: 0.7374 - val_loss: 0.6735 - val_acc: 0.7626\n",
      "Epoch 327/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7516 - acc: 0.7303 - val_loss: 0.6740 - val_acc: 0.7626\n",
      "Epoch 328/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7592 - acc: 0.7385 - val_loss: 0.6745 - val_acc: 0.7626\n",
      "Epoch 329/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7419 - acc: 0.7407 - val_loss: 0.6735 - val_acc: 0.7626\n",
      "Epoch 330/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7616 - acc: 0.7333 - val_loss: 0.6737 - val_acc: 0.7634\n",
      "Epoch 331/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7349 - acc: 0.7470 - val_loss: 0.6751 - val_acc: 0.7619\n",
      "Epoch 332/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7630 - acc: 0.7318 - val_loss: 0.6724 - val_acc: 0.7626\n",
      "Epoch 333/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7564 - acc: 0.7366 - val_loss: 0.6712 - val_acc: 0.7634\n",
      "Epoch 334/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7388 - acc: 0.7481 - val_loss: 0.6736 - val_acc: 0.7634\n",
      "Epoch 335/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7593 - acc: 0.7321 - val_loss: 0.6739 - val_acc: 0.7626\n",
      "Epoch 336/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7620 - acc: 0.7258 - val_loss: 0.6732 - val_acc: 0.7626\n",
      "Epoch 337/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7537 - acc: 0.7381 - val_loss: 0.6755 - val_acc: 0.7619\n",
      "Epoch 338/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7440 - acc: 0.7437 - val_loss: 0.6744 - val_acc: 0.7626\n",
      "Epoch 339/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7540 - acc: 0.7474 - val_loss: 0.6746 - val_acc: 0.7626\n",
      "Epoch 340/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7623 - acc: 0.7344 - val_loss: 0.6698 - val_acc: 0.7641\n",
      "Epoch 341/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7551 - acc: 0.7452 - val_loss: 0.6735 - val_acc: 0.7626\n",
      "Epoch 342/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7375 - acc: 0.7362 - val_loss: 0.6737 - val_acc: 0.7634\n",
      "Epoch 343/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7497 - acc: 0.7347 - val_loss: 0.6744 - val_acc: 0.7619\n",
      "Epoch 344/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7432 - acc: 0.7414 - val_loss: 0.6721 - val_acc: 0.7634\n",
      "Epoch 345/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7689 - acc: 0.7321 - val_loss: 0.6737 - val_acc: 0.7626\n",
      "Epoch 346/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7361 - acc: 0.7429 - val_loss: 0.6736 - val_acc: 0.7626\n",
      "Epoch 347/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7609 - acc: 0.7321 - val_loss: 0.6742 - val_acc: 0.7626\n",
      "Epoch 348/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7564 - acc: 0.7347 - val_loss: 0.6726 - val_acc: 0.7634\n",
      "Epoch 349/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7546 - acc: 0.7344 - val_loss: 0.6752 - val_acc: 0.7619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7469 - acc: 0.7344 - val_loss: 0.6721 - val_acc: 0.7626\n",
      "Epoch 351/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7536 - acc: 0.7429 - val_loss: 0.6747 - val_acc: 0.7626\n",
      "Epoch 352/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7458 - acc: 0.7433 - val_loss: 0.6742 - val_acc: 0.7626\n",
      "Epoch 353/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7519 - acc: 0.7314 - val_loss: 0.6738 - val_acc: 0.7626\n",
      "Epoch 354/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7447 - acc: 0.7374 - val_loss: 0.6747 - val_acc: 0.7619\n",
      "Epoch 355/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7600 - acc: 0.7288 - val_loss: 0.6743 - val_acc: 0.7626\n",
      "Epoch 356/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7549 - acc: 0.7329 - val_loss: 0.6728 - val_acc: 0.7634\n",
      "Epoch 357/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7519 - acc: 0.7400 - val_loss: 0.6743 - val_acc: 0.7626\n",
      "Epoch 358/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7457 - acc: 0.7470 - val_loss: 0.6719 - val_acc: 0.7626\n",
      "Epoch 359/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7442 - acc: 0.7359 - val_loss: 0.6738 - val_acc: 0.7619\n",
      "Epoch 360/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7466 - acc: 0.7400 - val_loss: 0.6736 - val_acc: 0.7626\n",
      "Epoch 361/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7512 - acc: 0.7362 - val_loss: 0.6733 - val_acc: 0.7634\n",
      "Epoch 362/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7441 - acc: 0.7411 - val_loss: 0.6726 - val_acc: 0.7634\n",
      "Epoch 363/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7573 - acc: 0.7340 - val_loss: 0.6673 - val_acc: 0.7641\n",
      "Epoch 364/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7460 - acc: 0.7381 - val_loss: 0.6746 - val_acc: 0.7619\n",
      "Epoch 365/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7518 - acc: 0.7388 - val_loss: 0.6704 - val_acc: 0.7634\n",
      "\n",
      "Epoch 00365: loss improved from inf to 0.75181, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-1-000365-0.751809-0.763393.hdf5\n",
      "Epoch 366/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7338 - acc: 0.7400 - val_loss: 0.6746 - val_acc: 0.7619\n",
      "Epoch 367/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7446 - acc: 0.7385 - val_loss: 0.6741 - val_acc: 0.7626\n",
      "Epoch 368/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7479 - acc: 0.7396 - val_loss: 0.6712 - val_acc: 0.7626\n",
      "Epoch 369/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7496 - acc: 0.7403 - val_loss: 0.6737 - val_acc: 0.7634\n",
      "\n",
      "Epoch 00369: loss improved from 0.75181 to 0.74955, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-1-000369-0.749553-0.763393.hdf5\n",
      "Epoch 370/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7444 - acc: 0.7414 - val_loss: 0.6743 - val_acc: 0.7626\n",
      "Epoch 371/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7681 - acc: 0.7329 - val_loss: 0.6746 - val_acc: 0.7619\n",
      "Epoch 372/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7386 - acc: 0.7381 - val_loss: 0.6727 - val_acc: 0.7641\n",
      "Epoch 373/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7470 - acc: 0.7377 - val_loss: 0.6738 - val_acc: 0.7619\n",
      "\n",
      "Epoch 00373: loss improved from 0.74955 to 0.74703, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-1-000373-0.747032-0.761905.hdf5\n",
      "Epoch 374/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7503 - acc: 0.7433 - val_loss: 0.6642 - val_acc: 0.7634\n",
      "Epoch 375/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7511 - acc: 0.7362 - val_loss: 0.6737 - val_acc: 0.7626\n",
      "Epoch 376/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7581 - acc: 0.7370 - val_loss: 0.6750 - val_acc: 0.7619\n",
      "Epoch 377/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7397 - acc: 0.7433 - val_loss: 0.6745 - val_acc: 0.7619\n",
      "\n",
      "Epoch 00377: loss improved from 0.74703 to 0.73974, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-1-000377-0.739743-0.761905.hdf5\n",
      "Epoch 378/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7580 - acc: 0.7325 - val_loss: 0.6742 - val_acc: 0.7619\n",
      "Epoch 379/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7405 - acc: 0.7448 - val_loss: 0.6742 - val_acc: 0.7626\n",
      "Epoch 380/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7539 - acc: 0.7340 - val_loss: 0.6749 - val_acc: 0.7619\n",
      "Epoch 381/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7410 - acc: 0.7440 - val_loss: 0.6745 - val_acc: 0.7619\n",
      "Epoch 382/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7523 - acc: 0.7374 - val_loss: 0.6752 - val_acc: 0.7619\n",
      "Epoch 383/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7481 - acc: 0.7455 - val_loss: 0.6745 - val_acc: 0.7619\n",
      "Epoch 384/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7500 - acc: 0.7444 - val_loss: 0.6753 - val_acc: 0.7619\n",
      "Epoch 385/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7517 - acc: 0.7407 - val_loss: 0.6726 - val_acc: 0.7634\n",
      "Epoch 386/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7634 - acc: 0.7400 - val_loss: 0.6721 - val_acc: 0.7634\n",
      "Epoch 387/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7682 - acc: 0.7292 - val_loss: 0.6697 - val_acc: 0.7641\n",
      "Epoch 388/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7526 - acc: 0.7370 - val_loss: 0.6746 - val_acc: 0.7619\n",
      "Epoch 389/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7669 - acc: 0.7307 - val_loss: 0.6733 - val_acc: 0.7634\n",
      "Epoch 390/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7721 - acc: 0.7347 - val_loss: 0.6710 - val_acc: 0.7634\n",
      "Epoch 391/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7537 - acc: 0.7299 - val_loss: 0.6744 - val_acc: 0.7619\n",
      "Epoch 392/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7427 - acc: 0.7381 - val_loss: 0.6714 - val_acc: 0.7634\n",
      "Epoch 393/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7468 - acc: 0.7411 - val_loss: 0.6742 - val_acc: 0.7626\n",
      "Epoch 394/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7452 - acc: 0.7414 - val_loss: 0.6715 - val_acc: 0.7634\n",
      "Epoch 395/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7448 - acc: 0.7400 - val_loss: 0.6735 - val_acc: 0.7634\n",
      "Epoch 396/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7511 - acc: 0.7362 - val_loss: 0.6740 - val_acc: 0.7626\n",
      "Epoch 397/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7540 - acc: 0.7336 - val_loss: 0.6731 - val_acc: 0.7634\n",
      "Epoch 398/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7409 - acc: 0.7359 - val_loss: 0.6737 - val_acc: 0.7626\n",
      "Epoch 399/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7557 - acc: 0.7351 - val_loss: 0.6751 - val_acc: 0.7619\n",
      "Epoch 400/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7524 - acc: 0.7407 - val_loss: 0.6752 - val_acc: 0.7619\n",
      "\n",
      "Epoch 00400: saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/1-000400-0.752401-0.761905.hdf5\n",
      "Epoch 401/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7463 - acc: 0.7366 - val_loss: 0.6709 - val_acc: 0.7634\n",
      "Epoch 402/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7559 - acc: 0.7310 - val_loss: 0.6739 - val_acc: 0.7626\n",
      "Epoch 403/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7601 - acc: 0.7240 - val_loss: 0.6744 - val_acc: 0.7619\n",
      "Epoch 404/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7524 - acc: 0.7433 - val_loss: 0.6734 - val_acc: 0.7626\n",
      "Epoch 405/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7619 - acc: 0.7329 - val_loss: 0.6750 - val_acc: 0.7619\n",
      "Epoch 406/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7578 - acc: 0.7351 - val_loss: 0.6728 - val_acc: 0.7641\n",
      "Epoch 407/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7542 - acc: 0.7347 - val_loss: 0.6740 - val_acc: 0.7626\n",
      "Epoch 408/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7520 - acc: 0.7381 - val_loss: 0.6748 - val_acc: 0.7619\n",
      "Epoch 409/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7490 - acc: 0.7359 - val_loss: 0.6751 - val_acc: 0.7619\n",
      "Epoch 410/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7631 - acc: 0.7351 - val_loss: 0.6750 - val_acc: 0.7619\n",
      "Epoch 411/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7479 - acc: 0.7355 - val_loss: 0.6725 - val_acc: 0.7626\n",
      "Epoch 412/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7475 - acc: 0.7414 - val_loss: 0.6744 - val_acc: 0.7626\n",
      "Epoch 413/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7561 - acc: 0.7374 - val_loss: 0.6743 - val_acc: 0.7619\n",
      "Epoch 414/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7533 - acc: 0.7411 - val_loss: 0.6736 - val_acc: 0.7626\n",
      "Epoch 415/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7588 - acc: 0.7429 - val_loss: 0.6741 - val_acc: 0.7619\n",
      "Epoch 416/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7613 - acc: 0.7347 - val_loss: 0.6745 - val_acc: 0.7619\n",
      "Epoch 417/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7402 - acc: 0.7474 - val_loss: 0.6700 - val_acc: 0.7649\n",
      "Epoch 418/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7394 - acc: 0.7448 - val_loss: 0.6743 - val_acc: 0.7619\n",
      "Epoch 419/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7533 - acc: 0.7411 - val_loss: 0.6720 - val_acc: 0.7641\n",
      "Epoch 420/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7506 - acc: 0.7385 - val_loss: 0.6735 - val_acc: 0.7634\n",
      "Epoch 421/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7548 - acc: 0.7318 - val_loss: 0.6753 - val_acc: 0.7619\n",
      "Epoch 422/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7512 - acc: 0.7344 - val_loss: 0.6744 - val_acc: 0.7626\n",
      "Epoch 423/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7372 - acc: 0.7411 - val_loss: 0.6745 - val_acc: 0.7619\n",
      "Epoch 424/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7489 - acc: 0.7344 - val_loss: 0.6739 - val_acc: 0.7626\n",
      "Epoch 425/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7489 - acc: 0.7385 - val_loss: 0.6745 - val_acc: 0.7626\n",
      "Epoch 426/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7610 - acc: 0.7396 - val_loss: 0.6723 - val_acc: 0.7634\n",
      "Epoch 427/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7554 - acc: 0.7366 - val_loss: 0.6700 - val_acc: 0.7641\n",
      "Epoch 428/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7538 - acc: 0.7318 - val_loss: 0.6742 - val_acc: 0.7626\n",
      "Epoch 429/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7541 - acc: 0.7381 - val_loss: 0.6736 - val_acc: 0.7626\n",
      "Epoch 430/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7599 - acc: 0.7381 - val_loss: 0.6744 - val_acc: 0.7626\n",
      "Epoch 431/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7375 - acc: 0.7333 - val_loss: 0.6734 - val_acc: 0.7626\n",
      "Epoch 432/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7507 - acc: 0.7336 - val_loss: 0.6723 - val_acc: 0.7626\n",
      "Epoch 433/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7624 - acc: 0.7385 - val_loss: 0.6745 - val_acc: 0.7619\n",
      "Epoch 434/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7347 - acc: 0.7396 - val_loss: 0.6747 - val_acc: 0.7619\n",
      "Epoch 435/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7548 - acc: 0.7381 - val_loss: 0.6730 - val_acc: 0.7626\n",
      "Epoch 436/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7590 - acc: 0.7318 - val_loss: 0.6745 - val_acc: 0.7619\n",
      "Epoch 437/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7438 - acc: 0.7388 - val_loss: 0.6724 - val_acc: 0.7626\n",
      "Epoch 438/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7548 - acc: 0.7333 - val_loss: 0.6736 - val_acc: 0.7619\n",
      "Epoch 439/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7603 - acc: 0.7318 - val_loss: 0.6746 - val_acc: 0.7619\n",
      "Epoch 440/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7510 - acc: 0.7295 - val_loss: 0.6731 - val_acc: 0.7634\n",
      "Epoch 441/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7436 - acc: 0.7470 - val_loss: 0.6746 - val_acc: 0.7619\n",
      "Epoch 442/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7492 - acc: 0.7374 - val_loss: 0.6738 - val_acc: 0.7626\n",
      "Epoch 443/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7665 - acc: 0.7333 - val_loss: 0.6730 - val_acc: 0.7634\n",
      "Epoch 444/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7648 - acc: 0.7333 - val_loss: 0.6749 - val_acc: 0.7619\n",
      "Epoch 445/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7429 - acc: 0.7347 - val_loss: 0.6720 - val_acc: 0.7634\n",
      "Epoch 446/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7508 - acc: 0.7269 - val_loss: 0.6728 - val_acc: 0.7634\n",
      "Epoch 447/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7514 - acc: 0.7266 - val_loss: 0.6748 - val_acc: 0.7619\n",
      "Epoch 448/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7493 - acc: 0.7377 - val_loss: 0.6735 - val_acc: 0.7626\n",
      "Epoch 449/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7566 - acc: 0.7448 - val_loss: 0.6738 - val_acc: 0.7626\n",
      "Epoch 450/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7463 - acc: 0.7307 - val_loss: 0.6742 - val_acc: 0.7619\n",
      "Epoch 451/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7570 - acc: 0.7426 - val_loss: 0.6737 - val_acc: 0.7619\n",
      "Epoch 452/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7537 - acc: 0.7381 - val_loss: 0.6734 - val_acc: 0.7626\n",
      "Epoch 453/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7417 - acc: 0.7336 - val_loss: 0.6735 - val_acc: 0.7626\n",
      "Epoch 454/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7503 - acc: 0.7403 - val_loss: 0.6722 - val_acc: 0.7626\n",
      "Epoch 455/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7612 - acc: 0.7336 - val_loss: 0.6720 - val_acc: 0.7641\n",
      "Epoch 456/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7674 - acc: 0.7366 - val_loss: 0.6752 - val_acc: 0.7619\n",
      "Epoch 457/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7583 - acc: 0.7362 - val_loss: 0.6732 - val_acc: 0.7634\n",
      "Epoch 458/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7610 - acc: 0.7351 - val_loss: 0.6739 - val_acc: 0.7626\n",
      "Epoch 459/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7380 - acc: 0.7396 - val_loss: 0.6749 - val_acc: 0.7619\n",
      "Epoch 460/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7454 - acc: 0.7426 - val_loss: 0.6750 - val_acc: 0.7619\n",
      "Epoch 461/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7421 - acc: 0.7448 - val_loss: 0.6741 - val_acc: 0.7626\n",
      "Epoch 462/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7588 - acc: 0.7273 - val_loss: 0.6738 - val_acc: 0.7626\n",
      "Epoch 463/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7479 - acc: 0.7370 - val_loss: 0.6731 - val_acc: 0.7634\n",
      "Epoch 464/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7563 - acc: 0.7351 - val_loss: 0.6729 - val_acc: 0.7626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7456 - acc: 0.7467 - val_loss: 0.6742 - val_acc: 0.7619\n",
      "\n",
      "Epoch 00465: loss improved from inf to 0.74558, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-1-000465-0.745576-0.761905.hdf5\n",
      "Epoch 00465: early stopping\n",
      "ModelCheckpoint 已经保存到 ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/1-final.hdf5\n",
      "save in: ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/log/20220201_2000_64_1_3_1.csv\n",
      "time: 0:12:11 s\n",
      "time: 731.0 s\n",
      "average 0.731000 s\n",
      "1 epoch finished\n",
      "--------------------   best   --------------------\n",
      "no_activities: 10\n",
      "\n",
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1348/1348 [==============================] - 1s 1ms/step\n",
      "1-milan:\tacc: 76.26%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 0, 0, 0, 0, 9, 0, 0, 0, 0, 4, 0, 0, 0, 4, 0, 0, 0, 4, 0, 4, 4, 0, 0, 0, 7, 7, 7, 0, 0, 0, 0, 7, 7, 7, 7, 7, 5, 7, 7, 5, 9, 9, 9, 9, 0, 9, 9, 9, 4, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 7, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 7, 7, 7, 7, 0, 7, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 0, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 0, 0, 0, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 0, 5, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 0, 0, 0, 9, 9, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7, 7, 7, 5, 7, 0, 5, 7, 7, 5, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 0, 7, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 9, 0, 7, 0, 0, 0, 0, 0, 0, 0, 9, 9, 0, 0, 7, 0, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 7, 0, 7, 0, 0, 7, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 4, 7, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 7, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 4, 0, 0, 7, 0, 7, 0, 0, 7, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 4, 0, 7, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 4, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 7, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 4, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 4, 0, 0, 7, 0, 0, 7, 7, 4, 4, 0, 4, 0, 4, 0, 4, 5, 4, 7, 4, 4, 4, 0, 0, 4, 4, 4, 4, 0, 4, 7, 0, 0, 4, 4, 0, 4, 7, 0, 0, 4, 4, 4, 0, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 7, 4, 4, 7, 4, 0, 7, 0, 4, 4, 0, 4, 4, 0, 4, 7, 0, 4, 4, 0, 4, 4, 7, 0, 4, 0, 4, 0, 4, 4, 4, 4, 4, 4, 0, 0, 4, 4, 0, 0, 7, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 9, 0, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 7, 0, 4, 0, 4, 0, 0, 0, 0, 7, 4, 4, 0, 9, 0, 9, 0, 0, 4, 4, 4, 0, 0, 0, 0, 0, 4, 0, 0, 0]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.788937  0.869984  0.827481       623\n",
      "         Work   0.000000  0.000000  0.000000        25\n",
      "Take_medicine   0.000000  0.000000  0.000000        20\n",
      "        Sleep   0.000000  0.000000  0.000000        32\n",
      "        Relax   0.719101  0.450704  0.554113       142\n",
      "   Leave_Home   0.858974  0.930556  0.893333        72\n",
      "          Eat   0.000000  0.000000  0.000000         8\n",
      "         Cook   0.657258  0.885870  0.754630       184\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        30\n",
      "      Bathing   0.780488  0.905660  0.838428       212\n",
      "\n",
      "     accuracy                       0.762611      1348\n",
      "    macro avg   0.380476  0.404277  0.386798      1348\n",
      " weighted avg   0.698713  0.762611  0.723385      1348\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  29   0   0   1   0   0]\n",
      " [  0   0   0   0   1   1   0  18   5   0]\n",
      " [  0   0   0   0   0   4   0   4   0   0]\n",
      " [  0   0   0   0   0  14   5   1   0   0]\n",
      " [  0   0   0   0 192   3   0  16   1   0]\n",
      " [  0   0   0   0   0 163   0  20   1   0]\n",
      " [  0   0   0   0   0   2  67   2   1   0]\n",
      " [  0   0   0   0  16  43   5 542  17   0]\n",
      " [  0   0   0   0   2  18   1  57  64   0]\n",
      " [  0   0   0   0   6   0   0  26   0   0]]\n",
      "--------------------   final   --------------------\n",
      "no_activities: 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1348/1348 [==============================] - 1s 1ms/step\n",
      "1-milan:\tacc: 76.26%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 0, 0, 0, 0, 9, 0, 0, 0, 0, 4, 0, 0, 0, 4, 0, 0, 0, 4, 0, 4, 4, 0, 0, 0, 7, 7, 7, 0, 0, 0, 0, 7, 7, 7, 7, 7, 5, 7, 7, 5, 9, 9, 9, 9, 0, 9, 9, 9, 4, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 7, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 7, 7, 7, 7, 0, 7, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 0, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 0, 0, 0, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 0, 5, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 0, 0, 0, 9, 9, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7, 7, 7, 5, 7, 0, 5, 7, 7, 5, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 0, 7, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 9, 0, 7, 0, 0, 0, 0, 0, 0, 0, 9, 9, 0, 0, 7, 0, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 7, 0, 7, 0, 0, 7, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 4, 7, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 7, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 4, 0, 0, 7, 0, 7, 0, 0, 7, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 4, 0, 7, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 4, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 7, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 4, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 4, 0, 0, 7, 0, 0, 7, 7, 4, 4, 0, 4, 0, 4, 0, 4, 5, 4, 7, 4, 4, 4, 0, 0, 4, 4, 4, 4, 0, 4, 7, 0, 0, 4, 4, 0, 4, 7, 0, 0, 4, 4, 4, 0, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 7, 4, 4, 7, 4, 0, 7, 0, 4, 4, 0, 4, 4, 0, 4, 7, 0, 4, 4, 0, 4, 4, 7, 0, 4, 0, 4, 0, 4, 4, 4, 4, 4, 4, 0, 0, 4, 4, 0, 0, 7, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 9, 0, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 7, 0, 4, 0, 4, 0, 0, 0, 0, 7, 4, 4, 0, 9, 0, 9, 0, 0, 4, 4, 4, 0, 0, 0, 0, 0, 4, 0, 0, 0]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.788937  0.869984  0.827481       623\n",
      "         Work   0.000000  0.000000  0.000000        25\n",
      "Take_medicine   0.000000  0.000000  0.000000        20\n",
      "        Sleep   0.000000  0.000000  0.000000        32\n",
      "        Relax   0.719101  0.450704  0.554113       142\n",
      "   Leave_Home   0.858974  0.930556  0.893333        72\n",
      "          Eat   0.000000  0.000000  0.000000         8\n",
      "         Cook   0.657258  0.885870  0.754630       184\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        30\n",
      "      Bathing   0.780488  0.905660  0.838428       212\n",
      "\n",
      "     accuracy                       0.762611      1348\n",
      "    macro avg   0.380476  0.404277  0.386798      1348\n",
      " weighted avg   0.698713  0.762611  0.723385      1348\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  29   0   0   1   0   0]\n",
      " [  0   0   0   0   1   1   0  18   5   0]\n",
      " [  0   0   0   0   0   4   0   4   0   0]\n",
      " [  0   0   0   0   0  14   5   1   0   0]\n",
      " [  0   0   0   0 192   3   0  16   1   0]\n",
      " [  0   0   0   0   0 163   0  20   1   0]\n",
      " [  0   0   0   0   0   2  67   2   1   0]\n",
      " [  0   0   0   0  16  43   5 542  17   0]\n",
      " [  0   0   0   0   2  18   1  57  64   0]\n",
      " [  0   0   0   0   6   0   0  26   0   0]]\n",
      "no_activities: 10\n",
      "\n",
      "Begin training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 1.6317 - acc: 0.4974 - val_loss: 1.2153 - val_acc: 0.6250\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.2763 - acc: 0.5930 - val_loss: 1.0470 - val_acc: 0.6585\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.1719 - acc: 0.6153 - val_loss: 0.9696 - val_acc: 0.7113\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1103 - acc: 0.6384 - val_loss: 0.9364 - val_acc: 0.7068\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0617 - acc: 0.6492 - val_loss: 0.9063 - val_acc: 0.7121\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 1.0394 - acc: 0.6466 - val_loss: 0.8762 - val_acc: 0.7284\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 1.0110 - acc: 0.6667 - val_loss: 0.8624 - val_acc: 0.7232\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9862 - acc: 0.6693 - val_loss: 0.8468 - val_acc: 0.7173\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9579 - acc: 0.6845 - val_loss: 0.8324 - val_acc: 0.7188\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9594 - acc: 0.6815 - val_loss: 0.8259 - val_acc: 0.7232\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.9505 - acc: 0.6916 - val_loss: 0.8118 - val_acc: 0.7321\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9360 - acc: 0.6957 - val_loss: 0.8072 - val_acc: 0.7351\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9278 - acc: 0.6886 - val_loss: 0.7973 - val_acc: 0.7329\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9205 - acc: 0.6920 - val_loss: 0.7857 - val_acc: 0.7388\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9058 - acc: 0.6927 - val_loss: 0.7818 - val_acc: 0.7381\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9077 - acc: 0.6871 - val_loss: 0.7736 - val_acc: 0.7426\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8821 - acc: 0.6968 - val_loss: 0.7649 - val_acc: 0.7455\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8846 - acc: 0.6931 - val_loss: 0.7603 - val_acc: 0.7440\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8695 - acc: 0.7061 - val_loss: 0.7579 - val_acc: 0.7500\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8651 - acc: 0.6990 - val_loss: 0.7536 - val_acc: 0.7463\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8574 - acc: 0.7128 - val_loss: 0.7485 - val_acc: 0.7440\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8362 - acc: 0.7150 - val_loss: 0.7412 - val_acc: 0.7403\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8338 - acc: 0.7128 - val_loss: 0.7417 - val_acc: 0.7448\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8465 - acc: 0.7076 - val_loss: 0.7361 - val_acc: 0.7470\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8369 - acc: 0.7232 - val_loss: 0.7340 - val_acc: 0.7463\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8334 - acc: 0.7165 - val_loss: 0.7270 - val_acc: 0.7463\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8222 - acc: 0.7195 - val_loss: 0.7221 - val_acc: 0.7485\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8222 - acc: 0.7206 - val_loss: 0.7191 - val_acc: 0.7493\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8212 - acc: 0.7161 - val_loss: 0.7204 - val_acc: 0.7485\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8105 - acc: 0.7188 - val_loss: 0.7183 - val_acc: 0.7478\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.8159 - acc: 0.7258 - val_loss: 0.7145 - val_acc: 0.7493\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.8022 - acc: 0.7355 - val_loss: 0.7089 - val_acc: 0.7552\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8209 - acc: 0.7195 - val_loss: 0.7062 - val_acc: 0.7522\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7908 - acc: 0.7269 - val_loss: 0.7084 - val_acc: 0.7567\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8077 - acc: 0.7195 - val_loss: 0.7074 - val_acc: 0.7545\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8002 - acc: 0.7307 - val_loss: 0.7052 - val_acc: 0.7604\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7920 - acc: 0.7292 - val_loss: 0.7027 - val_acc: 0.7589\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7922 - acc: 0.7292 - val_loss: 0.7000 - val_acc: 0.7604\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7849 - acc: 0.7295 - val_loss: 0.7002 - val_acc: 0.7582\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7696 - acc: 0.7411 - val_loss: 0.6995 - val_acc: 0.7574\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8028 - acc: 0.7281 - val_loss: 0.6954 - val_acc: 0.7619\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7694 - acc: 0.7377 - val_loss: 0.6941 - val_acc: 0.7619\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7731 - acc: 0.7374 - val_loss: 0.6903 - val_acc: 0.7641\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7827 - acc: 0.7281 - val_loss: 0.6913 - val_acc: 0.7664\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7684 - acc: 0.7347 - val_loss: 0.6903 - val_acc: 0.7664\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7693 - acc: 0.7400 - val_loss: 0.6902 - val_acc: 0.7634\n",
      "Epoch 47/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7697 - acc: 0.7288 - val_loss: 0.6897 - val_acc: 0.7604\n",
      "Epoch 48/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7571 - acc: 0.7437 - val_loss: 0.6839 - val_acc: 0.7671\n",
      "Epoch 49/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7567 - acc: 0.7411 - val_loss: 0.6880 - val_acc: 0.7612\n",
      "Epoch 50/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7644 - acc: 0.7362 - val_loss: 0.6860 - val_acc: 0.7589\n",
      "Epoch 51/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7537 - acc: 0.7351 - val_loss: 0.6858 - val_acc: 0.7552\n",
      "Epoch 52/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7612 - acc: 0.7422 - val_loss: 0.6871 - val_acc: 0.7604\n",
      "Epoch 53/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7778 - acc: 0.7347 - val_loss: 0.6858 - val_acc: 0.7641\n",
      "Epoch 54/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7575 - acc: 0.7392 - val_loss: 0.6811 - val_acc: 0.7634\n",
      "Epoch 55/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7605 - acc: 0.7314 - val_loss: 0.6822 - val_acc: 0.7626\n",
      "Epoch 56/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7630 - acc: 0.7474 - val_loss: 0.6799 - val_acc: 0.7671\n",
      "Epoch 57/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7601 - acc: 0.7347 - val_loss: 0.6786 - val_acc: 0.7679\n",
      "Epoch 58/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7561 - acc: 0.7392 - val_loss: 0.6756 - val_acc: 0.7656\n",
      "Epoch 59/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7513 - acc: 0.7426 - val_loss: 0.6783 - val_acc: 0.7649\n",
      "Epoch 60/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7412 - acc: 0.7362 - val_loss: 0.6781 - val_acc: 0.7656\n",
      "Epoch 61/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7476 - acc: 0.7429 - val_loss: 0.6781 - val_acc: 0.7664\n",
      "Epoch 62/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7370 - acc: 0.7414 - val_loss: 0.6721 - val_acc: 0.7671\n",
      "Epoch 63/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7239 - acc: 0.7541 - val_loss: 0.6709 - val_acc: 0.7679\n",
      "Epoch 64/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7559 - acc: 0.7336 - val_loss: 0.6766 - val_acc: 0.7701\n",
      "Epoch 65/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7553 - acc: 0.7426 - val_loss: 0.6735 - val_acc: 0.7679\n",
      "\n",
      "Epoch 00065: loss improved from inf to 0.75534, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-2-000065-0.755338-0.767857.hdf5\n",
      "Epoch 66/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7393 - acc: 0.7448 - val_loss: 0.6742 - val_acc: 0.7701\n",
      "Epoch 67/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7479 - acc: 0.7426 - val_loss: 0.6726 - val_acc: 0.7701\n",
      "Epoch 68/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7505 - acc: 0.7411 - val_loss: 0.6720 - val_acc: 0.7768\n",
      "Epoch 69/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7370 - acc: 0.7496 - val_loss: 0.6717 - val_acc: 0.7738\n",
      "\n",
      "Epoch 00069: loss improved from 0.75534 to 0.73704, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-2-000069-0.737038-0.773810.hdf5\n",
      "Epoch 70/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7513 - acc: 0.7452 - val_loss: 0.6687 - val_acc: 0.7738\n",
      "Epoch 71/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.7458 - acc: 0.7493 - val_loss: 0.6690 - val_acc: 0.7723\n",
      "Epoch 72/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7314 - acc: 0.7500 - val_loss: 0.6675 - val_acc: 0.7708\n",
      "Epoch 73/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7382 - acc: 0.7429 - val_loss: 0.6689 - val_acc: 0.7723\n",
      "Epoch 74/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7403 - acc: 0.7336 - val_loss: 0.6666 - val_acc: 0.7723\n",
      "Epoch 75/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7311 - acc: 0.7496 - val_loss: 0.6661 - val_acc: 0.7738\n",
      "Epoch 76/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7246 - acc: 0.7500 - val_loss: 0.6687 - val_acc: 0.7738\n",
      "Epoch 77/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7383 - acc: 0.7467 - val_loss: 0.6681 - val_acc: 0.7731\n",
      "Epoch 78/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7190 - acc: 0.7522 - val_loss: 0.6664 - val_acc: 0.7723\n",
      "Epoch 79/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7315 - acc: 0.7481 - val_loss: 0.6660 - val_acc: 0.7723\n",
      "Epoch 80/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7315 - acc: 0.7433 - val_loss: 0.6636 - val_acc: 0.7738\n",
      "Epoch 81/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7317 - acc: 0.7411 - val_loss: 0.6620 - val_acc: 0.7731\n",
      "\n",
      "Epoch 00081: loss improved from 0.73704 to 0.73173, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-2-000081-0.731728-0.773065.hdf5\n",
      "Epoch 82/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7216 - acc: 0.7522 - val_loss: 0.6617 - val_acc: 0.7768\n",
      "Epoch 83/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7313 - acc: 0.7400 - val_loss: 0.6623 - val_acc: 0.7746\n",
      "Epoch 84/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7279 - acc: 0.7481 - val_loss: 0.6623 - val_acc: 0.7790\n",
      "Epoch 85/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7173 - acc: 0.7552 - val_loss: 0.6594 - val_acc: 0.7731\n",
      "\n",
      "Epoch 00085: loss improved from 0.73173 to 0.71729, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-2-000085-0.717289-0.773065.hdf5\n",
      "Epoch 86/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7375 - acc: 0.7444 - val_loss: 0.6606 - val_acc: 0.7746\n",
      "Epoch 87/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7224 - acc: 0.7522 - val_loss: 0.6593 - val_acc: 0.7731\n",
      "Epoch 88/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7135 - acc: 0.7522 - val_loss: 0.6602 - val_acc: 0.7746\n",
      "Epoch 89/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7118 - acc: 0.7511 - val_loss: 0.6547 - val_acc: 0.7775\n",
      "\n",
      "Epoch 00089: loss improved from 0.71729 to 0.71183, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-2-000089-0.711826-0.777530.hdf5\n",
      "Epoch 90/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7146 - acc: 0.7481 - val_loss: 0.6587 - val_acc: 0.7775\n",
      "Epoch 91/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7223 - acc: 0.7478 - val_loss: 0.6548 - val_acc: 0.7768\n",
      "Epoch 92/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7013 - acc: 0.7533 - val_loss: 0.6551 - val_acc: 0.7760\n",
      "Epoch 93/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7213 - acc: 0.7418 - val_loss: 0.6535 - val_acc: 0.7753\n",
      "Epoch 94/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7158 - acc: 0.7422 - val_loss: 0.6540 - val_acc: 0.7746\n",
      "Epoch 95/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7356 - acc: 0.7426 - val_loss: 0.6567 - val_acc: 0.7738\n",
      "Epoch 96/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6975 - acc: 0.7504 - val_loss: 0.6553 - val_acc: 0.7746\n",
      "Epoch 97/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7246 - acc: 0.7526 - val_loss: 0.6569 - val_acc: 0.7716\n",
      "Epoch 98/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7368 - acc: 0.7385 - val_loss: 0.6568 - val_acc: 0.7753\n",
      "Epoch 99/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7135 - acc: 0.7507 - val_loss: 0.6545 - val_acc: 0.7768\n",
      "Epoch 100/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7042 - acc: 0.7560 - val_loss: 0.6537 - val_acc: 0.7775\n",
      "\n",
      "Epoch 00100: saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/2-000100-0.704229-0.777530.hdf5\n",
      "Epoch 101/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7043 - acc: 0.7533 - val_loss: 0.6517 - val_acc: 0.7768\n",
      "Epoch 102/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7170 - acc: 0.7537 - val_loss: 0.6535 - val_acc: 0.7760\n",
      "Epoch 103/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7211 - acc: 0.7474 - val_loss: 0.6521 - val_acc: 0.7746\n",
      "Epoch 104/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6996 - acc: 0.7574 - val_loss: 0.6520 - val_acc: 0.7768\n",
      "Epoch 105/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7097 - acc: 0.7474 - val_loss: 0.6515 - val_acc: 0.7783\n",
      "Epoch 106/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7167 - acc: 0.7537 - val_loss: 0.6514 - val_acc: 0.7731\n",
      "Epoch 107/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7243 - acc: 0.7463 - val_loss: 0.6505 - val_acc: 0.7768\n",
      "Epoch 108/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7067 - acc: 0.7519 - val_loss: 0.6503 - val_acc: 0.7760\n",
      "Epoch 109/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7052 - acc: 0.7474 - val_loss: 0.6470 - val_acc: 0.7775\n",
      "Epoch 110/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7092 - acc: 0.7541 - val_loss: 0.6505 - val_acc: 0.7783\n",
      "Epoch 111/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7093 - acc: 0.7504 - val_loss: 0.6466 - val_acc: 0.7768\n",
      "Epoch 112/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7176 - acc: 0.7489 - val_loss: 0.6501 - val_acc: 0.7753\n",
      "Epoch 113/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6984 - acc: 0.7545 - val_loss: 0.6501 - val_acc: 0.7768\n",
      "Epoch 114/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7103 - acc: 0.7392 - val_loss: 0.6487 - val_acc: 0.7783\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6884 - acc: 0.7533 - val_loss: 0.6471 - val_acc: 0.7812\n",
      "Epoch 116/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7006 - acc: 0.7593 - val_loss: 0.6468 - val_acc: 0.7805\n",
      "Epoch 117/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7184 - acc: 0.7433 - val_loss: 0.6445 - val_acc: 0.7812\n",
      "Epoch 118/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7166 - acc: 0.7511 - val_loss: 0.6480 - val_acc: 0.7775\n",
      "Epoch 119/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7012 - acc: 0.7511 - val_loss: 0.6474 - val_acc: 0.7760\n",
      "Epoch 120/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7186 - acc: 0.7411 - val_loss: 0.6468 - val_acc: 0.7768\n",
      "Epoch 121/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7005 - acc: 0.7448 - val_loss: 0.6447 - val_acc: 0.7768\n",
      "Epoch 122/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6999 - acc: 0.7440 - val_loss: 0.6467 - val_acc: 0.7753\n",
      "Epoch 123/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7156 - acc: 0.7455 - val_loss: 0.6464 - val_acc: 0.7768\n",
      "Epoch 124/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6937 - acc: 0.7545 - val_loss: 0.6449 - val_acc: 0.7798\n",
      "Epoch 125/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6926 - acc: 0.7541 - val_loss: 0.6438 - val_acc: 0.7775\n",
      "Epoch 126/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6998 - acc: 0.7422 - val_loss: 0.6442 - val_acc: 0.7805\n",
      "Epoch 127/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6770 - acc: 0.7645 - val_loss: 0.6455 - val_acc: 0.7775\n",
      "Epoch 128/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7033 - acc: 0.7552 - val_loss: 0.6429 - val_acc: 0.7805\n",
      "Epoch 129/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6859 - acc: 0.7537 - val_loss: 0.6423 - val_acc: 0.7805\n",
      "Epoch 130/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7127 - acc: 0.7433 - val_loss: 0.6434 - val_acc: 0.7820\n",
      "Epoch 131/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6972 - acc: 0.7533 - val_loss: 0.6437 - val_acc: 0.7790\n",
      "Epoch 132/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6987 - acc: 0.7533 - val_loss: 0.6399 - val_acc: 0.7798\n",
      "Epoch 133/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6935 - acc: 0.7496 - val_loss: 0.6438 - val_acc: 0.7783\n",
      "Epoch 134/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6774 - acc: 0.7623 - val_loss: 0.6424 - val_acc: 0.7775\n",
      "Epoch 135/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.6910 - acc: 0.7530 - val_loss: 0.6407 - val_acc: 0.7820\n",
      "Epoch 136/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6881 - acc: 0.7597 - val_loss: 0.6393 - val_acc: 0.7798\n",
      "Epoch 137/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7005 - acc: 0.7589 - val_loss: 0.6414 - val_acc: 0.7805\n",
      "Epoch 138/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6908 - acc: 0.7429 - val_loss: 0.6406 - val_acc: 0.7790\n",
      "Epoch 139/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.6965 - acc: 0.7582 - val_loss: 0.6343 - val_acc: 0.7783\n",
      "Epoch 140/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.6929 - acc: 0.7552 - val_loss: 0.6419 - val_acc: 0.7805\n",
      "Epoch 141/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6960 - acc: 0.7489 - val_loss: 0.6442 - val_acc: 0.7798\n",
      "Epoch 142/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6997 - acc: 0.7530 - val_loss: 0.6442 - val_acc: 0.7805\n",
      "Epoch 143/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.7047 - acc: 0.7403 - val_loss: 0.6419 - val_acc: 0.7827\n",
      "Epoch 144/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6967 - acc: 0.7515 - val_loss: 0.6409 - val_acc: 0.7805\n",
      "Epoch 145/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6790 - acc: 0.7574 - val_loss: 0.6407 - val_acc: 0.7827\n",
      "Epoch 146/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6944 - acc: 0.7522 - val_loss: 0.6402 - val_acc: 0.7820\n",
      "Epoch 147/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6922 - acc: 0.7515 - val_loss: 0.6394 - val_acc: 0.7805\n",
      "\n",
      "Epoch 00147: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 148/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6813 - acc: 0.7507 - val_loss: 0.6398 - val_acc: 0.7798\n",
      "Epoch 149/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6948 - acc: 0.7560 - val_loss: 0.6368 - val_acc: 0.7805\n",
      "Epoch 150/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6916 - acc: 0.7489 - val_loss: 0.6400 - val_acc: 0.7783\n",
      "Epoch 151/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6957 - acc: 0.7552 - val_loss: 0.6402 - val_acc: 0.7798\n",
      "Epoch 152/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6689 - acc: 0.7686 - val_loss: 0.6387 - val_acc: 0.7805\n",
      "Epoch 153/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7038 - acc: 0.7556 - val_loss: 0.6403 - val_acc: 0.7783\n",
      "Epoch 154/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6869 - acc: 0.7589 - val_loss: 0.6406 - val_acc: 0.7798\n",
      "Epoch 155/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6872 - acc: 0.7574 - val_loss: 0.6391 - val_acc: 0.7798\n",
      "Epoch 156/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6914 - acc: 0.7541 - val_loss: 0.6386 - val_acc: 0.7798\n",
      "Epoch 157/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6930 - acc: 0.7608 - val_loss: 0.6412 - val_acc: 0.7790\n",
      "Epoch 158/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6875 - acc: 0.7548 - val_loss: 0.6404 - val_acc: 0.7805\n",
      "Epoch 159/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7042 - acc: 0.7519 - val_loss: 0.6417 - val_acc: 0.7805\n",
      "Epoch 160/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6788 - acc: 0.7582 - val_loss: 0.6414 - val_acc: 0.7768\n",
      "Epoch 161/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6939 - acc: 0.7519 - val_loss: 0.6385 - val_acc: 0.7783\n",
      "Epoch 162/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6889 - acc: 0.7530 - val_loss: 0.6393 - val_acc: 0.7775\n",
      "Epoch 163/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6908 - acc: 0.7597 - val_loss: 0.6414 - val_acc: 0.7768\n",
      "Epoch 164/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6987 - acc: 0.7470 - val_loss: 0.6385 - val_acc: 0.7805\n",
      "Epoch 165/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6891 - acc: 0.7470 - val_loss: 0.6405 - val_acc: 0.7783\n",
      "\n",
      "Epoch 00165: loss improved from inf to 0.68914, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-2-000165-0.689141-0.778274.hdf5\n",
      "Epoch 166/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6779 - acc: 0.7582 - val_loss: 0.6393 - val_acc: 0.7805\n",
      "Epoch 167/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7047 - acc: 0.7504 - val_loss: 0.6396 - val_acc: 0.7798\n",
      "Epoch 168/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6841 - acc: 0.7556 - val_loss: 0.6361 - val_acc: 0.7812\n",
      "Epoch 169/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6805 - acc: 0.7504 - val_loss: 0.6394 - val_acc: 0.7798\n",
      "\n",
      "Epoch 00169: loss improved from 0.68914 to 0.68050, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-2-000169-0.680495-0.779762.hdf5\n",
      "Epoch 170/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6935 - acc: 0.7500 - val_loss: 0.6402 - val_acc: 0.7798\n",
      "Epoch 171/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6829 - acc: 0.7560 - val_loss: 0.6405 - val_acc: 0.7783\n",
      "Epoch 172/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6941 - acc: 0.7533 - val_loss: 0.6408 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 173/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6800 - acc: 0.7619 - val_loss: 0.6403 - val_acc: 0.7798\n",
      "\n",
      "Epoch 00173: loss improved from 0.68050 to 0.67999, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-2-000173-0.679994-0.779762.hdf5\n",
      "Epoch 174/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6721 - acc: 0.7593 - val_loss: 0.6408 - val_acc: 0.7790\n",
      "Epoch 175/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6870 - acc: 0.7615 - val_loss: 0.6398 - val_acc: 0.7798\n",
      "Epoch 176/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6803 - acc: 0.7586 - val_loss: 0.6384 - val_acc: 0.7798\n",
      "Epoch 177/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7037 - acc: 0.7515 - val_loss: 0.6395 - val_acc: 0.7798\n",
      "Epoch 178/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6810 - acc: 0.7552 - val_loss: 0.6401 - val_acc: 0.7798\n",
      "Epoch 179/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6954 - acc: 0.7489 - val_loss: 0.6399 - val_acc: 0.7805\n",
      "Epoch 180/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6733 - acc: 0.7608 - val_loss: 0.6382 - val_acc: 0.7798\n",
      "Epoch 181/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6842 - acc: 0.7526 - val_loss: 0.6385 - val_acc: 0.7805\n",
      "Epoch 182/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6737 - acc: 0.7541 - val_loss: 0.6400 - val_acc: 0.7798\n",
      "Epoch 183/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6943 - acc: 0.7511 - val_loss: 0.6408 - val_acc: 0.7790\n",
      "Epoch 184/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6847 - acc: 0.7545 - val_loss: 0.6398 - val_acc: 0.7790\n",
      "Epoch 185/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6984 - acc: 0.7444 - val_loss: 0.6390 - val_acc: 0.7805\n",
      "Epoch 186/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6729 - acc: 0.7653 - val_loss: 0.6401 - val_acc: 0.7798\n",
      "Epoch 187/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6936 - acc: 0.7493 - val_loss: 0.6383 - val_acc: 0.7798\n",
      "Epoch 188/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6810 - acc: 0.7600 - val_loss: 0.6394 - val_acc: 0.7790\n",
      "Epoch 189/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7013 - acc: 0.7474 - val_loss: 0.6404 - val_acc: 0.7790\n",
      "Epoch 190/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6931 - acc: 0.7556 - val_loss: 0.6391 - val_acc: 0.7798\n",
      "Epoch 191/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6874 - acc: 0.7574 - val_loss: 0.6408 - val_acc: 0.7783\n",
      "Epoch 192/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6690 - acc: 0.7619 - val_loss: 0.6391 - val_acc: 0.7798\n",
      "\n",
      "Epoch 00192: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 193/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6831 - acc: 0.7604 - val_loss: 0.6401 - val_acc: 0.7790\n",
      "Epoch 194/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6861 - acc: 0.7500 - val_loss: 0.6399 - val_acc: 0.7798\n",
      "Epoch 195/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6877 - acc: 0.7537 - val_loss: 0.6387 - val_acc: 0.7805\n",
      "Epoch 196/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6794 - acc: 0.7600 - val_loss: 0.6394 - val_acc: 0.7798\n",
      "Epoch 197/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6801 - acc: 0.7545 - val_loss: 0.6406 - val_acc: 0.7790\n",
      "Epoch 198/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6760 - acc: 0.7541 - val_loss: 0.6364 - val_acc: 0.7805\n",
      "Epoch 199/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6799 - acc: 0.7504 - val_loss: 0.6406 - val_acc: 0.7790\n",
      "Epoch 200/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6772 - acc: 0.7556 - val_loss: 0.6405 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00200: saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/2-000200-0.677164-0.779018.hdf5\n",
      "Epoch 201/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6765 - acc: 0.7604 - val_loss: 0.6395 - val_acc: 0.7798\n",
      "Epoch 202/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6783 - acc: 0.7574 - val_loss: 0.6401 - val_acc: 0.7798\n",
      "Epoch 203/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6907 - acc: 0.7563 - val_loss: 0.6393 - val_acc: 0.7798\n",
      "Epoch 204/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6780 - acc: 0.7600 - val_loss: 0.6406 - val_acc: 0.7790\n",
      "Epoch 205/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6732 - acc: 0.7682 - val_loss: 0.6390 - val_acc: 0.7798\n",
      "Epoch 206/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6925 - acc: 0.7504 - val_loss: 0.6396 - val_acc: 0.7790\n",
      "Epoch 207/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6775 - acc: 0.7589 - val_loss: 0.6401 - val_acc: 0.7790\n",
      "Epoch 208/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7016 - acc: 0.7500 - val_loss: 0.6389 - val_acc: 0.7790\n",
      "Epoch 209/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6950 - acc: 0.7444 - val_loss: 0.6400 - val_acc: 0.7790\n",
      "Epoch 210/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6908 - acc: 0.7530 - val_loss: 0.6409 - val_acc: 0.7783\n",
      "Epoch 211/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6786 - acc: 0.7593 - val_loss: 0.6405 - val_acc: 0.7783\n",
      "Epoch 212/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7034 - acc: 0.7493 - val_loss: 0.6407 - val_acc: 0.7783\n",
      "Epoch 213/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6857 - acc: 0.7500 - val_loss: 0.6408 - val_acc: 0.7783\n",
      "Epoch 214/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6981 - acc: 0.7403 - val_loss: 0.6382 - val_acc: 0.7798\n",
      "Epoch 215/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6808 - acc: 0.7545 - val_loss: 0.6390 - val_acc: 0.7790\n",
      "Epoch 216/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6861 - acc: 0.7533 - val_loss: 0.6377 - val_acc: 0.7805\n",
      "Epoch 217/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6821 - acc: 0.7682 - val_loss: 0.6380 - val_acc: 0.7805\n",
      "Epoch 218/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6890 - acc: 0.7597 - val_loss: 0.6400 - val_acc: 0.7790\n",
      "Epoch 219/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6849 - acc: 0.7589 - val_loss: 0.6387 - val_acc: 0.7798\n",
      "Epoch 220/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6866 - acc: 0.7586 - val_loss: 0.6356 - val_acc: 0.7805\n",
      "Epoch 221/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7007 - acc: 0.7574 - val_loss: 0.6398 - val_acc: 0.7798\n",
      "Epoch 222/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6757 - acc: 0.7623 - val_loss: 0.6391 - val_acc: 0.7805\n",
      "Epoch 223/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6805 - acc: 0.7530 - val_loss: 0.6383 - val_acc: 0.7805\n",
      "Epoch 224/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6808 - acc: 0.7541 - val_loss: 0.6381 - val_acc: 0.7805\n",
      "Epoch 225/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6845 - acc: 0.7485 - val_loss: 0.6405 - val_acc: 0.7798\n",
      "Epoch 226/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6957 - acc: 0.7500 - val_loss: 0.6397 - val_acc: 0.7798\n",
      "Epoch 227/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6864 - acc: 0.7478 - val_loss: 0.6410 - val_acc: 0.7790\n",
      "Epoch 228/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6817 - acc: 0.7537 - val_loss: 0.6391 - val_acc: 0.7805\n",
      "Epoch 229/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6858 - acc: 0.7560 - val_loss: 0.6399 - val_acc: 0.7798\n",
      "Epoch 230/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6835 - acc: 0.7567 - val_loss: 0.6384 - val_acc: 0.7805\n",
      "Epoch 231/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6867 - acc: 0.7563 - val_loss: 0.6391 - val_acc: 0.7798\n",
      "Epoch 232/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6928 - acc: 0.7515 - val_loss: 0.6386 - val_acc: 0.7798\n",
      "Epoch 233/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6877 - acc: 0.7526 - val_loss: 0.6407 - val_acc: 0.7790\n",
      "Epoch 234/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6800 - acc: 0.7567 - val_loss: 0.6353 - val_acc: 0.7805\n",
      "Epoch 235/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6936 - acc: 0.7522 - val_loss: 0.6386 - val_acc: 0.7805\n",
      "Epoch 236/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6766 - acc: 0.7574 - val_loss: 0.6380 - val_acc: 0.7805\n",
      "Epoch 237/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6838 - acc: 0.7582 - val_loss: 0.6397 - val_acc: 0.7798\n",
      "Epoch 238/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6825 - acc: 0.7593 - val_loss: 0.6399 - val_acc: 0.7798\n",
      "Epoch 239/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6862 - acc: 0.7459 - val_loss: 0.6396 - val_acc: 0.7798\n",
      "Epoch 240/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6883 - acc: 0.7519 - val_loss: 0.6405 - val_acc: 0.7790\n",
      "Epoch 241/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6849 - acc: 0.7496 - val_loss: 0.6392 - val_acc: 0.7798\n",
      "Epoch 242/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6922 - acc: 0.7478 - val_loss: 0.6393 - val_acc: 0.7798\n",
      "Epoch 243/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6941 - acc: 0.7504 - val_loss: 0.6386 - val_acc: 0.7798\n",
      "Epoch 244/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6841 - acc: 0.7526 - val_loss: 0.6390 - val_acc: 0.7798\n",
      "Epoch 245/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.6974 - acc: 0.7533 - val_loss: 0.6381 - val_acc: 0.7798\n",
      "Epoch 246/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6961 - acc: 0.7515 - val_loss: 0.6404 - val_acc: 0.7790\n",
      "Epoch 247/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6850 - acc: 0.7619 - val_loss: 0.6400 - val_acc: 0.7790\n",
      "Epoch 248/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6926 - acc: 0.7496 - val_loss: 0.6408 - val_acc: 0.7790\n",
      "Epoch 249/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6760 - acc: 0.7608 - val_loss: 0.6404 - val_acc: 0.7790\n",
      "Epoch 250/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6822 - acc: 0.7600 - val_loss: 0.6411 - val_acc: 0.7790\n",
      "Epoch 251/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6731 - acc: 0.7630 - val_loss: 0.6410 - val_acc: 0.7790\n",
      "Epoch 252/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6800 - acc: 0.7586 - val_loss: 0.6398 - val_acc: 0.7798\n",
      "Epoch 253/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6746 - acc: 0.7567 - val_loss: 0.6410 - val_acc: 0.7790\n",
      "Epoch 254/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6687 - acc: 0.7586 - val_loss: 0.6396 - val_acc: 0.7798\n",
      "Epoch 255/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6735 - acc: 0.7634 - val_loss: 0.6407 - val_acc: 0.7790\n",
      "Epoch 256/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6814 - acc: 0.7593 - val_loss: 0.6388 - val_acc: 0.7805\n",
      "Epoch 257/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6740 - acc: 0.7567 - val_loss: 0.6403 - val_acc: 0.7790\n",
      "Epoch 258/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7016 - acc: 0.7407 - val_loss: 0.6381 - val_acc: 0.7805\n",
      "Epoch 259/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6918 - acc: 0.7522 - val_loss: 0.6339 - val_acc: 0.7805\n",
      "Epoch 260/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6875 - acc: 0.7593 - val_loss: 0.6397 - val_acc: 0.7790\n",
      "Epoch 261/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6822 - acc: 0.7556 - val_loss: 0.6402 - val_acc: 0.7798\n",
      "Epoch 262/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6800 - acc: 0.7649 - val_loss: 0.6408 - val_acc: 0.7783\n",
      "Epoch 263/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6821 - acc: 0.7571 - val_loss: 0.6401 - val_acc: 0.7790\n",
      "Epoch 264/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6784 - acc: 0.7597 - val_loss: 0.6407 - val_acc: 0.7790\n",
      "Epoch 265/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6951 - acc: 0.7504 - val_loss: 0.6382 - val_acc: 0.7805\n",
      "\n",
      "Epoch 00265: loss improved from inf to 0.69510, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-2-000265-0.695097-0.780506.hdf5\n",
      "Epoch 266/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6860 - acc: 0.7567 - val_loss: 0.6364 - val_acc: 0.7805\n",
      "Epoch 267/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6836 - acc: 0.7574 - val_loss: 0.6403 - val_acc: 0.7798\n",
      "Epoch 268/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6957 - acc: 0.7474 - val_loss: 0.6400 - val_acc: 0.7798\n",
      "Epoch 269/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6868 - acc: 0.7571 - val_loss: 0.6348 - val_acc: 0.7812\n",
      "\n",
      "Epoch 00269: loss improved from 0.69510 to 0.68678, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-2-000269-0.686781-0.781250.hdf5\n",
      "Epoch 270/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6795 - acc: 0.7615 - val_loss: 0.6394 - val_acc: 0.7798\n",
      "Epoch 271/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6964 - acc: 0.7526 - val_loss: 0.6394 - val_acc: 0.7798\n",
      "Epoch 272/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6822 - acc: 0.7563 - val_loss: 0.6404 - val_acc: 0.7790\n",
      "Epoch 273/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6888 - acc: 0.7552 - val_loss: 0.6408 - val_acc: 0.7790\n",
      "Epoch 274/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6839 - acc: 0.7589 - val_loss: 0.6397 - val_acc: 0.7798\n",
      "Epoch 275/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7053 - acc: 0.7507 - val_loss: 0.6381 - val_acc: 0.7798\n",
      "Epoch 276/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6934 - acc: 0.7530 - val_loss: 0.6409 - val_acc: 0.7790\n",
      "Epoch 277/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6991 - acc: 0.7526 - val_loss: 0.6391 - val_acc: 0.7805\n",
      "Epoch 278/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6852 - acc: 0.7444 - val_loss: 0.6402 - val_acc: 0.7790\n",
      "Epoch 279/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6838 - acc: 0.7470 - val_loss: 0.6406 - val_acc: 0.7790\n",
      "Epoch 280/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6965 - acc: 0.7533 - val_loss: 0.6385 - val_acc: 0.7798\n",
      "Epoch 281/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6805 - acc: 0.7556 - val_loss: 0.6406 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00281: loss improved from 0.68678 to 0.68047, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-2-000281-0.680468-0.779018.hdf5\n",
      "Epoch 282/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6785 - acc: 0.7626 - val_loss: 0.6381 - val_acc: 0.7805\n",
      "Epoch 283/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6817 - acc: 0.7630 - val_loss: 0.6408 - val_acc: 0.7790\n",
      "Epoch 284/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6872 - acc: 0.7519 - val_loss: 0.6385 - val_acc: 0.7798\n",
      "Epoch 285/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6895 - acc: 0.7578 - val_loss: 0.6353 - val_acc: 0.7805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6891 - acc: 0.7530 - val_loss: 0.6376 - val_acc: 0.7805\n",
      "Epoch 287/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6868 - acc: 0.7560 - val_loss: 0.6385 - val_acc: 0.7798\n",
      "Epoch 288/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6627 - acc: 0.7638 - val_loss: 0.6398 - val_acc: 0.7790\n",
      "Epoch 289/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6919 - acc: 0.7504 - val_loss: 0.6399 - val_acc: 0.7798\n",
      "Epoch 290/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6835 - acc: 0.7444 - val_loss: 0.6404 - val_acc: 0.7790\n",
      "Epoch 291/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6840 - acc: 0.7571 - val_loss: 0.6395 - val_acc: 0.7798\n",
      "Epoch 292/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6737 - acc: 0.7556 - val_loss: 0.6384 - val_acc: 0.7798\n",
      "Epoch 293/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6854 - acc: 0.7604 - val_loss: 0.6399 - val_acc: 0.7790\n",
      "Epoch 294/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6860 - acc: 0.7493 - val_loss: 0.6391 - val_acc: 0.7790\n",
      "Epoch 295/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6842 - acc: 0.7589 - val_loss: 0.6395 - val_acc: 0.7798\n",
      "Epoch 296/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6834 - acc: 0.7467 - val_loss: 0.6400 - val_acc: 0.7798\n",
      "Epoch 297/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6843 - acc: 0.7522 - val_loss: 0.6403 - val_acc: 0.7798\n",
      "Epoch 298/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.6802 - acc: 0.7556 - val_loss: 0.6384 - val_acc: 0.7798\n",
      "Epoch 299/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6817 - acc: 0.7630 - val_loss: 0.6392 - val_acc: 0.7798\n",
      "Epoch 300/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6851 - acc: 0.7604 - val_loss: 0.6403 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00300: saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/2-000300-0.685060-0.779018.hdf5\n",
      "Epoch 301/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6713 - acc: 0.7638 - val_loss: 0.6393 - val_acc: 0.7805\n",
      "Epoch 302/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6925 - acc: 0.7560 - val_loss: 0.6409 - val_acc: 0.7790\n",
      "Epoch 303/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6913 - acc: 0.7560 - val_loss: 0.6405 - val_acc: 0.7790\n",
      "Epoch 304/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6811 - acc: 0.7612 - val_loss: 0.6393 - val_acc: 0.7798\n",
      "Epoch 305/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6894 - acc: 0.7608 - val_loss: 0.6385 - val_acc: 0.7798\n",
      "Epoch 306/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6942 - acc: 0.7552 - val_loss: 0.6391 - val_acc: 0.7790\n",
      "Epoch 307/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6739 - acc: 0.7552 - val_loss: 0.6385 - val_acc: 0.7805\n",
      "Epoch 308/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6735 - acc: 0.7560 - val_loss: 0.6387 - val_acc: 0.7798\n",
      "Epoch 309/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6966 - acc: 0.7515 - val_loss: 0.6384 - val_acc: 0.7805\n",
      "Epoch 310/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6972 - acc: 0.7560 - val_loss: 0.6402 - val_acc: 0.7790\n",
      "Epoch 311/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6801 - acc: 0.7578 - val_loss: 0.6373 - val_acc: 0.7805\n",
      "Epoch 312/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6785 - acc: 0.7574 - val_loss: 0.6374 - val_acc: 0.7805\n",
      "Epoch 313/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6955 - acc: 0.7522 - val_loss: 0.6407 - val_acc: 0.7790\n",
      "Epoch 314/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7040 - acc: 0.7489 - val_loss: 0.6398 - val_acc: 0.7790\n",
      "Epoch 315/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6751 - acc: 0.7664 - val_loss: 0.6380 - val_acc: 0.7798\n",
      "Epoch 316/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6919 - acc: 0.7493 - val_loss: 0.6407 - val_acc: 0.7790\n",
      "Epoch 317/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6953 - acc: 0.7515 - val_loss: 0.6388 - val_acc: 0.7798\n",
      "Epoch 318/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6769 - acc: 0.7604 - val_loss: 0.6403 - val_acc: 0.7790\n",
      "Epoch 319/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6835 - acc: 0.7541 - val_loss: 0.6381 - val_acc: 0.7805\n",
      "Epoch 320/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6811 - acc: 0.7533 - val_loss: 0.6405 - val_acc: 0.7790\n",
      "Epoch 321/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6866 - acc: 0.7552 - val_loss: 0.6400 - val_acc: 0.7790\n",
      "Epoch 322/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6804 - acc: 0.7526 - val_loss: 0.6398 - val_acc: 0.7798\n",
      "Epoch 323/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6873 - acc: 0.7515 - val_loss: 0.6393 - val_acc: 0.7798\n",
      "Epoch 324/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6963 - acc: 0.7500 - val_loss: 0.6350 - val_acc: 0.7798\n",
      "Epoch 325/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6909 - acc: 0.7504 - val_loss: 0.6405 - val_acc: 0.7790\n",
      "Epoch 326/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6909 - acc: 0.7519 - val_loss: 0.6399 - val_acc: 0.7790\n",
      "Epoch 327/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6769 - acc: 0.7638 - val_loss: 0.6384 - val_acc: 0.7798\n",
      "Epoch 328/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6822 - acc: 0.7548 - val_loss: 0.6386 - val_acc: 0.7805\n",
      "Epoch 329/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6898 - acc: 0.7526 - val_loss: 0.6383 - val_acc: 0.7798\n",
      "Epoch 330/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6915 - acc: 0.7600 - val_loss: 0.6393 - val_acc: 0.7798\n",
      "Epoch 331/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6760 - acc: 0.7582 - val_loss: 0.6384 - val_acc: 0.7798\n",
      "Epoch 332/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6874 - acc: 0.7493 - val_loss: 0.6397 - val_acc: 0.7798\n",
      "Epoch 333/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6986 - acc: 0.7388 - val_loss: 0.6409 - val_acc: 0.7790\n",
      "Epoch 334/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6973 - acc: 0.7578 - val_loss: 0.6389 - val_acc: 0.7805\n",
      "Epoch 335/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6961 - acc: 0.7489 - val_loss: 0.6362 - val_acc: 0.7812\n",
      "Epoch 336/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6741 - acc: 0.7615 - val_loss: 0.6389 - val_acc: 0.7798\n",
      "Epoch 337/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7047 - acc: 0.7500 - val_loss: 0.6378 - val_acc: 0.7805\n",
      "Epoch 338/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6866 - acc: 0.7493 - val_loss: 0.6400 - val_acc: 0.7798\n",
      "Epoch 339/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6952 - acc: 0.7489 - val_loss: 0.6402 - val_acc: 0.7790\n",
      "Epoch 340/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6937 - acc: 0.7560 - val_loss: 0.6398 - val_acc: 0.7798\n",
      "Epoch 341/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6953 - acc: 0.7478 - val_loss: 0.6401 - val_acc: 0.7798\n",
      "Epoch 342/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6986 - acc: 0.7519 - val_loss: 0.6386 - val_acc: 0.7805\n",
      "Epoch 343/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6875 - acc: 0.7530 - val_loss: 0.6391 - val_acc: 0.7798\n",
      "Epoch 344/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6848 - acc: 0.7571 - val_loss: 0.6399 - val_acc: 0.7790\n",
      "Epoch 345/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6881 - acc: 0.7500 - val_loss: 0.6403 - val_acc: 0.7798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 346/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6874 - acc: 0.7519 - val_loss: 0.6400 - val_acc: 0.7790\n",
      "Epoch 347/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6939 - acc: 0.7493 - val_loss: 0.6408 - val_acc: 0.7790\n",
      "Epoch 348/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6975 - acc: 0.7522 - val_loss: 0.6399 - val_acc: 0.7790\n",
      "Epoch 349/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6762 - acc: 0.7571 - val_loss: 0.6389 - val_acc: 0.7798\n",
      "Epoch 350/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6930 - acc: 0.7448 - val_loss: 0.6398 - val_acc: 0.7798\n",
      "Epoch 351/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7033 - acc: 0.7429 - val_loss: 0.6390 - val_acc: 0.7798\n",
      "Epoch 352/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6970 - acc: 0.7489 - val_loss: 0.6400 - val_acc: 0.7790\n",
      "Epoch 353/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6796 - acc: 0.7567 - val_loss: 0.6405 - val_acc: 0.7790\n",
      "Epoch 354/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6671 - acc: 0.7641 - val_loss: 0.6401 - val_acc: 0.7798\n",
      "Epoch 355/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6922 - acc: 0.7582 - val_loss: 0.6393 - val_acc: 0.7798\n",
      "Epoch 356/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6821 - acc: 0.7589 - val_loss: 0.6405 - val_acc: 0.7790\n",
      "Epoch 357/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6968 - acc: 0.7507 - val_loss: 0.6395 - val_acc: 0.7798\n",
      "Epoch 358/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6773 - acc: 0.7578 - val_loss: 0.6393 - val_acc: 0.7798\n",
      "Epoch 359/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6858 - acc: 0.7522 - val_loss: 0.6402 - val_acc: 0.7798\n",
      "Epoch 360/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6867 - acc: 0.7519 - val_loss: 0.6405 - val_acc: 0.7790\n",
      "Epoch 361/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6862 - acc: 0.7440 - val_loss: 0.6399 - val_acc: 0.7790\n",
      "Epoch 362/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6875 - acc: 0.7522 - val_loss: 0.6397 - val_acc: 0.7798\n",
      "Epoch 363/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6791 - acc: 0.7493 - val_loss: 0.6391 - val_acc: 0.7798\n",
      "Epoch 364/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6813 - acc: 0.7571 - val_loss: 0.6398 - val_acc: 0.7798\n",
      "Epoch 365/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6780 - acc: 0.7552 - val_loss: 0.6407 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00365: loss improved from inf to 0.67798, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-2-000365-0.677980-0.779018.hdf5\n",
      "Epoch 366/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6864 - acc: 0.7522 - val_loss: 0.6399 - val_acc: 0.7790\n",
      "Epoch 367/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6799 - acc: 0.7504 - val_loss: 0.6388 - val_acc: 0.7798\n",
      "Epoch 368/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6823 - acc: 0.7541 - val_loss: 0.6389 - val_acc: 0.7798\n",
      "Epoch 369/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6923 - acc: 0.7600 - val_loss: 0.6403 - val_acc: 0.7790\n",
      "Epoch 370/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6836 - acc: 0.7600 - val_loss: 0.6385 - val_acc: 0.7798\n",
      "Epoch 371/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6868 - acc: 0.7623 - val_loss: 0.6377 - val_acc: 0.7805\n",
      "Epoch 372/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6881 - acc: 0.7574 - val_loss: 0.6402 - val_acc: 0.7790\n",
      "Epoch 373/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6923 - acc: 0.7485 - val_loss: 0.6407 - val_acc: 0.7790\n",
      "Epoch 374/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6901 - acc: 0.7552 - val_loss: 0.6390 - val_acc: 0.7805\n",
      "Epoch 375/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6918 - acc: 0.7537 - val_loss: 0.6393 - val_acc: 0.7798\n",
      "Epoch 376/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6839 - acc: 0.7541 - val_loss: 0.6396 - val_acc: 0.7790\n",
      "Epoch 377/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6873 - acc: 0.7556 - val_loss: 0.6408 - val_acc: 0.7790\n",
      "Epoch 378/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6772 - acc: 0.7600 - val_loss: 0.6398 - val_acc: 0.7798\n",
      "Epoch 379/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6721 - acc: 0.7619 - val_loss: 0.6396 - val_acc: 0.7798\n",
      "Epoch 380/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6937 - acc: 0.7507 - val_loss: 0.6395 - val_acc: 0.7798\n",
      "Epoch 381/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6913 - acc: 0.7593 - val_loss: 0.6393 - val_acc: 0.7798\n",
      "Epoch 382/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6705 - acc: 0.7630 - val_loss: 0.6392 - val_acc: 0.7798\n",
      "Epoch 383/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6974 - acc: 0.7530 - val_loss: 0.6403 - val_acc: 0.7790\n",
      "Epoch 384/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6868 - acc: 0.7571 - val_loss: 0.6397 - val_acc: 0.7790\n",
      "Epoch 385/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6955 - acc: 0.7552 - val_loss: 0.6386 - val_acc: 0.7798\n",
      "Epoch 386/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6961 - acc: 0.7496 - val_loss: 0.6385 - val_acc: 0.7805\n",
      "Epoch 387/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6847 - acc: 0.7511 - val_loss: 0.6331 - val_acc: 0.7798\n",
      "Epoch 388/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6854 - acc: 0.7470 - val_loss: 0.6395 - val_acc: 0.7798\n",
      "Epoch 389/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6865 - acc: 0.7526 - val_loss: 0.6374 - val_acc: 0.7805\n",
      "Epoch 390/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6882 - acc: 0.7541 - val_loss: 0.6386 - val_acc: 0.7805\n",
      "Epoch 391/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6834 - acc: 0.7511 - val_loss: 0.6373 - val_acc: 0.7805\n",
      "Epoch 392/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6725 - acc: 0.7615 - val_loss: 0.6390 - val_acc: 0.7798\n",
      "Epoch 393/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6766 - acc: 0.7586 - val_loss: 0.6397 - val_acc: 0.7798\n",
      "\n",
      "Epoch 00393: loss improved from 0.67798 to 0.67656, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-2-000393-0.676562-0.779762.hdf5\n",
      "Epoch 394/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6933 - acc: 0.7511 - val_loss: 0.6393 - val_acc: 0.7790\n",
      "Epoch 395/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6825 - acc: 0.7541 - val_loss: 0.6400 - val_acc: 0.7798\n",
      "Epoch 396/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6729 - acc: 0.7541 - val_loss: 0.6385 - val_acc: 0.7805\n",
      "Epoch 397/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6791 - acc: 0.7574 - val_loss: 0.6396 - val_acc: 0.7798\n",
      "Epoch 398/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6846 - acc: 0.7563 - val_loss: 0.6385 - val_acc: 0.7798\n",
      "Epoch 399/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6931 - acc: 0.7522 - val_loss: 0.6367 - val_acc: 0.7812\n",
      "Epoch 400/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6805 - acc: 0.7593 - val_loss: 0.6396 - val_acc: 0.7798\n",
      "\n",
      "Epoch 00400: saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/2-000400-0.680458-0.779762.hdf5\n",
      "Epoch 401/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6807 - acc: 0.7507 - val_loss: 0.6379 - val_acc: 0.7805\n",
      "Epoch 402/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6911 - acc: 0.7511 - val_loss: 0.6406 - val_acc: 0.7790\n",
      "Epoch 403/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6811 - acc: 0.7500 - val_loss: 0.6380 - val_acc: 0.7805\n",
      "Epoch 404/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6870 - acc: 0.7511 - val_loss: 0.6389 - val_acc: 0.7805\n",
      "Epoch 405/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6896 - acc: 0.7463 - val_loss: 0.6397 - val_acc: 0.7798\n",
      "Epoch 406/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6960 - acc: 0.7608 - val_loss: 0.6404 - val_acc: 0.7790\n",
      "Epoch 407/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6787 - acc: 0.7597 - val_loss: 0.6404 - val_acc: 0.7790\n",
      "Epoch 408/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6879 - acc: 0.7593 - val_loss: 0.6406 - val_acc: 0.7790\n",
      "Epoch 409/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6795 - acc: 0.7574 - val_loss: 0.6385 - val_acc: 0.7798\n",
      "Epoch 410/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6815 - acc: 0.7660 - val_loss: 0.6403 - val_acc: 0.7790\n",
      "Epoch 411/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6829 - acc: 0.7537 - val_loss: 0.6391 - val_acc: 0.7798\n",
      "Epoch 412/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6984 - acc: 0.7556 - val_loss: 0.6377 - val_acc: 0.7805\n",
      "Epoch 413/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6718 - acc: 0.7634 - val_loss: 0.6387 - val_acc: 0.7798\n",
      "Epoch 414/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6807 - acc: 0.7593 - val_loss: 0.6379 - val_acc: 0.7798\n",
      "Epoch 415/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6803 - acc: 0.7608 - val_loss: 0.6380 - val_acc: 0.7805\n",
      "Epoch 416/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.6849 - acc: 0.7537 - val_loss: 0.6394 - val_acc: 0.7798\n",
      "Epoch 417/1000\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 0.6883 - acc: 0.7545 - val_loss: 0.6380 - val_acc: 0.7798\n",
      "Epoch 418/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6865 - acc: 0.7522 - val_loss: 0.6395 - val_acc: 0.7798\n",
      "Epoch 419/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6936 - acc: 0.7560 - val_loss: 0.6393 - val_acc: 0.7798\n",
      "Epoch 420/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6815 - acc: 0.7519 - val_loss: 0.6402 - val_acc: 0.7790\n",
      "Epoch 421/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6807 - acc: 0.7530 - val_loss: 0.6404 - val_acc: 0.7790\n",
      "Epoch 422/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6962 - acc: 0.7530 - val_loss: 0.6403 - val_acc: 0.7790\n",
      "Epoch 423/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6856 - acc: 0.7589 - val_loss: 0.6410 - val_acc: 0.7790\n",
      "Epoch 424/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6776 - acc: 0.7589 - val_loss: 0.6384 - val_acc: 0.7805\n",
      "Epoch 425/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6804 - acc: 0.7560 - val_loss: 0.6325 - val_acc: 0.7805\n",
      "Epoch 426/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6897 - acc: 0.7519 - val_loss: 0.6378 - val_acc: 0.7805\n",
      "Epoch 427/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6808 - acc: 0.7597 - val_loss: 0.6403 - val_acc: 0.7790\n",
      "Epoch 428/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6801 - acc: 0.7552 - val_loss: 0.6381 - val_acc: 0.7805\n",
      "Epoch 429/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6949 - acc: 0.7493 - val_loss: 0.6399 - val_acc: 0.7798\n",
      "Epoch 430/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7006 - acc: 0.7511 - val_loss: 0.6397 - val_acc: 0.7798\n",
      "Epoch 431/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6760 - acc: 0.7630 - val_loss: 0.6405 - val_acc: 0.7790\n",
      "Epoch 432/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6832 - acc: 0.7511 - val_loss: 0.6396 - val_acc: 0.7798\n",
      "Epoch 433/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6736 - acc: 0.7496 - val_loss: 0.6390 - val_acc: 0.7805\n",
      "Epoch 434/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6811 - acc: 0.7604 - val_loss: 0.6398 - val_acc: 0.7798\n",
      "Epoch 435/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6807 - acc: 0.7578 - val_loss: 0.6391 - val_acc: 0.7790\n",
      "Epoch 436/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6929 - acc: 0.7481 - val_loss: 0.6399 - val_acc: 0.7798\n",
      "Epoch 437/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6734 - acc: 0.7574 - val_loss: 0.6381 - val_acc: 0.7805\n",
      "Epoch 438/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6771 - acc: 0.7586 - val_loss: 0.6403 - val_acc: 0.7790\n",
      "Epoch 439/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6908 - acc: 0.7567 - val_loss: 0.6376 - val_acc: 0.7798\n",
      "Epoch 440/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6744 - acc: 0.7567 - val_loss: 0.6399 - val_acc: 0.7798\n",
      "Epoch 441/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6787 - acc: 0.7582 - val_loss: 0.6393 - val_acc: 0.7798\n",
      "Epoch 442/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6833 - acc: 0.7500 - val_loss: 0.6399 - val_acc: 0.7790\n",
      "Epoch 443/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6814 - acc: 0.7541 - val_loss: 0.6391 - val_acc: 0.7798\n",
      "Epoch 444/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6822 - acc: 0.7533 - val_loss: 0.6392 - val_acc: 0.7790\n",
      "Epoch 445/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6770 - acc: 0.7604 - val_loss: 0.6406 - val_acc: 0.7790\n",
      "Epoch 446/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6848 - acc: 0.7552 - val_loss: 0.6399 - val_acc: 0.7790\n",
      "Epoch 447/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6807 - acc: 0.7548 - val_loss: 0.6393 - val_acc: 0.7798\n",
      "Epoch 448/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6768 - acc: 0.7600 - val_loss: 0.6396 - val_acc: 0.7798\n",
      "Epoch 449/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6801 - acc: 0.7597 - val_loss: 0.6403 - val_acc: 0.7790\n",
      "Epoch 450/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7001 - acc: 0.7400 - val_loss: 0.6403 - val_acc: 0.7790\n",
      "Epoch 451/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6878 - acc: 0.7526 - val_loss: 0.6402 - val_acc: 0.7790\n",
      "Epoch 452/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6794 - acc: 0.7522 - val_loss: 0.6379 - val_acc: 0.7805\n",
      "Epoch 453/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6867 - acc: 0.7638 - val_loss: 0.6403 - val_acc: 0.7790\n",
      "Epoch 454/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6979 - acc: 0.7504 - val_loss: 0.6409 - val_acc: 0.7790\n",
      "Epoch 455/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6827 - acc: 0.7526 - val_loss: 0.6390 - val_acc: 0.7798\n",
      "Epoch 456/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6768 - acc: 0.7563 - val_loss: 0.6401 - val_acc: 0.7798\n",
      "Epoch 457/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6832 - acc: 0.7526 - val_loss: 0.6392 - val_acc: 0.7798\n",
      "Epoch 458/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6778 - acc: 0.7619 - val_loss: 0.6400 - val_acc: 0.7790\n",
      "Epoch 459/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6787 - acc: 0.7530 - val_loss: 0.6406 - val_acc: 0.7790\n",
      "Epoch 460/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7059 - acc: 0.7504 - val_loss: 0.6389 - val_acc: 0.7798\n",
      "Epoch 461/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6771 - acc: 0.7600 - val_loss: 0.6394 - val_acc: 0.7790\n",
      "Epoch 462/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6912 - acc: 0.7586 - val_loss: 0.6390 - val_acc: 0.7805\n",
      "Epoch 463/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6780 - acc: 0.7593 - val_loss: 0.6405 - val_acc: 0.7790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 464/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6801 - acc: 0.7522 - val_loss: 0.6406 - val_acc: 0.7790\n",
      "Epoch 465/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7079 - acc: 0.7478 - val_loss: 0.6398 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00465: loss improved from inf to 0.70790, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-2-000465-0.707898-0.779018.hdf5\n",
      "Epoch 466/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6945 - acc: 0.7463 - val_loss: 0.6400 - val_acc: 0.7798\n",
      "Epoch 467/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6894 - acc: 0.7548 - val_loss: 0.6404 - val_acc: 0.7790\n",
      "Epoch 468/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6819 - acc: 0.7578 - val_loss: 0.6397 - val_acc: 0.7798\n",
      "Epoch 469/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6932 - acc: 0.7593 - val_loss: 0.6361 - val_acc: 0.7805\n",
      "\n",
      "Epoch 00469: loss improved from 0.70790 to 0.69321, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-2-000469-0.693211-0.780506.hdf5\n",
      "Epoch 470/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6823 - acc: 0.7589 - val_loss: 0.6395 - val_acc: 0.7798\n",
      "Epoch 471/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6919 - acc: 0.7496 - val_loss: 0.6396 - val_acc: 0.7798\n",
      "Epoch 472/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.6911 - acc: 0.7481 - val_loss: 0.6390 - val_acc: 0.7798\n",
      "Epoch 473/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.6910 - acc: 0.7526 - val_loss: 0.6373 - val_acc: 0.7805\n",
      "\n",
      "Epoch 00473: loss improved from 0.69321 to 0.69099, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-2-000473-0.690990-0.780506.hdf5\n",
      "Epoch 474/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.6774 - acc: 0.7641 - val_loss: 0.6395 - val_acc: 0.7798\n",
      "Epoch 475/1000\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.6731 - acc: 0.7545 - val_loss: 0.6383 - val_acc: 0.7798\n",
      "Epoch 476/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.6936 - acc: 0.7530 - val_loss: 0.6380 - val_acc: 0.7798\n",
      "Epoch 477/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.6866 - acc: 0.7478 - val_loss: 0.6393 - val_acc: 0.7798\n",
      "\n",
      "Epoch 00477: loss improved from 0.69099 to 0.68662, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-2-000477-0.686619-0.779762.hdf5\n",
      "Epoch 478/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.6926 - acc: 0.7530 - val_loss: 0.6377 - val_acc: 0.7805\n",
      "Epoch 479/1000\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.6875 - acc: 0.7608 - val_loss: 0.6378 - val_acc: 0.7798\n",
      "Epoch 480/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.6878 - acc: 0.7522 - val_loss: 0.6392 - val_acc: 0.7805\n",
      "Epoch 481/1000\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.6898 - acc: 0.7507 - val_loss: 0.6397 - val_acc: 0.7798\n",
      "Epoch 482/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.6736 - acc: 0.7604 - val_loss: 0.6392 - val_acc: 0.7798\n",
      "Epoch 483/1000\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.6981 - acc: 0.7459 - val_loss: 0.6389 - val_acc: 0.7798\n",
      "Epoch 484/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.6841 - acc: 0.7511 - val_loss: 0.6406 - val_acc: 0.7790\n",
      "Epoch 485/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6784 - acc: 0.7574 - val_loss: 0.6403 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00485: loss improved from 0.68662 to 0.67842, saving model to ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/Pbest-2-000485-0.678424-0.779018.hdf5\n",
      "Epoch 486/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6812 - acc: 0.7537 - val_loss: 0.6408 - val_acc: 0.7790\n",
      "Epoch 487/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6938 - acc: 0.7545 - val_loss: 0.6383 - val_acc: 0.7798\n",
      "Epoch 488/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6846 - acc: 0.7560 - val_loss: 0.6377 - val_acc: 0.7805\n",
      "Epoch 00488: early stopping\n",
      "ModelCheckpoint 已经保存到 ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/weights/2-final.hdf5\n",
      "save in: ../datasets/casas/results/WCNNR/milan/3/20220201_2000_64_1_3_1/log/20220201_2000_64_1_3_1.csv\n",
      "time: 0:12:45 s\n",
      "time: 765.0 s\n",
      "average 0.765000 s\n",
      "2 epoch finished\n",
      "--------------------   best   --------------------\n",
      "no_activities: 10\n",
      "\n",
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1348/1348 [==============================] - 2s 1ms/step\n",
      "2-milan:\tacc: 77.82%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 7, 0, 7, 2, 2, 0, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 4, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 7, 0, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 0, 7, 7, 0, 7, 7, 7, 0, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 0, 7, 0, 7, 7, 7, 7, 0, 7, 4, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 4, 7, 7, 7, 7, 7, 4, 0, 0, 7, 7, 7, 7, 0, 0, 7, 0, 7, 7, 7, 7, 7, 7, 7, 0, 7, 0, 7, 7, 7, 7, 7, 9, 0, 7, 7, 0, 7, 7, 7, 0, 9, 7, 7, 7, 0, 7, 7, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 0, 5, 0, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9, 0, 9, 9, 9, 0, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 0, 0, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 2, 7, 7, 2, 2, 2, 7, 7, 0, 2, 2, 7, 7, 0, 0, 9, 0, 0, 9, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 4, 0, 0, 7, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 4, 0, 0, 0, 7, 0, 7, 0, 0, 9, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 7, 0, 7, 0, 7, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 4, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 4, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 5, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 4, 4, 4, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 4, 4, 4, 4, 0, 4, 0, 4, 4, 4, 4, 4, 4, 0, 4, 0, 4, 4, 4, 4, 0, 0, 0, 4, 0, 0, 4, 4, 4, 0, 4, 4, 0, 4, 4, 0, 0, 4, 0, 4, 4, 7, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 0, 4, 4, 4, 4, 0, 4, 4, 0, 4, 4, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 7, 0, 0, 0, 4, 4, 0, 0, 4, 0, 0, 7, 0, 4, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 4, 0, 0, 0, 0]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.750000  0.910112  0.822335       623\n",
      "         Work   0.000000  0.000000  0.000000        26\n",
      "Take_medicine   1.000000  0.500000  0.666667        20\n",
      "        Sleep   0.000000  0.000000  0.000000        32\n",
      "        Relax   0.798077  0.580420  0.672065       143\n",
      "   Leave_Home   0.898551  0.873239  0.885714        71\n",
      "          Eat   0.000000  0.000000  0.000000         7\n",
      "         Cook   0.782609  0.778378  0.780488       185\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        29\n",
      "      Bathing   0.813333  0.863208  0.837529       212\n",
      "\n",
      "     accuracy                       0.778190      1348\n",
      "    macro avg   0.504257  0.450536  0.466480      1348\n",
      " weighted avg   0.728770  0.778190  0.746725      1348\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  27   0   0   2   0   0]\n",
      " [  0   0   0   0   0   1   0  25   0   0]\n",
      " [  0   0   0   0   0   2   0   5   0   0]\n",
      " [  0   0   0  10   0   8   0   2   0   0]\n",
      " [  0   0   0   0 183   5   0  23   1   0]\n",
      " [  0   0   0   0   2 144   0  36   3   0]\n",
      " [  0   0   0   0   0   1  62   7   1   0]\n",
      " [  0   0   0   0  13  20   7 567  16   0]\n",
      " [  0   0   0   0   0   3   0  57  83   0]\n",
      " [  0   0   0   0   0   0   0  32   0   0]]\n",
      "--------------------   final   --------------------\n",
      "no_activities: 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1348/1348 [==============================] - 2s 1ms/step\n",
      "2-milan:\tacc: 77.97%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 0, 0, 0, 7, 0, 7, 2, 2, 0, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 4, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 4, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 7, 0, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 0, 7, 7, 0, 7, 7, 7, 0, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 0, 7, 7, 7, 7, 0, 7, 4, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 4, 7, 7, 7, 7, 7, 4, 0, 0, 7, 7, 7, 7, 0, 0, 7, 0, 7, 7, 7, 7, 7, 7, 7, 0, 7, 0, 7, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 7, 0, 9, 7, 7, 7, 0, 7, 2, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 0, 5, 0, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9, 0, 9, 9, 9, 0, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 0, 0, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 5, 0, 0, 0, 0, 0, 0, 7, 2, 7, 7, 2, 2, 2, 7, 2, 0, 2, 2, 2, 7, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 4, 0, 0, 7, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 4, 0, 0, 0, 7, 0, 7, 0, 0, 7, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 7, 0, 7, 0, 7, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 4, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 4, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 7, 4, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 0, 0, 5, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 4, 4, 4, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 0, 4, 4, 4, 4, 0, 0, 0, 4, 0, 0, 4, 4, 4, 0, 4, 4, 0, 4, 4, 0, 0, 4, 0, 4, 4, 7, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 0, 4, 4, 4, 4, 0, 4, 4, 0, 4, 4, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 7, 0, 0, 0, 4, 4, 0, 0, 4, 0, 0, 7, 0, 4, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 4, 0, 0, 0, 0]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.753333  0.906902  0.823015       623\n",
      "         Work   0.000000  0.000000  0.000000        26\n",
      "Take_medicine   0.923077  0.600000  0.727273        20\n",
      "        Sleep   0.000000  0.000000  0.000000        32\n",
      "        Relax   0.772727  0.594406  0.671937       143\n",
      "   Leave_Home   0.873239  0.873239  0.873239        71\n",
      "          Eat   0.000000  0.000000  0.000000         7\n",
      "         Cook   0.788043  0.783784  0.785908       185\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        29\n",
      "      Bathing   0.827273  0.858491  0.842593       212\n",
      "\n",
      "     accuracy                       0.779674      1348\n",
      "    macro avg   0.493769  0.461682  0.472396      1348\n",
      " weighted avg   0.728085  0.779674  0.748808      1348\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  27   0   0   2   0   0]\n",
      " [  0   0   0   0   0   1   0  24   1   0]\n",
      " [  0   0   0   0   0   2   0   5   0   0]\n",
      " [  0   0   0  12   0   6   0   2   0   0]\n",
      " [  0   0   0   0 182   5   0  23   2   0]\n",
      " [  0   0   0   1   1 145   0  35   3   0]\n",
      " [  0   0   0   0   0   1  62   7   1   0]\n",
      " [  0   0   0   0  10  21   9 565  18   0]\n",
      " [  0   0   0   0   0   3   0  55  85   0]\n",
      " [  0   0   0   0   0   0   0  32   0   0]]\n",
      "best: current database: milan \t 77.28% (+/- 0.72%)\n",
      "final: current database: milan \t 77.38% (+/- 0.79%)\n",
      "CPU times: user 35min 32s, sys: 1min 30s, total: 37min 2s\n",
      "Wall time: 39min 27s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dict_config_cus['distance_int'] = '3'\n",
    "train_val(dict_config_cus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "scrolled": true
   },
   "source": [
    "```bash\n",
    "best: current database: milan \t 77.28% (+/- 0.72%)\n",
    "final: current database: milan \t 77.38% (+/- 0.79%)\n",
    "CPU times: user 35min 32s, sys: 1min 30s, total: 37min 2s\n",
    "Wall time: 39min 27s\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='constrain_4'>CS_4</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current dataset: milan\n",
      "../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1\n",
      "no_activities: 10\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_46 (InputLayer)        (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_46 (Embedding)     (None, 2000, 64)          172544    \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 2000, 12)          780       \n",
      "_________________________________________________________________\n",
      "activation_136 (Activation)  (None, 2000, 12)          0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_46 (Glo (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 18)                234       \n",
      "_________________________________________________________________\n",
      "activation_137 (Activation)  (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 12)                228       \n",
      "_________________________________________________________________\n",
      "activation_138 (Activation)  (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 10)                130       \n",
      "=================================================================\n",
      "Total params: 173,916\n",
      "Trainable params: 173,916\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Create subdir directory: ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights...\n",
      "Begin training ...\n",
      "Epoch 1/1000\n",
      "42/42 [==============================] - 4s 88ms/step - loss: 1.7795 - acc: 0.4594 - val_loss: 1.4026 - val_acc: 0.5766\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.4100 - acc: 0.5517 - val_loss: 1.2420 - val_acc: 0.6324\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.3183 - acc: 0.5833 - val_loss: 1.1734 - val_acc: 0.6391\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.2406 - acc: 0.6053 - val_loss: 1.1170 - val_acc: 0.6443\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.2078 - acc: 0.6094 - val_loss: 1.0695 - val_acc: 0.6667\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.1591 - acc: 0.6306 - val_loss: 1.0368 - val_acc: 0.6704\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.1411 - acc: 0.6157 - val_loss: 0.9976 - val_acc: 0.6749\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.1238 - acc: 0.6302 - val_loss: 0.9756 - val_acc: 0.6749\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.1009 - acc: 0.6391 - val_loss: 0.9609 - val_acc: 0.6882\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0912 - acc: 0.6451 - val_loss: 0.9443 - val_acc: 0.6838\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0459 - acc: 0.6518 - val_loss: 0.9233 - val_acc: 0.6905\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0607 - acc: 0.6544 - val_loss: 0.9109 - val_acc: 0.7106\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0576 - acc: 0.6514 - val_loss: 0.9018 - val_acc: 0.7135\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.0375 - acc: 0.6577 - val_loss: 0.8861 - val_acc: 0.7247\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0278 - acc: 0.6693 - val_loss: 0.8795 - val_acc: 0.7292\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0138 - acc: 0.6678 - val_loss: 0.8711 - val_acc: 0.7329\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0028 - acc: 0.6689 - val_loss: 0.8641 - val_acc: 0.7440\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0070 - acc: 0.6656 - val_loss: 0.8590 - val_acc: 0.7448\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9886 - acc: 0.6700 - val_loss: 0.8477 - val_acc: 0.7440\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0026 - acc: 0.6763 - val_loss: 0.8336 - val_acc: 0.7522\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9870 - acc: 0.6763 - val_loss: 0.8348 - val_acc: 0.7463\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9882 - acc: 0.6752 - val_loss: 0.8205 - val_acc: 0.7522\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.9793 - acc: 0.6693 - val_loss: 0.8224 - val_acc: 0.7493\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9608 - acc: 0.6845 - val_loss: 0.8190 - val_acc: 0.7463\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9546 - acc: 0.6804 - val_loss: 0.8118 - val_acc: 0.7507\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9677 - acc: 0.6693 - val_loss: 0.8087 - val_acc: 0.7493\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9528 - acc: 0.6801 - val_loss: 0.8015 - val_acc: 0.7485\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9335 - acc: 0.6845 - val_loss: 0.7934 - val_acc: 0.7470\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9346 - acc: 0.6923 - val_loss: 0.7883 - val_acc: 0.7500\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9416 - acc: 0.6815 - val_loss: 0.7905 - val_acc: 0.7463\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9354 - acc: 0.6871 - val_loss: 0.7849 - val_acc: 0.7448\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9380 - acc: 0.6853 - val_loss: 0.7791 - val_acc: 0.7552\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9185 - acc: 0.6901 - val_loss: 0.7800 - val_acc: 0.7537\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9286 - acc: 0.6949 - val_loss: 0.7746 - val_acc: 0.7507\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9174 - acc: 0.6927 - val_loss: 0.7700 - val_acc: 0.7560\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9096 - acc: 0.6987 - val_loss: 0.7683 - val_acc: 0.7560\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9136 - acc: 0.6998 - val_loss: 0.7619 - val_acc: 0.7560\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8960 - acc: 0.6953 - val_loss: 0.7608 - val_acc: 0.7552\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9106 - acc: 0.7016 - val_loss: 0.7595 - val_acc: 0.7552\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9018 - acc: 0.6972 - val_loss: 0.7539 - val_acc: 0.7664\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8923 - acc: 0.7106 - val_loss: 0.7542 - val_acc: 0.7626\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8959 - acc: 0.6949 - val_loss: 0.7512 - val_acc: 0.7619\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9008 - acc: 0.7035 - val_loss: 0.7479 - val_acc: 0.7597\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8968 - acc: 0.7068 - val_loss: 0.7491 - val_acc: 0.7619\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8815 - acc: 0.7005 - val_loss: 0.7433 - val_acc: 0.7626\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8873 - acc: 0.7083 - val_loss: 0.7428 - val_acc: 0.7693\n",
      "Epoch 47/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8776 - acc: 0.7128 - val_loss: 0.7420 - val_acc: 0.7597\n",
      "Epoch 48/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.8720 - acc: 0.7113 - val_loss: 0.7359 - val_acc: 0.7708\n",
      "Epoch 49/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.8780 - acc: 0.7046 - val_loss: 0.7369 - val_acc: 0.7649\n",
      "Epoch 50/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8770 - acc: 0.7094 - val_loss: 0.7316 - val_acc: 0.7723\n",
      "Epoch 51/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.8754 - acc: 0.7054 - val_loss: 0.7328 - val_acc: 0.7679\n",
      "Epoch 52/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8642 - acc: 0.7106 - val_loss: 0.7325 - val_acc: 0.7679\n",
      "Epoch 53/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8663 - acc: 0.7046 - val_loss: 0.7308 - val_acc: 0.7619\n",
      "Epoch 54/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8569 - acc: 0.7180 - val_loss: 0.7280 - val_acc: 0.7649\n",
      "Epoch 55/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.8626 - acc: 0.7042 - val_loss: 0.7256 - val_acc: 0.7693\n",
      "Epoch 56/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.8606 - acc: 0.7161 - val_loss: 0.7247 - val_acc: 0.7649\n",
      "Epoch 57/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8514 - acc: 0.7158 - val_loss: 0.7217 - val_acc: 0.7656\n",
      "Epoch 58/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8473 - acc: 0.7210 - val_loss: 0.7205 - val_acc: 0.7656\n",
      "Epoch 59/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8445 - acc: 0.7124 - val_loss: 0.7179 - val_acc: 0.7656\n",
      "Epoch 60/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8411 - acc: 0.7106 - val_loss: 0.7147 - val_acc: 0.7671\n",
      "Epoch 61/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8487 - acc: 0.7195 - val_loss: 0.7138 - val_acc: 0.7679\n",
      "Epoch 62/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8593 - acc: 0.7132 - val_loss: 0.7111 - val_acc: 0.7664\n",
      "Epoch 63/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8559 - acc: 0.7143 - val_loss: 0.7088 - val_acc: 0.7693\n",
      "Epoch 64/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8416 - acc: 0.7191 - val_loss: 0.7088 - val_acc: 0.7679\n",
      "Epoch 65/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8476 - acc: 0.7087 - val_loss: 0.7098 - val_acc: 0.7664\n",
      "\n",
      "Epoch 00065: loss improved from inf to 0.84756, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-0-000065-0.847555-0.766369.hdf5\n",
      "Epoch 66/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8434 - acc: 0.7165 - val_loss: 0.7061 - val_acc: 0.7693\n",
      "Epoch 67/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8327 - acc: 0.7232 - val_loss: 0.7059 - val_acc: 0.7723\n",
      "Epoch 68/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.8338 - acc: 0.7228 - val_loss: 0.7005 - val_acc: 0.7723\n",
      "Epoch 69/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8327 - acc: 0.7169 - val_loss: 0.7047 - val_acc: 0.7686\n",
      "\n",
      "Epoch 00069: loss improved from 0.84756 to 0.83269, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-0-000069-0.832695-0.768601.hdf5\n",
      "Epoch 70/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8162 - acc: 0.7139 - val_loss: 0.7031 - val_acc: 0.7708\n",
      "Epoch 71/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8380 - acc: 0.7161 - val_loss: 0.6999 - val_acc: 0.7679\n",
      "Epoch 72/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8272 - acc: 0.7199 - val_loss: 0.6978 - val_acc: 0.7686\n",
      "Epoch 73/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8254 - acc: 0.7221 - val_loss: 0.6984 - val_acc: 0.7686\n",
      "\n",
      "Epoch 00073: loss improved from 0.83269 to 0.82538, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-0-000073-0.825383-0.768601.hdf5\n",
      "Epoch 74/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8223 - acc: 0.7147 - val_loss: 0.6968 - val_acc: 0.7716\n",
      "Epoch 75/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8127 - acc: 0.7269 - val_loss: 0.6965 - val_acc: 0.7738\n",
      "Epoch 76/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8117 - acc: 0.7225 - val_loss: 0.6943 - val_acc: 0.7775\n",
      "Epoch 77/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8226 - acc: 0.7206 - val_loss: 0.6892 - val_acc: 0.7768\n",
      "\n",
      "Epoch 00077: loss improved from 0.82538 to 0.82265, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-0-000077-0.822645-0.776786.hdf5\n",
      "Epoch 78/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8208 - acc: 0.7154 - val_loss: 0.6924 - val_acc: 0.7790\n",
      "Epoch 79/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8173 - acc: 0.7266 - val_loss: 0.6906 - val_acc: 0.7783\n",
      "Epoch 80/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8124 - acc: 0.7310 - val_loss: 0.6905 - val_acc: 0.7760\n",
      "Epoch 81/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8182 - acc: 0.7254 - val_loss: 0.6876 - val_acc: 0.7805\n",
      "\n",
      "Epoch 00081: loss improved from 0.82265 to 0.81823, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-0-000081-0.818227-0.780506.hdf5\n",
      "Epoch 82/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8022 - acc: 0.7325 - val_loss: 0.6854 - val_acc: 0.7842\n",
      "Epoch 83/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8116 - acc: 0.7206 - val_loss: 0.6854 - val_acc: 0.7798\n",
      "Epoch 84/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8071 - acc: 0.7266 - val_loss: 0.6889 - val_acc: 0.7708\n",
      "Epoch 85/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8060 - acc: 0.7299 - val_loss: 0.6842 - val_acc: 0.7768\n",
      "\n",
      "Epoch 00085: loss improved from 0.81823 to 0.80604, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-0-000085-0.806042-0.776786.hdf5\n",
      "Epoch 86/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8024 - acc: 0.7362 - val_loss: 0.6837 - val_acc: 0.7790\n",
      "Epoch 87/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8075 - acc: 0.7288 - val_loss: 0.6833 - val_acc: 0.7768\n",
      "Epoch 88/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8045 - acc: 0.7214 - val_loss: 0.6832 - val_acc: 0.7783\n",
      "Epoch 89/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8019 - acc: 0.7284 - val_loss: 0.6804 - val_acc: 0.7820\n",
      "\n",
      "Epoch 00089: loss improved from 0.80604 to 0.80193, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-0-000089-0.801933-0.781994.hdf5\n",
      "Epoch 90/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8009 - acc: 0.7199 - val_loss: 0.6805 - val_acc: 0.7775\n",
      "Epoch 91/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7922 - acc: 0.7303 - val_loss: 0.6798 - val_acc: 0.7760\n",
      "Epoch 92/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8037 - acc: 0.7303 - val_loss: 0.6796 - val_acc: 0.7768\n",
      "Epoch 93/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7920 - acc: 0.7318 - val_loss: 0.6779 - val_acc: 0.7768\n",
      "\n",
      "Epoch 00093: loss improved from 0.80193 to 0.79202, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-0-000093-0.792017-0.776786.hdf5\n",
      "Epoch 94/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7940 - acc: 0.7228 - val_loss: 0.6744 - val_acc: 0.7798\n",
      "Epoch 95/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7979 - acc: 0.7258 - val_loss: 0.6728 - val_acc: 0.7798\n",
      "Epoch 96/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7774 - acc: 0.7385 - val_loss: 0.6756 - val_acc: 0.7812\n",
      "Epoch 97/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8006 - acc: 0.7310 - val_loss: 0.6744 - val_acc: 0.7805\n",
      "Epoch 98/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7981 - acc: 0.7269 - val_loss: 0.6765 - val_acc: 0.7790\n",
      "Epoch 99/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7773 - acc: 0.7377 - val_loss: 0.6722 - val_acc: 0.7790\n",
      "Epoch 100/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7756 - acc: 0.7381 - val_loss: 0.6703 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00100: saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/0-000100-0.775642-0.779018.hdf5\n",
      "Epoch 101/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7945 - acc: 0.7277 - val_loss: 0.6724 - val_acc: 0.7798\n",
      "Epoch 102/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7848 - acc: 0.7321 - val_loss: 0.6752 - val_acc: 0.7783\n",
      "Epoch 103/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7769 - acc: 0.7392 - val_loss: 0.6733 - val_acc: 0.7790\n",
      "Epoch 104/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7846 - acc: 0.7396 - val_loss: 0.6716 - val_acc: 0.7827\n",
      "Epoch 105/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7908 - acc: 0.7355 - val_loss: 0.6721 - val_acc: 0.7790\n",
      "Epoch 106/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7702 - acc: 0.7299 - val_loss: 0.6696 - val_acc: 0.7798\n",
      "Epoch 107/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7787 - acc: 0.7303 - val_loss: 0.6695 - val_acc: 0.7805\n",
      "Epoch 108/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7901 - acc: 0.7299 - val_loss: 0.6680 - val_acc: 0.7775\n",
      "Epoch 109/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7865 - acc: 0.7295 - val_loss: 0.6704 - val_acc: 0.7805\n",
      "Epoch 110/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7791 - acc: 0.7422 - val_loss: 0.6702 - val_acc: 0.7827\n",
      "Epoch 111/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7872 - acc: 0.7355 - val_loss: 0.6636 - val_acc: 0.7775\n",
      "Epoch 112/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7777 - acc: 0.7377 - val_loss: 0.6710 - val_acc: 0.7738\n",
      "Epoch 113/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7605 - acc: 0.7325 - val_loss: 0.6680 - val_acc: 0.7753\n",
      "Epoch 114/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7939 - acc: 0.7240 - val_loss: 0.6666 - val_acc: 0.7775\n",
      "Epoch 115/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7747 - acc: 0.7396 - val_loss: 0.6680 - val_acc: 0.7753\n",
      "Epoch 116/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7679 - acc: 0.7310 - val_loss: 0.6687 - val_acc: 0.7768\n",
      "Epoch 117/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7545 - acc: 0.7400 - val_loss: 0.6663 - val_acc: 0.7783\n",
      "Epoch 118/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7557 - acc: 0.7362 - val_loss: 0.6663 - val_acc: 0.7753\n",
      "Epoch 119/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7858 - acc: 0.7396 - val_loss: 0.6672 - val_acc: 0.7775\n",
      "Epoch 120/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7754 - acc: 0.7310 - val_loss: 0.6650 - val_acc: 0.7805\n",
      "Epoch 121/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7763 - acc: 0.7347 - val_loss: 0.6654 - val_acc: 0.7820\n",
      "Epoch 122/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7733 - acc: 0.7392 - val_loss: 0.6637 - val_acc: 0.7783\n",
      "Epoch 123/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7534 - acc: 0.7392 - val_loss: 0.6645 - val_acc: 0.7768\n",
      "Epoch 124/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7748 - acc: 0.7310 - val_loss: 0.6625 - val_acc: 0.7827\n",
      "Epoch 125/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7650 - acc: 0.7418 - val_loss: 0.6644 - val_acc: 0.7768\n",
      "Epoch 126/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7729 - acc: 0.7366 - val_loss: 0.6635 - val_acc: 0.7798\n",
      "Epoch 127/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7714 - acc: 0.7377 - val_loss: 0.6658 - val_acc: 0.7768\n",
      "Epoch 128/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7812 - acc: 0.7232 - val_loss: 0.6628 - val_acc: 0.7805\n",
      "Epoch 129/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7771 - acc: 0.7299 - val_loss: 0.6637 - val_acc: 0.7760\n",
      "Epoch 130/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7651 - acc: 0.7437 - val_loss: 0.6595 - val_acc: 0.7798\n",
      "Epoch 131/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7708 - acc: 0.7396 - val_loss: 0.6614 - val_acc: 0.7760\n",
      "Epoch 132/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7560 - acc: 0.7437 - val_loss: 0.6604 - val_acc: 0.7783\n",
      "Epoch 133/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7539 - acc: 0.7426 - val_loss: 0.6609 - val_acc: 0.7790\n",
      "Epoch 134/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7500 - acc: 0.7463 - val_loss: 0.6591 - val_acc: 0.7760\n",
      "Epoch 135/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7668 - acc: 0.7374 - val_loss: 0.6600 - val_acc: 0.7760\n",
      "Epoch 136/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7555 - acc: 0.7403 - val_loss: 0.6599 - val_acc: 0.7790\n",
      "Epoch 137/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7516 - acc: 0.7459 - val_loss: 0.6435 - val_acc: 0.7850\n",
      "Epoch 138/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7660 - acc: 0.7325 - val_loss: 0.6588 - val_acc: 0.7760\n",
      "Epoch 139/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7525 - acc: 0.7396 - val_loss: 0.6574 - val_acc: 0.7731\n",
      "Epoch 140/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7217 - acc: 0.7552 - val_loss: 0.6556 - val_acc: 0.7708\n",
      "Epoch 141/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7534 - acc: 0.7351 - val_loss: 0.6580 - val_acc: 0.7731\n",
      "Epoch 142/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7522 - acc: 0.7433 - val_loss: 0.6578 - val_acc: 0.7731\n",
      "Epoch 143/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7561 - acc: 0.7407 - val_loss: 0.6547 - val_acc: 0.7775\n",
      "Epoch 144/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7588 - acc: 0.7414 - val_loss: 0.6571 - val_acc: 0.7760\n",
      "Epoch 145/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7549 - acc: 0.7396 - val_loss: 0.6577 - val_acc: 0.7775\n",
      "Epoch 146/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7568 - acc: 0.7418 - val_loss: 0.6571 - val_acc: 0.7753\n",
      "Epoch 147/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7573 - acc: 0.7400 - val_loss: 0.6578 - val_acc: 0.7783\n",
      "Epoch 148/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7341 - acc: 0.7537 - val_loss: 0.6572 - val_acc: 0.7768\n",
      "Epoch 149/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7572 - acc: 0.7336 - val_loss: 0.6578 - val_acc: 0.7738\n",
      "Epoch 150/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7497 - acc: 0.7392 - val_loss: 0.6558 - val_acc: 0.7738\n",
      "Epoch 151/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7648 - acc: 0.7366 - val_loss: 0.6583 - val_acc: 0.7731\n",
      "Epoch 152/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7517 - acc: 0.7452 - val_loss: 0.6588 - val_acc: 0.7738\n",
      "Epoch 153/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7448 - acc: 0.7481 - val_loss: 0.6565 - val_acc: 0.7746\n",
      "Epoch 154/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7543 - acc: 0.7478 - val_loss: 0.6565 - val_acc: 0.7738\n",
      "Epoch 155/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7417 - acc: 0.7481 - val_loss: 0.6529 - val_acc: 0.7753\n",
      "Epoch 156/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7464 - acc: 0.7411 - val_loss: 0.6517 - val_acc: 0.7753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7444 - acc: 0.7433 - val_loss: 0.6560 - val_acc: 0.7738\n",
      "Epoch 158/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7515 - acc: 0.7347 - val_loss: 0.6529 - val_acc: 0.7731\n",
      "Epoch 159/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7502 - acc: 0.7381 - val_loss: 0.6548 - val_acc: 0.7738\n",
      "Epoch 160/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7382 - acc: 0.7496 - val_loss: 0.6548 - val_acc: 0.7738\n",
      "\n",
      "Epoch 00160: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 161/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7427 - acc: 0.7392 - val_loss: 0.6536 - val_acc: 0.7746\n",
      "Epoch 162/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7409 - acc: 0.7400 - val_loss: 0.6543 - val_acc: 0.7738\n",
      "Epoch 163/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7400 - acc: 0.7496 - val_loss: 0.6543 - val_acc: 0.7738\n",
      "Epoch 164/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7483 - acc: 0.7459 - val_loss: 0.6544 - val_acc: 0.7731\n",
      "Epoch 165/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7681 - acc: 0.7295 - val_loss: 0.6540 - val_acc: 0.7731\n",
      "\n",
      "Epoch 00165: loss improved from inf to 0.76812, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-0-000165-0.768115-0.773065.hdf5\n",
      "Epoch 166/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7577 - acc: 0.7433 - val_loss: 0.6509 - val_acc: 0.7731\n",
      "Epoch 167/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7505 - acc: 0.7414 - val_loss: 0.6556 - val_acc: 0.7723\n",
      "Epoch 168/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7311 - acc: 0.7481 - val_loss: 0.6525 - val_acc: 0.7753\n",
      "Epoch 169/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7612 - acc: 0.7318 - val_loss: 0.6546 - val_acc: 0.7723\n",
      "\n",
      "Epoch 00169: loss improved from 0.76812 to 0.76120, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-0-000169-0.761203-0.772321.hdf5\n",
      "Epoch 170/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7475 - acc: 0.7392 - val_loss: 0.6521 - val_acc: 0.7746\n",
      "Epoch 171/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7409 - acc: 0.7388 - val_loss: 0.6552 - val_acc: 0.7738\n",
      "Epoch 172/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7445 - acc: 0.7347 - val_loss: 0.6542 - val_acc: 0.7723\n",
      "Epoch 173/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7498 - acc: 0.7400 - val_loss: 0.6557 - val_acc: 0.7731\n",
      "\n",
      "Epoch 00173: loss improved from 0.76120 to 0.74982, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-0-000173-0.749821-0.773065.hdf5\n",
      "Epoch 174/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7462 - acc: 0.7422 - val_loss: 0.6556 - val_acc: 0.7716\n",
      "Epoch 175/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7492 - acc: 0.7333 - val_loss: 0.6553 - val_acc: 0.7723\n",
      "Epoch 176/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7455 - acc: 0.7433 - val_loss: 0.6513 - val_acc: 0.7746\n",
      "Epoch 177/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7350 - acc: 0.7396 - val_loss: 0.6520 - val_acc: 0.7723\n",
      "\n",
      "Epoch 00177: loss improved from 0.74982 to 0.73496, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-0-000177-0.734958-0.772321.hdf5\n",
      "Epoch 178/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7431 - acc: 0.7481 - val_loss: 0.6507 - val_acc: 0.7738\n",
      "Epoch 179/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7642 - acc: 0.7381 - val_loss: 0.6535 - val_acc: 0.7723\n",
      "Epoch 180/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7510 - acc: 0.7489 - val_loss: 0.6550 - val_acc: 0.7723\n",
      "\n",
      "Epoch 00180: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 181/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7421 - acc: 0.7426 - val_loss: 0.6523 - val_acc: 0.7746\n",
      "Epoch 182/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7552 - acc: 0.7374 - val_loss: 0.6534 - val_acc: 0.7738\n",
      "Epoch 183/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7614 - acc: 0.7437 - val_loss: 0.6548 - val_acc: 0.7731\n",
      "Epoch 184/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7470 - acc: 0.7500 - val_loss: 0.6553 - val_acc: 0.7716\n",
      "Epoch 185/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7484 - acc: 0.7411 - val_loss: 0.6561 - val_acc: 0.7716\n",
      "Epoch 186/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7482 - acc: 0.7459 - val_loss: 0.6535 - val_acc: 0.7723\n",
      "Epoch 187/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7541 - acc: 0.7440 - val_loss: 0.6533 - val_acc: 0.7723\n",
      "Epoch 188/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7507 - acc: 0.7440 - val_loss: 0.6548 - val_acc: 0.7723\n",
      "Epoch 189/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7489 - acc: 0.7377 - val_loss: 0.6548 - val_acc: 0.7731\n",
      "Epoch 190/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7424 - acc: 0.7493 - val_loss: 0.6535 - val_acc: 0.7738\n",
      "Epoch 191/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7488 - acc: 0.7340 - val_loss: 0.6553 - val_acc: 0.7731\n",
      "Epoch 192/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7591 - acc: 0.7455 - val_loss: 0.6554 - val_acc: 0.7716\n",
      "Epoch 193/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7418 - acc: 0.7433 - val_loss: 0.6437 - val_acc: 0.7723\n",
      "Epoch 194/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7383 - acc: 0.7448 - val_loss: 0.6525 - val_acc: 0.7723\n",
      "Epoch 195/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7551 - acc: 0.7388 - val_loss: 0.6552 - val_acc: 0.7716\n",
      "Epoch 196/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7402 - acc: 0.7437 - val_loss: 0.6544 - val_acc: 0.7731\n",
      "Epoch 197/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7339 - acc: 0.7530 - val_loss: 0.6560 - val_acc: 0.7723\n",
      "\n",
      "Epoch 00197: loss improved from 0.73496 to 0.73392, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-0-000197-0.733923-0.772321.hdf5\n",
      "Epoch 198/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7539 - acc: 0.7407 - val_loss: 0.6501 - val_acc: 0.7738\n",
      "Epoch 199/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7444 - acc: 0.7496 - val_loss: 0.6525 - val_acc: 0.7738\n",
      "Epoch 200/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7500 - acc: 0.7381 - val_loss: 0.6536 - val_acc: 0.7731\n",
      "\n",
      "Epoch 00200: saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/0-000200-0.750016-0.773065.hdf5\n",
      "\n",
      "Epoch 00200: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 201/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7404 - acc: 0.7433 - val_loss: 0.6522 - val_acc: 0.7738\n",
      "Epoch 202/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7445 - acc: 0.7414 - val_loss: 0.6538 - val_acc: 0.7723\n",
      "Epoch 203/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7410 - acc: 0.7407 - val_loss: 0.6551 - val_acc: 0.7716\n",
      "Epoch 204/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7557 - acc: 0.7407 - val_loss: 0.6524 - val_acc: 0.7731\n",
      "Epoch 205/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7580 - acc: 0.7388 - val_loss: 0.6547 - val_acc: 0.7716\n",
      "Epoch 206/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7471 - acc: 0.7366 - val_loss: 0.6529 - val_acc: 0.7723\n",
      "Epoch 207/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7409 - acc: 0.7489 - val_loss: 0.6531 - val_acc: 0.7731\n",
      "Epoch 208/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7566 - acc: 0.7433 - val_loss: 0.6542 - val_acc: 0.7723\n",
      "Epoch 209/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7441 - acc: 0.7411 - val_loss: 0.6538 - val_acc: 0.7723\n",
      "Epoch 210/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7334 - acc: 0.7519 - val_loss: 0.6539 - val_acc: 0.7723\n",
      "Epoch 211/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7555 - acc: 0.7340 - val_loss: 0.6533 - val_acc: 0.7723\n",
      "Epoch 212/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7384 - acc: 0.7366 - val_loss: 0.6523 - val_acc: 0.7723\n",
      "Epoch 213/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7604 - acc: 0.7414 - val_loss: 0.6541 - val_acc: 0.7723\n",
      "Epoch 214/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7329 - acc: 0.7448 - val_loss: 0.6547 - val_acc: 0.7723\n",
      "Epoch 215/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7397 - acc: 0.7448 - val_loss: 0.6530 - val_acc: 0.7731\n",
      "Epoch 216/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7510 - acc: 0.7437 - val_loss: 0.6522 - val_acc: 0.7723\n",
      "Epoch 217/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7382 - acc: 0.7470 - val_loss: 0.6541 - val_acc: 0.7723\n",
      "Epoch 218/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7721 - acc: 0.7385 - val_loss: 0.6530 - val_acc: 0.7738\n",
      "Epoch 219/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7348 - acc: 0.7463 - val_loss: 0.6547 - val_acc: 0.7716\n",
      "Epoch 220/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7277 - acc: 0.7519 - val_loss: 0.6545 - val_acc: 0.7723\n",
      "Epoch 221/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7383 - acc: 0.7455 - val_loss: 0.6547 - val_acc: 0.7716\n",
      "Epoch 222/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7492 - acc: 0.7336 - val_loss: 0.6537 - val_acc: 0.7731\n",
      "Epoch 223/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7369 - acc: 0.7481 - val_loss: 0.6522 - val_acc: 0.7731\n",
      "Epoch 224/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7483 - acc: 0.7467 - val_loss: 0.6538 - val_acc: 0.7731\n",
      "Epoch 225/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7480 - acc: 0.7481 - val_loss: 0.6527 - val_acc: 0.7731\n",
      "Epoch 226/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7503 - acc: 0.7440 - val_loss: 0.6558 - val_acc: 0.7716\n",
      "Epoch 227/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7478 - acc: 0.7403 - val_loss: 0.6542 - val_acc: 0.7723\n",
      "Epoch 228/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7512 - acc: 0.7515 - val_loss: 0.6539 - val_acc: 0.7723\n",
      "Epoch 229/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7437 - acc: 0.7422 - val_loss: 0.6543 - val_acc: 0.7716\n",
      "Epoch 230/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7419 - acc: 0.7377 - val_loss: 0.6549 - val_acc: 0.7716\n",
      "Epoch 231/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7352 - acc: 0.7400 - val_loss: 0.6537 - val_acc: 0.7723\n",
      "Epoch 232/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7402 - acc: 0.7485 - val_loss: 0.6543 - val_acc: 0.7723\n",
      "Epoch 233/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7316 - acc: 0.7385 - val_loss: 0.6549 - val_acc: 0.7716\n",
      "Epoch 234/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7431 - acc: 0.7392 - val_loss: 0.6550 - val_acc: 0.7716\n",
      "Epoch 235/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7597 - acc: 0.7426 - val_loss: 0.6521 - val_acc: 0.7731\n",
      "Epoch 236/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7358 - acc: 0.7481 - val_loss: 0.6534 - val_acc: 0.7723\n",
      "Epoch 237/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7391 - acc: 0.7407 - val_loss: 0.6529 - val_acc: 0.7731\n",
      "Epoch 238/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7413 - acc: 0.7489 - val_loss: 0.6545 - val_acc: 0.7716\n",
      "Epoch 239/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7591 - acc: 0.7359 - val_loss: 0.6543 - val_acc: 0.7723\n",
      "Epoch 240/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7420 - acc: 0.7448 - val_loss: 0.6552 - val_acc: 0.7716\n",
      "Epoch 241/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7531 - acc: 0.7321 - val_loss: 0.6545 - val_acc: 0.7723\n",
      "Epoch 242/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7576 - acc: 0.7448 - val_loss: 0.6499 - val_acc: 0.7731\n",
      "Epoch 243/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7418 - acc: 0.7474 - val_loss: 0.6557 - val_acc: 0.7716\n",
      "Epoch 244/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7451 - acc: 0.7347 - val_loss: 0.6545 - val_acc: 0.7716\n",
      "Epoch 245/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7435 - acc: 0.7470 - val_loss: 0.6490 - val_acc: 0.7738\n",
      "Epoch 246/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7435 - acc: 0.7440 - val_loss: 0.6529 - val_acc: 0.7738\n",
      "Epoch 247/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7528 - acc: 0.7340 - val_loss: 0.6552 - val_acc: 0.7723\n",
      "Epoch 248/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7440 - acc: 0.7414 - val_loss: 0.6482 - val_acc: 0.7738\n",
      "Epoch 249/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7457 - acc: 0.7511 - val_loss: 0.6542 - val_acc: 0.7716\n",
      "Epoch 250/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7437 - acc: 0.7407 - val_loss: 0.6543 - val_acc: 0.7716\n",
      "Epoch 251/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7403 - acc: 0.7374 - val_loss: 0.6552 - val_acc: 0.7716\n",
      "Epoch 252/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7514 - acc: 0.7351 - val_loss: 0.6553 - val_acc: 0.7716\n",
      "Epoch 253/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7343 - acc: 0.7429 - val_loss: 0.6544 - val_acc: 0.7716\n",
      "Epoch 254/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7279 - acc: 0.7470 - val_loss: 0.6542 - val_acc: 0.7723\n",
      "Epoch 255/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7430 - acc: 0.7448 - val_loss: 0.6552 - val_acc: 0.7716\n",
      "Epoch 256/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7425 - acc: 0.7418 - val_loss: 0.6544 - val_acc: 0.7723\n",
      "Epoch 257/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7600 - acc: 0.7374 - val_loss: 0.6542 - val_acc: 0.7723\n",
      "Epoch 258/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7349 - acc: 0.7452 - val_loss: 0.6544 - val_acc: 0.7723\n",
      "Epoch 259/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7485 - acc: 0.7422 - val_loss: 0.6511 - val_acc: 0.7731\n",
      "Epoch 260/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7586 - acc: 0.7392 - val_loss: 0.6537 - val_acc: 0.7731\n",
      "Epoch 261/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7471 - acc: 0.7455 - val_loss: 0.6552 - val_acc: 0.7716\n",
      "Epoch 262/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7501 - acc: 0.7422 - val_loss: 0.6538 - val_acc: 0.7723\n",
      "Epoch 263/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7445 - acc: 0.7478 - val_loss: 0.6538 - val_acc: 0.7716\n",
      "Epoch 264/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7506 - acc: 0.7481 - val_loss: 0.6546 - val_acc: 0.7723\n",
      "Epoch 265/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7546 - acc: 0.7433 - val_loss: 0.6543 - val_acc: 0.7723\n",
      "\n",
      "Epoch 00265: loss improved from inf to 0.75456, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-0-000265-0.754559-0.772321.hdf5\n",
      "Epoch 266/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7419 - acc: 0.7440 - val_loss: 0.6529 - val_acc: 0.7731\n",
      "Epoch 267/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7474 - acc: 0.7467 - val_loss: 0.6538 - val_acc: 0.7723\n",
      "Epoch 268/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7516 - acc: 0.7318 - val_loss: 0.6514 - val_acc: 0.7731\n",
      "Epoch 269/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7426 - acc: 0.7418 - val_loss: 0.6551 - val_acc: 0.7716\n",
      "\n",
      "Epoch 00269: loss improved from 0.75456 to 0.74257, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-0-000269-0.742569-0.771577.hdf5\n",
      "Epoch 270/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7542 - acc: 0.7392 - val_loss: 0.6525 - val_acc: 0.7738\n",
      "Epoch 271/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7269 - acc: 0.7515 - val_loss: 0.6486 - val_acc: 0.7746\n",
      "Epoch 272/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7501 - acc: 0.7478 - val_loss: 0.6538 - val_acc: 0.7723\n",
      "Epoch 273/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7444 - acc: 0.7463 - val_loss: 0.6540 - val_acc: 0.7723\n",
      "Epoch 274/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7340 - acc: 0.7533 - val_loss: 0.6543 - val_acc: 0.7723\n",
      "Epoch 275/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7441 - acc: 0.7455 - val_loss: 0.6527 - val_acc: 0.7731\n",
      "Epoch 276/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7348 - acc: 0.7448 - val_loss: 0.6521 - val_acc: 0.7731\n",
      "Epoch 277/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7373 - acc: 0.7481 - val_loss: 0.6535 - val_acc: 0.7723\n",
      "\n",
      "Epoch 00277: loss improved from 0.74257 to 0.73729, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-0-000277-0.737294-0.772321.hdf5\n",
      "Epoch 278/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7232 - acc: 0.7522 - val_loss: 0.6540 - val_acc: 0.7723\n",
      "Epoch 279/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7513 - acc: 0.7433 - val_loss: 0.6535 - val_acc: 0.7731\n",
      "Epoch 280/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7454 - acc: 0.7366 - val_loss: 0.6519 - val_acc: 0.7731\n",
      "Epoch 281/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7495 - acc: 0.7463 - val_loss: 0.6542 - val_acc: 0.7723\n",
      "Epoch 282/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7339 - acc: 0.7444 - val_loss: 0.6537 - val_acc: 0.7723\n",
      "Epoch 283/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7299 - acc: 0.7455 - val_loss: 0.6540 - val_acc: 0.7716\n",
      "Epoch 284/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7429 - acc: 0.7418 - val_loss: 0.6522 - val_acc: 0.7723\n",
      "Epoch 285/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7693 - acc: 0.7288 - val_loss: 0.6541 - val_acc: 0.7723\n",
      "Epoch 286/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7390 - acc: 0.7493 - val_loss: 0.6527 - val_acc: 0.7731\n",
      "Epoch 287/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7320 - acc: 0.7452 - val_loss: 0.6540 - val_acc: 0.7723\n",
      "Epoch 288/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7471 - acc: 0.7422 - val_loss: 0.6541 - val_acc: 0.7723\n",
      "Epoch 289/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7406 - acc: 0.7377 - val_loss: 0.6544 - val_acc: 0.7716\n",
      "Epoch 290/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7369 - acc: 0.7433 - val_loss: 0.6535 - val_acc: 0.7723\n",
      "Epoch 291/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7466 - acc: 0.7403 - val_loss: 0.6541 - val_acc: 0.7723\n",
      "Epoch 292/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7329 - acc: 0.7444 - val_loss: 0.6540 - val_acc: 0.7723\n",
      "Epoch 293/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7362 - acc: 0.7444 - val_loss: 0.6550 - val_acc: 0.7716\n",
      "\n",
      "Epoch 00293: loss improved from 0.73729 to 0.73624, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-0-000293-0.736236-0.771577.hdf5\n",
      "Epoch 294/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7383 - acc: 0.7485 - val_loss: 0.6491 - val_acc: 0.7723\n",
      "Epoch 295/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7180 - acc: 0.7496 - val_loss: 0.6536 - val_acc: 0.7723\n",
      "Epoch 296/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7434 - acc: 0.7370 - val_loss: 0.6541 - val_acc: 0.7731\n",
      "Epoch 297/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7537 - acc: 0.7388 - val_loss: 0.6509 - val_acc: 0.7738\n",
      "Epoch 298/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7551 - acc: 0.7377 - val_loss: 0.6516 - val_acc: 0.7731\n",
      "Epoch 299/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7436 - acc: 0.7370 - val_loss: 0.6549 - val_acc: 0.7716\n",
      "Epoch 300/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7434 - acc: 0.7388 - val_loss: 0.6494 - val_acc: 0.7731\n",
      "\n",
      "Epoch 00300: saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/0-000300-0.743437-0.773065.hdf5\n",
      "Epoch 301/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7449 - acc: 0.7414 - val_loss: 0.6551 - val_acc: 0.7716\n",
      "Epoch 302/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7400 - acc: 0.7567 - val_loss: 0.6511 - val_acc: 0.7746\n",
      "Epoch 303/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7450 - acc: 0.7414 - val_loss: 0.6539 - val_acc: 0.7723\n",
      "Epoch 304/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7447 - acc: 0.7437 - val_loss: 0.6544 - val_acc: 0.7723\n",
      "Epoch 305/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7427 - acc: 0.7426 - val_loss: 0.6547 - val_acc: 0.7723\n",
      "Epoch 306/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7585 - acc: 0.7418 - val_loss: 0.6512 - val_acc: 0.7731\n",
      "Epoch 307/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7517 - acc: 0.7433 - val_loss: 0.6548 - val_acc: 0.7723\n",
      "Epoch 308/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7565 - acc: 0.7411 - val_loss: 0.6530 - val_acc: 0.7738\n",
      "Epoch 309/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7470 - acc: 0.7440 - val_loss: 0.6549 - val_acc: 0.7716\n",
      "Epoch 310/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7492 - acc: 0.7366 - val_loss: 0.6528 - val_acc: 0.7731\n",
      "Epoch 311/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7570 - acc: 0.7407 - val_loss: 0.6532 - val_acc: 0.7731\n",
      "Epoch 312/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7323 - acc: 0.7515 - val_loss: 0.6531 - val_acc: 0.7731\n",
      "Epoch 313/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7518 - acc: 0.7444 - val_loss: 0.6536 - val_acc: 0.7731\n",
      "Epoch 314/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7423 - acc: 0.7597 - val_loss: 0.6530 - val_acc: 0.7731\n",
      "Epoch 315/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7517 - acc: 0.7392 - val_loss: 0.6542 - val_acc: 0.7716\n",
      "Epoch 316/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7333 - acc: 0.7467 - val_loss: 0.6526 - val_acc: 0.7731\n",
      "Epoch 317/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7404 - acc: 0.7467 - val_loss: 0.6539 - val_acc: 0.7723\n",
      "Epoch 318/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7408 - acc: 0.7433 - val_loss: 0.6556 - val_acc: 0.7716\n",
      "Epoch 319/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7392 - acc: 0.7366 - val_loss: 0.6537 - val_acc: 0.7723\n",
      "Epoch 320/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7516 - acc: 0.7411 - val_loss: 0.6541 - val_acc: 0.7723\n",
      "Epoch 321/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7416 - acc: 0.7400 - val_loss: 0.6547 - val_acc: 0.7716\n",
      "Epoch 322/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7455 - acc: 0.7407 - val_loss: 0.6533 - val_acc: 0.7723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 323/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7482 - acc: 0.7407 - val_loss: 0.6526 - val_acc: 0.7731\n",
      "Epoch 324/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7370 - acc: 0.7407 - val_loss: 0.6526 - val_acc: 0.7731\n",
      "Epoch 325/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7400 - acc: 0.7422 - val_loss: 0.6532 - val_acc: 0.7731\n",
      "Epoch 326/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7491 - acc: 0.7392 - val_loss: 0.6525 - val_acc: 0.7738\n",
      "Epoch 327/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7402 - acc: 0.7396 - val_loss: 0.6545 - val_acc: 0.7723\n",
      "Epoch 328/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7492 - acc: 0.7478 - val_loss: 0.6531 - val_acc: 0.7723\n",
      "Epoch 329/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7557 - acc: 0.7392 - val_loss: 0.6490 - val_acc: 0.7746\n",
      "Epoch 330/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7403 - acc: 0.7474 - val_loss: 0.6544 - val_acc: 0.7723\n",
      "Epoch 331/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7421 - acc: 0.7448 - val_loss: 0.6533 - val_acc: 0.7731\n",
      "Epoch 332/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7397 - acc: 0.7481 - val_loss: 0.6553 - val_acc: 0.7716\n",
      "Epoch 333/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7339 - acc: 0.7455 - val_loss: 0.6541 - val_acc: 0.7716\n",
      "Epoch 334/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7402 - acc: 0.7478 - val_loss: 0.6530 - val_acc: 0.7738\n",
      "Epoch 335/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7485 - acc: 0.7392 - val_loss: 0.6545 - val_acc: 0.7716\n",
      "Epoch 336/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7504 - acc: 0.7374 - val_loss: 0.6539 - val_acc: 0.7723\n",
      "Epoch 337/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7357 - acc: 0.7440 - val_loss: 0.6540 - val_acc: 0.7731\n",
      "Epoch 338/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7319 - acc: 0.7511 - val_loss: 0.6540 - val_acc: 0.7723\n",
      "Epoch 339/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7391 - acc: 0.7489 - val_loss: 0.6535 - val_acc: 0.7731\n",
      "Epoch 340/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7380 - acc: 0.7437 - val_loss: 0.6504 - val_acc: 0.7738\n",
      "Epoch 341/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7459 - acc: 0.7385 - val_loss: 0.6539 - val_acc: 0.7723\n",
      "Epoch 342/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7334 - acc: 0.7541 - val_loss: 0.6533 - val_acc: 0.7723\n",
      "Epoch 343/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7292 - acc: 0.7511 - val_loss: 0.6554 - val_acc: 0.7716\n",
      "Epoch 344/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7503 - acc: 0.7396 - val_loss: 0.6526 - val_acc: 0.7731\n",
      "Epoch 345/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7379 - acc: 0.7385 - val_loss: 0.6540 - val_acc: 0.7731\n",
      "Epoch 346/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7362 - acc: 0.7433 - val_loss: 0.6542 - val_acc: 0.7723\n",
      "Epoch 347/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7443 - acc: 0.7448 - val_loss: 0.6554 - val_acc: 0.7716\n",
      "Epoch 348/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7401 - acc: 0.7388 - val_loss: 0.6553 - val_acc: 0.7716\n",
      "Epoch 349/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7359 - acc: 0.7452 - val_loss: 0.6544 - val_acc: 0.7716\n",
      "Epoch 350/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7379 - acc: 0.7422 - val_loss: 0.6535 - val_acc: 0.7723\n",
      "Epoch 351/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7419 - acc: 0.7388 - val_loss: 0.6541 - val_acc: 0.7723\n",
      "Epoch 352/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7239 - acc: 0.7489 - val_loss: 0.6525 - val_acc: 0.7738\n",
      "Epoch 353/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7571 - acc: 0.7452 - val_loss: 0.6492 - val_acc: 0.7753\n",
      "Epoch 354/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7545 - acc: 0.7452 - val_loss: 0.6541 - val_acc: 0.7723\n",
      "Epoch 355/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7480 - acc: 0.7440 - val_loss: 0.6533 - val_acc: 0.7731\n",
      "Epoch 356/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7584 - acc: 0.7440 - val_loss: 0.6546 - val_acc: 0.7731\n",
      "Epoch 357/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7544 - acc: 0.7429 - val_loss: 0.6536 - val_acc: 0.7731\n",
      "Epoch 358/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7566 - acc: 0.7359 - val_loss: 0.6514 - val_acc: 0.7738\n",
      "Epoch 359/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7505 - acc: 0.7437 - val_loss: 0.6495 - val_acc: 0.7746\n",
      "Epoch 360/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7277 - acc: 0.7541 - val_loss: 0.6538 - val_acc: 0.7731\n",
      "Epoch 361/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7402 - acc: 0.7366 - val_loss: 0.6480 - val_acc: 0.7738\n",
      "Epoch 362/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7465 - acc: 0.7478 - val_loss: 0.6526 - val_acc: 0.7738\n",
      "Epoch 363/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7544 - acc: 0.7470 - val_loss: 0.6489 - val_acc: 0.7731\n",
      "Epoch 364/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7609 - acc: 0.7396 - val_loss: 0.6545 - val_acc: 0.7731\n",
      "Epoch 365/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7459 - acc: 0.7459 - val_loss: 0.6546 - val_acc: 0.7723\n",
      "\n",
      "Epoch 00365: loss improved from inf to 0.74586, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-0-000365-0.745862-0.772321.hdf5\n",
      "Epoch 366/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7478 - acc: 0.7396 - val_loss: 0.6548 - val_acc: 0.7723\n",
      "Epoch 367/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7520 - acc: 0.7440 - val_loss: 0.6535 - val_acc: 0.7738\n",
      "Epoch 368/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7253 - acc: 0.7496 - val_loss: 0.6541 - val_acc: 0.7731\n",
      "Epoch 369/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7351 - acc: 0.7459 - val_loss: 0.6513 - val_acc: 0.7738\n",
      "\n",
      "Epoch 00369: loss improved from 0.74586 to 0.73506, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-0-000369-0.735063-0.773810.hdf5\n",
      "Epoch 370/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7555 - acc: 0.7344 - val_loss: 0.6509 - val_acc: 0.7738\n",
      "Epoch 371/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7447 - acc: 0.7392 - val_loss: 0.6540 - val_acc: 0.7723\n",
      "Epoch 372/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7370 - acc: 0.7444 - val_loss: 0.6557 - val_acc: 0.7723\n",
      "Epoch 373/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7368 - acc: 0.7359 - val_loss: 0.6546 - val_acc: 0.7723\n",
      "Epoch 374/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7268 - acc: 0.7455 - val_loss: 0.6530 - val_acc: 0.7738\n",
      "Epoch 375/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7508 - acc: 0.7448 - val_loss: 0.6510 - val_acc: 0.7746\n",
      "Epoch 376/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7523 - acc: 0.7411 - val_loss: 0.6550 - val_acc: 0.7723\n",
      "Epoch 377/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7509 - acc: 0.7396 - val_loss: 0.6547 - val_acc: 0.7731\n",
      "Epoch 378/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7470 - acc: 0.7392 - val_loss: 0.6535 - val_acc: 0.7738\n",
      "Epoch 379/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7400 - acc: 0.7366 - val_loss: 0.6529 - val_acc: 0.7738\n",
      "Epoch 380/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7365 - acc: 0.7403 - val_loss: 0.6541 - val_acc: 0.7723\n",
      "Epoch 381/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7320 - acc: 0.7448 - val_loss: 0.6536 - val_acc: 0.7731\n",
      "\n",
      "Epoch 00381: loss improved from 0.73506 to 0.73196, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-0-000381-0.731964-0.773065.hdf5\n",
      "Epoch 382/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7474 - acc: 0.7470 - val_loss: 0.6532 - val_acc: 0.7731\n",
      "Epoch 383/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7406 - acc: 0.7400 - val_loss: 0.6545 - val_acc: 0.7723\n",
      "Epoch 384/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7496 - acc: 0.7437 - val_loss: 0.6533 - val_acc: 0.7731\n",
      "Epoch 385/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7514 - acc: 0.7440 - val_loss: 0.6544 - val_acc: 0.7731\n",
      "Epoch 386/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7553 - acc: 0.7381 - val_loss: 0.6542 - val_acc: 0.7731\n",
      "Epoch 387/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7374 - acc: 0.7515 - val_loss: 0.6543 - val_acc: 0.7731\n",
      "Epoch 388/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7608 - acc: 0.7422 - val_loss: 0.6549 - val_acc: 0.7723\n",
      "Epoch 389/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7366 - acc: 0.7496 - val_loss: 0.6529 - val_acc: 0.7738\n",
      "Epoch 390/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7461 - acc: 0.7396 - val_loss: 0.6536 - val_acc: 0.7731\n",
      "Epoch 391/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7644 - acc: 0.7347 - val_loss: 0.6506 - val_acc: 0.7738\n",
      "Epoch 392/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7501 - acc: 0.7470 - val_loss: 0.6501 - val_acc: 0.7738\n",
      "Epoch 393/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7439 - acc: 0.7362 - val_loss: 0.6536 - val_acc: 0.7731\n",
      "Epoch 394/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7311 - acc: 0.7485 - val_loss: 0.6531 - val_acc: 0.7738\n",
      "Epoch 395/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7478 - acc: 0.7440 - val_loss: 0.6505 - val_acc: 0.7746\n",
      "Epoch 396/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7374 - acc: 0.7411 - val_loss: 0.6553 - val_acc: 0.7723\n",
      "Epoch 397/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7359 - acc: 0.7440 - val_loss: 0.6540 - val_acc: 0.7731\n",
      "Epoch 398/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7538 - acc: 0.7470 - val_loss: 0.6549 - val_acc: 0.7723\n",
      "Epoch 399/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7476 - acc: 0.7403 - val_loss: 0.6545 - val_acc: 0.7731\n",
      "Epoch 400/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7268 - acc: 0.7440 - val_loss: 0.6531 - val_acc: 0.7731\n",
      "\n",
      "Epoch 00400: saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/0-000400-0.726835-0.773065.hdf5\n",
      "Epoch 401/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7387 - acc: 0.7433 - val_loss: 0.6523 - val_acc: 0.7746\n",
      "Epoch 402/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7370 - acc: 0.7407 - val_loss: 0.6546 - val_acc: 0.7723\n",
      "Epoch 403/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7464 - acc: 0.7433 - val_loss: 0.6539 - val_acc: 0.7723\n",
      "Epoch 404/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7349 - acc: 0.7519 - val_loss: 0.6545 - val_acc: 0.7723\n",
      "Epoch 405/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7424 - acc: 0.7463 - val_loss: 0.6495 - val_acc: 0.7731\n",
      "Epoch 406/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7441 - acc: 0.7400 - val_loss: 0.6538 - val_acc: 0.7723\n",
      "Epoch 407/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7391 - acc: 0.7504 - val_loss: 0.6519 - val_acc: 0.7746\n",
      "Epoch 408/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7535 - acc: 0.7392 - val_loss: 0.6538 - val_acc: 0.7731\n",
      "Epoch 409/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7510 - acc: 0.7422 - val_loss: 0.6540 - val_acc: 0.7731\n",
      "Epoch 410/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7357 - acc: 0.7433 - val_loss: 0.6541 - val_acc: 0.7731\n",
      "Epoch 411/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.7411 - acc: 0.7452 - val_loss: 0.6550 - val_acc: 0.7723\n",
      "Epoch 412/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7415 - acc: 0.7426 - val_loss: 0.6514 - val_acc: 0.7746\n",
      "Epoch 413/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7450 - acc: 0.7459 - val_loss: 0.6540 - val_acc: 0.7738\n",
      "Epoch 414/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7425 - acc: 0.7467 - val_loss: 0.6533 - val_acc: 0.7738\n",
      "Epoch 415/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7446 - acc: 0.7474 - val_loss: 0.6547 - val_acc: 0.7723\n",
      "Epoch 416/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7634 - acc: 0.7414 - val_loss: 0.6514 - val_acc: 0.7738\n",
      "Epoch 417/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7551 - acc: 0.7437 - val_loss: 0.6528 - val_acc: 0.7738\n",
      "Epoch 418/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7521 - acc: 0.7444 - val_loss: 0.6534 - val_acc: 0.7731\n",
      "Epoch 419/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7355 - acc: 0.7470 - val_loss: 0.6548 - val_acc: 0.7723\n",
      "Epoch 420/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7621 - acc: 0.7403 - val_loss: 0.6527 - val_acc: 0.7738\n",
      "Epoch 421/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7342 - acc: 0.7403 - val_loss: 0.6534 - val_acc: 0.7738\n",
      "Epoch 422/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7377 - acc: 0.7374 - val_loss: 0.6538 - val_acc: 0.7723\n",
      "Epoch 423/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7432 - acc: 0.7533 - val_loss: 0.6553 - val_acc: 0.7723\n",
      "Epoch 424/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7661 - acc: 0.7422 - val_loss: 0.6552 - val_acc: 0.7723\n",
      "Epoch 425/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7378 - acc: 0.7459 - val_loss: 0.6540 - val_acc: 0.7731\n",
      "Epoch 426/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7373 - acc: 0.7537 - val_loss: 0.6533 - val_acc: 0.7731\n",
      "Epoch 427/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7316 - acc: 0.7467 - val_loss: 0.6542 - val_acc: 0.7731\n",
      "Epoch 428/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7434 - acc: 0.7504 - val_loss: 0.6542 - val_acc: 0.7731\n",
      "Epoch 429/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7339 - acc: 0.7485 - val_loss: 0.6535 - val_acc: 0.7731\n",
      "Epoch 430/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7457 - acc: 0.7388 - val_loss: 0.6529 - val_acc: 0.7731\n",
      "Epoch 431/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7435 - acc: 0.7333 - val_loss: 0.6553 - val_acc: 0.7723\n",
      "Epoch 432/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7620 - acc: 0.7403 - val_loss: 0.6538 - val_acc: 0.7731\n",
      "Epoch 433/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7525 - acc: 0.7411 - val_loss: 0.6540 - val_acc: 0.7723\n",
      "Epoch 434/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7433 - acc: 0.7388 - val_loss: 0.6530 - val_acc: 0.7731\n",
      "Epoch 435/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7356 - acc: 0.7474 - val_loss: 0.6537 - val_acc: 0.7731\n",
      "Epoch 436/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7467 - acc: 0.7437 - val_loss: 0.6519 - val_acc: 0.7746\n",
      "Epoch 437/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7533 - acc: 0.7385 - val_loss: 0.6527 - val_acc: 0.7738\n",
      "Epoch 438/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7462 - acc: 0.7407 - val_loss: 0.6541 - val_acc: 0.7731\n",
      "Epoch 439/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7456 - acc: 0.7459 - val_loss: 0.6540 - val_acc: 0.7723\n",
      "Epoch 440/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7389 - acc: 0.7422 - val_loss: 0.6554 - val_acc: 0.7723\n",
      "Epoch 441/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7509 - acc: 0.7422 - val_loss: 0.6541 - val_acc: 0.7723\n",
      "Epoch 442/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7331 - acc: 0.7452 - val_loss: 0.6545 - val_acc: 0.7723\n",
      "Epoch 443/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7431 - acc: 0.7414 - val_loss: 0.6520 - val_acc: 0.7746\n",
      "Epoch 444/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7506 - acc: 0.7414 - val_loss: 0.6527 - val_acc: 0.7731\n",
      "Epoch 445/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7524 - acc: 0.7407 - val_loss: 0.6544 - val_acc: 0.7731\n",
      "Epoch 446/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7412 - acc: 0.7444 - val_loss: 0.6544 - val_acc: 0.7723\n",
      "Epoch 447/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7414 - acc: 0.7467 - val_loss: 0.6548 - val_acc: 0.7723\n",
      "Epoch 448/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7502 - acc: 0.7403 - val_loss: 0.6546 - val_acc: 0.7723\n",
      "Epoch 449/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7348 - acc: 0.7426 - val_loss: 0.6543 - val_acc: 0.7723\n",
      "Epoch 450/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7470 - acc: 0.7385 - val_loss: 0.6514 - val_acc: 0.7746\n",
      "Epoch 451/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7449 - acc: 0.7459 - val_loss: 0.6530 - val_acc: 0.7731\n",
      "Epoch 452/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7483 - acc: 0.7500 - val_loss: 0.6545 - val_acc: 0.7731\n",
      "Epoch 453/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7422 - acc: 0.7548 - val_loss: 0.6524 - val_acc: 0.7738\n",
      "Epoch 454/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7544 - acc: 0.7437 - val_loss: 0.6478 - val_acc: 0.7738\n",
      "Epoch 455/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7488 - acc: 0.7314 - val_loss: 0.6534 - val_acc: 0.7731\n",
      "Epoch 456/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7435 - acc: 0.7470 - val_loss: 0.6537 - val_acc: 0.7731\n",
      "Epoch 457/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7409 - acc: 0.7459 - val_loss: 0.6537 - val_acc: 0.7731\n",
      "Epoch 458/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7311 - acc: 0.7530 - val_loss: 0.6543 - val_acc: 0.7723\n",
      "Epoch 459/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7549 - acc: 0.7396 - val_loss: 0.6544 - val_acc: 0.7723\n",
      "Epoch 460/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7587 - acc: 0.7325 - val_loss: 0.6517 - val_acc: 0.7738\n",
      "Epoch 461/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7450 - acc: 0.7455 - val_loss: 0.6542 - val_acc: 0.7731\n",
      "Epoch 462/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7531 - acc: 0.7362 - val_loss: 0.6538 - val_acc: 0.7731\n",
      "Epoch 463/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7412 - acc: 0.7444 - val_loss: 0.6548 - val_acc: 0.7731\n",
      "Epoch 464/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7501 - acc: 0.7478 - val_loss: 0.6522 - val_acc: 0.7738\n",
      "Epoch 465/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7493 - acc: 0.7448 - val_loss: 0.6542 - val_acc: 0.7723\n",
      "\n",
      "Epoch 00465: loss improved from inf to 0.74933, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-0-000465-0.749333-0.772321.hdf5\n",
      "Epoch 466/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7303 - acc: 0.7455 - val_loss: 0.6543 - val_acc: 0.7731\n",
      "Epoch 467/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7438 - acc: 0.7470 - val_loss: 0.6544 - val_acc: 0.7723\n",
      "Epoch 468/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7474 - acc: 0.7433 - val_loss: 0.6556 - val_acc: 0.7723\n",
      "Epoch 469/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7356 - acc: 0.7455 - val_loss: 0.6512 - val_acc: 0.7746\n",
      "\n",
      "Epoch 00469: loss improved from 0.74933 to 0.73561, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-0-000469-0.735612-0.774554.hdf5\n",
      "Epoch 470/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7341 - acc: 0.7519 - val_loss: 0.6552 - val_acc: 0.7723\n",
      "Epoch 471/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7479 - acc: 0.7385 - val_loss: 0.6539 - val_acc: 0.7731\n",
      "Epoch 472/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7333 - acc: 0.7507 - val_loss: 0.6545 - val_acc: 0.7731\n",
      "Epoch 473/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7454 - acc: 0.7459 - val_loss: 0.6541 - val_acc: 0.7731\n",
      "Epoch 474/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7372 - acc: 0.7500 - val_loss: 0.6534 - val_acc: 0.7731\n",
      "Epoch 475/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7500 - acc: 0.7440 - val_loss: 0.6531 - val_acc: 0.7738\n",
      "Epoch 476/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7417 - acc: 0.7440 - val_loss: 0.6519 - val_acc: 0.7738\n",
      "Epoch 477/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7380 - acc: 0.7478 - val_loss: 0.6535 - val_acc: 0.7731\n",
      "Epoch 478/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7498 - acc: 0.7452 - val_loss: 0.6527 - val_acc: 0.7731\n",
      "Epoch 479/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7573 - acc: 0.7426 - val_loss: 0.6528 - val_acc: 0.7738\n",
      "Epoch 480/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7586 - acc: 0.7370 - val_loss: 0.6523 - val_acc: 0.7738\n",
      "Epoch 481/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7530 - acc: 0.7344 - val_loss: 0.6530 - val_acc: 0.7738\n",
      "Epoch 482/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7346 - acc: 0.7496 - val_loss: 0.6534 - val_acc: 0.7738\n",
      "Epoch 483/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7373 - acc: 0.7470 - val_loss: 0.6541 - val_acc: 0.7738\n",
      "Epoch 484/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7338 - acc: 0.7515 - val_loss: 0.6547 - val_acc: 0.7723\n",
      "Epoch 485/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7422 - acc: 0.7481 - val_loss: 0.6543 - val_acc: 0.7723\n",
      "Epoch 486/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7478 - acc: 0.7392 - val_loss: 0.6523 - val_acc: 0.7738\n",
      "Epoch 487/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7346 - acc: 0.7448 - val_loss: 0.6535 - val_acc: 0.7731\n",
      "Epoch 488/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7595 - acc: 0.7321 - val_loss: 0.6523 - val_acc: 0.7746\n",
      "Epoch 489/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7389 - acc: 0.7455 - val_loss: 0.6535 - val_acc: 0.7731\n",
      "Epoch 490/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7442 - acc: 0.7344 - val_loss: 0.6542 - val_acc: 0.7731\n",
      "Epoch 491/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7433 - acc: 0.7448 - val_loss: 0.6518 - val_acc: 0.7738\n",
      "Epoch 492/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7467 - acc: 0.7437 - val_loss: 0.6546 - val_acc: 0.7731\n",
      "Epoch 493/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7352 - acc: 0.7485 - val_loss: 0.6521 - val_acc: 0.7738\n",
      "\n",
      "Epoch 00493: loss improved from 0.73561 to 0.73523, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-0-000493-0.735227-0.773810.hdf5\n",
      "Epoch 494/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7373 - acc: 0.7504 - val_loss: 0.6517 - val_acc: 0.7746\n",
      "Epoch 495/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7294 - acc: 0.7522 - val_loss: 0.6504 - val_acc: 0.7746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00495: early stopping\n",
      "ModelCheckpoint 已经保存到 ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/0-final.hdf5\n",
      "Create subdir directory: ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/log...\n",
      "save in: ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/log/20220201_2000_64_1_3_1.csv\n",
      "time: 0:13:11 s\n",
      "time: 791.0 s\n",
      "average 0.791000 s\n",
      "0 epoch finished\n",
      "--------------------   best   --------------------\n",
      "no_activities: 10\n",
      "\n",
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1349/1349 [==============================] - 2s 1ms/step\n",
      "0-milan:\tacc: 77.32%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 4, 4, 0, 4, 4, 0, 4, 0, 4, 0, 0, 7, 0, 0, 0, 0, 7, 7, 7, 2, 2, 7, 2, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 7, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 7, 9, 0, 9, 9, 9, 9, 9, 9, 7, 0, 7, 7, 7, 0, 7, 0, 0, 7, 7, 0, 7, 0, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 0, 7, 7, 0, 7, 0, 7, 7, 7, 7, 0, 7, 0, 7, 7, 0, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 0, 0, 7, 7, 7, 7, 0, 7, 0, 7, 0, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 0, 7, 7, 7, 7, 7, 7, 0, 7, 0, 0, 0, 7, 0, 7, 0, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 4, 5, 5, 4, 4, 5, 0, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 4, 5, 5, 5, 5, 7, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 2, 7, 7, 2, 2, 7, 2, 2, 7, 7, 2, 2, 7, 2, 0, 0, 0, 0, 0, 0, 7, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 7, 0, 0, 9, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 0, 7, 0, 0, 0, 0, 4, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 4, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 9, 7, 7, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 5, 0, 4, 0, 0, 0, 7, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 4, 4, 4, 0, 7, 4, 4, 0, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 0, 4, 0, 4, 4, 0, 4, 4, 4, 0, 0, 4, 7, 0, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 0, 7, 4, 4, 4, 0, 4, 4, 4, 7, 4, 4, 4, 0, 7, 7, 7, 4, 4, 0, 4, 0, 4, 4, 4, 4, 0, 0, 4, 0, 4, 4, 4, 7, 4, 4, 4, 0, 7, 4, 4, 4, 4, 4, 4, 0, 0, 4, 4, 4, 4, 4, 4, 0, 0, 0, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 4, 0, 0, 0, 0, 4, 4, 4, 0, 0, 0, 0, 4, 4, 0, 0, 7, 9, 0, 0, 0, 0, 0, 0, 4, 0, 4, 0, 0, 0, 4, 0, 4]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.764547  0.906902  0.829662       623\n",
      "         Work   0.000000  0.000000  0.000000        26\n",
      "Take_medicine   1.000000  0.550000  0.709677        20\n",
      "        Sleep   0.000000  0.000000  0.000000        32\n",
      "        Relax   0.747664  0.559441  0.640000       143\n",
      "   Leave_Home   0.910448  0.859155  0.884058        71\n",
      "          Eat   0.000000  0.000000  0.000000         7\n",
      "         Cook   0.723618  0.778378  0.750000       185\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        30\n",
      "      Bathing   0.805310  0.858491  0.831050       212\n",
      "\n",
      "     accuracy                       0.773165      1349\n",
      "    macro avg   0.495159  0.451237  0.464445      1349\n",
      " weighted avg   0.720879  0.773165  0.741508      1349\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  28   0   0   2   0   0]\n",
      " [  0   0   0   0   0   0   0  18   8   0]\n",
      " [  0   0   0   0   0   3   0   4   0   0]\n",
      " [  0   0   0  11   0   9   0   0   0   0]\n",
      " [  0   0   0   0 182   5   0  25   0   0]\n",
      " [  0   0   0   0   1 144   0  40   0   0]\n",
      " [  0   0   0   0   0   2  61   2   6   0]\n",
      " [  0   0   0   0  13  26   6 565  13   0]\n",
      " [  0   0   0   0   1  10   0  52  80   0]\n",
      " [  0   0   0   0   1   0   0  31   0   0]]\n",
      "--------------------   final   --------------------\n",
      "no_activities: 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1349/1349 [==============================] - 2s 1ms/step\n",
      "0-milan:\tacc: 77.32%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 4, 4, 0, 4, 4, 0, 4, 0, 4, 0, 0, 7, 0, 0, 0, 0, 7, 7, 7, 2, 2, 7, 2, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 7, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 7, 9, 0, 9, 9, 9, 9, 9, 9, 7, 0, 7, 7, 7, 0, 7, 0, 0, 7, 7, 0, 7, 0, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 0, 7, 7, 0, 7, 0, 7, 7, 7, 7, 0, 7, 0, 7, 7, 0, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 0, 0, 7, 7, 7, 7, 0, 7, 0, 7, 0, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 0, 7, 7, 7, 7, 7, 7, 0, 7, 0, 0, 0, 7, 0, 7, 0, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 4, 5, 5, 4, 4, 5, 0, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 4, 5, 5, 5, 5, 7, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 2, 7, 7, 2, 2, 7, 2, 2, 7, 7, 2, 2, 7, 2, 0, 0, 0, 0, 0, 0, 7, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 7, 0, 0, 9, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 0, 7, 0, 0, 0, 0, 4, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 4, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 9, 7, 7, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 5, 0, 4, 0, 0, 0, 7, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 4, 4, 4, 0, 7, 4, 4, 0, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 0, 4, 0, 4, 4, 0, 4, 4, 4, 0, 0, 4, 7, 0, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 0, 7, 4, 4, 4, 0, 4, 4, 4, 7, 4, 4, 4, 0, 7, 7, 7, 4, 4, 0, 4, 0, 4, 4, 4, 4, 0, 0, 4, 0, 4, 4, 4, 7, 4, 4, 4, 0, 7, 4, 4, 4, 4, 4, 4, 0, 0, 4, 4, 4, 4, 4, 4, 0, 0, 0, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 4, 0, 0, 0, 0, 4, 4, 4, 0, 0, 0, 0, 4, 4, 0, 0, 7, 9, 0, 0, 0, 0, 0, 0, 4, 0, 4, 0, 0, 0, 4, 0, 4]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.764547  0.906902  0.829662       623\n",
      "         Work   0.000000  0.000000  0.000000        26\n",
      "Take_medicine   1.000000  0.550000  0.709677        20\n",
      "        Sleep   0.000000  0.000000  0.000000        32\n",
      "        Relax   0.747664  0.559441  0.640000       143\n",
      "   Leave_Home   0.910448  0.859155  0.884058        71\n",
      "          Eat   0.000000  0.000000  0.000000         7\n",
      "         Cook   0.723618  0.778378  0.750000       185\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        30\n",
      "      Bathing   0.805310  0.858491  0.831050       212\n",
      "\n",
      "     accuracy                       0.773165      1349\n",
      "    macro avg   0.495159  0.451237  0.464445      1349\n",
      " weighted avg   0.720879  0.773165  0.741508      1349\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  28   0   0   2   0   0]\n",
      " [  0   0   0   0   0   0   0  18   8   0]\n",
      " [  0   0   0   0   0   3   0   4   0   0]\n",
      " [  0   0   0  11   0   9   0   0   0   0]\n",
      " [  0   0   0   0 182   5   0  25   0   0]\n",
      " [  0   0   0   0   1 144   0  40   0   0]\n",
      " [  0   0   0   0   0   2  61   2   6   0]\n",
      " [  0   0   0   0  13  26   6 565  13   0]\n",
      " [  0   0   0   0   1  10   0  52  80   0]\n",
      " [  0   0   0   0   1   0   0  31   0   0]]\n",
      "no_activities: 10\n",
      "\n",
      "Begin training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "42/42 [==============================] - 4s 90ms/step - loss: 1.7489 - acc: 0.4077 - val_loss: 1.4543 - val_acc: 0.5141\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.4487 - acc: 0.5446 - val_loss: 1.2414 - val_acc: 0.6057\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.3057 - acc: 0.5897 - val_loss: 1.1086 - val_acc: 0.6815\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.2064 - acc: 0.6339 - val_loss: 1.0366 - val_acc: 0.6935\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.1437 - acc: 0.6447 - val_loss: 0.9844 - val_acc: 0.6964\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.1104 - acc: 0.6592 - val_loss: 0.9514 - val_acc: 0.7016\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0716 - acc: 0.6603 - val_loss: 0.9136 - val_acc: 0.7061\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0691 - acc: 0.6533 - val_loss: 0.8921 - val_acc: 0.7284\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0318 - acc: 0.6722 - val_loss: 0.8762 - val_acc: 0.7351\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0129 - acc: 0.6864 - val_loss: 0.8623 - val_acc: 0.7426\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.0006 - acc: 0.6734 - val_loss: 0.8545 - val_acc: 0.7292\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9775 - acc: 0.6894 - val_loss: 0.8317 - val_acc: 0.7582\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9712 - acc: 0.6942 - val_loss: 0.8238 - val_acc: 0.7582\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9658 - acc: 0.6894 - val_loss: 0.8139 - val_acc: 0.7582\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9439 - acc: 0.6983 - val_loss: 0.8072 - val_acc: 0.7604\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9674 - acc: 0.6879 - val_loss: 0.8043 - val_acc: 0.7589\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9472 - acc: 0.6864 - val_loss: 0.7963 - val_acc: 0.7597\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9301 - acc: 0.6975 - val_loss: 0.7915 - val_acc: 0.7664\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9352 - acc: 0.6868 - val_loss: 0.7882 - val_acc: 0.7656\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9295 - acc: 0.7005 - val_loss: 0.7829 - val_acc: 0.7664\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9244 - acc: 0.6897 - val_loss: 0.7816 - val_acc: 0.7656\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9040 - acc: 0.7113 - val_loss: 0.7745 - val_acc: 0.7641\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8903 - acc: 0.7128 - val_loss: 0.7672 - val_acc: 0.7664\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9035 - acc: 0.6949 - val_loss: 0.7658 - val_acc: 0.7693\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8872 - acc: 0.7083 - val_loss: 0.7572 - val_acc: 0.7708\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8897 - acc: 0.7001 - val_loss: 0.7618 - val_acc: 0.7604\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9000 - acc: 0.7054 - val_loss: 0.7558 - val_acc: 0.7686\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8753 - acc: 0.7132 - val_loss: 0.7504 - val_acc: 0.7716\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8824 - acc: 0.7098 - val_loss: 0.7486 - val_acc: 0.7634\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8585 - acc: 0.7113 - val_loss: 0.7468 - val_acc: 0.7679\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8787 - acc: 0.7143 - val_loss: 0.7446 - val_acc: 0.7656\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8819 - acc: 0.7061 - val_loss: 0.7436 - val_acc: 0.7679\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8567 - acc: 0.7158 - val_loss: 0.7401 - val_acc: 0.7708\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8748 - acc: 0.7065 - val_loss: 0.7394 - val_acc: 0.7686\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8586 - acc: 0.7147 - val_loss: 0.7389 - val_acc: 0.7656\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8527 - acc: 0.7143 - val_loss: 0.7324 - val_acc: 0.7664\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8618 - acc: 0.7091 - val_loss: 0.7348 - val_acc: 0.7641\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8579 - acc: 0.7020 - val_loss: 0.7267 - val_acc: 0.7686\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8383 - acc: 0.7199 - val_loss: 0.7261 - val_acc: 0.7693\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8463 - acc: 0.7117 - val_loss: 0.7288 - val_acc: 0.7693\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8409 - acc: 0.7135 - val_loss: 0.7261 - val_acc: 0.7664\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8466 - acc: 0.7325 - val_loss: 0.7242 - val_acc: 0.7679\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8315 - acc: 0.7221 - val_loss: 0.7209 - val_acc: 0.7679\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8437 - acc: 0.7210 - val_loss: 0.7205 - val_acc: 0.7679\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8296 - acc: 0.7303 - val_loss: 0.7159 - val_acc: 0.7649\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8265 - acc: 0.7236 - val_loss: 0.7164 - val_acc: 0.7656\n",
      "Epoch 47/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8179 - acc: 0.7281 - val_loss: 0.7121 - val_acc: 0.7701\n",
      "Epoch 48/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8339 - acc: 0.7210 - val_loss: 0.7130 - val_acc: 0.7716\n",
      "Epoch 49/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8434 - acc: 0.7236 - val_loss: 0.7109 - val_acc: 0.7671\n",
      "Epoch 50/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8182 - acc: 0.7243 - val_loss: 0.7069 - val_acc: 0.7723\n",
      "Epoch 51/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8219 - acc: 0.7202 - val_loss: 0.7058 - val_acc: 0.7708\n",
      "Epoch 52/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8135 - acc: 0.7273 - val_loss: 0.7051 - val_acc: 0.7723\n",
      "Epoch 53/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8070 - acc: 0.7254 - val_loss: 0.7052 - val_acc: 0.7708\n",
      "Epoch 54/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8163 - acc: 0.7221 - val_loss: 0.7041 - val_acc: 0.7671\n",
      "Epoch 55/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8195 - acc: 0.7247 - val_loss: 0.7006 - val_acc: 0.7723\n",
      "Epoch 56/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.8085 - acc: 0.7273 - val_loss: 0.7021 - val_acc: 0.7686\n",
      "Epoch 57/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8051 - acc: 0.7281 - val_loss: 0.7019 - val_acc: 0.7731\n",
      "Epoch 58/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8148 - acc: 0.7236 - val_loss: 0.6980 - val_acc: 0.7746\n",
      "Epoch 59/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7985 - acc: 0.7199 - val_loss: 0.6955 - val_acc: 0.7716\n",
      "Epoch 60/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8003 - acc: 0.7288 - val_loss: 0.6976 - val_acc: 0.7731\n",
      "Epoch 61/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7995 - acc: 0.7303 - val_loss: 0.6963 - val_acc: 0.7738\n",
      "Epoch 62/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7921 - acc: 0.7318 - val_loss: 0.6913 - val_acc: 0.7753\n",
      "Epoch 63/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8040 - acc: 0.7273 - val_loss: 0.6951 - val_acc: 0.7746\n",
      "Epoch 64/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7989 - acc: 0.7284 - val_loss: 0.6954 - val_acc: 0.7738\n",
      "Epoch 65/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7934 - acc: 0.7307 - val_loss: 0.6937 - val_acc: 0.7746\n",
      "\n",
      "Epoch 00065: loss improved from inf to 0.79337, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-1-000065-0.793365-0.774554.hdf5\n",
      "Epoch 66/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7952 - acc: 0.7251 - val_loss: 0.6938 - val_acc: 0.7708\n",
      "Epoch 67/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7956 - acc: 0.7325 - val_loss: 0.6923 - val_acc: 0.7746\n",
      "Epoch 68/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8049 - acc: 0.7232 - val_loss: 0.6923 - val_acc: 0.7760\n",
      "Epoch 69/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7987 - acc: 0.7251 - val_loss: 0.6902 - val_acc: 0.7746\n",
      "Epoch 70/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7772 - acc: 0.7325 - val_loss: 0.6898 - val_acc: 0.7731\n",
      "Epoch 71/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7891 - acc: 0.7225 - val_loss: 0.6894 - val_acc: 0.7738\n",
      "Epoch 72/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7869 - acc: 0.7292 - val_loss: 0.6893 - val_acc: 0.7731\n",
      "Epoch 73/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7902 - acc: 0.7295 - val_loss: 0.6889 - val_acc: 0.7716\n",
      "\n",
      "Epoch 00073: loss improved from 0.79337 to 0.79018, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-1-000073-0.790178-0.771577.hdf5\n",
      "Epoch 74/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7887 - acc: 0.7295 - val_loss: 0.6872 - val_acc: 0.7760\n",
      "Epoch 75/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7799 - acc: 0.7388 - val_loss: 0.6824 - val_acc: 0.7753\n",
      "Epoch 76/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7803 - acc: 0.7269 - val_loss: 0.6819 - val_acc: 0.7746\n",
      "Epoch 77/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7819 - acc: 0.7281 - val_loss: 0.6825 - val_acc: 0.7738\n",
      "\n",
      "Epoch 00077: loss improved from 0.79018 to 0.78190, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-1-000077-0.781905-0.773810.hdf5\n",
      "Epoch 78/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7847 - acc: 0.7437 - val_loss: 0.6804 - val_acc: 0.7738\n",
      "Epoch 79/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7632 - acc: 0.7340 - val_loss: 0.6815 - val_acc: 0.7716\n",
      "Epoch 80/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7921 - acc: 0.7333 - val_loss: 0.6773 - val_acc: 0.7753\n",
      "Epoch 81/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7731 - acc: 0.7388 - val_loss: 0.6804 - val_acc: 0.7746\n",
      "\n",
      "Epoch 00081: loss improved from 0.78190 to 0.77310, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-1-000081-0.773102-0.774554.hdf5\n",
      "Epoch 82/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7988 - acc: 0.7240 - val_loss: 0.6791 - val_acc: 0.7760\n",
      "Epoch 83/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7816 - acc: 0.7206 - val_loss: 0.6790 - val_acc: 0.7753\n",
      "Epoch 84/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7931 - acc: 0.7228 - val_loss: 0.6753 - val_acc: 0.7760\n",
      "Epoch 85/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7819 - acc: 0.7273 - val_loss: 0.6779 - val_acc: 0.7723\n",
      "Epoch 86/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7935 - acc: 0.7202 - val_loss: 0.6794 - val_acc: 0.7746\n",
      "Epoch 87/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7791 - acc: 0.7314 - val_loss: 0.6781 - val_acc: 0.7738\n",
      "Epoch 88/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7747 - acc: 0.7281 - val_loss: 0.6753 - val_acc: 0.7746\n",
      "Epoch 89/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7530 - acc: 0.7392 - val_loss: 0.6764 - val_acc: 0.7760\n",
      "\n",
      "Epoch 00089: loss improved from 0.77310 to 0.75299, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-1-000089-0.752991-0.776042.hdf5\n",
      "Epoch 90/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7717 - acc: 0.7292 - val_loss: 0.6776 - val_acc: 0.7738\n",
      "Epoch 91/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7800 - acc: 0.7377 - val_loss: 0.6754 - val_acc: 0.7760\n",
      "Epoch 92/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7736 - acc: 0.7310 - val_loss: 0.6758 - val_acc: 0.7738\n",
      "Epoch 93/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7683 - acc: 0.7299 - val_loss: 0.6743 - val_acc: 0.7738\n",
      "Epoch 94/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7751 - acc: 0.7370 - val_loss: 0.6745 - val_acc: 0.7716\n",
      "Epoch 95/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7683 - acc: 0.7355 - val_loss: 0.6730 - val_acc: 0.7753\n",
      "Epoch 96/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7738 - acc: 0.7355 - val_loss: 0.6729 - val_acc: 0.7731\n",
      "Epoch 97/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7626 - acc: 0.7370 - val_loss: 0.6721 - val_acc: 0.7731\n",
      "Epoch 98/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7737 - acc: 0.7329 - val_loss: 0.6694 - val_acc: 0.7760\n",
      "Epoch 99/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7708 - acc: 0.7299 - val_loss: 0.6709 - val_acc: 0.7746\n",
      "Epoch 100/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7598 - acc: 0.7370 - val_loss: 0.6724 - val_acc: 0.7716\n",
      "\n",
      "Epoch 00100: saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/1-000100-0.759834-0.771577.hdf5\n",
      "Epoch 101/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7650 - acc: 0.7340 - val_loss: 0.6730 - val_acc: 0.7746\n",
      "Epoch 102/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7645 - acc: 0.7321 - val_loss: 0.6734 - val_acc: 0.7746\n",
      "Epoch 103/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7562 - acc: 0.7266 - val_loss: 0.6707 - val_acc: 0.7753\n",
      "Epoch 104/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7648 - acc: 0.7292 - val_loss: 0.6726 - val_acc: 0.7731\n",
      "Epoch 105/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7637 - acc: 0.7340 - val_loss: 0.6711 - val_acc: 0.7775\n",
      "Epoch 106/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7594 - acc: 0.7355 - val_loss: 0.6708 - val_acc: 0.7753\n",
      "Epoch 107/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7534 - acc: 0.7370 - val_loss: 0.6716 - val_acc: 0.7760\n",
      "Epoch 108/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7524 - acc: 0.7370 - val_loss: 0.6701 - val_acc: 0.7753\n",
      "Epoch 109/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7665 - acc: 0.7362 - val_loss: 0.6678 - val_acc: 0.7746\n",
      "Epoch 110/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7589 - acc: 0.7347 - val_loss: 0.6689 - val_acc: 0.7746\n",
      "Epoch 111/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7786 - acc: 0.7292 - val_loss: 0.6681 - val_acc: 0.7753\n",
      "Epoch 112/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7678 - acc: 0.7392 - val_loss: 0.6699 - val_acc: 0.7768\n",
      "Epoch 113/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7546 - acc: 0.7388 - val_loss: 0.6685 - val_acc: 0.7753\n",
      "Epoch 114/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7597 - acc: 0.7347 - val_loss: 0.6654 - val_acc: 0.7768\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7544 - acc: 0.7370 - val_loss: 0.6648 - val_acc: 0.7775\n",
      "Epoch 116/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7501 - acc: 0.7351 - val_loss: 0.6685 - val_acc: 0.7731\n",
      "Epoch 117/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7557 - acc: 0.7374 - val_loss: 0.6681 - val_acc: 0.7768\n",
      "Epoch 118/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7409 - acc: 0.7411 - val_loss: 0.6663 - val_acc: 0.7760\n",
      "Epoch 119/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7482 - acc: 0.7377 - val_loss: 0.6665 - val_acc: 0.7753\n",
      "Epoch 120/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7560 - acc: 0.7310 - val_loss: 0.6644 - val_acc: 0.7746\n",
      "Epoch 121/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7494 - acc: 0.7403 - val_loss: 0.6648 - val_acc: 0.7753\n",
      "Epoch 122/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7391 - acc: 0.7344 - val_loss: 0.6653 - val_acc: 0.7760\n",
      "Epoch 123/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7443 - acc: 0.7470 - val_loss: 0.6660 - val_acc: 0.7746\n",
      "Epoch 124/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7382 - acc: 0.7440 - val_loss: 0.6643 - val_acc: 0.7760\n",
      "Epoch 125/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7295 - acc: 0.7467 - val_loss: 0.6649 - val_acc: 0.7760\n",
      "Epoch 126/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7562 - acc: 0.7388 - val_loss: 0.6636 - val_acc: 0.7738\n",
      "Epoch 127/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7361 - acc: 0.7422 - val_loss: 0.6576 - val_acc: 0.7775\n",
      "Epoch 128/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7372 - acc: 0.7414 - val_loss: 0.6619 - val_acc: 0.7760\n",
      "Epoch 129/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7510 - acc: 0.7359 - val_loss: 0.6643 - val_acc: 0.7760\n",
      "Epoch 130/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7454 - acc: 0.7381 - val_loss: 0.6655 - val_acc: 0.7775\n",
      "Epoch 131/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7334 - acc: 0.7422 - val_loss: 0.6601 - val_acc: 0.7790\n",
      "Epoch 132/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7427 - acc: 0.7362 - val_loss: 0.6616 - val_acc: 0.7768\n",
      "Epoch 133/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7513 - acc: 0.7388 - val_loss: 0.6573 - val_acc: 0.7798\n",
      "Epoch 134/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7403 - acc: 0.7429 - val_loss: 0.6607 - val_acc: 0.7798\n",
      "Epoch 135/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7387 - acc: 0.7444 - val_loss: 0.6611 - val_acc: 0.7783\n",
      "Epoch 136/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7653 - acc: 0.7333 - val_loss: 0.6604 - val_acc: 0.7768\n",
      "Epoch 137/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7484 - acc: 0.7370 - val_loss: 0.6614 - val_acc: 0.7783\n",
      "Epoch 138/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7579 - acc: 0.7433 - val_loss: 0.6610 - val_acc: 0.7768\n",
      "Epoch 139/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7620 - acc: 0.7310 - val_loss: 0.6604 - val_acc: 0.7790\n",
      "Epoch 140/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7493 - acc: 0.7414 - val_loss: 0.6603 - val_acc: 0.7805\n",
      "Epoch 141/1000\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 0.7534 - acc: 0.7336 - val_loss: 0.6595 - val_acc: 0.7805\n",
      "Epoch 142/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7263 - acc: 0.7444 - val_loss: 0.6591 - val_acc: 0.7790\n",
      "Epoch 143/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7486 - acc: 0.7388 - val_loss: 0.6611 - val_acc: 0.7783\n",
      "Epoch 144/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7546 - acc: 0.7351 - val_loss: 0.6609 - val_acc: 0.7768\n",
      "Epoch 145/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7558 - acc: 0.7333 - val_loss: 0.6572 - val_acc: 0.7790\n",
      "Epoch 146/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7387 - acc: 0.7396 - val_loss: 0.6589 - val_acc: 0.7775\n",
      "Epoch 147/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7426 - acc: 0.7310 - val_loss: 0.6580 - val_acc: 0.7783\n",
      "Epoch 148/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7244 - acc: 0.7470 - val_loss: 0.6576 - val_acc: 0.7790\n",
      "Epoch 149/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7393 - acc: 0.7381 - val_loss: 0.6595 - val_acc: 0.7790\n",
      "Epoch 150/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7338 - acc: 0.7403 - val_loss: 0.6580 - val_acc: 0.7783\n",
      "Epoch 151/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7367 - acc: 0.7448 - val_loss: 0.6558 - val_acc: 0.7798\n",
      "Epoch 152/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7341 - acc: 0.7489 - val_loss: 0.6582 - val_acc: 0.7798\n",
      "Epoch 153/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7527 - acc: 0.7433 - val_loss: 0.6579 - val_acc: 0.7790\n",
      "Epoch 154/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7245 - acc: 0.7422 - val_loss: 0.6586 - val_acc: 0.7790\n",
      "Epoch 155/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7331 - acc: 0.7541 - val_loss: 0.6592 - val_acc: 0.7790\n",
      "Epoch 156/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7237 - acc: 0.7515 - val_loss: 0.6570 - val_acc: 0.7790\n",
      "Epoch 157/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7366 - acc: 0.7418 - val_loss: 0.6592 - val_acc: 0.7790\n",
      "Epoch 158/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7380 - acc: 0.7426 - val_loss: 0.6574 - val_acc: 0.7783\n",
      "Epoch 159/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7299 - acc: 0.7422 - val_loss: 0.6557 - val_acc: 0.7783\n",
      "Epoch 160/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7381 - acc: 0.7411 - val_loss: 0.6507 - val_acc: 0.7790\n",
      "Epoch 161/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7464 - acc: 0.7385 - val_loss: 0.6554 - val_acc: 0.7775\n",
      "Epoch 162/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7358 - acc: 0.7381 - val_loss: 0.6563 - val_acc: 0.7805\n",
      "Epoch 163/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7235 - acc: 0.7433 - val_loss: 0.6531 - val_acc: 0.7798\n",
      "Epoch 164/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7366 - acc: 0.7374 - val_loss: 0.6540 - val_acc: 0.7798\n",
      "Epoch 165/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7311 - acc: 0.7440 - val_loss: 0.6542 - val_acc: 0.7805\n",
      "\n",
      "Epoch 00165: loss improved from inf to 0.73110, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-1-000165-0.731104-0.780506.hdf5\n",
      "Epoch 166/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7226 - acc: 0.7474 - val_loss: 0.6564 - val_acc: 0.7820\n",
      "Epoch 167/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7337 - acc: 0.7455 - val_loss: 0.6531 - val_acc: 0.7820\n",
      "Epoch 168/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7277 - acc: 0.7470 - val_loss: 0.6533 - val_acc: 0.7820\n",
      "Epoch 169/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7407 - acc: 0.7351 - val_loss: 0.6496 - val_acc: 0.7812\n",
      "Epoch 170/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7396 - acc: 0.7418 - val_loss: 0.6530 - val_acc: 0.7812\n",
      "Epoch 171/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7137 - acc: 0.7489 - val_loss: 0.6521 - val_acc: 0.7827\n",
      "Epoch 172/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7257 - acc: 0.7392 - val_loss: 0.6524 - val_acc: 0.7805\n",
      "Epoch 173/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7318 - acc: 0.7437 - val_loss: 0.6539 - val_acc: 0.7805\n",
      "Epoch 174/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7301 - acc: 0.7411 - val_loss: 0.6485 - val_acc: 0.7812\n",
      "Epoch 175/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7380 - acc: 0.7385 - val_loss: 0.6525 - val_acc: 0.7790\n",
      "Epoch 176/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7285 - acc: 0.7400 - val_loss: 0.6518 - val_acc: 0.7798\n",
      "Epoch 177/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7341 - acc: 0.7459 - val_loss: 0.6513 - val_acc: 0.7798\n",
      "Epoch 178/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7319 - acc: 0.7489 - val_loss: 0.6480 - val_acc: 0.7827\n",
      "Epoch 179/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7305 - acc: 0.7455 - val_loss: 0.6537 - val_acc: 0.7820\n",
      "Epoch 180/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7301 - acc: 0.7478 - val_loss: 0.6521 - val_acc: 0.7842\n",
      "Epoch 181/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7280 - acc: 0.7440 - val_loss: 0.6512 - val_acc: 0.7805\n",
      "\n",
      "Epoch 00181: loss improved from 0.73110 to 0.72803, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-1-000181-0.728033-0.780506.hdf5\n",
      "Epoch 182/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7346 - acc: 0.7374 - val_loss: 0.6517 - val_acc: 0.7835\n",
      "Epoch 183/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7284 - acc: 0.7537 - val_loss: 0.6516 - val_acc: 0.7805\n",
      "Epoch 184/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7470 - acc: 0.7455 - val_loss: 0.6525 - val_acc: 0.7798\n",
      "Epoch 185/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7224 - acc: 0.7403 - val_loss: 0.6507 - val_acc: 0.7842\n",
      "\n",
      "Epoch 00185: loss improved from 0.72803 to 0.72242, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-1-000185-0.722417-0.784226.hdf5\n",
      "Epoch 186/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7273 - acc: 0.7478 - val_loss: 0.6509 - val_acc: 0.7835\n",
      "Epoch 187/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7217 - acc: 0.7481 - val_loss: 0.6501 - val_acc: 0.7835\n",
      "Epoch 188/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7236 - acc: 0.7496 - val_loss: 0.6479 - val_acc: 0.7827\n",
      "Epoch 189/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7223 - acc: 0.7519 - val_loss: 0.6494 - val_acc: 0.7842\n",
      "\n",
      "Epoch 00189: loss improved from 0.72242 to 0.72225, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-1-000189-0.722253-0.784226.hdf5\n",
      "Epoch 190/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7217 - acc: 0.7489 - val_loss: 0.6515 - val_acc: 0.7835\n",
      "Epoch 191/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7267 - acc: 0.7496 - val_loss: 0.6483 - val_acc: 0.7835\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 192/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7109 - acc: 0.7489 - val_loss: 0.6488 - val_acc: 0.7827\n",
      "Epoch 193/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7223 - acc: 0.7537 - val_loss: 0.6476 - val_acc: 0.7835\n",
      "Epoch 194/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7382 - acc: 0.7347 - val_loss: 0.6437 - val_acc: 0.7835\n",
      "Epoch 195/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7192 - acc: 0.7530 - val_loss: 0.6486 - val_acc: 0.7827\n",
      "Epoch 196/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7201 - acc: 0.7485 - val_loss: 0.6480 - val_acc: 0.7850\n",
      "Epoch 197/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7274 - acc: 0.7522 - val_loss: 0.6490 - val_acc: 0.7820\n",
      "Epoch 198/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7193 - acc: 0.7478 - val_loss: 0.6489 - val_acc: 0.7827\n",
      "Epoch 199/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7310 - acc: 0.7455 - val_loss: 0.6497 - val_acc: 0.7820\n",
      "Epoch 200/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.7001 - acc: 0.7504 - val_loss: 0.6500 - val_acc: 0.7827\n",
      "\n",
      "Epoch 00200: saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/1-000200-0.700117-0.782738.hdf5\n",
      "Epoch 201/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7314 - acc: 0.7474 - val_loss: 0.6491 - val_acc: 0.7812\n",
      "Epoch 202/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7070 - acc: 0.7548 - val_loss: 0.6491 - val_acc: 0.7835\n",
      "Epoch 203/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7203 - acc: 0.7526 - val_loss: 0.6496 - val_acc: 0.7835\n",
      "Epoch 204/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7265 - acc: 0.7429 - val_loss: 0.6504 - val_acc: 0.7827\n",
      "Epoch 205/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.7290 - acc: 0.7455 - val_loss: 0.6497 - val_acc: 0.7835\n",
      "Epoch 206/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7211 - acc: 0.7504 - val_loss: 0.6508 - val_acc: 0.7835\n",
      "Epoch 207/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7140 - acc: 0.7429 - val_loss: 0.6508 - val_acc: 0.7835\n",
      "Epoch 208/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7276 - acc: 0.7470 - val_loss: 0.6505 - val_acc: 0.7842\n",
      "Epoch 209/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7142 - acc: 0.7515 - val_loss: 0.6507 - val_acc: 0.7842\n",
      "Epoch 210/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7160 - acc: 0.7519 - val_loss: 0.6501 - val_acc: 0.7820\n",
      "Epoch 211/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7225 - acc: 0.7459 - val_loss: 0.6502 - val_acc: 0.7835\n",
      "Epoch 212/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7207 - acc: 0.7467 - val_loss: 0.6506 - val_acc: 0.7820\n",
      "Epoch 213/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7215 - acc: 0.7541 - val_loss: 0.6501 - val_acc: 0.7820\n",
      "Epoch 214/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7279 - acc: 0.7403 - val_loss: 0.6489 - val_acc: 0.7827\n",
      "Epoch 215/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7256 - acc: 0.7478 - val_loss: 0.6485 - val_acc: 0.7850\n",
      "Epoch 216/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7240 - acc: 0.7485 - val_loss: 0.6501 - val_acc: 0.7850\n",
      "Epoch 217/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7141 - acc: 0.7560 - val_loss: 0.6510 - val_acc: 0.7827\n",
      "Epoch 218/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7285 - acc: 0.7362 - val_loss: 0.6486 - val_acc: 0.7827\n",
      "Epoch 219/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7291 - acc: 0.7507 - val_loss: 0.6501 - val_acc: 0.7835\n",
      "Epoch 220/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7161 - acc: 0.7459 - val_loss: 0.6494 - val_acc: 0.7850\n",
      "\n",
      "Epoch 00220: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 221/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7135 - acc: 0.7467 - val_loss: 0.6491 - val_acc: 0.7850\n",
      "Epoch 222/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7299 - acc: 0.7407 - val_loss: 0.6507 - val_acc: 0.7842\n",
      "Epoch 223/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7181 - acc: 0.7485 - val_loss: 0.6508 - val_acc: 0.7842\n",
      "Epoch 224/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7289 - acc: 0.7515 - val_loss: 0.6511 - val_acc: 0.7842\n",
      "Epoch 225/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7212 - acc: 0.7459 - val_loss: 0.6465 - val_acc: 0.7850\n",
      "Epoch 226/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7238 - acc: 0.7452 - val_loss: 0.6505 - val_acc: 0.7835\n",
      "Epoch 227/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7293 - acc: 0.7422 - val_loss: 0.6496 - val_acc: 0.7842\n",
      "Epoch 228/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7269 - acc: 0.7481 - val_loss: 0.6512 - val_acc: 0.7835\n",
      "Epoch 229/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7246 - acc: 0.7429 - val_loss: 0.6493 - val_acc: 0.7842\n",
      "Epoch 230/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7258 - acc: 0.7411 - val_loss: 0.6503 - val_acc: 0.7835\n",
      "Epoch 231/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7055 - acc: 0.7530 - val_loss: 0.6472 - val_acc: 0.7850\n",
      "Epoch 232/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7199 - acc: 0.7452 - val_loss: 0.6500 - val_acc: 0.7842\n",
      "Epoch 233/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7245 - acc: 0.7474 - val_loss: 0.6499 - val_acc: 0.7842\n",
      "Epoch 234/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7228 - acc: 0.7459 - val_loss: 0.6476 - val_acc: 0.7850\n",
      "Epoch 235/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7205 - acc: 0.7533 - val_loss: 0.6469 - val_acc: 0.7850\n",
      "Epoch 236/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7277 - acc: 0.7448 - val_loss: 0.6507 - val_acc: 0.7835\n",
      "Epoch 237/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7346 - acc: 0.7429 - val_loss: 0.6492 - val_acc: 0.7842\n",
      "Epoch 238/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7272 - acc: 0.7448 - val_loss: 0.6502 - val_acc: 0.7835\n",
      "Epoch 239/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7378 - acc: 0.7548 - val_loss: 0.6434 - val_acc: 0.7857\n",
      "Epoch 240/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7324 - acc: 0.7448 - val_loss: 0.6502 - val_acc: 0.7835\n",
      "\n",
      "Epoch 00240: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 241/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7304 - acc: 0.7440 - val_loss: 0.6498 - val_acc: 0.7842\n",
      "Epoch 242/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7162 - acc: 0.7426 - val_loss: 0.6502 - val_acc: 0.7835\n",
      "Epoch 243/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7322 - acc: 0.7485 - val_loss: 0.6473 - val_acc: 0.7850\n",
      "Epoch 244/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7153 - acc: 0.7463 - val_loss: 0.6501 - val_acc: 0.7835\n",
      "Epoch 245/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7432 - acc: 0.7407 - val_loss: 0.6500 - val_acc: 0.7842\n",
      "Epoch 246/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7265 - acc: 0.7481 - val_loss: 0.6510 - val_acc: 0.7835\n",
      "Epoch 247/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7338 - acc: 0.7470 - val_loss: 0.6488 - val_acc: 0.7842\n",
      "Epoch 248/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7097 - acc: 0.7493 - val_loss: 0.6488 - val_acc: 0.7842\n",
      "Epoch 249/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7165 - acc: 0.7467 - val_loss: 0.6500 - val_acc: 0.7835\n",
      "Epoch 250/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7162 - acc: 0.7556 - val_loss: 0.6506 - val_acc: 0.7835\n",
      "Epoch 251/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.7395 - acc: 0.7392 - val_loss: 0.6477 - val_acc: 0.7850\n",
      "Epoch 252/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7248 - acc: 0.7437 - val_loss: 0.6499 - val_acc: 0.7842\n",
      "Epoch 253/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7357 - acc: 0.7414 - val_loss: 0.6480 - val_acc: 0.7842\n",
      "Epoch 254/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7154 - acc: 0.7500 - val_loss: 0.6494 - val_acc: 0.7842\n",
      "Epoch 255/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7162 - acc: 0.7548 - val_loss: 0.6497 - val_acc: 0.7842\n",
      "Epoch 256/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7297 - acc: 0.7437 - val_loss: 0.6483 - val_acc: 0.7850\n",
      "Epoch 257/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7179 - acc: 0.7545 - val_loss: 0.6490 - val_acc: 0.7850\n",
      "Epoch 258/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7244 - acc: 0.7422 - val_loss: 0.6495 - val_acc: 0.7842\n",
      "Epoch 259/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7277 - acc: 0.7511 - val_loss: 0.6502 - val_acc: 0.7835\n",
      "Epoch 260/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7213 - acc: 0.7485 - val_loss: 0.6484 - val_acc: 0.7842\n",
      "Epoch 261/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7086 - acc: 0.7560 - val_loss: 0.6508 - val_acc: 0.7835\n",
      "Epoch 262/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7190 - acc: 0.7485 - val_loss: 0.6500 - val_acc: 0.7835\n",
      "Epoch 263/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7082 - acc: 0.7496 - val_loss: 0.6501 - val_acc: 0.7842\n",
      "Epoch 264/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7274 - acc: 0.7422 - val_loss: 0.6503 - val_acc: 0.7835\n",
      "Epoch 265/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7282 - acc: 0.7429 - val_loss: 0.6463 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00265: loss improved from inf to 0.72817, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-1-000265-0.728171-0.785714.hdf5\n",
      "Epoch 266/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7231 - acc: 0.7437 - val_loss: 0.6497 - val_acc: 0.7842\n",
      "Epoch 267/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7224 - acc: 0.7474 - val_loss: 0.6483 - val_acc: 0.7850\n",
      "Epoch 268/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7262 - acc: 0.7493 - val_loss: 0.6509 - val_acc: 0.7835\n",
      "Epoch 269/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7100 - acc: 0.7522 - val_loss: 0.6478 - val_acc: 0.7850\n",
      "\n",
      "Epoch 00269: loss improved from 0.72817 to 0.71004, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-1-000269-0.710036-0.784970.hdf5\n",
      "Epoch 270/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7207 - acc: 0.7474 - val_loss: 0.6507 - val_acc: 0.7835\n",
      "Epoch 271/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7167 - acc: 0.7426 - val_loss: 0.6506 - val_acc: 0.7835\n",
      "Epoch 272/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7061 - acc: 0.7526 - val_loss: 0.6474 - val_acc: 0.7842\n",
      "Epoch 273/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7155 - acc: 0.7507 - val_loss: 0.6478 - val_acc: 0.7850\n",
      "Epoch 274/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7307 - acc: 0.7444 - val_loss: 0.6489 - val_acc: 0.7842\n",
      "Epoch 275/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6997 - acc: 0.7504 - val_loss: 0.6499 - val_acc: 0.7842\n",
      "Epoch 276/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7236 - acc: 0.7433 - val_loss: 0.6474 - val_acc: 0.7857\n",
      "Epoch 277/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7218 - acc: 0.7496 - val_loss: 0.6506 - val_acc: 0.7835\n",
      "Epoch 278/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7265 - acc: 0.7422 - val_loss: 0.6477 - val_acc: 0.7850\n",
      "Epoch 279/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7234 - acc: 0.7444 - val_loss: 0.6501 - val_acc: 0.7835\n",
      "Epoch 280/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7139 - acc: 0.7500 - val_loss: 0.6509 - val_acc: 0.7835\n",
      "Epoch 281/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7325 - acc: 0.7400 - val_loss: 0.6490 - val_acc: 0.7850\n",
      "Epoch 282/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7262 - acc: 0.7448 - val_loss: 0.6488 - val_acc: 0.7842\n",
      "Epoch 283/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7209 - acc: 0.7429 - val_loss: 0.6494 - val_acc: 0.7835\n",
      "Epoch 284/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7276 - acc: 0.7440 - val_loss: 0.6492 - val_acc: 0.7850\n",
      "Epoch 285/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7088 - acc: 0.7545 - val_loss: 0.6503 - val_acc: 0.7835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00285: loss improved from 0.71004 to 0.70879, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-1-000285-0.708792-0.783482.hdf5\n",
      "Epoch 286/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7126 - acc: 0.7578 - val_loss: 0.6501 - val_acc: 0.7835\n",
      "Epoch 287/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7218 - acc: 0.7444 - val_loss: 0.6470 - val_acc: 0.7850\n",
      "Epoch 288/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7215 - acc: 0.7552 - val_loss: 0.6490 - val_acc: 0.7842\n",
      "Epoch 289/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7388 - acc: 0.7392 - val_loss: 0.6497 - val_acc: 0.7842\n",
      "Epoch 290/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7167 - acc: 0.7474 - val_loss: 0.6496 - val_acc: 0.7842\n",
      "Epoch 291/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7244 - acc: 0.7429 - val_loss: 0.6497 - val_acc: 0.7835\n",
      "Epoch 292/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7264 - acc: 0.7556 - val_loss: 0.6488 - val_acc: 0.7842\n",
      "Epoch 293/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7325 - acc: 0.7444 - val_loss: 0.6494 - val_acc: 0.7842\n",
      "Epoch 294/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7117 - acc: 0.7440 - val_loss: 0.6492 - val_acc: 0.7850\n",
      "Epoch 295/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7225 - acc: 0.7507 - val_loss: 0.6482 - val_acc: 0.7850\n",
      "Epoch 296/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7109 - acc: 0.7541 - val_loss: 0.6498 - val_acc: 0.7835\n",
      "Epoch 297/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7113 - acc: 0.7537 - val_loss: 0.6493 - val_acc: 0.7842\n",
      "Epoch 298/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7224 - acc: 0.7440 - val_loss: 0.6502 - val_acc: 0.7835\n",
      "Epoch 299/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7216 - acc: 0.7504 - val_loss: 0.6490 - val_acc: 0.7842\n",
      "Epoch 300/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7410 - acc: 0.7385 - val_loss: 0.6488 - val_acc: 0.7842\n",
      "\n",
      "Epoch 00300: saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/1-000300-0.741021-0.784226.hdf5\n",
      "Epoch 301/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7264 - acc: 0.7522 - val_loss: 0.6504 - val_acc: 0.7835\n",
      "Epoch 302/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7341 - acc: 0.7448 - val_loss: 0.6493 - val_acc: 0.7842\n",
      "Epoch 303/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7209 - acc: 0.7511 - val_loss: 0.6494 - val_acc: 0.7842\n",
      "Epoch 304/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7322 - acc: 0.7385 - val_loss: 0.6484 - val_acc: 0.7850\n",
      "Epoch 305/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7259 - acc: 0.7448 - val_loss: 0.6493 - val_acc: 0.7842\n",
      "Epoch 306/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7276 - acc: 0.7470 - val_loss: 0.6499 - val_acc: 0.7835\n",
      "Epoch 307/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7172 - acc: 0.7507 - val_loss: 0.6507 - val_acc: 0.7835\n",
      "Epoch 308/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7202 - acc: 0.7530 - val_loss: 0.6490 - val_acc: 0.7842\n",
      "Epoch 309/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7248 - acc: 0.7526 - val_loss: 0.6488 - val_acc: 0.7842\n",
      "Epoch 310/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7229 - acc: 0.7422 - val_loss: 0.6489 - val_acc: 0.7842\n",
      "Epoch 311/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7210 - acc: 0.7489 - val_loss: 0.6489 - val_acc: 0.7842\n",
      "Epoch 312/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7290 - acc: 0.7459 - val_loss: 0.6476 - val_acc: 0.7850\n",
      "Epoch 313/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7314 - acc: 0.7433 - val_loss: 0.6493 - val_acc: 0.7842\n",
      "Epoch 314/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7333 - acc: 0.7485 - val_loss: 0.6483 - val_acc: 0.7842\n",
      "Epoch 315/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7184 - acc: 0.7548 - val_loss: 0.6454 - val_acc: 0.7850\n",
      "Epoch 316/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7317 - acc: 0.7403 - val_loss: 0.6499 - val_acc: 0.7842\n",
      "Epoch 317/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7185 - acc: 0.7496 - val_loss: 0.6498 - val_acc: 0.7842\n",
      "Epoch 318/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7259 - acc: 0.7481 - val_loss: 0.6493 - val_acc: 0.7842\n",
      "Epoch 319/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7297 - acc: 0.7530 - val_loss: 0.6503 - val_acc: 0.7835\n",
      "Epoch 320/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7141 - acc: 0.7519 - val_loss: 0.6504 - val_acc: 0.7835\n",
      "Epoch 321/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7286 - acc: 0.7385 - val_loss: 0.6496 - val_acc: 0.7842\n",
      "Epoch 322/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7269 - acc: 0.7444 - val_loss: 0.6485 - val_acc: 0.7850\n",
      "Epoch 323/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7107 - acc: 0.7515 - val_loss: 0.6499 - val_acc: 0.7835\n",
      "Epoch 324/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7117 - acc: 0.7526 - val_loss: 0.6507 - val_acc: 0.7835\n",
      "Epoch 325/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7293 - acc: 0.7504 - val_loss: 0.6479 - val_acc: 0.7842\n",
      "Epoch 326/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7182 - acc: 0.7537 - val_loss: 0.6481 - val_acc: 0.7842\n",
      "Epoch 327/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7112 - acc: 0.7530 - val_loss: 0.6484 - val_acc: 0.7842\n",
      "Epoch 328/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7277 - acc: 0.7493 - val_loss: 0.6475 - val_acc: 0.7842\n",
      "Epoch 329/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7166 - acc: 0.7485 - val_loss: 0.6498 - val_acc: 0.7842\n",
      "Epoch 330/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7280 - acc: 0.7485 - val_loss: 0.6483 - val_acc: 0.7850\n",
      "Epoch 331/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7072 - acc: 0.7504 - val_loss: 0.6501 - val_acc: 0.7835\n",
      "Epoch 332/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7133 - acc: 0.7500 - val_loss: 0.6473 - val_acc: 0.7850\n",
      "Epoch 333/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7203 - acc: 0.7474 - val_loss: 0.6500 - val_acc: 0.7842\n",
      "Epoch 334/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7372 - acc: 0.7310 - val_loss: 0.6467 - val_acc: 0.7857\n",
      "Epoch 335/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7114 - acc: 0.7533 - val_loss: 0.6506 - val_acc: 0.7835\n",
      "Epoch 336/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7246 - acc: 0.7452 - val_loss: 0.6502 - val_acc: 0.7835\n",
      "Epoch 337/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7237 - acc: 0.7504 - val_loss: 0.6489 - val_acc: 0.7842\n",
      "Epoch 338/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7185 - acc: 0.7493 - val_loss: 0.6498 - val_acc: 0.7842\n",
      "Epoch 339/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7319 - acc: 0.7455 - val_loss: 0.6497 - val_acc: 0.7835\n",
      "Epoch 340/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7242 - acc: 0.7474 - val_loss: 0.6496 - val_acc: 0.7842\n",
      "Epoch 341/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7162 - acc: 0.7511 - val_loss: 0.6482 - val_acc: 0.7842\n",
      "Epoch 342/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7098 - acc: 0.7563 - val_loss: 0.6503 - val_acc: 0.7835\n",
      "Epoch 343/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7186 - acc: 0.7500 - val_loss: 0.6491 - val_acc: 0.7842\n",
      "Epoch 344/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7181 - acc: 0.7440 - val_loss: 0.6492 - val_acc: 0.7842\n",
      "Epoch 345/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7246 - acc: 0.7485 - val_loss: 0.6494 - val_acc: 0.7835\n",
      "Epoch 346/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7151 - acc: 0.7489 - val_loss: 0.6486 - val_acc: 0.7850\n",
      "Epoch 347/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7257 - acc: 0.7448 - val_loss: 0.6496 - val_acc: 0.7835\n",
      "Epoch 348/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7269 - acc: 0.7429 - val_loss: 0.6497 - val_acc: 0.7842\n",
      "Epoch 349/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7222 - acc: 0.7467 - val_loss: 0.6479 - val_acc: 0.7857\n",
      "Epoch 350/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7144 - acc: 0.7444 - val_loss: 0.6496 - val_acc: 0.7842\n",
      "Epoch 351/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7219 - acc: 0.7433 - val_loss: 0.6495 - val_acc: 0.7842\n",
      "Epoch 352/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7144 - acc: 0.7522 - val_loss: 0.6509 - val_acc: 0.7835\n",
      "Epoch 353/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7174 - acc: 0.7533 - val_loss: 0.6507 - val_acc: 0.7835\n",
      "Epoch 354/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7222 - acc: 0.7496 - val_loss: 0.6504 - val_acc: 0.7835\n",
      "Epoch 355/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7343 - acc: 0.7507 - val_loss: 0.6508 - val_acc: 0.7835\n",
      "Epoch 356/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7146 - acc: 0.7556 - val_loss: 0.6490 - val_acc: 0.7842\n",
      "Epoch 357/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7302 - acc: 0.7433 - val_loss: 0.6483 - val_acc: 0.7850\n",
      "Epoch 358/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7357 - acc: 0.7392 - val_loss: 0.6472 - val_acc: 0.7850\n",
      "Epoch 359/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7235 - acc: 0.7519 - val_loss: 0.6484 - val_acc: 0.7850\n",
      "Epoch 360/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7017 - acc: 0.7578 - val_loss: 0.6499 - val_acc: 0.7835\n",
      "Epoch 361/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7217 - acc: 0.7511 - val_loss: 0.6490 - val_acc: 0.7842\n",
      "Epoch 362/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7075 - acc: 0.7500 - val_loss: 0.6467 - val_acc: 0.7850\n",
      "Epoch 363/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7317 - acc: 0.7455 - val_loss: 0.6490 - val_acc: 0.7842\n",
      "Epoch 364/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7107 - acc: 0.7496 - val_loss: 0.6490 - val_acc: 0.7842\n",
      "Epoch 365/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7165 - acc: 0.7522 - val_loss: 0.6496 - val_acc: 0.7835\n",
      "\n",
      "Epoch 00365: loss improved from inf to 0.71652, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-1-000365-0.716522-0.783482.hdf5\n",
      "Epoch 366/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7206 - acc: 0.7474 - val_loss: 0.6502 - val_acc: 0.7835\n",
      "Epoch 367/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7174 - acc: 0.7552 - val_loss: 0.6488 - val_acc: 0.7842\n",
      "Epoch 368/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7308 - acc: 0.7400 - val_loss: 0.6493 - val_acc: 0.7842\n",
      "Epoch 369/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7182 - acc: 0.7470 - val_loss: 0.6508 - val_acc: 0.7835\n",
      "Epoch 370/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7184 - acc: 0.7481 - val_loss: 0.6494 - val_acc: 0.7842\n",
      "Epoch 371/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7103 - acc: 0.7470 - val_loss: 0.6478 - val_acc: 0.7842\n",
      "Epoch 372/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7087 - acc: 0.7481 - val_loss: 0.6498 - val_acc: 0.7842\n",
      "Epoch 373/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7241 - acc: 0.7481 - val_loss: 0.6470 - val_acc: 0.7850\n",
      "Epoch 374/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7134 - acc: 0.7545 - val_loss: 0.6496 - val_acc: 0.7842\n",
      "Epoch 375/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7168 - acc: 0.7496 - val_loss: 0.6501 - val_acc: 0.7835\n",
      "Epoch 376/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7339 - acc: 0.7470 - val_loss: 0.6482 - val_acc: 0.7850\n",
      "Epoch 377/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7248 - acc: 0.7515 - val_loss: 0.6484 - val_acc: 0.7842\n",
      "Epoch 378/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7176 - acc: 0.7474 - val_loss: 0.6496 - val_acc: 0.7842\n",
      "Epoch 379/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7225 - acc: 0.7500 - val_loss: 0.6453 - val_acc: 0.7857\n",
      "Epoch 380/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7286 - acc: 0.7478 - val_loss: 0.6503 - val_acc: 0.7835\n",
      "Epoch 381/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7279 - acc: 0.7437 - val_loss: 0.6472 - val_acc: 0.7857\n",
      "Epoch 382/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7221 - acc: 0.7507 - val_loss: 0.6506 - val_acc: 0.7835\n",
      "Epoch 383/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7109 - acc: 0.7533 - val_loss: 0.6493 - val_acc: 0.7842\n",
      "Epoch 384/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7239 - acc: 0.7522 - val_loss: 0.6491 - val_acc: 0.7842\n",
      "Epoch 385/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7205 - acc: 0.7522 - val_loss: 0.6489 - val_acc: 0.7842\n",
      "Epoch 386/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7250 - acc: 0.7470 - val_loss: 0.6493 - val_acc: 0.7842\n",
      "Epoch 387/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7330 - acc: 0.7362 - val_loss: 0.6492 - val_acc: 0.7842\n",
      "Epoch 388/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7143 - acc: 0.7511 - val_loss: 0.6471 - val_acc: 0.7850\n",
      "Epoch 389/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7148 - acc: 0.7507 - val_loss: 0.6504 - val_acc: 0.7835\n",
      "\n",
      "Epoch 00389: loss improved from 0.71652 to 0.71484, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-1-000389-0.714837-0.783482.hdf5\n",
      "Epoch 390/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7123 - acc: 0.7511 - val_loss: 0.6501 - val_acc: 0.7842\n",
      "Epoch 391/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7189 - acc: 0.7515 - val_loss: 0.6438 - val_acc: 0.7857\n",
      "Epoch 392/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7332 - acc: 0.7474 - val_loss: 0.6498 - val_acc: 0.7842\n",
      "Epoch 393/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7349 - acc: 0.7370 - val_loss: 0.6482 - val_acc: 0.7850\n",
      "Epoch 394/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7332 - acc: 0.7444 - val_loss: 0.6499 - val_acc: 0.7835\n",
      "Epoch 395/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7300 - acc: 0.7452 - val_loss: 0.6496 - val_acc: 0.7835\n",
      "Epoch 396/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7167 - acc: 0.7504 - val_loss: 0.6480 - val_acc: 0.7842\n",
      "Epoch 397/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7208 - acc: 0.7388 - val_loss: 0.6503 - val_acc: 0.7835\n",
      "Epoch 398/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7269 - acc: 0.7426 - val_loss: 0.6504 - val_acc: 0.7835\n",
      "Epoch 399/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7358 - acc: 0.7467 - val_loss: 0.6488 - val_acc: 0.7850\n",
      "Epoch 400/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7076 - acc: 0.7500 - val_loss: 0.6461 - val_acc: 0.7842\n",
      "\n",
      "Epoch 00400: saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/1-000400-0.707592-0.784226.hdf5\n",
      "Epoch 401/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7256 - acc: 0.7496 - val_loss: 0.6503 - val_acc: 0.7835\n",
      "Epoch 402/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7254 - acc: 0.7504 - val_loss: 0.6441 - val_acc: 0.7842\n",
      "Epoch 403/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7201 - acc: 0.7426 - val_loss: 0.6470 - val_acc: 0.7850\n",
      "Epoch 404/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7099 - acc: 0.7444 - val_loss: 0.6505 - val_acc: 0.7835\n",
      "Epoch 405/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7299 - acc: 0.7444 - val_loss: 0.6504 - val_acc: 0.7835\n",
      "Epoch 406/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7138 - acc: 0.7548 - val_loss: 0.6478 - val_acc: 0.7850\n",
      "Epoch 407/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7130 - acc: 0.7452 - val_loss: 0.6499 - val_acc: 0.7842\n",
      "Epoch 408/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7197 - acc: 0.7455 - val_loss: 0.6505 - val_acc: 0.7835\n",
      "Epoch 409/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7306 - acc: 0.7440 - val_loss: 0.6467 - val_acc: 0.7842\n",
      "Epoch 410/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7293 - acc: 0.7481 - val_loss: 0.6476 - val_acc: 0.7842\n",
      "Epoch 411/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7240 - acc: 0.7478 - val_loss: 0.6509 - val_acc: 0.7835\n",
      "Epoch 412/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7263 - acc: 0.7452 - val_loss: 0.6502 - val_acc: 0.7842\n",
      "Epoch 413/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7177 - acc: 0.7448 - val_loss: 0.6505 - val_acc: 0.7835\n",
      "Epoch 414/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7205 - acc: 0.7452 - val_loss: 0.6493 - val_acc: 0.7842\n",
      "Epoch 415/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7234 - acc: 0.7459 - val_loss: 0.6481 - val_acc: 0.7842\n",
      "Epoch 416/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7220 - acc: 0.7522 - val_loss: 0.6494 - val_acc: 0.7842\n",
      "Epoch 417/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7177 - acc: 0.7507 - val_loss: 0.6507 - val_acc: 0.7835\n",
      "Epoch 418/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7245 - acc: 0.7463 - val_loss: 0.6501 - val_acc: 0.7835\n",
      "Epoch 419/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7313 - acc: 0.7504 - val_loss: 0.6494 - val_acc: 0.7842\n",
      "Epoch 420/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7080 - acc: 0.7522 - val_loss: 0.6484 - val_acc: 0.7842\n",
      "Epoch 421/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7356 - acc: 0.7429 - val_loss: 0.6501 - val_acc: 0.7835\n",
      "Epoch 422/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7194 - acc: 0.7470 - val_loss: 0.6506 - val_acc: 0.7835\n",
      "Epoch 423/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7163 - acc: 0.7500 - val_loss: 0.6501 - val_acc: 0.7835\n",
      "Epoch 424/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7255 - acc: 0.7474 - val_loss: 0.6497 - val_acc: 0.7842\n",
      "Epoch 425/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7203 - acc: 0.7504 - val_loss: 0.6488 - val_acc: 0.7842\n",
      "Epoch 426/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7249 - acc: 0.7426 - val_loss: 0.6479 - val_acc: 0.7850\n",
      "Epoch 427/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7087 - acc: 0.7507 - val_loss: 0.6488 - val_acc: 0.7842\n",
      "Epoch 428/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7307 - acc: 0.7422 - val_loss: 0.6491 - val_acc: 0.7850\n",
      "Epoch 429/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7399 - acc: 0.7362 - val_loss: 0.6497 - val_acc: 0.7842\n",
      "Epoch 430/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7297 - acc: 0.7437 - val_loss: 0.6484 - val_acc: 0.7842\n",
      "Epoch 431/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7180 - acc: 0.7485 - val_loss: 0.6474 - val_acc: 0.7842\n",
      "Epoch 432/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7183 - acc: 0.7467 - val_loss: 0.6502 - val_acc: 0.7835\n",
      "Epoch 433/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7306 - acc: 0.7440 - val_loss: 0.6492 - val_acc: 0.7842\n",
      "Epoch 434/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7298 - acc: 0.7507 - val_loss: 0.6483 - val_acc: 0.7842\n",
      "Epoch 435/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7330 - acc: 0.7452 - val_loss: 0.6452 - val_acc: 0.7857\n",
      "Epoch 436/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7220 - acc: 0.7478 - val_loss: 0.6434 - val_acc: 0.7857\n",
      "Epoch 437/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7264 - acc: 0.7507 - val_loss: 0.6497 - val_acc: 0.7842\n",
      "Epoch 438/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7283 - acc: 0.7500 - val_loss: 0.6495 - val_acc: 0.7842\n",
      "Epoch 439/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7298 - acc: 0.7493 - val_loss: 0.6504 - val_acc: 0.7835\n",
      "Epoch 440/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.7351 - acc: 0.7455 - val_loss: 0.6486 - val_acc: 0.7842\n",
      "Epoch 441/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7190 - acc: 0.7567 - val_loss: 0.6482 - val_acc: 0.7842\n",
      "Epoch 442/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7184 - acc: 0.7560 - val_loss: 0.6501 - val_acc: 0.7835\n",
      "Epoch 443/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7117 - acc: 0.7541 - val_loss: 0.6483 - val_acc: 0.7842\n",
      "Epoch 444/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7277 - acc: 0.7455 - val_loss: 0.6484 - val_acc: 0.7850\n",
      "Epoch 445/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7275 - acc: 0.7493 - val_loss: 0.6491 - val_acc: 0.7842\n",
      "Epoch 446/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7038 - acc: 0.7533 - val_loss: 0.6505 - val_acc: 0.7835\n",
      "Epoch 447/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7254 - acc: 0.7485 - val_loss: 0.6473 - val_acc: 0.7850\n",
      "Epoch 448/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7204 - acc: 0.7507 - val_loss: 0.6443 - val_acc: 0.7857\n",
      "Epoch 449/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7177 - acc: 0.7522 - val_loss: 0.6505 - val_acc: 0.7835\n",
      "Epoch 450/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7170 - acc: 0.7418 - val_loss: 0.6486 - val_acc: 0.7842\n",
      "Epoch 451/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7227 - acc: 0.7485 - val_loss: 0.6507 - val_acc: 0.7835\n",
      "Epoch 452/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7203 - acc: 0.7444 - val_loss: 0.6503 - val_acc: 0.7835\n",
      "Epoch 453/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7367 - acc: 0.7474 - val_loss: 0.6504 - val_acc: 0.7835\n",
      "Epoch 454/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7234 - acc: 0.7433 - val_loss: 0.6500 - val_acc: 0.7835\n",
      "Epoch 455/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7118 - acc: 0.7481 - val_loss: 0.6501 - val_acc: 0.7835\n",
      "Epoch 456/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7231 - acc: 0.7489 - val_loss: 0.6490 - val_acc: 0.7850\n",
      "Epoch 457/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7257 - acc: 0.7418 - val_loss: 0.6483 - val_acc: 0.7842\n",
      "Epoch 458/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7201 - acc: 0.7444 - val_loss: 0.6493 - val_acc: 0.7842\n",
      "Epoch 459/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7519 - acc: 0.7355 - val_loss: 0.6488 - val_acc: 0.7850\n",
      "Epoch 460/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7166 - acc: 0.7489 - val_loss: 0.6490 - val_acc: 0.7842\n",
      "Epoch 461/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7232 - acc: 0.7526 - val_loss: 0.6501 - val_acc: 0.7835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 462/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7185 - acc: 0.7560 - val_loss: 0.6497 - val_acc: 0.7835\n",
      "Epoch 463/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7288 - acc: 0.7496 - val_loss: 0.6485 - val_acc: 0.7850\n",
      "Epoch 464/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7183 - acc: 0.7489 - val_loss: 0.6508 - val_acc: 0.7835\n",
      "Epoch 465/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7176 - acc: 0.7530 - val_loss: 0.6477 - val_acc: 0.7850\n",
      "\n",
      "Epoch 00465: loss improved from inf to 0.71759, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-1-000465-0.717588-0.784970.hdf5\n",
      "Epoch 466/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7182 - acc: 0.7548 - val_loss: 0.6468 - val_acc: 0.7842\n",
      "Epoch 467/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7155 - acc: 0.7511 - val_loss: 0.6494 - val_acc: 0.7842\n",
      "Epoch 468/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7230 - acc: 0.7537 - val_loss: 0.6473 - val_acc: 0.7842\n",
      "Epoch 469/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7257 - acc: 0.7455 - val_loss: 0.6495 - val_acc: 0.7835\n",
      "Epoch 470/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7276 - acc: 0.7526 - val_loss: 0.6475 - val_acc: 0.7850\n",
      "Epoch 471/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7197 - acc: 0.7455 - val_loss: 0.6489 - val_acc: 0.7850\n",
      "Epoch 472/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7096 - acc: 0.7612 - val_loss: 0.6494 - val_acc: 0.7842\n",
      "Epoch 473/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7311 - acc: 0.7481 - val_loss: 0.6494 - val_acc: 0.7842\n",
      "Epoch 474/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7160 - acc: 0.7589 - val_loss: 0.6499 - val_acc: 0.7835\n",
      "Epoch 475/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7205 - acc: 0.7426 - val_loss: 0.6481 - val_acc: 0.7842\n",
      "Epoch 00475: early stopping\n",
      "ModelCheckpoint 已经保存到 ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/1-final.hdf5\n",
      "save in: ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/log/20220201_2000_64_1_3_1.csv\n",
      "time: 0:12:26 s\n",
      "time: 746.0 s\n",
      "average 0.746000 s\n",
      "1 epoch finished\n",
      "--------------------   best   --------------------\n",
      "no_activities: 10\n",
      "\n",
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1348/1348 [==============================] - 2s 1ms/step\n",
      "1-milan:\tacc: 78.41%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [9, 9, 9, 9, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 7, 7, 0, 9, 9, 9, 9, 9, 9, 9, 9, 4, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 7, 7, 7, 0, 0, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 0, 7, 7, 0, 0, 0, 7, 4, 7, 7, 0, 7, 0, 0, 7, 0, 7, 0, 7, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 0, 7, 0, 7, 7, 0, 7, 0, 7, 4, 0, 0, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 4, 7, 7, 0, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 4, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 0, 7, 0, 0, 7, 7, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 0, 5, 5, 5, 5, 9, 5, 5, 0, 5, 5, 5, 5, 5, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7, 7, 7, 0, 2, 5, 4, 7, 2, 0, 0, 0, 7, 0, 0, 0, 4, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 9, 9, 0, 0, 7, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 4, 7, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 4, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 4, 4, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 9, 4, 4, 4, 4, 4, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 0, 4, 4, 0, 4, 4, 4, 4, 0, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 0, 4, 7, 4, 4, 4, 4, 0, 7, 4, 4, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 0, 4, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.757536  0.927769  0.834055       623\n",
      "         Work   0.000000  0.000000  0.000000        25\n",
      "Take_medicine   1.000000  0.250000  0.400000        20\n",
      "        Sleep   0.000000  0.000000  0.000000        32\n",
      "        Relax   0.752475  0.535211  0.625514       142\n",
      "   Leave_Home   0.942029  0.902778  0.921986        72\n",
      "          Eat   0.000000  0.000000  0.000000         8\n",
      "         Cook   0.812865  0.755435  0.783099       184\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        30\n",
      "      Bathing   0.811715  0.915094  0.860310       212\n",
      "\n",
      "     accuracy                       0.784125      1348\n",
      "    macro avg   0.507662  0.428629  0.442496      1348\n",
      " weighted avg   0.733141  0.784125  0.748737      1348\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  28   0   0   2   0   0]\n",
      " [  0   0   0   0   0   1   0  22   2   0]\n",
      " [  0   0   0   0   0   0   0   8   0   0]\n",
      " [  0   0   0   5   0   8   1   5   1   0]\n",
      " [  0   0   0   0 194   3   0  14   1   0]\n",
      " [  0   0   0   0   1 139   0  38   6   0]\n",
      " [  0   0   0   0   1   0  65   6   0   0]\n",
      " [  0   0   0   0  11  16   3 578  15   0]\n",
      " [  0   0   0   0   2   4   0  60  76   0]\n",
      " [  0   0   0   0   2   0   0  30   0   0]]\n",
      "--------------------   final   --------------------\n",
      "no_activities: 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1348/1348 [==============================] - 2s 1ms/step\n",
      "1-milan:\tacc: 78.41%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [9, 9, 9, 9, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 7, 7, 0, 9, 9, 9, 9, 9, 9, 9, 9, 4, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 7, 7, 7, 0, 0, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 0, 7, 7, 0, 0, 0, 7, 4, 7, 7, 0, 7, 0, 0, 7, 0, 7, 0, 7, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 0, 7, 0, 7, 7, 0, 7, 0, 7, 4, 0, 0, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 4, 7, 7, 0, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 4, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 0, 7, 0, 0, 7, 7, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 0, 5, 5, 5, 5, 9, 5, 5, 0, 5, 5, 5, 5, 5, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7, 7, 7, 0, 2, 5, 4, 7, 2, 0, 0, 0, 7, 0, 0, 0, 4, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 9, 9, 0, 0, 7, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 4, 7, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 4, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 4, 4, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 9, 4, 4, 4, 4, 4, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 0, 4, 4, 0, 4, 4, 4, 4, 0, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 0, 4, 7, 4, 4, 4, 4, 0, 7, 4, 4, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 0, 4, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.757536  0.927769  0.834055       623\n",
      "         Work   0.000000  0.000000  0.000000        25\n",
      "Take_medicine   1.000000  0.250000  0.400000        20\n",
      "        Sleep   0.000000  0.000000  0.000000        32\n",
      "        Relax   0.752475  0.535211  0.625514       142\n",
      "   Leave_Home   0.942029  0.902778  0.921986        72\n",
      "          Eat   0.000000  0.000000  0.000000         8\n",
      "         Cook   0.812865  0.755435  0.783099       184\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        30\n",
      "      Bathing   0.811715  0.915094  0.860310       212\n",
      "\n",
      "     accuracy                       0.784125      1348\n",
      "    macro avg   0.507662  0.428629  0.442496      1348\n",
      " weighted avg   0.733141  0.784125  0.748737      1348\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  28   0   0   2   0   0]\n",
      " [  0   0   0   0   0   1   0  22   2   0]\n",
      " [  0   0   0   0   0   0   0   8   0   0]\n",
      " [  0   0   0   5   0   8   1   5   1   0]\n",
      " [  0   0   0   0 194   3   0  14   1   0]\n",
      " [  0   0   0   0   1 139   0  38   6   0]\n",
      " [  0   0   0   0   1   0  65   6   0   0]\n",
      " [  0   0   0   0  11  16   3 578  15   0]\n",
      " [  0   0   0   0   2   4   0  60  76   0]\n",
      " [  0   0   0   0   2   0   0  30   0   0]]\n",
      "no_activities: 10\n",
      "\n",
      "Begin training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "42/42 [==============================] - 4s 97ms/step - loss: 1.6064 - acc: 0.4751 - val_loss: 1.2801 - val_acc: 0.5253\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.3151 - acc: 0.5651 - val_loss: 1.1392 - val_acc: 0.6629\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.2082 - acc: 0.6272 - val_loss: 1.0565 - val_acc: 0.6808\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.1470 - acc: 0.6410 - val_loss: 1.0069 - val_acc: 0.6860\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.1115 - acc: 0.6477 - val_loss: 0.9756 - val_acc: 0.6964\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0718 - acc: 0.6570 - val_loss: 0.9488 - val_acc: 0.6860\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0378 - acc: 0.6585 - val_loss: 0.9231 - val_acc: 0.6897\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0189 - acc: 0.6615 - val_loss: 0.9025 - val_acc: 0.6987\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0081 - acc: 0.6618 - val_loss: 0.8910 - val_acc: 0.6987\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0086 - acc: 0.6566 - val_loss: 0.8766 - val_acc: 0.7001\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9816 - acc: 0.6659 - val_loss: 0.8679 - val_acc: 0.6994\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9654 - acc: 0.6737 - val_loss: 0.8551 - val_acc: 0.7001\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9575 - acc: 0.6804 - val_loss: 0.8487 - val_acc: 0.7024\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9465 - acc: 0.6782 - val_loss: 0.8418 - val_acc: 0.7068\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9320 - acc: 0.6860 - val_loss: 0.8340 - val_acc: 0.7158\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9504 - acc: 0.6752 - val_loss: 0.8284 - val_acc: 0.7076\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9368 - acc: 0.6778 - val_loss: 0.8281 - val_acc: 0.7098\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9234 - acc: 0.6838 - val_loss: 0.8170 - val_acc: 0.7135\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9065 - acc: 0.6882 - val_loss: 0.8137 - val_acc: 0.7083\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9177 - acc: 0.6771 - val_loss: 0.8131 - val_acc: 0.7188\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9034 - acc: 0.6882 - val_loss: 0.8116 - val_acc: 0.7195\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.9004 - acc: 0.6927 - val_loss: 0.8046 - val_acc: 0.7143\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8807 - acc: 0.6886 - val_loss: 0.7964 - val_acc: 0.7202\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8969 - acc: 0.6908 - val_loss: 0.7956 - val_acc: 0.7232\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8953 - acc: 0.6849 - val_loss: 0.7931 - val_acc: 0.7195\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8775 - acc: 0.6972 - val_loss: 0.7932 - val_acc: 0.7188\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8862 - acc: 0.6912 - val_loss: 0.7923 - val_acc: 0.7210\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8680 - acc: 0.7098 - val_loss: 0.7838 - val_acc: 0.7195\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8761 - acc: 0.6923 - val_loss: 0.7866 - val_acc: 0.7240\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8738 - acc: 0.6923 - val_loss: 0.7834 - val_acc: 0.7210\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.8795 - acc: 0.6908 - val_loss: 0.7789 - val_acc: 0.7284\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.8573 - acc: 0.6938 - val_loss: 0.7750 - val_acc: 0.7284\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8527 - acc: 0.6994 - val_loss: 0.7744 - val_acc: 0.7277\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8414 - acc: 0.7013 - val_loss: 0.7730 - val_acc: 0.7284\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8662 - acc: 0.6961 - val_loss: 0.7725 - val_acc: 0.7262\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8546 - acc: 0.7013 - val_loss: 0.7713 - val_acc: 0.7225\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8561 - acc: 0.6931 - val_loss: 0.7677 - val_acc: 0.7299\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8644 - acc: 0.6916 - val_loss: 0.7668 - val_acc: 0.7292\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8446 - acc: 0.7065 - val_loss: 0.7651 - val_acc: 0.7359\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8540 - acc: 0.7005 - val_loss: 0.7653 - val_acc: 0.7240\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8482 - acc: 0.6998 - val_loss: 0.7577 - val_acc: 0.7359\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8584 - acc: 0.7035 - val_loss: 0.7603 - val_acc: 0.7381\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8456 - acc: 0.7050 - val_loss: 0.7586 - val_acc: 0.7366\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8267 - acc: 0.7094 - val_loss: 0.7572 - val_acc: 0.7344\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8485 - acc: 0.6998 - val_loss: 0.7567 - val_acc: 0.7359\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8293 - acc: 0.7031 - val_loss: 0.7531 - val_acc: 0.7329\n",
      "Epoch 47/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8406 - acc: 0.6957 - val_loss: 0.7523 - val_acc: 0.7336\n",
      "Epoch 48/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8311 - acc: 0.6990 - val_loss: 0.7508 - val_acc: 0.7359\n",
      "Epoch 49/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8442 - acc: 0.7080 - val_loss: 0.7502 - val_acc: 0.7359\n",
      "Epoch 50/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8367 - acc: 0.7009 - val_loss: 0.7525 - val_acc: 0.7344\n",
      "Epoch 51/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8367 - acc: 0.7042 - val_loss: 0.7512 - val_acc: 0.7307\n",
      "Epoch 52/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8257 - acc: 0.7113 - val_loss: 0.7480 - val_acc: 0.7336\n",
      "Epoch 53/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8370 - acc: 0.6998 - val_loss: 0.7488 - val_acc: 0.7336\n",
      "Epoch 54/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8211 - acc: 0.7098 - val_loss: 0.7473 - val_acc: 0.7351\n",
      "Epoch 55/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8149 - acc: 0.7091 - val_loss: 0.7457 - val_acc: 0.7396\n",
      "Epoch 56/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8235 - acc: 0.7039 - val_loss: 0.7483 - val_acc: 0.7329\n",
      "Epoch 57/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8184 - acc: 0.7042 - val_loss: 0.7464 - val_acc: 0.7329\n",
      "Epoch 58/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8184 - acc: 0.7143 - val_loss: 0.7437 - val_acc: 0.7344\n",
      "Epoch 59/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8235 - acc: 0.7072 - val_loss: 0.7389 - val_acc: 0.7344\n",
      "Epoch 60/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8188 - acc: 0.6987 - val_loss: 0.7417 - val_acc: 0.7351\n",
      "Epoch 61/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8326 - acc: 0.7161 - val_loss: 0.7451 - val_acc: 0.7307\n",
      "Epoch 62/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8046 - acc: 0.7158 - val_loss: 0.7423 - val_acc: 0.7329\n",
      "Epoch 63/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8144 - acc: 0.7143 - val_loss: 0.7377 - val_acc: 0.7329\n",
      "Epoch 64/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.8191 - acc: 0.7080 - val_loss: 0.7409 - val_acc: 0.7336\n",
      "Epoch 65/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8010 - acc: 0.7106 - val_loss: 0.7409 - val_acc: 0.7351\n",
      "\n",
      "Epoch 00065: loss improved from inf to 0.80099, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-2-000065-0.800992-0.735119.hdf5\n",
      "Epoch 66/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8200 - acc: 0.7098 - val_loss: 0.7380 - val_acc: 0.7336\n",
      "Epoch 67/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8173 - acc: 0.7117 - val_loss: 0.7398 - val_acc: 0.7366\n",
      "Epoch 68/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8073 - acc: 0.7139 - val_loss: 0.7349 - val_acc: 0.7396\n",
      "Epoch 69/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7997 - acc: 0.7165 - val_loss: 0.7358 - val_acc: 0.7366\n",
      "\n",
      "Epoch 00069: loss improved from 0.80099 to 0.79974, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-2-000069-0.799738-0.736607.hdf5\n",
      "Epoch 70/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8187 - acc: 0.7150 - val_loss: 0.7350 - val_acc: 0.7336\n",
      "Epoch 71/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7999 - acc: 0.7128 - val_loss: 0.7352 - val_acc: 0.7344\n",
      "Epoch 72/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8172 - acc: 0.7154 - val_loss: 0.7351 - val_acc: 0.7344\n",
      "Epoch 73/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8000 - acc: 0.7132 - val_loss: 0.7344 - val_acc: 0.7336\n",
      "Epoch 74/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8093 - acc: 0.7180 - val_loss: 0.7333 - val_acc: 0.7344\n",
      "Epoch 75/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8008 - acc: 0.7039 - val_loss: 0.7331 - val_acc: 0.7351\n",
      "Epoch 76/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8000 - acc: 0.7147 - val_loss: 0.7294 - val_acc: 0.7321\n",
      "Epoch 77/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7994 - acc: 0.7121 - val_loss: 0.7342 - val_acc: 0.7388\n",
      "\n",
      "Epoch 00077: loss improved from 0.79974 to 0.79940, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-2-000077-0.799404-0.738839.hdf5\n",
      "Epoch 78/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8063 - acc: 0.7150 - val_loss: 0.7322 - val_acc: 0.7374\n",
      "Epoch 79/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8072 - acc: 0.7143 - val_loss: 0.7288 - val_acc: 0.7396\n",
      "Epoch 80/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8024 - acc: 0.7039 - val_loss: 0.7321 - val_acc: 0.7388\n",
      "Epoch 81/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7985 - acc: 0.7124 - val_loss: 0.7283 - val_acc: 0.7366\n",
      "\n",
      "Epoch 00081: loss improved from 0.79940 to 0.79847, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-2-000081-0.798475-0.736607.hdf5\n",
      "Epoch 82/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7948 - acc: 0.7135 - val_loss: 0.7292 - val_acc: 0.7388\n",
      "Epoch 83/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7957 - acc: 0.7202 - val_loss: 0.7285 - val_acc: 0.7351\n",
      "Epoch 84/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7979 - acc: 0.7117 - val_loss: 0.7267 - val_acc: 0.7366\n",
      "Epoch 85/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7988 - acc: 0.7143 - val_loss: 0.7273 - val_acc: 0.7351\n",
      "Epoch 86/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7927 - acc: 0.7154 - val_loss: 0.7276 - val_acc: 0.7329\n",
      "Epoch 87/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7837 - acc: 0.7243 - val_loss: 0.7248 - val_acc: 0.7403\n",
      "Epoch 88/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7788 - acc: 0.7128 - val_loss: 0.7215 - val_acc: 0.7388\n",
      "Epoch 89/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7854 - acc: 0.7161 - val_loss: 0.7215 - val_acc: 0.7366\n",
      "\n",
      "Epoch 00089: loss improved from 0.79847 to 0.78542, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-2-000089-0.785424-0.736607.hdf5\n",
      "Epoch 90/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7920 - acc: 0.7132 - val_loss: 0.7237 - val_acc: 0.7329\n",
      "Epoch 91/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7843 - acc: 0.7277 - val_loss: 0.7229 - val_acc: 0.7374\n",
      "Epoch 92/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7765 - acc: 0.7221 - val_loss: 0.7220 - val_acc: 0.7381\n",
      "Epoch 93/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7947 - acc: 0.7124 - val_loss: 0.7248 - val_acc: 0.7321\n",
      "Epoch 94/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7989 - acc: 0.7128 - val_loss: 0.7238 - val_acc: 0.7366\n",
      "Epoch 95/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7807 - acc: 0.7221 - val_loss: 0.7213 - val_acc: 0.7351\n",
      "Epoch 96/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7944 - acc: 0.7094 - val_loss: 0.7236 - val_acc: 0.7381\n",
      "Epoch 97/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7884 - acc: 0.7132 - val_loss: 0.7226 - val_acc: 0.7366\n",
      "Epoch 98/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7792 - acc: 0.7243 - val_loss: 0.7217 - val_acc: 0.7374\n",
      "Epoch 99/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7725 - acc: 0.7225 - val_loss: 0.7201 - val_acc: 0.7388\n",
      "Epoch 100/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7796 - acc: 0.7195 - val_loss: 0.7197 - val_acc: 0.7374\n",
      "\n",
      "Epoch 00100: saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/2-000100-0.779643-0.737351.hdf5\n",
      "Epoch 101/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7817 - acc: 0.7188 - val_loss: 0.7186 - val_acc: 0.7374\n",
      "Epoch 102/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7872 - acc: 0.7206 - val_loss: 0.7174 - val_acc: 0.7433\n",
      "Epoch 103/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7826 - acc: 0.7199 - val_loss: 0.7197 - val_acc: 0.7359\n",
      "Epoch 104/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7866 - acc: 0.7150 - val_loss: 0.7187 - val_acc: 0.7433\n",
      "Epoch 105/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7791 - acc: 0.7195 - val_loss: 0.7175 - val_acc: 0.7418\n",
      "Epoch 106/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7686 - acc: 0.7269 - val_loss: 0.7185 - val_acc: 0.7336\n",
      "Epoch 107/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7766 - acc: 0.7225 - val_loss: 0.7181 - val_acc: 0.7388\n",
      "Epoch 108/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7742 - acc: 0.7195 - val_loss: 0.7174 - val_acc: 0.7396\n",
      "Epoch 109/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7654 - acc: 0.7251 - val_loss: 0.7140 - val_acc: 0.7381\n",
      "Epoch 110/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7645 - acc: 0.7232 - val_loss: 0.7165 - val_acc: 0.7381\n",
      "Epoch 111/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7702 - acc: 0.7318 - val_loss: 0.7149 - val_acc: 0.7403\n",
      "Epoch 112/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7648 - acc: 0.7169 - val_loss: 0.7161 - val_acc: 0.7448\n",
      "Epoch 113/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7596 - acc: 0.7210 - val_loss: 0.7164 - val_acc: 0.7440\n",
      "Epoch 114/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7636 - acc: 0.7195 - val_loss: 0.7151 - val_acc: 0.7448\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7643 - acc: 0.7206 - val_loss: 0.7148 - val_acc: 0.7396\n",
      "Epoch 116/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7665 - acc: 0.7147 - val_loss: 0.7147 - val_acc: 0.7411\n",
      "Epoch 117/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7632 - acc: 0.7243 - val_loss: 0.7156 - val_acc: 0.7448\n",
      "Epoch 118/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7606 - acc: 0.7273 - val_loss: 0.7113 - val_acc: 0.7455\n",
      "Epoch 119/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7588 - acc: 0.7347 - val_loss: 0.7103 - val_acc: 0.7485\n",
      "Epoch 120/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7494 - acc: 0.7266 - val_loss: 0.7098 - val_acc: 0.7470\n",
      "Epoch 121/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7523 - acc: 0.7236 - val_loss: 0.7103 - val_acc: 0.7478\n",
      "Epoch 122/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7688 - acc: 0.7314 - val_loss: 0.7115 - val_acc: 0.7470\n",
      "Epoch 123/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7676 - acc: 0.7221 - val_loss: 0.7121 - val_acc: 0.7440\n",
      "Epoch 124/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7544 - acc: 0.7269 - val_loss: 0.7090 - val_acc: 0.7470\n",
      "Epoch 125/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7585 - acc: 0.7214 - val_loss: 0.7110 - val_acc: 0.7448\n",
      "Epoch 126/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7582 - acc: 0.7314 - val_loss: 0.7110 - val_acc: 0.7493\n",
      "Epoch 127/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7528 - acc: 0.7284 - val_loss: 0.7099 - val_acc: 0.7507\n",
      "Epoch 128/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7511 - acc: 0.7273 - val_loss: 0.7095 - val_acc: 0.7455\n",
      "Epoch 129/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7515 - acc: 0.7281 - val_loss: 0.7069 - val_acc: 0.7500\n",
      "Epoch 130/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7690 - acc: 0.7210 - val_loss: 0.7083 - val_acc: 0.7500\n",
      "Epoch 131/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7536 - acc: 0.7191 - val_loss: 0.7099 - val_acc: 0.7515\n",
      "Epoch 132/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7659 - acc: 0.7214 - val_loss: 0.7075 - val_acc: 0.7522\n",
      "Epoch 133/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7496 - acc: 0.7307 - val_loss: 0.7065 - val_acc: 0.7507\n",
      "Epoch 134/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7508 - acc: 0.7121 - val_loss: 0.7075 - val_acc: 0.7500\n",
      "Epoch 135/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7519 - acc: 0.7262 - val_loss: 0.7070 - val_acc: 0.7530\n",
      "Epoch 136/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7555 - acc: 0.7251 - val_loss: 0.7081 - val_acc: 0.7545\n",
      "Epoch 137/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7545 - acc: 0.7284 - val_loss: 0.7067 - val_acc: 0.7530\n",
      "Epoch 138/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7459 - acc: 0.7318 - val_loss: 0.7064 - val_acc: 0.7485\n",
      "Epoch 139/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7319 - acc: 0.7307 - val_loss: 0.7043 - val_acc: 0.7530\n",
      "Epoch 140/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7612 - acc: 0.7139 - val_loss: 0.7054 - val_acc: 0.7500\n",
      "Epoch 141/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7584 - acc: 0.7295 - val_loss: 0.7033 - val_acc: 0.7545\n",
      "Epoch 142/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7453 - acc: 0.7292 - val_loss: 0.7016 - val_acc: 0.7537\n",
      "Epoch 143/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7270 - acc: 0.7258 - val_loss: 0.7033 - val_acc: 0.7515\n",
      "Epoch 144/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7477 - acc: 0.7236 - val_loss: 0.7046 - val_acc: 0.7515\n",
      "Epoch 145/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7339 - acc: 0.7266 - val_loss: 0.7036 - val_acc: 0.7545\n",
      "Epoch 146/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7449 - acc: 0.7329 - val_loss: 0.7010 - val_acc: 0.7485\n",
      "Epoch 147/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7290 - acc: 0.7344 - val_loss: 0.7032 - val_acc: 0.7440\n",
      "Epoch 148/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7389 - acc: 0.7307 - val_loss: 0.7011 - val_acc: 0.7500\n",
      "Epoch 149/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7570 - acc: 0.7147 - val_loss: 0.7033 - val_acc: 0.7500\n",
      "Epoch 150/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7468 - acc: 0.7292 - val_loss: 0.7000 - val_acc: 0.7530\n",
      "Epoch 151/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7477 - acc: 0.7254 - val_loss: 0.7016 - val_acc: 0.7515\n",
      "Epoch 152/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7464 - acc: 0.7269 - val_loss: 0.7002 - val_acc: 0.7589\n",
      "Epoch 153/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7361 - acc: 0.7370 - val_loss: 0.6983 - val_acc: 0.7552\n",
      "Epoch 154/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7513 - acc: 0.7288 - val_loss: 0.6966 - val_acc: 0.7567\n",
      "Epoch 155/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7397 - acc: 0.7325 - val_loss: 0.6963 - val_acc: 0.7545\n",
      "Epoch 156/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7453 - acc: 0.7269 - val_loss: 0.6977 - val_acc: 0.7545\n",
      "Epoch 157/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7282 - acc: 0.7321 - val_loss: 0.6961 - val_acc: 0.7522\n",
      "Epoch 158/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7270 - acc: 0.7351 - val_loss: 0.6958 - val_acc: 0.7507\n",
      "Epoch 159/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7453 - acc: 0.7281 - val_loss: 0.6942 - val_acc: 0.7530\n",
      "Epoch 160/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7350 - acc: 0.7269 - val_loss: 0.6928 - val_acc: 0.7567\n",
      "Epoch 161/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7453 - acc: 0.7202 - val_loss: 0.6953 - val_acc: 0.7522\n",
      "Epoch 162/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7224 - acc: 0.7336 - val_loss: 0.6901 - val_acc: 0.7537\n",
      "Epoch 163/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7292 - acc: 0.7463 - val_loss: 0.6945 - val_acc: 0.7545\n",
      "Epoch 164/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7343 - acc: 0.7321 - val_loss: 0.6946 - val_acc: 0.7507\n",
      "Epoch 165/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7374 - acc: 0.7281 - val_loss: 0.6927 - val_acc: 0.7552\n",
      "\n",
      "Epoch 00165: loss improved from inf to 0.73742, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-2-000165-0.737417-0.755208.hdf5\n",
      "Epoch 166/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7324 - acc: 0.7355 - val_loss: 0.6928 - val_acc: 0.7545\n",
      "Epoch 167/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7258 - acc: 0.7374 - val_loss: 0.6871 - val_acc: 0.7560\n",
      "Epoch 168/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7492 - acc: 0.7254 - val_loss: 0.6923 - val_acc: 0.7567\n",
      "Epoch 169/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7331 - acc: 0.7251 - val_loss: 0.6893 - val_acc: 0.7589\n",
      "\n",
      "Epoch 00169: loss improved from 0.73742 to 0.73311, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-2-000169-0.733105-0.758929.hdf5\n",
      "Epoch 170/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7341 - acc: 0.7333 - val_loss: 0.6924 - val_acc: 0.7567\n",
      "Epoch 171/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7313 - acc: 0.7310 - val_loss: 0.6903 - val_acc: 0.7582\n",
      "Epoch 172/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7266 - acc: 0.7347 - val_loss: 0.6898 - val_acc: 0.7567\n",
      "Epoch 173/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7302 - acc: 0.7254 - val_loss: 0.6896 - val_acc: 0.7604\n",
      "\n",
      "Epoch 00173: loss improved from 0.73311 to 0.73022, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-2-000173-0.730223-0.760417.hdf5\n",
      "Epoch 174/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7353 - acc: 0.7258 - val_loss: 0.6907 - val_acc: 0.7560\n",
      "Epoch 175/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7258 - acc: 0.7340 - val_loss: 0.6873 - val_acc: 0.7604\n",
      "Epoch 176/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7217 - acc: 0.7355 - val_loss: 0.6896 - val_acc: 0.7560\n",
      "Epoch 177/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7294 - acc: 0.7236 - val_loss: 0.6901 - val_acc: 0.7582\n",
      "\n",
      "Epoch 00177: loss improved from 0.73022 to 0.72939, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-2-000177-0.729393-0.758185.hdf5\n",
      "Epoch 178/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7267 - acc: 0.7247 - val_loss: 0.6884 - val_acc: 0.7589\n",
      "Epoch 179/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7281 - acc: 0.7411 - val_loss: 0.6884 - val_acc: 0.7574\n",
      "Epoch 180/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7276 - acc: 0.7288 - val_loss: 0.6880 - val_acc: 0.7567\n",
      "Epoch 181/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7147 - acc: 0.7344 - val_loss: 0.6879 - val_acc: 0.7537\n",
      "\n",
      "Epoch 00181: loss improved from 0.72939 to 0.71474, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-2-000181-0.714738-0.753720.hdf5\n",
      "Epoch 182/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7190 - acc: 0.7370 - val_loss: 0.6862 - val_acc: 0.7537\n",
      "Epoch 183/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7003 - acc: 0.7325 - val_loss: 0.6865 - val_acc: 0.7552\n",
      "Epoch 184/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7298 - acc: 0.7288 - val_loss: 0.6881 - val_acc: 0.7545\n",
      "Epoch 185/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7245 - acc: 0.7344 - val_loss: 0.6867 - val_acc: 0.7604\n",
      "Epoch 186/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7306 - acc: 0.7340 - val_loss: 0.6863 - val_acc: 0.7582\n",
      "Epoch 187/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7222 - acc: 0.7385 - val_loss: 0.6856 - val_acc: 0.7619\n",
      "Epoch 188/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7079 - acc: 0.7329 - val_loss: 0.6854 - val_acc: 0.7589\n",
      "Epoch 189/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7097 - acc: 0.7426 - val_loss: 0.6856 - val_acc: 0.7619\n",
      "\n",
      "Epoch 00189: loss improved from 0.71474 to 0.70967, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-2-000189-0.709669-0.761905.hdf5\n",
      "Epoch 190/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7134 - acc: 0.7344 - val_loss: 0.6852 - val_acc: 0.7582\n",
      "Epoch 191/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7148 - acc: 0.7366 - val_loss: 0.6826 - val_acc: 0.7604\n",
      "Epoch 192/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7377 - acc: 0.7251 - val_loss: 0.6847 - val_acc: 0.7626\n",
      "Epoch 193/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7165 - acc: 0.7351 - val_loss: 0.6845 - val_acc: 0.7641\n",
      "Epoch 194/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7161 - acc: 0.7388 - val_loss: 0.6831 - val_acc: 0.7589\n",
      "Epoch 195/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7125 - acc: 0.7370 - val_loss: 0.6827 - val_acc: 0.7612\n",
      "Epoch 196/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7232 - acc: 0.7281 - val_loss: 0.6823 - val_acc: 0.7567\n",
      "Epoch 197/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7238 - acc: 0.7292 - val_loss: 0.6844 - val_acc: 0.7597\n",
      "Epoch 198/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7150 - acc: 0.7370 - val_loss: 0.6854 - val_acc: 0.7597\n",
      "Epoch 199/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7024 - acc: 0.7440 - val_loss: 0.6823 - val_acc: 0.7612\n",
      "Epoch 200/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7102 - acc: 0.7318 - val_loss: 0.6838 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00200: saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/2-000200-0.710217-0.757440.hdf5\n",
      "Epoch 201/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7059 - acc: 0.7377 - val_loss: 0.6786 - val_acc: 0.7597\n",
      "Epoch 202/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7027 - acc: 0.7362 - val_loss: 0.6834 - val_acc: 0.7597\n",
      "Epoch 203/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7106 - acc: 0.7433 - val_loss: 0.6809 - val_acc: 0.7626\n",
      "\n",
      "Epoch 00203: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 204/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7294 - acc: 0.7355 - val_loss: 0.6824 - val_acc: 0.7604\n",
      "Epoch 205/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7226 - acc: 0.7325 - val_loss: 0.6816 - val_acc: 0.7626\n",
      "Epoch 206/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7331 - acc: 0.7366 - val_loss: 0.6807 - val_acc: 0.7619\n",
      "Epoch 207/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7082 - acc: 0.7299 - val_loss: 0.6799 - val_acc: 0.7612\n",
      "Epoch 208/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7167 - acc: 0.7336 - val_loss: 0.6811 - val_acc: 0.7604\n",
      "Epoch 209/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7306 - acc: 0.7362 - val_loss: 0.6829 - val_acc: 0.7604\n",
      "Epoch 210/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6978 - acc: 0.7452 - val_loss: 0.6823 - val_acc: 0.7612\n",
      "Epoch 211/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7158 - acc: 0.7374 - val_loss: 0.6818 - val_acc: 0.7612\n",
      "Epoch 212/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7075 - acc: 0.7396 - val_loss: 0.6820 - val_acc: 0.7612\n",
      "Epoch 213/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7191 - acc: 0.7325 - val_loss: 0.6814 - val_acc: 0.7634\n",
      "Epoch 214/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7247 - acc: 0.7266 - val_loss: 0.6814 - val_acc: 0.7634\n",
      "Epoch 215/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7087 - acc: 0.7318 - val_loss: 0.6817 - val_acc: 0.7634\n",
      "Epoch 216/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7163 - acc: 0.7418 - val_loss: 0.6817 - val_acc: 0.7626\n",
      "Epoch 217/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7209 - acc: 0.7377 - val_loss: 0.6795 - val_acc: 0.7641\n",
      "Epoch 218/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7104 - acc: 0.7336 - val_loss: 0.6817 - val_acc: 0.7634\n",
      "Epoch 219/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7175 - acc: 0.7374 - val_loss: 0.6800 - val_acc: 0.7649\n",
      "Epoch 220/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7059 - acc: 0.7448 - val_loss: 0.6817 - val_acc: 0.7634\n",
      "Epoch 221/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7147 - acc: 0.7351 - val_loss: 0.6793 - val_acc: 0.7656\n",
      "Epoch 222/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7011 - acc: 0.7340 - val_loss: 0.6816 - val_acc: 0.7634\n",
      "Epoch 223/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7045 - acc: 0.7381 - val_loss: 0.6819 - val_acc: 0.7634\n",
      "Epoch 224/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7206 - acc: 0.7325 - val_loss: 0.6756 - val_acc: 0.7664\n",
      "Epoch 225/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7086 - acc: 0.7385 - val_loss: 0.6814 - val_acc: 0.7626\n",
      "Epoch 226/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7285 - acc: 0.7307 - val_loss: 0.6807 - val_acc: 0.7664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 227/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7214 - acc: 0.7333 - val_loss: 0.6816 - val_acc: 0.7641\n",
      "Epoch 228/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7117 - acc: 0.7418 - val_loss: 0.6813 - val_acc: 0.7634\n",
      "Epoch 229/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7292 - acc: 0.7295 - val_loss: 0.6811 - val_acc: 0.7649\n",
      "Epoch 230/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7064 - acc: 0.7362 - val_loss: 0.6788 - val_acc: 0.7641\n",
      "\n",
      "Epoch 00230: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 231/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7180 - acc: 0.7351 - val_loss: 0.6804 - val_acc: 0.7634\n",
      "Epoch 232/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7134 - acc: 0.7374 - val_loss: 0.6808 - val_acc: 0.7634\n",
      "Epoch 233/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7049 - acc: 0.7314 - val_loss: 0.6803 - val_acc: 0.7649\n",
      "Epoch 234/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7171 - acc: 0.7329 - val_loss: 0.6798 - val_acc: 0.7649\n",
      "Epoch 235/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7144 - acc: 0.7329 - val_loss: 0.6814 - val_acc: 0.7641\n",
      "Epoch 236/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7187 - acc: 0.7381 - val_loss: 0.6807 - val_acc: 0.7641\n",
      "Epoch 237/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7186 - acc: 0.7340 - val_loss: 0.6811 - val_acc: 0.7649\n",
      "Epoch 238/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7112 - acc: 0.7362 - val_loss: 0.6793 - val_acc: 0.7656\n",
      "Epoch 239/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7144 - acc: 0.7396 - val_loss: 0.6806 - val_acc: 0.7649\n",
      "Epoch 240/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7152 - acc: 0.7426 - val_loss: 0.6788 - val_acc: 0.7664\n",
      "Epoch 241/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7126 - acc: 0.7429 - val_loss: 0.6799 - val_acc: 0.7664\n",
      "Epoch 242/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7083 - acc: 0.7381 - val_loss: 0.6774 - val_acc: 0.7664\n",
      "Epoch 243/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7169 - acc: 0.7340 - val_loss: 0.6792 - val_acc: 0.7664\n",
      "Epoch 244/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7035 - acc: 0.7403 - val_loss: 0.6806 - val_acc: 0.7656\n",
      "Epoch 245/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7133 - acc: 0.7400 - val_loss: 0.6814 - val_acc: 0.7649\n",
      "Epoch 246/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7114 - acc: 0.7370 - val_loss: 0.6794 - val_acc: 0.7656\n",
      "Epoch 247/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7072 - acc: 0.7314 - val_loss: 0.6815 - val_acc: 0.7649\n",
      "Epoch 248/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7127 - acc: 0.7418 - val_loss: 0.6812 - val_acc: 0.7656\n",
      "Epoch 249/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7163 - acc: 0.7303 - val_loss: 0.6802 - val_acc: 0.7656\n",
      "Epoch 250/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7136 - acc: 0.7344 - val_loss: 0.6774 - val_acc: 0.7656\n",
      "\n",
      "Epoch 00250: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 251/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6903 - acc: 0.7545 - val_loss: 0.6804 - val_acc: 0.7656\n",
      "Epoch 252/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7157 - acc: 0.7437 - val_loss: 0.6809 - val_acc: 0.7656\n",
      "Epoch 253/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7092 - acc: 0.7362 - val_loss: 0.6808 - val_acc: 0.7656\n",
      "Epoch 254/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7053 - acc: 0.7366 - val_loss: 0.6808 - val_acc: 0.7649\n",
      "Epoch 255/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7042 - acc: 0.7310 - val_loss: 0.6796 - val_acc: 0.7656\n",
      "Epoch 256/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7063 - acc: 0.7355 - val_loss: 0.6810 - val_acc: 0.7649\n",
      "Epoch 257/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7230 - acc: 0.7299 - val_loss: 0.6810 - val_acc: 0.7656\n",
      "Epoch 258/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7096 - acc: 0.7440 - val_loss: 0.6681 - val_acc: 0.7664\n",
      "Epoch 259/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7143 - acc: 0.7303 - val_loss: 0.6798 - val_acc: 0.7656\n",
      "Epoch 260/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7178 - acc: 0.7318 - val_loss: 0.6810 - val_acc: 0.7649\n",
      "Epoch 261/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7235 - acc: 0.7400 - val_loss: 0.6797 - val_acc: 0.7664\n",
      "Epoch 262/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7202 - acc: 0.7299 - val_loss: 0.6803 - val_acc: 0.7656\n",
      "Epoch 263/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7232 - acc: 0.7321 - val_loss: 0.6802 - val_acc: 0.7656\n",
      "Epoch 264/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6967 - acc: 0.7478 - val_loss: 0.6808 - val_acc: 0.7656\n",
      "Epoch 265/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7233 - acc: 0.7258 - val_loss: 0.6798 - val_acc: 0.7664\n",
      "\n",
      "Epoch 00265: loss improved from inf to 0.72328, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-2-000265-0.723281-0.766369.hdf5\n",
      "Epoch 266/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7112 - acc: 0.7243 - val_loss: 0.6776 - val_acc: 0.7656\n",
      "Epoch 267/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7180 - acc: 0.7288 - val_loss: 0.6797 - val_acc: 0.7656\n",
      "Epoch 268/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6976 - acc: 0.7459 - val_loss: 0.6806 - val_acc: 0.7649\n",
      "Epoch 269/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7067 - acc: 0.7519 - val_loss: 0.6815 - val_acc: 0.7649\n",
      "\n",
      "Epoch 00269: loss improved from 0.72328 to 0.70674, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-2-000269-0.706741-0.764881.hdf5\n",
      "Epoch 270/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7098 - acc: 0.7448 - val_loss: 0.6808 - val_acc: 0.7649\n",
      "Epoch 271/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7132 - acc: 0.7422 - val_loss: 0.6805 - val_acc: 0.7649\n",
      "Epoch 272/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7126 - acc: 0.7340 - val_loss: 0.6797 - val_acc: 0.7656\n",
      "Epoch 273/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7131 - acc: 0.7411 - val_loss: 0.6802 - val_acc: 0.7649\n",
      "Epoch 274/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7285 - acc: 0.7388 - val_loss: 0.6803 - val_acc: 0.7656\n",
      "Epoch 275/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7074 - acc: 0.7362 - val_loss: 0.6811 - val_acc: 0.7649\n",
      "Epoch 276/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7055 - acc: 0.7433 - val_loss: 0.6818 - val_acc: 0.7649\n",
      "Epoch 277/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7073 - acc: 0.7329 - val_loss: 0.6804 - val_acc: 0.7649\n",
      "Epoch 278/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7217 - acc: 0.7385 - val_loss: 0.6799 - val_acc: 0.7656\n",
      "Epoch 279/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7106 - acc: 0.7392 - val_loss: 0.6810 - val_acc: 0.7656\n",
      "Epoch 280/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7125 - acc: 0.7366 - val_loss: 0.6794 - val_acc: 0.7664\n",
      "Epoch 281/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7048 - acc: 0.7355 - val_loss: 0.6797 - val_acc: 0.7656\n",
      "\n",
      "Epoch 00281: loss improved from 0.70674 to 0.70477, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-2-000281-0.704768-0.765625.hdf5\n",
      "Epoch 282/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7224 - acc: 0.7303 - val_loss: 0.6800 - val_acc: 0.7656\n",
      "Epoch 283/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7127 - acc: 0.7336 - val_loss: 0.6811 - val_acc: 0.7649\n",
      "Epoch 284/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7172 - acc: 0.7347 - val_loss: 0.6806 - val_acc: 0.7656\n",
      "Epoch 285/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7020 - acc: 0.7422 - val_loss: 0.6813 - val_acc: 0.7649\n",
      "\n",
      "Epoch 00285: loss improved from 0.70477 to 0.70204, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-2-000285-0.702036-0.764881.hdf5\n",
      "Epoch 286/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7026 - acc: 0.7448 - val_loss: 0.6812 - val_acc: 0.7649\n",
      "Epoch 287/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6983 - acc: 0.7411 - val_loss: 0.6807 - val_acc: 0.7656\n",
      "Epoch 288/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7213 - acc: 0.7295 - val_loss: 0.6816 - val_acc: 0.7649\n",
      "Epoch 289/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7079 - acc: 0.7374 - val_loss: 0.6800 - val_acc: 0.7656\n",
      "Epoch 290/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7185 - acc: 0.7392 - val_loss: 0.6800 - val_acc: 0.7656\n",
      "Epoch 291/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7009 - acc: 0.7411 - val_loss: 0.6803 - val_acc: 0.7649\n",
      "Epoch 292/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7171 - acc: 0.7392 - val_loss: 0.6803 - val_acc: 0.7656\n",
      "Epoch 293/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7055 - acc: 0.7359 - val_loss: 0.6814 - val_acc: 0.7649\n",
      "Epoch 294/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7149 - acc: 0.7381 - val_loss: 0.6801 - val_acc: 0.7656\n",
      "Epoch 295/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7202 - acc: 0.7429 - val_loss: 0.6806 - val_acc: 0.7649\n",
      "Epoch 296/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7054 - acc: 0.7422 - val_loss: 0.6809 - val_acc: 0.7656\n",
      "Epoch 297/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7231 - acc: 0.7318 - val_loss: 0.6799 - val_acc: 0.7656\n",
      "Epoch 298/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7176 - acc: 0.7385 - val_loss: 0.6789 - val_acc: 0.7664\n",
      "Epoch 299/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7210 - acc: 0.7333 - val_loss: 0.6794 - val_acc: 0.7664\n",
      "Epoch 300/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7075 - acc: 0.7396 - val_loss: 0.6809 - val_acc: 0.7656\n",
      "\n",
      "Epoch 00300: saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/2-000300-0.707473-0.765625.hdf5\n",
      "Epoch 301/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7285 - acc: 0.7299 - val_loss: 0.6808 - val_acc: 0.7656\n",
      "Epoch 302/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7092 - acc: 0.7448 - val_loss: 0.6807 - val_acc: 0.7656\n",
      "Epoch 303/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7060 - acc: 0.7385 - val_loss: 0.6792 - val_acc: 0.7656\n",
      "Epoch 304/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7127 - acc: 0.7429 - val_loss: 0.6809 - val_acc: 0.7649\n",
      "Epoch 305/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7224 - acc: 0.7396 - val_loss: 0.6772 - val_acc: 0.7664\n",
      "Epoch 306/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7115 - acc: 0.7414 - val_loss: 0.6812 - val_acc: 0.7649\n",
      "Epoch 307/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7159 - acc: 0.7359 - val_loss: 0.6818 - val_acc: 0.7649\n",
      "Epoch 308/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6990 - acc: 0.7478 - val_loss: 0.6804 - val_acc: 0.7656\n",
      "Epoch 309/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7229 - acc: 0.7359 - val_loss: 0.6803 - val_acc: 0.7656\n",
      "Epoch 310/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7165 - acc: 0.7325 - val_loss: 0.6806 - val_acc: 0.7656\n",
      "Epoch 311/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7137 - acc: 0.7359 - val_loss: 0.6787 - val_acc: 0.7671\n",
      "Epoch 312/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6950 - acc: 0.7496 - val_loss: 0.6796 - val_acc: 0.7664\n",
      "Epoch 313/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6958 - acc: 0.7455 - val_loss: 0.6804 - val_acc: 0.7656\n",
      "Epoch 314/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7127 - acc: 0.7344 - val_loss: 0.6813 - val_acc: 0.7649\n",
      "Epoch 315/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.6998 - acc: 0.7474 - val_loss: 0.6797 - val_acc: 0.7656\n",
      "Epoch 316/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6990 - acc: 0.7489 - val_loss: 0.6797 - val_acc: 0.7656\n",
      "Epoch 317/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7039 - acc: 0.7362 - val_loss: 0.6813 - val_acc: 0.7649\n",
      "Epoch 318/1000\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.7033 - acc: 0.7411 - val_loss: 0.6809 - val_acc: 0.7656\n",
      "Epoch 319/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7184 - acc: 0.7455 - val_loss: 0.6792 - val_acc: 0.7656\n",
      "Epoch 320/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7056 - acc: 0.7370 - val_loss: 0.6818 - val_acc: 0.7649\n",
      "Epoch 321/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7162 - acc: 0.7340 - val_loss: 0.6817 - val_acc: 0.7649\n",
      "Epoch 322/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7103 - acc: 0.7396 - val_loss: 0.6806 - val_acc: 0.7649\n",
      "Epoch 323/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7009 - acc: 0.7474 - val_loss: 0.6795 - val_acc: 0.7656\n",
      "Epoch 324/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7156 - acc: 0.7388 - val_loss: 0.6806 - val_acc: 0.7656\n",
      "Epoch 325/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7049 - acc: 0.7385 - val_loss: 0.6803 - val_acc: 0.7656\n",
      "Epoch 326/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7041 - acc: 0.7359 - val_loss: 0.6814 - val_acc: 0.7649\n",
      "Epoch 327/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7007 - acc: 0.7403 - val_loss: 0.6796 - val_acc: 0.7656\n",
      "Epoch 328/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7153 - acc: 0.7359 - val_loss: 0.6815 - val_acc: 0.7649\n",
      "Epoch 329/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7136 - acc: 0.7411 - val_loss: 0.6793 - val_acc: 0.7656\n",
      "Epoch 330/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7143 - acc: 0.7381 - val_loss: 0.6805 - val_acc: 0.7656\n",
      "Epoch 331/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7085 - acc: 0.7374 - val_loss: 0.6798 - val_acc: 0.7649\n",
      "Epoch 332/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7160 - acc: 0.7325 - val_loss: 0.6762 - val_acc: 0.7656\n",
      "Epoch 333/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7140 - acc: 0.7318 - val_loss: 0.6804 - val_acc: 0.7649\n",
      "Epoch 334/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7064 - acc: 0.7452 - val_loss: 0.6794 - val_acc: 0.7656\n",
      "Epoch 335/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7081 - acc: 0.7318 - val_loss: 0.6799 - val_acc: 0.7656\n",
      "Epoch 336/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7139 - acc: 0.7403 - val_loss: 0.6806 - val_acc: 0.7656\n",
      "Epoch 337/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7056 - acc: 0.7452 - val_loss: 0.6806 - val_acc: 0.7656\n",
      "Epoch 338/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7115 - acc: 0.7295 - val_loss: 0.6786 - val_acc: 0.7656\n",
      "Epoch 339/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7218 - acc: 0.7329 - val_loss: 0.6794 - val_acc: 0.7656\n",
      "Epoch 340/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7105 - acc: 0.7340 - val_loss: 0.6811 - val_acc: 0.7649\n",
      "Epoch 341/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6949 - acc: 0.7426 - val_loss: 0.6803 - val_acc: 0.7664\n",
      "Epoch 342/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6896 - acc: 0.7426 - val_loss: 0.6811 - val_acc: 0.7649\n",
      "Epoch 343/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7171 - acc: 0.7407 - val_loss: 0.6780 - val_acc: 0.7679\n",
      "Epoch 344/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7178 - acc: 0.7362 - val_loss: 0.6806 - val_acc: 0.7656\n",
      "Epoch 345/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7150 - acc: 0.7388 - val_loss: 0.6802 - val_acc: 0.7649\n",
      "Epoch 346/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7145 - acc: 0.7333 - val_loss: 0.6785 - val_acc: 0.7664\n",
      "Epoch 347/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7102 - acc: 0.7407 - val_loss: 0.6815 - val_acc: 0.7649\n",
      "Epoch 348/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7241 - acc: 0.7314 - val_loss: 0.6804 - val_acc: 0.7656\n",
      "Epoch 349/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7042 - acc: 0.7437 - val_loss: 0.6748 - val_acc: 0.7671\n",
      "Epoch 350/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7331 - acc: 0.7240 - val_loss: 0.6804 - val_acc: 0.7656\n",
      "Epoch 351/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7029 - acc: 0.7377 - val_loss: 0.6796 - val_acc: 0.7656\n",
      "Epoch 352/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7118 - acc: 0.7370 - val_loss: 0.6811 - val_acc: 0.7656\n",
      "Epoch 353/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7084 - acc: 0.7292 - val_loss: 0.6808 - val_acc: 0.7656\n",
      "Epoch 354/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6997 - acc: 0.7359 - val_loss: 0.6788 - val_acc: 0.7664\n",
      "Epoch 355/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6973 - acc: 0.7474 - val_loss: 0.6804 - val_acc: 0.7649\n",
      "Epoch 356/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7030 - acc: 0.7414 - val_loss: 0.6795 - val_acc: 0.7664\n",
      "Epoch 357/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7055 - acc: 0.7362 - val_loss: 0.6816 - val_acc: 0.7649\n",
      "Epoch 358/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6967 - acc: 0.7481 - val_loss: 0.6798 - val_acc: 0.7664\n",
      "Epoch 359/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7046 - acc: 0.7314 - val_loss: 0.6806 - val_acc: 0.7649\n",
      "Epoch 360/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7277 - acc: 0.7277 - val_loss: 0.6787 - val_acc: 0.7656\n",
      "Epoch 361/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7074 - acc: 0.7437 - val_loss: 0.6803 - val_acc: 0.7649\n",
      "Epoch 362/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7224 - acc: 0.7351 - val_loss: 0.6803 - val_acc: 0.7656\n",
      "Epoch 363/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6982 - acc: 0.7340 - val_loss: 0.6804 - val_acc: 0.7656\n",
      "Epoch 364/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6949 - acc: 0.7366 - val_loss: 0.6803 - val_acc: 0.7656\n",
      "Epoch 365/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7217 - acc: 0.7429 - val_loss: 0.6797 - val_acc: 0.7656\n",
      "\n",
      "Epoch 00365: loss improved from inf to 0.72168, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-2-000365-0.721676-0.765625.hdf5\n",
      "Epoch 366/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7245 - acc: 0.7411 - val_loss: 0.6798 - val_acc: 0.7656\n",
      "Epoch 367/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7195 - acc: 0.7433 - val_loss: 0.6795 - val_acc: 0.7656\n",
      "Epoch 368/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7074 - acc: 0.7418 - val_loss: 0.6813 - val_acc: 0.7649\n",
      "Epoch 369/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7017 - acc: 0.7407 - val_loss: 0.6810 - val_acc: 0.7649\n",
      "\n",
      "Epoch 00369: loss improved from 0.72168 to 0.70170, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-2-000369-0.701701-0.764881.hdf5\n",
      "Epoch 370/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7161 - acc: 0.7336 - val_loss: 0.6801 - val_acc: 0.7656\n",
      "Epoch 371/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6929 - acc: 0.7400 - val_loss: 0.6811 - val_acc: 0.7649\n",
      "Epoch 372/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7150 - acc: 0.7307 - val_loss: 0.6802 - val_acc: 0.7656\n",
      "Epoch 373/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7058 - acc: 0.7422 - val_loss: 0.6802 - val_acc: 0.7649\n",
      "Epoch 374/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7139 - acc: 0.7355 - val_loss: 0.6802 - val_acc: 0.7664\n",
      "Epoch 375/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7018 - acc: 0.7355 - val_loss: 0.6806 - val_acc: 0.7649\n",
      "Epoch 376/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7236 - acc: 0.7321 - val_loss: 0.6807 - val_acc: 0.7649\n",
      "Epoch 377/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7096 - acc: 0.7452 - val_loss: 0.6803 - val_acc: 0.7649\n",
      "Epoch 378/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6990 - acc: 0.7489 - val_loss: 0.6814 - val_acc: 0.7649\n",
      "Epoch 379/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7110 - acc: 0.7321 - val_loss: 0.6814 - val_acc: 0.7649\n",
      "Epoch 380/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7099 - acc: 0.7392 - val_loss: 0.6815 - val_acc: 0.7649\n",
      "Epoch 381/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7085 - acc: 0.7374 - val_loss: 0.6808 - val_acc: 0.7649\n",
      "Epoch 382/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7080 - acc: 0.7377 - val_loss: 0.6799 - val_acc: 0.7664\n",
      "Epoch 383/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7133 - acc: 0.7388 - val_loss: 0.6815 - val_acc: 0.7649\n",
      "Epoch 384/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7097 - acc: 0.7355 - val_loss: 0.6791 - val_acc: 0.7664\n",
      "Epoch 385/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7182 - acc: 0.7221 - val_loss: 0.6791 - val_acc: 0.7656\n",
      "Epoch 386/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7256 - acc: 0.7370 - val_loss: 0.6813 - val_acc: 0.7649\n",
      "Epoch 387/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7097 - acc: 0.7359 - val_loss: 0.6782 - val_acc: 0.7664\n",
      "Epoch 388/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7079 - acc: 0.7407 - val_loss: 0.6785 - val_acc: 0.7656\n",
      "Epoch 389/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7235 - acc: 0.7333 - val_loss: 0.6792 - val_acc: 0.7656\n",
      "Epoch 390/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7138 - acc: 0.7336 - val_loss: 0.6816 - val_acc: 0.7649\n",
      "Epoch 391/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7166 - acc: 0.7340 - val_loss: 0.6772 - val_acc: 0.7656\n",
      "Epoch 392/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7177 - acc: 0.7362 - val_loss: 0.6809 - val_acc: 0.7656\n",
      "Epoch 393/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7220 - acc: 0.7318 - val_loss: 0.6778 - val_acc: 0.7671\n",
      "Epoch 394/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7132 - acc: 0.7366 - val_loss: 0.6789 - val_acc: 0.7664\n",
      "Epoch 395/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7209 - acc: 0.7440 - val_loss: 0.6798 - val_acc: 0.7649\n",
      "Epoch 396/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7165 - acc: 0.7396 - val_loss: 0.6752 - val_acc: 0.7664\n",
      "Epoch 397/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7117 - acc: 0.7400 - val_loss: 0.6796 - val_acc: 0.7656\n",
      "Epoch 398/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7116 - acc: 0.7437 - val_loss: 0.6816 - val_acc: 0.7649\n",
      "Epoch 399/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7016 - acc: 0.7459 - val_loss: 0.6792 - val_acc: 0.7656\n",
      "Epoch 400/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7094 - acc: 0.7448 - val_loss: 0.6803 - val_acc: 0.7649\n",
      "\n",
      "Epoch 00400: saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/2-000400-0.709394-0.764881.hdf5\n",
      "Epoch 401/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7077 - acc: 0.7377 - val_loss: 0.6799 - val_acc: 0.7649\n",
      "Epoch 402/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7014 - acc: 0.7392 - val_loss: 0.6802 - val_acc: 0.7656\n",
      "Epoch 403/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7081 - acc: 0.7392 - val_loss: 0.6808 - val_acc: 0.7649\n",
      "Epoch 404/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7076 - acc: 0.7240 - val_loss: 0.6794 - val_acc: 0.7656\n",
      "Epoch 405/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7155 - acc: 0.7433 - val_loss: 0.6792 - val_acc: 0.7664\n",
      "Epoch 406/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7033 - acc: 0.7359 - val_loss: 0.6787 - val_acc: 0.7656\n",
      "Epoch 407/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7035 - acc: 0.7400 - val_loss: 0.6807 - val_acc: 0.7649\n",
      "Epoch 408/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7062 - acc: 0.7336 - val_loss: 0.6798 - val_acc: 0.7656\n",
      "Epoch 409/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7063 - acc: 0.7359 - val_loss: 0.6788 - val_acc: 0.7656\n",
      "Epoch 410/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7191 - acc: 0.7314 - val_loss: 0.6810 - val_acc: 0.7649\n",
      "Epoch 411/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7235 - acc: 0.7269 - val_loss: 0.6813 - val_acc: 0.7649\n",
      "Epoch 412/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7131 - acc: 0.7340 - val_loss: 0.6791 - val_acc: 0.7656\n",
      "Epoch 413/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7030 - acc: 0.7411 - val_loss: 0.6804 - val_acc: 0.7656\n",
      "Epoch 414/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7231 - acc: 0.7292 - val_loss: 0.6795 - val_acc: 0.7656\n",
      "Epoch 415/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6981 - acc: 0.7463 - val_loss: 0.6804 - val_acc: 0.7649\n",
      "Epoch 416/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7003 - acc: 0.7414 - val_loss: 0.6814 - val_acc: 0.7649\n",
      "Epoch 417/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7117 - acc: 0.7329 - val_loss: 0.6767 - val_acc: 0.7656\n",
      "Epoch 418/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6988 - acc: 0.7433 - val_loss: 0.6811 - val_acc: 0.7649\n",
      "Epoch 419/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6914 - acc: 0.7481 - val_loss: 0.6796 - val_acc: 0.7656\n",
      "Epoch 420/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6948 - acc: 0.7448 - val_loss: 0.6797 - val_acc: 0.7641\n",
      "Epoch 421/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6909 - acc: 0.7459 - val_loss: 0.6803 - val_acc: 0.7656\n",
      "Epoch 422/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7257 - acc: 0.7314 - val_loss: 0.6809 - val_acc: 0.7641\n",
      "Epoch 423/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7152 - acc: 0.7340 - val_loss: 0.6787 - val_acc: 0.7664\n",
      "Epoch 424/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7095 - acc: 0.7370 - val_loss: 0.6816 - val_acc: 0.7649\n",
      "Epoch 425/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7129 - acc: 0.7366 - val_loss: 0.6802 - val_acc: 0.7656\n",
      "Epoch 426/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7107 - acc: 0.7281 - val_loss: 0.6776 - val_acc: 0.7664\n",
      "Epoch 427/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7032 - acc: 0.7452 - val_loss: 0.6800 - val_acc: 0.7656\n",
      "Epoch 428/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7202 - acc: 0.7366 - val_loss: 0.6795 - val_acc: 0.7664\n",
      "Epoch 429/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7075 - acc: 0.7314 - val_loss: 0.6815 - val_acc: 0.7649\n",
      "Epoch 430/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7077 - acc: 0.7478 - val_loss: 0.6804 - val_acc: 0.7649\n",
      "Epoch 431/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7225 - acc: 0.7374 - val_loss: 0.6743 - val_acc: 0.7671\n",
      "Epoch 432/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7094 - acc: 0.7336 - val_loss: 0.6775 - val_acc: 0.7656\n",
      "Epoch 433/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7099 - acc: 0.7340 - val_loss: 0.6798 - val_acc: 0.7656\n",
      "Epoch 434/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6945 - acc: 0.7388 - val_loss: 0.6774 - val_acc: 0.7664\n",
      "Epoch 435/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7070 - acc: 0.7426 - val_loss: 0.6791 - val_acc: 0.7656\n",
      "Epoch 436/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7117 - acc: 0.7362 - val_loss: 0.6786 - val_acc: 0.7656\n",
      "Epoch 437/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7184 - acc: 0.7336 - val_loss: 0.6802 - val_acc: 0.7656\n",
      "Epoch 438/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7209 - acc: 0.7307 - val_loss: 0.6785 - val_acc: 0.7656\n",
      "Epoch 439/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7015 - acc: 0.7355 - val_loss: 0.6808 - val_acc: 0.7649\n",
      "Epoch 440/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7136 - acc: 0.7333 - val_loss: 0.6815 - val_acc: 0.7649\n",
      "Epoch 441/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7091 - acc: 0.7407 - val_loss: 0.6795 - val_acc: 0.7656\n",
      "Epoch 442/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7015 - acc: 0.7414 - val_loss: 0.6815 - val_acc: 0.7649\n",
      "Epoch 443/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6955 - acc: 0.7396 - val_loss: 0.6782 - val_acc: 0.7664\n",
      "Epoch 444/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7148 - acc: 0.7325 - val_loss: 0.6806 - val_acc: 0.7656\n",
      "Epoch 445/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7083 - acc: 0.7333 - val_loss: 0.6793 - val_acc: 0.7656\n",
      "Epoch 446/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7070 - acc: 0.7429 - val_loss: 0.6764 - val_acc: 0.7664\n",
      "Epoch 447/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7076 - acc: 0.7403 - val_loss: 0.6807 - val_acc: 0.7649\n",
      "Epoch 448/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7066 - acc: 0.7388 - val_loss: 0.6784 - val_acc: 0.7656\n",
      "Epoch 449/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7099 - acc: 0.7396 - val_loss: 0.6795 - val_acc: 0.7664\n",
      "Epoch 450/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7098 - acc: 0.7299 - val_loss: 0.6811 - val_acc: 0.7649\n",
      "Epoch 451/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7011 - acc: 0.7429 - val_loss: 0.6801 - val_acc: 0.7656\n",
      "Epoch 452/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7011 - acc: 0.7426 - val_loss: 0.6804 - val_acc: 0.7649\n",
      "Epoch 453/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7052 - acc: 0.7325 - val_loss: 0.6801 - val_acc: 0.7649\n",
      "Epoch 454/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7150 - acc: 0.7329 - val_loss: 0.6814 - val_acc: 0.7649\n",
      "Epoch 455/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7013 - acc: 0.7429 - val_loss: 0.6805 - val_acc: 0.7656\n",
      "Epoch 456/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7053 - acc: 0.7388 - val_loss: 0.6803 - val_acc: 0.7649\n",
      "Epoch 457/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7141 - acc: 0.7333 - val_loss: 0.6804 - val_acc: 0.7649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 458/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7024 - acc: 0.7340 - val_loss: 0.6790 - val_acc: 0.7656\n",
      "Epoch 459/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7013 - acc: 0.7414 - val_loss: 0.6788 - val_acc: 0.7664\n",
      "Epoch 460/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7292 - acc: 0.7370 - val_loss: 0.6796 - val_acc: 0.7656\n",
      "Epoch 461/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7102 - acc: 0.7340 - val_loss: 0.6811 - val_acc: 0.7649\n",
      "Epoch 462/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7084 - acc: 0.7418 - val_loss: 0.6802 - val_acc: 0.7656\n",
      "Epoch 463/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7017 - acc: 0.7344 - val_loss: 0.6812 - val_acc: 0.7649\n",
      "Epoch 464/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7140 - acc: 0.7336 - val_loss: 0.6772 - val_acc: 0.7656\n",
      "Epoch 465/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6993 - acc: 0.7381 - val_loss: 0.6811 - val_acc: 0.7641\n",
      "\n",
      "Epoch 00465: loss improved from inf to 0.69934, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-2-000465-0.699343-0.764137.hdf5\n",
      "Epoch 466/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7269 - acc: 0.7273 - val_loss: 0.6814 - val_acc: 0.7641\n",
      "Epoch 467/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7108 - acc: 0.7374 - val_loss: 0.6798 - val_acc: 0.7649\n",
      "Epoch 468/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7072 - acc: 0.7407 - val_loss: 0.6805 - val_acc: 0.7649\n",
      "Epoch 469/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6938 - acc: 0.7541 - val_loss: 0.6805 - val_acc: 0.7649\n",
      "\n",
      "Epoch 00469: loss improved from 0.69934 to 0.69381, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-2-000469-0.693811-0.764881.hdf5\n",
      "Epoch 470/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7041 - acc: 0.7329 - val_loss: 0.6791 - val_acc: 0.7656\n",
      "Epoch 471/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7085 - acc: 0.7355 - val_loss: 0.6804 - val_acc: 0.7641\n",
      "Epoch 472/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7051 - acc: 0.7396 - val_loss: 0.6803 - val_acc: 0.7649\n",
      "Epoch 473/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7132 - acc: 0.7333 - val_loss: 0.6799 - val_acc: 0.7649\n",
      "Epoch 474/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7059 - acc: 0.7388 - val_loss: 0.6810 - val_acc: 0.7641\n",
      "Epoch 475/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7229 - acc: 0.7321 - val_loss: 0.6809 - val_acc: 0.7656\n",
      "Epoch 476/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6995 - acc: 0.7307 - val_loss: 0.6783 - val_acc: 0.7656\n",
      "Epoch 477/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7129 - acc: 0.7381 - val_loss: 0.6770 - val_acc: 0.7664\n",
      "Epoch 478/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7145 - acc: 0.7396 - val_loss: 0.6805 - val_acc: 0.7649\n",
      "Epoch 479/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7133 - acc: 0.7307 - val_loss: 0.6785 - val_acc: 0.7671\n",
      "Epoch 480/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7223 - acc: 0.7388 - val_loss: 0.6807 - val_acc: 0.7649\n",
      "Epoch 481/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7170 - acc: 0.7418 - val_loss: 0.6805 - val_acc: 0.7649\n",
      "Epoch 482/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7149 - acc: 0.7281 - val_loss: 0.6809 - val_acc: 0.7649\n",
      "Epoch 483/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6978 - acc: 0.7418 - val_loss: 0.6789 - val_acc: 0.7656\n",
      "Epoch 484/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7038 - acc: 0.7318 - val_loss: 0.6802 - val_acc: 0.7656\n",
      "Epoch 485/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7246 - acc: 0.7355 - val_loss: 0.6804 - val_acc: 0.7656\n",
      "Epoch 486/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7224 - acc: 0.7392 - val_loss: 0.6780 - val_acc: 0.7656\n",
      "Epoch 487/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7013 - acc: 0.7459 - val_loss: 0.6802 - val_acc: 0.7656\n",
      "Epoch 488/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7103 - acc: 0.7299 - val_loss: 0.6794 - val_acc: 0.7664\n",
      "Epoch 489/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7175 - acc: 0.7325 - val_loss: 0.6812 - val_acc: 0.7649\n",
      "Epoch 490/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6982 - acc: 0.7448 - val_loss: 0.6808 - val_acc: 0.7649\n",
      "Epoch 491/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6957 - acc: 0.7426 - val_loss: 0.6807 - val_acc: 0.7656\n",
      "Epoch 492/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6932 - acc: 0.7370 - val_loss: 0.6807 - val_acc: 0.7649\n",
      "Epoch 493/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7255 - acc: 0.7288 - val_loss: 0.6807 - val_acc: 0.7656\n",
      "Epoch 494/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7000 - acc: 0.7303 - val_loss: 0.6802 - val_acc: 0.7656\n",
      "Epoch 495/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7068 - acc: 0.7396 - val_loss: 0.6805 - val_acc: 0.7649\n",
      "Epoch 496/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7235 - acc: 0.7321 - val_loss: 0.6727 - val_acc: 0.7671\n",
      "Epoch 497/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7102 - acc: 0.7377 - val_loss: 0.6809 - val_acc: 0.7649\n",
      "Epoch 498/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7102 - acc: 0.7307 - val_loss: 0.6805 - val_acc: 0.7656\n",
      "Epoch 499/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6894 - acc: 0.7385 - val_loss: 0.6807 - val_acc: 0.7656\n",
      "Epoch 500/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6922 - acc: 0.7437 - val_loss: 0.6775 - val_acc: 0.7664\n",
      "\n",
      "Epoch 00500: saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/2-000500-0.692234-0.766369.hdf5\n",
      "Epoch 501/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7075 - acc: 0.7344 - val_loss: 0.6797 - val_acc: 0.7656\n",
      "Epoch 502/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7211 - acc: 0.7377 - val_loss: 0.6781 - val_acc: 0.7664\n",
      "Epoch 503/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7121 - acc: 0.7344 - val_loss: 0.6807 - val_acc: 0.7649\n",
      "Epoch 504/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7125 - acc: 0.7288 - val_loss: 0.6803 - val_acc: 0.7649\n",
      "Epoch 505/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7134 - acc: 0.7388 - val_loss: 0.6777 - val_acc: 0.7664\n",
      "Epoch 506/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7094 - acc: 0.7426 - val_loss: 0.6793 - val_acc: 0.7656\n",
      "Epoch 507/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7102 - acc: 0.7381 - val_loss: 0.6809 - val_acc: 0.7649\n",
      "Epoch 508/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7081 - acc: 0.7370 - val_loss: 0.6790 - val_acc: 0.7664\n",
      "Epoch 509/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7171 - acc: 0.7440 - val_loss: 0.6800 - val_acc: 0.7664\n",
      "Epoch 510/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7240 - acc: 0.7321 - val_loss: 0.6802 - val_acc: 0.7649\n",
      "Epoch 511/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6934 - acc: 0.7414 - val_loss: 0.6790 - val_acc: 0.7649\n",
      "Epoch 512/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7048 - acc: 0.7329 - val_loss: 0.6796 - val_acc: 0.7649\n",
      "Epoch 513/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7004 - acc: 0.7392 - val_loss: 0.6800 - val_acc: 0.7649\n",
      "Epoch 514/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7146 - acc: 0.7314 - val_loss: 0.6800 - val_acc: 0.7641\n",
      "Epoch 515/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6999 - acc: 0.7455 - val_loss: 0.6814 - val_acc: 0.7641\n",
      "Epoch 516/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7127 - acc: 0.7407 - val_loss: 0.6795 - val_acc: 0.7656\n",
      "Epoch 517/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7028 - acc: 0.7381 - val_loss: 0.6793 - val_acc: 0.7664\n",
      "Epoch 518/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7155 - acc: 0.7381 - val_loss: 0.6804 - val_acc: 0.7649\n",
      "Epoch 519/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7068 - acc: 0.7336 - val_loss: 0.6808 - val_acc: 0.7641\n",
      "Epoch 520/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7165 - acc: 0.7295 - val_loss: 0.6803 - val_acc: 0.7649\n",
      "Epoch 521/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7171 - acc: 0.7407 - val_loss: 0.6805 - val_acc: 0.7656\n",
      "Epoch 522/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7069 - acc: 0.7400 - val_loss: 0.6799 - val_acc: 0.7649\n",
      "Epoch 523/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7024 - acc: 0.7429 - val_loss: 0.6798 - val_acc: 0.7664\n",
      "Epoch 524/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7240 - acc: 0.7333 - val_loss: 0.6805 - val_acc: 0.7649\n",
      "Epoch 525/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7102 - acc: 0.7437 - val_loss: 0.6807 - val_acc: 0.7656\n",
      "Epoch 526/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7078 - acc: 0.7396 - val_loss: 0.6796 - val_acc: 0.7656\n",
      "Epoch 527/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7035 - acc: 0.7344 - val_loss: 0.6800 - val_acc: 0.7656\n",
      "Epoch 528/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7101 - acc: 0.7392 - val_loss: 0.6786 - val_acc: 0.7664\n",
      "Epoch 529/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7141 - acc: 0.7381 - val_loss: 0.6804 - val_acc: 0.7649\n",
      "Epoch 530/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7118 - acc: 0.7407 - val_loss: 0.6793 - val_acc: 0.7656\n",
      "Epoch 531/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7171 - acc: 0.7366 - val_loss: 0.6793 - val_acc: 0.7664\n",
      "Epoch 532/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7070 - acc: 0.7437 - val_loss: 0.6794 - val_acc: 0.7664\n",
      "Epoch 533/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7219 - acc: 0.7281 - val_loss: 0.6795 - val_acc: 0.7656\n",
      "Epoch 534/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6974 - acc: 0.7422 - val_loss: 0.6799 - val_acc: 0.7649\n",
      "Epoch 535/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7103 - acc: 0.7355 - val_loss: 0.6797 - val_acc: 0.7649\n",
      "Epoch 536/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7071 - acc: 0.7385 - val_loss: 0.6800 - val_acc: 0.7649\n",
      "Epoch 537/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7010 - acc: 0.7422 - val_loss: 0.6792 - val_acc: 0.7656\n",
      "Epoch 538/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7124 - acc: 0.7318 - val_loss: 0.6793 - val_acc: 0.7649\n",
      "Epoch 539/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7151 - acc: 0.7388 - val_loss: 0.6751 - val_acc: 0.7656\n",
      "Epoch 540/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7245 - acc: 0.7344 - val_loss: 0.6807 - val_acc: 0.7649\n",
      "Epoch 541/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7089 - acc: 0.7347 - val_loss: 0.6802 - val_acc: 0.7649\n",
      "Epoch 542/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7180 - acc: 0.7333 - val_loss: 0.6801 - val_acc: 0.7649\n",
      "Epoch 543/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7160 - acc: 0.7299 - val_loss: 0.6811 - val_acc: 0.7641\n",
      "Epoch 544/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7246 - acc: 0.7340 - val_loss: 0.6786 - val_acc: 0.7656\n",
      "Epoch 545/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7191 - acc: 0.7292 - val_loss: 0.6802 - val_acc: 0.7649\n",
      "Epoch 546/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7290 - acc: 0.7347 - val_loss: 0.6810 - val_acc: 0.7649\n",
      "Epoch 547/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7172 - acc: 0.7418 - val_loss: 0.6806 - val_acc: 0.7649\n",
      "Epoch 548/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7192 - acc: 0.7407 - val_loss: 0.6813 - val_acc: 0.7649\n",
      "Epoch 549/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7128 - acc: 0.7340 - val_loss: 0.6811 - val_acc: 0.7649\n",
      "Epoch 550/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7187 - acc: 0.7403 - val_loss: 0.6776 - val_acc: 0.7656\n",
      "Epoch 551/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.7120 - acc: 0.7370 - val_loss: 0.6793 - val_acc: 0.7649\n",
      "Epoch 552/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7260 - acc: 0.7351 - val_loss: 0.6786 - val_acc: 0.7664\n",
      "Epoch 553/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.7129 - acc: 0.7340 - val_loss: 0.6766 - val_acc: 0.7656\n",
      "Epoch 554/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7160 - acc: 0.7366 - val_loss: 0.6799 - val_acc: 0.7656\n",
      "Epoch 555/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7160 - acc: 0.7455 - val_loss: 0.6762 - val_acc: 0.7656\n",
      "Epoch 556/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7232 - acc: 0.7333 - val_loss: 0.6802 - val_acc: 0.7656\n",
      "Epoch 557/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7012 - acc: 0.7459 - val_loss: 0.6781 - val_acc: 0.7671\n",
      "Epoch 558/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7202 - acc: 0.7314 - val_loss: 0.6805 - val_acc: 0.7649\n",
      "Epoch 559/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7020 - acc: 0.7433 - val_loss: 0.6804 - val_acc: 0.7641\n",
      "Epoch 560/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7007 - acc: 0.7407 - val_loss: 0.6807 - val_acc: 0.7641\n",
      "Epoch 561/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6856 - acc: 0.7448 - val_loss: 0.6799 - val_acc: 0.7656\n",
      "Epoch 562/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.6945 - acc: 0.7459 - val_loss: 0.6810 - val_acc: 0.7641\n",
      "Epoch 563/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7058 - acc: 0.7362 - val_loss: 0.6807 - val_acc: 0.7641\n",
      "Epoch 564/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7030 - acc: 0.7452 - val_loss: 0.6788 - val_acc: 0.7656\n",
      "Epoch 565/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7031 - acc: 0.7374 - val_loss: 0.6806 - val_acc: 0.7641\n",
      "\n",
      "Epoch 00565: loss improved from inf to 0.70314, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-2-000565-0.703140-0.764137.hdf5\n",
      "Epoch 566/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6922 - acc: 0.7452 - val_loss: 0.6793 - val_acc: 0.7649\n",
      "Epoch 567/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7092 - acc: 0.7407 - val_loss: 0.6794 - val_acc: 0.7649\n",
      "Epoch 568/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7156 - acc: 0.7292 - val_loss: 0.6807 - val_acc: 0.7641\n",
      "Epoch 569/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7061 - acc: 0.7403 - val_loss: 0.6796 - val_acc: 0.7649\n",
      "Epoch 570/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7023 - acc: 0.7440 - val_loss: 0.6783 - val_acc: 0.7649\n",
      "Epoch 571/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6947 - acc: 0.7388 - val_loss: 0.6751 - val_acc: 0.7656\n",
      "Epoch 572/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7179 - acc: 0.7385 - val_loss: 0.6794 - val_acc: 0.7649\n",
      "Epoch 573/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7103 - acc: 0.7370 - val_loss: 0.6782 - val_acc: 0.7656\n",
      "Epoch 574/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7012 - acc: 0.7485 - val_loss: 0.6812 - val_acc: 0.7641\n",
      "Epoch 575/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7158 - acc: 0.7333 - val_loss: 0.6804 - val_acc: 0.7649\n",
      "Epoch 576/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6957 - acc: 0.7440 - val_loss: 0.6801 - val_acc: 0.7649\n",
      "Epoch 577/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7091 - acc: 0.7385 - val_loss: 0.6813 - val_acc: 0.7641\n",
      "Epoch 578/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7103 - acc: 0.7377 - val_loss: 0.6800 - val_acc: 0.7641\n",
      "Epoch 579/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7178 - acc: 0.7295 - val_loss: 0.6808 - val_acc: 0.7641\n",
      "Epoch 580/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7107 - acc: 0.7314 - val_loss: 0.6807 - val_acc: 0.7641\n",
      "Epoch 581/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7049 - acc: 0.7414 - val_loss: 0.6807 - val_acc: 0.7649\n",
      "Epoch 582/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7068 - acc: 0.7403 - val_loss: 0.6737 - val_acc: 0.7664\n",
      "Epoch 583/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7105 - acc: 0.7396 - val_loss: 0.6780 - val_acc: 0.7664\n",
      "Epoch 584/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7182 - acc: 0.7418 - val_loss: 0.6750 - val_acc: 0.7656\n",
      "Epoch 585/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7038 - acc: 0.7366 - val_loss: 0.6807 - val_acc: 0.7656\n",
      "Epoch 586/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7214 - acc: 0.7340 - val_loss: 0.6795 - val_acc: 0.7656\n",
      "Epoch 587/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7151 - acc: 0.7440 - val_loss: 0.6812 - val_acc: 0.7649\n",
      "Epoch 588/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7169 - acc: 0.7385 - val_loss: 0.6793 - val_acc: 0.7656\n",
      "Epoch 589/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7107 - acc: 0.7418 - val_loss: 0.6808 - val_acc: 0.7649\n",
      "Epoch 590/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7073 - acc: 0.7440 - val_loss: 0.6790 - val_acc: 0.7656\n",
      "Epoch 591/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6896 - acc: 0.7511 - val_loss: 0.6804 - val_acc: 0.7649\n",
      "Epoch 592/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6897 - acc: 0.7407 - val_loss: 0.6792 - val_acc: 0.7656\n",
      "Epoch 593/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7441 - acc: 0.7225 - val_loss: 0.6813 - val_acc: 0.7649\n",
      "Epoch 594/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7149 - acc: 0.7277 - val_loss: 0.6810 - val_acc: 0.7649\n",
      "Epoch 595/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7174 - acc: 0.7295 - val_loss: 0.6809 - val_acc: 0.7649\n",
      "Epoch 596/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7173 - acc: 0.7314 - val_loss: 0.6800 - val_acc: 0.7656\n",
      "Epoch 597/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7092 - acc: 0.7422 - val_loss: 0.6801 - val_acc: 0.7656\n",
      "Epoch 598/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7130 - acc: 0.7366 - val_loss: 0.6788 - val_acc: 0.7664\n",
      "Epoch 599/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7162 - acc: 0.7467 - val_loss: 0.6809 - val_acc: 0.7649\n",
      "Epoch 600/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7160 - acc: 0.7321 - val_loss: 0.6805 - val_acc: 0.7656\n",
      "\n",
      "Epoch 00600: saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/2-000600-0.715978-0.765625.hdf5\n",
      "Epoch 601/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7136 - acc: 0.7377 - val_loss: 0.6795 - val_acc: 0.7656\n",
      "Epoch 602/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7177 - acc: 0.7344 - val_loss: 0.6798 - val_acc: 0.7649\n",
      "Epoch 603/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7158 - acc: 0.7347 - val_loss: 0.6784 - val_acc: 0.7664\n",
      "Epoch 604/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7316 - acc: 0.7366 - val_loss: 0.6802 - val_acc: 0.7656\n",
      "Epoch 605/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7101 - acc: 0.7344 - val_loss: 0.6789 - val_acc: 0.7664\n",
      "Epoch 606/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7159 - acc: 0.7381 - val_loss: 0.6798 - val_acc: 0.7649\n",
      "Epoch 607/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7159 - acc: 0.7288 - val_loss: 0.6791 - val_acc: 0.7664\n",
      "Epoch 608/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7103 - acc: 0.7388 - val_loss: 0.6774 - val_acc: 0.7664\n",
      "Epoch 609/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7123 - acc: 0.7355 - val_loss: 0.6809 - val_acc: 0.7649\n",
      "Epoch 610/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7053 - acc: 0.7414 - val_loss: 0.6800 - val_acc: 0.7656\n",
      "Epoch 611/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7139 - acc: 0.7329 - val_loss: 0.6792 - val_acc: 0.7656\n",
      "Epoch 612/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7268 - acc: 0.7232 - val_loss: 0.6792 - val_acc: 0.7656\n",
      "Epoch 613/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7055 - acc: 0.7481 - val_loss: 0.6792 - val_acc: 0.7656\n",
      "Epoch 614/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7245 - acc: 0.7351 - val_loss: 0.6783 - val_acc: 0.7664\n",
      "Epoch 615/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7243 - acc: 0.7258 - val_loss: 0.6765 - val_acc: 0.7664\n",
      "Epoch 616/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7175 - acc: 0.7388 - val_loss: 0.6797 - val_acc: 0.7656\n",
      "Epoch 617/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7048 - acc: 0.7377 - val_loss: 0.6814 - val_acc: 0.7649\n",
      "Epoch 618/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7110 - acc: 0.7455 - val_loss: 0.6767 - val_acc: 0.7656\n",
      "Epoch 619/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7197 - acc: 0.7273 - val_loss: 0.6803 - val_acc: 0.7656\n",
      "Epoch 620/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6926 - acc: 0.7418 - val_loss: 0.6794 - val_acc: 0.7649\n",
      "Epoch 621/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7149 - acc: 0.7403 - val_loss: 0.6769 - val_acc: 0.7656\n",
      "Epoch 622/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7120 - acc: 0.7374 - val_loss: 0.6806 - val_acc: 0.7649\n",
      "Epoch 623/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7036 - acc: 0.7355 - val_loss: 0.6794 - val_acc: 0.7649\n",
      "Epoch 624/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7109 - acc: 0.7388 - val_loss: 0.6802 - val_acc: 0.7656\n",
      "Epoch 625/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7125 - acc: 0.7362 - val_loss: 0.6799 - val_acc: 0.7656\n",
      "Epoch 626/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6942 - acc: 0.7448 - val_loss: 0.6803 - val_acc: 0.7649\n",
      "Epoch 627/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7195 - acc: 0.7307 - val_loss: 0.6802 - val_acc: 0.7649\n",
      "Epoch 628/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7163 - acc: 0.7388 - val_loss: 0.6807 - val_acc: 0.7649\n",
      "Epoch 629/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7098 - acc: 0.7429 - val_loss: 0.6807 - val_acc: 0.7656\n",
      "Epoch 630/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7055 - acc: 0.7329 - val_loss: 0.6812 - val_acc: 0.7649\n",
      "Epoch 631/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7205 - acc: 0.7340 - val_loss: 0.6781 - val_acc: 0.7664\n",
      "Epoch 632/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7217 - acc: 0.7310 - val_loss: 0.6810 - val_acc: 0.7641\n",
      "Epoch 633/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7093 - acc: 0.7452 - val_loss: 0.6794 - val_acc: 0.7649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 634/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7120 - acc: 0.7325 - val_loss: 0.6790 - val_acc: 0.7656\n",
      "Epoch 635/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7083 - acc: 0.7396 - val_loss: 0.6793 - val_acc: 0.7656\n",
      "Epoch 636/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6953 - acc: 0.7370 - val_loss: 0.6797 - val_acc: 0.7649\n",
      "Epoch 637/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7173 - acc: 0.7355 - val_loss: 0.6811 - val_acc: 0.7641\n",
      "Epoch 638/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6953 - acc: 0.7489 - val_loss: 0.6801 - val_acc: 0.7649\n",
      "Epoch 639/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6982 - acc: 0.7288 - val_loss: 0.6812 - val_acc: 0.7641\n",
      "Epoch 640/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7029 - acc: 0.7452 - val_loss: 0.6806 - val_acc: 0.7641\n",
      "Epoch 641/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7111 - acc: 0.7381 - val_loss: 0.6803 - val_acc: 0.7656\n",
      "Epoch 642/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7058 - acc: 0.7396 - val_loss: 0.6794 - val_acc: 0.7656\n",
      "Epoch 643/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7184 - acc: 0.7359 - val_loss: 0.6788 - val_acc: 0.7656\n",
      "Epoch 644/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7180 - acc: 0.7351 - val_loss: 0.6802 - val_acc: 0.7649\n",
      "Epoch 645/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7251 - acc: 0.7418 - val_loss: 0.6791 - val_acc: 0.7656\n",
      "Epoch 646/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7250 - acc: 0.7344 - val_loss: 0.6783 - val_acc: 0.7656\n",
      "Epoch 647/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7068 - acc: 0.7325 - val_loss: 0.6792 - val_acc: 0.7664\n",
      "Epoch 648/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7000 - acc: 0.7392 - val_loss: 0.6803 - val_acc: 0.7649\n",
      "Epoch 649/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7055 - acc: 0.7403 - val_loss: 0.6797 - val_acc: 0.7656\n",
      "Epoch 650/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7098 - acc: 0.7381 - val_loss: 0.6812 - val_acc: 0.7649\n",
      "Epoch 651/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7019 - acc: 0.7478 - val_loss: 0.6803 - val_acc: 0.7649\n",
      "Epoch 652/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6971 - acc: 0.7347 - val_loss: 0.6810 - val_acc: 0.7649\n",
      "Epoch 653/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7226 - acc: 0.7284 - val_loss: 0.6773 - val_acc: 0.7664\n",
      "Epoch 654/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7041 - acc: 0.7407 - val_loss: 0.6749 - val_acc: 0.7656\n",
      "Epoch 655/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7093 - acc: 0.7281 - val_loss: 0.6810 - val_acc: 0.7649\n",
      "Epoch 656/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7247 - acc: 0.7385 - val_loss: 0.6682 - val_acc: 0.7656\n",
      "Epoch 657/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7004 - acc: 0.7392 - val_loss: 0.6799 - val_acc: 0.7641\n",
      "Epoch 658/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7199 - acc: 0.7388 - val_loss: 0.6781 - val_acc: 0.7664\n",
      "Epoch 659/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7174 - acc: 0.7351 - val_loss: 0.6804 - val_acc: 0.7649\n",
      "Epoch 660/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7072 - acc: 0.7429 - val_loss: 0.6806 - val_acc: 0.7649\n",
      "Epoch 661/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7041 - acc: 0.7377 - val_loss: 0.6803 - val_acc: 0.7649\n",
      "Epoch 662/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7059 - acc: 0.7370 - val_loss: 0.6759 - val_acc: 0.7671\n",
      "Epoch 663/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7055 - acc: 0.7388 - val_loss: 0.6796 - val_acc: 0.7649\n",
      "Epoch 664/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7140 - acc: 0.7340 - val_loss: 0.6796 - val_acc: 0.7656\n",
      "Epoch 665/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7042 - acc: 0.7470 - val_loss: 0.6799 - val_acc: 0.7656\n",
      "\n",
      "Epoch 00665: loss improved from inf to 0.70417, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-2-000665-0.704167-0.765625.hdf5\n",
      "Epoch 666/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6930 - acc: 0.7418 - val_loss: 0.6783 - val_acc: 0.7664\n",
      "Epoch 667/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7073 - acc: 0.7385 - val_loss: 0.6790 - val_acc: 0.7656\n",
      "Epoch 668/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7162 - acc: 0.7388 - val_loss: 0.6795 - val_acc: 0.7656\n",
      "Epoch 669/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7235 - acc: 0.7243 - val_loss: 0.6798 - val_acc: 0.7656\n",
      "Epoch 670/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7131 - acc: 0.7344 - val_loss: 0.6791 - val_acc: 0.7656\n",
      "Epoch 671/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7013 - acc: 0.7407 - val_loss: 0.6804 - val_acc: 0.7649\n",
      "Epoch 672/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7180 - acc: 0.7340 - val_loss: 0.6802 - val_acc: 0.7656\n",
      "Epoch 673/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7149 - acc: 0.7392 - val_loss: 0.6797 - val_acc: 0.7656\n",
      "Epoch 674/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7122 - acc: 0.7336 - val_loss: 0.6805 - val_acc: 0.7649\n",
      "Epoch 675/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7232 - acc: 0.7269 - val_loss: 0.6791 - val_acc: 0.7664\n",
      "Epoch 676/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7161 - acc: 0.7340 - val_loss: 0.6795 - val_acc: 0.7656\n",
      "Epoch 677/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7159 - acc: 0.7340 - val_loss: 0.6802 - val_acc: 0.7649\n",
      "Epoch 678/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6996 - acc: 0.7448 - val_loss: 0.6796 - val_acc: 0.7664\n",
      "Epoch 679/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6949 - acc: 0.7459 - val_loss: 0.6804 - val_acc: 0.7649\n",
      "Epoch 680/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7095 - acc: 0.7359 - val_loss: 0.6768 - val_acc: 0.7664\n",
      "Epoch 681/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7018 - acc: 0.7433 - val_loss: 0.6803 - val_acc: 0.7656\n",
      "\n",
      "Epoch 00681: loss improved from 0.70417 to 0.70180, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-2-000681-0.701800-0.765625.hdf5\n",
      "Epoch 682/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7176 - acc: 0.7344 - val_loss: 0.6769 - val_acc: 0.7656\n",
      "Epoch 683/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7246 - acc: 0.7288 - val_loss: 0.6799 - val_acc: 0.7656\n",
      "Epoch 684/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7160 - acc: 0.7351 - val_loss: 0.6797 - val_acc: 0.7656\n",
      "Epoch 685/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6918 - acc: 0.7403 - val_loss: 0.6807 - val_acc: 0.7649\n",
      "\n",
      "Epoch 00685: loss improved from 0.70180 to 0.69175, saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/Pbest-2-000685-0.691754-0.764881.hdf5\n",
      "Epoch 686/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7128 - acc: 0.7385 - val_loss: 0.6685 - val_acc: 0.7656\n",
      "Epoch 687/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7089 - acc: 0.7407 - val_loss: 0.6813 - val_acc: 0.7649\n",
      "Epoch 688/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7211 - acc: 0.7336 - val_loss: 0.6796 - val_acc: 0.7656\n",
      "Epoch 689/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7020 - acc: 0.7474 - val_loss: 0.6799 - val_acc: 0.7656\n",
      "Epoch 690/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7051 - acc: 0.7333 - val_loss: 0.6807 - val_acc: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 691/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7102 - acc: 0.7392 - val_loss: 0.6779 - val_acc: 0.7664\n",
      "Epoch 692/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6893 - acc: 0.7504 - val_loss: 0.6801 - val_acc: 0.7656\n",
      "Epoch 693/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7084 - acc: 0.7422 - val_loss: 0.6793 - val_acc: 0.7656\n",
      "Epoch 694/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7080 - acc: 0.7467 - val_loss: 0.6803 - val_acc: 0.7649\n",
      "Epoch 695/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7162 - acc: 0.7407 - val_loss: 0.6793 - val_acc: 0.7656\n",
      "Epoch 696/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7166 - acc: 0.7388 - val_loss: 0.6800 - val_acc: 0.7649\n",
      "Epoch 697/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7163 - acc: 0.7374 - val_loss: 0.6756 - val_acc: 0.7664\n",
      "Epoch 698/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7131 - acc: 0.7418 - val_loss: 0.6780 - val_acc: 0.7664\n",
      "Epoch 699/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7104 - acc: 0.7422 - val_loss: 0.6812 - val_acc: 0.7649\n",
      "Epoch 700/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7233 - acc: 0.7392 - val_loss: 0.6751 - val_acc: 0.7671\n",
      "\n",
      "Epoch 00700: saving model to ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/2-000700-0.723263-0.767113.hdf5\n",
      "Epoch 701/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7163 - acc: 0.7307 - val_loss: 0.6809 - val_acc: 0.7649\n",
      "Epoch 702/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7004 - acc: 0.7452 - val_loss: 0.6757 - val_acc: 0.7656\n",
      "Epoch 703/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6994 - acc: 0.7411 - val_loss: 0.6810 - val_acc: 0.7649\n",
      "Epoch 704/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7067 - acc: 0.7400 - val_loss: 0.6800 - val_acc: 0.7656\n",
      "Epoch 705/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7042 - acc: 0.7422 - val_loss: 0.6798 - val_acc: 0.7656\n",
      "Epoch 706/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7030 - acc: 0.7355 - val_loss: 0.6782 - val_acc: 0.7656\n",
      "Epoch 707/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7017 - acc: 0.7459 - val_loss: 0.6794 - val_acc: 0.7656\n",
      "Epoch 708/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7034 - acc: 0.7329 - val_loss: 0.6790 - val_acc: 0.7664\n",
      "Epoch 709/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7024 - acc: 0.7321 - val_loss: 0.6813 - val_acc: 0.7649\n",
      "Epoch 710/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7122 - acc: 0.7344 - val_loss: 0.6811 - val_acc: 0.7649\n",
      "Epoch 711/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7067 - acc: 0.7422 - val_loss: 0.6780 - val_acc: 0.7664\n",
      "Epoch 712/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7058 - acc: 0.7400 - val_loss: 0.6797 - val_acc: 0.7649\n",
      "Epoch 713/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7089 - acc: 0.7340 - val_loss: 0.6811 - val_acc: 0.7649\n",
      "Epoch 714/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7025 - acc: 0.7362 - val_loss: 0.6813 - val_acc: 0.7649\n",
      "Epoch 715/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7036 - acc: 0.7333 - val_loss: 0.6799 - val_acc: 0.7656\n",
      "Epoch 716/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7161 - acc: 0.7362 - val_loss: 0.6810 - val_acc: 0.7649\n",
      "Epoch 717/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7222 - acc: 0.7374 - val_loss: 0.6799 - val_acc: 0.7656\n",
      "Epoch 718/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7210 - acc: 0.7400 - val_loss: 0.6781 - val_acc: 0.7664\n",
      "Epoch 719/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7203 - acc: 0.7277 - val_loss: 0.6802 - val_acc: 0.7656\n",
      "Epoch 720/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7124 - acc: 0.7396 - val_loss: 0.6787 - val_acc: 0.7656\n",
      "Epoch 721/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7101 - acc: 0.7362 - val_loss: 0.6811 - val_acc: 0.7649\n",
      "Epoch 722/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7061 - acc: 0.7385 - val_loss: 0.6799 - val_acc: 0.7649\n",
      "Epoch 723/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7072 - acc: 0.7385 - val_loss: 0.6807 - val_acc: 0.7649\n",
      "Epoch 724/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7112 - acc: 0.7340 - val_loss: 0.6812 - val_acc: 0.7649\n",
      "Epoch 725/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7074 - acc: 0.7392 - val_loss: 0.6768 - val_acc: 0.7656\n",
      "Epoch 726/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7051 - acc: 0.7381 - val_loss: 0.6783 - val_acc: 0.7664\n",
      "Epoch 727/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7074 - acc: 0.7400 - val_loss: 0.6777 - val_acc: 0.7656\n",
      "Epoch 728/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7177 - acc: 0.7303 - val_loss: 0.6804 - val_acc: 0.7649\n",
      "Epoch 729/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7309 - acc: 0.7325 - val_loss: 0.6797 - val_acc: 0.7656\n",
      "Epoch 730/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7071 - acc: 0.7325 - val_loss: 0.6806 - val_acc: 0.7641\n",
      "Epoch 731/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7103 - acc: 0.7385 - val_loss: 0.6805 - val_acc: 0.7641\n",
      "Epoch 732/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7195 - acc: 0.7422 - val_loss: 0.6763 - val_acc: 0.7649\n",
      "Epoch 733/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7287 - acc: 0.7303 - val_loss: 0.6796 - val_acc: 0.7656\n",
      "Epoch 734/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7134 - acc: 0.7336 - val_loss: 0.6807 - val_acc: 0.7649\n",
      "Epoch 735/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7048 - acc: 0.7277 - val_loss: 0.6790 - val_acc: 0.7649\n",
      "Epoch 736/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7073 - acc: 0.7362 - val_loss: 0.6808 - val_acc: 0.7641\n",
      "Epoch 737/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7106 - acc: 0.7336 - val_loss: 0.6806 - val_acc: 0.7641\n",
      "Epoch 738/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7187 - acc: 0.7318 - val_loss: 0.6794 - val_acc: 0.7649\n",
      "Epoch 739/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7224 - acc: 0.7325 - val_loss: 0.6795 - val_acc: 0.7664\n",
      "Epoch 740/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7126 - acc: 0.7403 - val_loss: 0.6772 - val_acc: 0.7656\n",
      "Epoch 741/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7075 - acc: 0.7426 - val_loss: 0.6786 - val_acc: 0.7656\n",
      "Epoch 742/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7264 - acc: 0.7321 - val_loss: 0.6810 - val_acc: 0.7649\n",
      "Epoch 743/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7048 - acc: 0.7422 - val_loss: 0.6790 - val_acc: 0.7656\n",
      "Epoch 744/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7077 - acc: 0.7381 - val_loss: 0.6759 - val_acc: 0.7664\n",
      "Epoch 745/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7206 - acc: 0.7321 - val_loss: 0.6800 - val_acc: 0.7656\n",
      "Epoch 746/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7329 - acc: 0.7396 - val_loss: 0.6798 - val_acc: 0.7649\n",
      "Epoch 747/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7037 - acc: 0.7437 - val_loss: 0.6800 - val_acc: 0.7656\n",
      "Epoch 748/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7090 - acc: 0.7437 - val_loss: 0.6799 - val_acc: 0.7656\n",
      "Epoch 749/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7173 - acc: 0.7400 - val_loss: 0.6789 - val_acc: 0.7656\n",
      "Epoch 750/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7055 - acc: 0.7396 - val_loss: 0.6806 - val_acc: 0.7649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 751/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7117 - acc: 0.7381 - val_loss: 0.6767 - val_acc: 0.7664\n",
      "Epoch 752/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7144 - acc: 0.7336 - val_loss: 0.6798 - val_acc: 0.7656\n",
      "Epoch 753/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7129 - acc: 0.7314 - val_loss: 0.6794 - val_acc: 0.7649\n",
      "Epoch 754/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7059 - acc: 0.7329 - val_loss: 0.6801 - val_acc: 0.7641\n",
      "Epoch 755/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7169 - acc: 0.7333 - val_loss: 0.6796 - val_acc: 0.7656\n",
      "Epoch 756/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7168 - acc: 0.7366 - val_loss: 0.6798 - val_acc: 0.7656\n",
      "Epoch 757/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7058 - acc: 0.7422 - val_loss: 0.6796 - val_acc: 0.7656\n",
      "Epoch 758/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7242 - acc: 0.7355 - val_loss: 0.6797 - val_acc: 0.7656\n",
      "Epoch 759/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7184 - acc: 0.7403 - val_loss: 0.6787 - val_acc: 0.7664\n",
      "Epoch 760/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7016 - acc: 0.7422 - val_loss: 0.6788 - val_acc: 0.7671\n",
      "Epoch 761/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7053 - acc: 0.7455 - val_loss: 0.6799 - val_acc: 0.7649\n",
      "Epoch 00761: early stopping\n",
      "ModelCheckpoint 已经保存到 ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/weights/2-final.hdf5\n",
      "save in: ../datasets/casas/results/WCNNR/milan/4/20220201_2000_64_1_3_1/log/20220201_2000_64_1_3_1.csv\n",
      "time: 0:19:53 s\n",
      "time: 1193.0 s\n",
      "average 1.193000 s\n",
      "2 epoch finished\n",
      "--------------------   best   --------------------\n",
      "no_activities: 10\n",
      "\n",
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1348/1348 [==============================] - 2s 1ms/step\n",
      "2-milan:\tacc: 76.56%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 0, 4, 0, 0, 4, 0, 4, 4, 0, 4, 4, 4, 0, 0, 4, 0, 7, 0, 0, 0, 0, 7, 7, 7, 2, 2, 0, 7, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 7, 0, 7, 7, 7, 7, 7, 0, 0, 7, 0, 7, 7, 7, 0, 7, 7, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 0, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 0, 7, 7, 0, 0, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 0, 7, 0, 7, 7, 7, 7, 7, 7, 7, 0, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 0, 7, 0, 7, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 0, 0, 0, 7, 7, 7, 0, 7, 7, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 0, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 0, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 0, 0, 0, 9, 0, 0, 9, 0, 9, 9, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 9, 0, 0, 9, 9, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7, 7, 7, 7, 7, 2, 7, 0, 2, 2, 7, 7, 0, 0, 9, 0, 0, 7, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 4, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 9, 9, 0, 7, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 7, 7, 0, 7, 0, 7, 0, 4, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 4, 4, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 4, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 5, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 4, 0, 7, 4, 4, 4, 4, 0, 4, 7, 4, 4, 0, 4, 4, 4, 4, 4, 0, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 0, 4, 4, 0, 4, 0, 4, 0, 0, 4, 4, 4, 4, 4, 4, 0, 0, 4, 0, 4, 4, 0, 0, 4, 4, 4, 7, 4, 4, 0, 4, 4, 4, 7, 4, 4, 4, 0, 4, 0, 4, 4, 4, 0, 4, 0, 0, 4, 0, 4, 4, 0, 0, 4, 4, 0, 4, 0, 4, 4, 4, 4, 0, 0, 0, 0, 0, 4, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 4, 7, 0, 0, 0, 0, 0, 9, 0, 0, 0, 4, 0, 0, 7, 4, 0, 0, 0, 9, 0, 7, 0, 4, 0, 4, 0, 4, 4, 0, 0, 0, 0, 0, 0, 9]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.759285  0.886035  0.817778       623\n",
      "         Work   0.000000  0.000000  0.000000        26\n",
      "Take_medicine   1.000000  0.250000  0.400000        20\n",
      "        Sleep   0.000000  0.000000  0.000000        32\n",
      "        Relax   0.737864  0.531469  0.617886       143\n",
      "   Leave_Home   0.914286  0.901408  0.907801        71\n",
      "          Eat   0.000000  0.000000  0.000000         7\n",
      "         Cook   0.753927  0.778378  0.765957       185\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        29\n",
      "      Bathing   0.757937  0.900943  0.823276       212\n",
      "\n",
      "     accuracy                       0.765579      1348\n",
      "    macro avg   0.492330  0.424823  0.433270      1348\n",
      " weighted avg   0.714853  0.765579  0.731843      1348\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  27   0   0   2   0   0]\n",
      " [  0   0   0   0   0   0   0  15  11   0]\n",
      " [  0   0   0   0   0   3   0   4   0   0]\n",
      " [  0   0   0   5   0  13   0   2   0   0]\n",
      " [  0   0   0   0 191   3   1  17   0   0]\n",
      " [  0   0   0   0   0 144   0  41   0   0]\n",
      " [  0   0   0   0   0   0  64   7   0   0]\n",
      " [  0   0   0   0  29  21   5 552  16   0]\n",
      " [  0   0   0   0   3   7   0  57  76   0]\n",
      " [  0   0   0   0   2   0   0  30   0   0]]\n",
      "--------------------   final   --------------------\n",
      "no_activities: 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1348/1348 [==============================] - 2s 2ms/step\n",
      "2-milan:\tacc: 76.56%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 0, 4, 0, 0, 4, 0, 4, 4, 0, 4, 4, 4, 0, 0, 4, 0, 7, 0, 0, 0, 0, 7, 7, 7, 2, 2, 0, 7, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 7, 0, 7, 7, 7, 7, 7, 0, 0, 7, 0, 7, 7, 7, 0, 7, 7, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 0, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 0, 7, 7, 0, 0, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 0, 7, 0, 7, 7, 7, 7, 7, 7, 7, 0, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 0, 7, 0, 7, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 0, 0, 0, 7, 7, 7, 0, 7, 7, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 0, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 0, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 0, 0, 0, 9, 0, 0, 9, 0, 9, 9, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 9, 0, 0, 9, 9, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7, 7, 7, 7, 7, 2, 7, 0, 2, 2, 7, 7, 0, 0, 9, 0, 0, 7, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 4, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 9, 9, 0, 7, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 7, 7, 0, 7, 0, 7, 0, 4, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 4, 4, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 4, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 5, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 4, 0, 7, 4, 4, 4, 4, 0, 4, 7, 4, 4, 0, 4, 4, 4, 4, 4, 0, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 0, 4, 4, 0, 4, 0, 4, 0, 0, 4, 4, 4, 4, 4, 4, 0, 0, 4, 0, 4, 4, 0, 0, 4, 4, 4, 7, 4, 4, 0, 4, 4, 4, 7, 4, 4, 4, 0, 4, 0, 4, 4, 4, 0, 4, 0, 0, 4, 0, 4, 4, 0, 0, 4, 4, 0, 4, 0, 4, 4, 4, 4, 0, 0, 0, 0, 0, 4, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 4, 7, 0, 0, 0, 0, 0, 9, 0, 0, 0, 4, 0, 0, 7, 4, 0, 0, 0, 9, 0, 7, 0, 4, 0, 4, 0, 4, 4, 0, 0, 0, 0, 0, 0, 9]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.759285  0.886035  0.817778       623\n",
      "         Work   0.000000  0.000000  0.000000        26\n",
      "Take_medicine   1.000000  0.250000  0.400000        20\n",
      "        Sleep   0.000000  0.000000  0.000000        32\n",
      "        Relax   0.737864  0.531469  0.617886       143\n",
      "   Leave_Home   0.914286  0.901408  0.907801        71\n",
      "          Eat   0.000000  0.000000  0.000000         7\n",
      "         Cook   0.753927  0.778378  0.765957       185\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        29\n",
      "      Bathing   0.757937  0.900943  0.823276       212\n",
      "\n",
      "     accuracy                       0.765579      1348\n",
      "    macro avg   0.492330  0.424823  0.433270      1348\n",
      " weighted avg   0.714853  0.765579  0.731843      1348\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  27   0   0   2   0   0]\n",
      " [  0   0   0   0   0   0   0  15  11   0]\n",
      " [  0   0   0   0   0   3   0   4   0   0]\n",
      " [  0   0   0   5   0  13   0   2   0   0]\n",
      " [  0   0   0   0 191   3   1  17   0   0]\n",
      " [  0   0   0   0   0 144   0  41   0   0]\n",
      " [  0   0   0   0   0   0  64   7   0   0]\n",
      " [  0   0   0   0  29  21   5 552  16   0]\n",
      " [  0   0   0   0   3   7   0  57  76   0]\n",
      " [  0   0   0   0   2   0   0  30   0   0]]\n",
      "best: current database: milan \t 77.43% (+/- 0.76%)\n",
      "final: current database: milan \t 77.43% (+/- 0.76%)\n",
      "CPU times: user 41min 32s, sys: 1min 43s, total: 43min 15s\n",
      "Wall time: 45min 59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dict_config_cus['distance_int'] = '4'\n",
    "train_val(dict_config_cus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "scrolled": true
   },
   "source": [
    "```bash\n",
    "best: current database: milan \t 77.43% (+/- 0.76%)\n",
    "final: current database: milan \t 77.43% (+/- 0.76%)\n",
    "CPU times: user 41min 32s, sys: 1min 43s, total: 43min 15s\n",
    "Wall time: 45min 59s\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='constrain_5'>CS_5</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current dataset: milan\n",
      "../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1\n",
      "no_activities: 10\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_55 (InputLayer)        (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_55 (Embedding)     (None, 2000, 64)          172544    \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 2000, 12)          780       \n",
      "_________________________________________________________________\n",
      "activation_163 (Activation)  (None, 2000, 12)          0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_55 (Glo (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (None, 18)                234       \n",
      "_________________________________________________________________\n",
      "activation_164 (Activation)  (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 12)                228       \n",
      "_________________________________________________________________\n",
      "activation_165 (Activation)  (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_165 (Dense)            (None, 10)                130       \n",
      "=================================================================\n",
      "Total params: 173,916\n",
      "Trainable params: 173,916\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Create subdir directory: ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights...\n",
      "Begin training ...\n",
      "Epoch 1/1000\n",
      "42/42 [==============================] - 4s 100ms/step - loss: 1.6817 - acc: 0.4654 - val_loss: 1.3471 - val_acc: 0.5298\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.3599 - acc: 0.5554 - val_loss: 1.1984 - val_acc: 0.6518\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.2582 - acc: 0.6045 - val_loss: 1.1122 - val_acc: 0.6577\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.1967 - acc: 0.6198 - val_loss: 1.0632 - val_acc: 0.6555\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 1.1649 - acc: 0.6257 - val_loss: 1.0266 - val_acc: 0.6949\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.1150 - acc: 0.6391 - val_loss: 1.0004 - val_acc: 0.6890\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.1032 - acc: 0.6410 - val_loss: 0.9828 - val_acc: 0.6897\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.0807 - acc: 0.6544 - val_loss: 0.9603 - val_acc: 0.6942\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0648 - acc: 0.6492 - val_loss: 0.9445 - val_acc: 0.6927\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.0547 - acc: 0.6525 - val_loss: 0.9303 - val_acc: 0.6957\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0572 - acc: 0.6607 - val_loss: 0.9231 - val_acc: 0.7016\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0221 - acc: 0.6652 - val_loss: 0.9102 - val_acc: 0.7054\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.0135 - acc: 0.6622 - val_loss: 0.9019 - val_acc: 0.6942\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0221 - acc: 0.6603 - val_loss: 0.8921 - val_acc: 0.7024\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 1.0031 - acc: 0.6644 - val_loss: 0.8791 - val_acc: 0.7024\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 1.0064 - acc: 0.6696 - val_loss: 0.8739 - val_acc: 0.7314\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9804 - acc: 0.6719 - val_loss: 0.8635 - val_acc: 0.7292\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9856 - acc: 0.6693 - val_loss: 0.8609 - val_acc: 0.7269\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9691 - acc: 0.6786 - val_loss: 0.8530 - val_acc: 0.7344\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9656 - acc: 0.6819 - val_loss: 0.8468 - val_acc: 0.7366\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9584 - acc: 0.6823 - val_loss: 0.8403 - val_acc: 0.7321\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9537 - acc: 0.6916 - val_loss: 0.8331 - val_acc: 0.7388\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9396 - acc: 0.6853 - val_loss: 0.8275 - val_acc: 0.7418\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9301 - acc: 0.6927 - val_loss: 0.8211 - val_acc: 0.7366\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9498 - acc: 0.6920 - val_loss: 0.8159 - val_acc: 0.7440\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.9270 - acc: 0.6968 - val_loss: 0.8132 - val_acc: 0.7455\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9276 - acc: 0.6987 - val_loss: 0.8093 - val_acc: 0.7478\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8978 - acc: 0.7057 - val_loss: 0.8024 - val_acc: 0.7493\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9138 - acc: 0.7083 - val_loss: 0.7947 - val_acc: 0.7478\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9117 - acc: 0.7020 - val_loss: 0.7937 - val_acc: 0.7478\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9053 - acc: 0.7035 - val_loss: 0.7886 - val_acc: 0.7493\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9057 - acc: 0.7106 - val_loss: 0.7789 - val_acc: 0.7485\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8970 - acc: 0.7102 - val_loss: 0.7752 - val_acc: 0.7545\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8916 - acc: 0.7221 - val_loss: 0.7777 - val_acc: 0.7545\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.8916 - acc: 0.7132 - val_loss: 0.7709 - val_acc: 0.7552\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8800 - acc: 0.7214 - val_loss: 0.7643 - val_acc: 0.7626\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9013 - acc: 0.7109 - val_loss: 0.7667 - val_acc: 0.7545\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8776 - acc: 0.7158 - val_loss: 0.7594 - val_acc: 0.7567\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8912 - acc: 0.7072 - val_loss: 0.7593 - val_acc: 0.7560\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8708 - acc: 0.7161 - val_loss: 0.7555 - val_acc: 0.7500\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8834 - acc: 0.7158 - val_loss: 0.7527 - val_acc: 0.7612\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8642 - acc: 0.7165 - val_loss: 0.7514 - val_acc: 0.7574\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8755 - acc: 0.7083 - val_loss: 0.7476 - val_acc: 0.7604\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8871 - acc: 0.7106 - val_loss: 0.7476 - val_acc: 0.7500\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8774 - acc: 0.7098 - val_loss: 0.7372 - val_acc: 0.7597\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8647 - acc: 0.7191 - val_loss: 0.7362 - val_acc: 0.7664\n",
      "Epoch 47/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8556 - acc: 0.7202 - val_loss: 0.7356 - val_acc: 0.7679\n",
      "Epoch 48/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8482 - acc: 0.7303 - val_loss: 0.7294 - val_acc: 0.7686\n",
      "Epoch 49/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8520 - acc: 0.7188 - val_loss: 0.7298 - val_acc: 0.7612\n",
      "Epoch 50/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8617 - acc: 0.7128 - val_loss: 0.7283 - val_acc: 0.7641\n",
      "Epoch 51/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8742 - acc: 0.7158 - val_loss: 0.7286 - val_acc: 0.7649\n",
      "Epoch 52/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8672 - acc: 0.7109 - val_loss: 0.7299 - val_acc: 0.7656\n",
      "Epoch 53/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8441 - acc: 0.7251 - val_loss: 0.7284 - val_acc: 0.7626\n",
      "Epoch 54/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8477 - acc: 0.7173 - val_loss: 0.7255 - val_acc: 0.7649\n",
      "Epoch 55/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8383 - acc: 0.7221 - val_loss: 0.7226 - val_acc: 0.7612\n",
      "Epoch 56/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8321 - acc: 0.7199 - val_loss: 0.7190 - val_acc: 0.7649\n",
      "Epoch 57/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8245 - acc: 0.7284 - val_loss: 0.7153 - val_acc: 0.7738\n",
      "Epoch 58/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8348 - acc: 0.7217 - val_loss: 0.7144 - val_acc: 0.7641\n",
      "Epoch 59/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8395 - acc: 0.7292 - val_loss: 0.7091 - val_acc: 0.7708\n",
      "Epoch 60/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8403 - acc: 0.7176 - val_loss: 0.7108 - val_acc: 0.7679\n",
      "Epoch 61/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8341 - acc: 0.7180 - val_loss: 0.7091 - val_acc: 0.7686\n",
      "Epoch 62/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8170 - acc: 0.7217 - val_loss: 0.7080 - val_acc: 0.7671\n",
      "Epoch 63/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8380 - acc: 0.7214 - val_loss: 0.7048 - val_acc: 0.7716\n",
      "Epoch 64/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8230 - acc: 0.7318 - val_loss: 0.7018 - val_acc: 0.7708\n",
      "Epoch 65/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8246 - acc: 0.7318 - val_loss: 0.7031 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00065: loss improved from inf to 0.82463, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-0-000065-0.824626-0.779018.hdf5\n",
      "Epoch 66/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8138 - acc: 0.7292 - val_loss: 0.7023 - val_acc: 0.7708\n",
      "Epoch 67/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8187 - acc: 0.7266 - val_loss: 0.7003 - val_acc: 0.7768\n",
      "Epoch 68/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8083 - acc: 0.7281 - val_loss: 0.7002 - val_acc: 0.7708\n",
      "Epoch 69/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8203 - acc: 0.7281 - val_loss: 0.6967 - val_acc: 0.7708\n",
      "\n",
      "Epoch 00069: loss improved from 0.82463 to 0.82034, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-0-000069-0.820341-0.770833.hdf5\n",
      "Epoch 70/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8239 - acc: 0.7303 - val_loss: 0.6965 - val_acc: 0.7746\n",
      "Epoch 71/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8067 - acc: 0.7292 - val_loss: 0.6964 - val_acc: 0.7731\n",
      "Epoch 72/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8007 - acc: 0.7310 - val_loss: 0.6917 - val_acc: 0.7805\n",
      "Epoch 73/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8141 - acc: 0.7228 - val_loss: 0.6924 - val_acc: 0.7820\n",
      "\n",
      "Epoch 00073: loss improved from 0.82034 to 0.81412, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-0-000073-0.814116-0.781994.hdf5\n",
      "Epoch 74/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8086 - acc: 0.7329 - val_loss: 0.6925 - val_acc: 0.7805\n",
      "Epoch 75/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8047 - acc: 0.7336 - val_loss: 0.6919 - val_acc: 0.7783\n",
      "Epoch 76/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8062 - acc: 0.7269 - val_loss: 0.6900 - val_acc: 0.7902\n",
      "Epoch 77/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8322 - acc: 0.7225 - val_loss: 0.6875 - val_acc: 0.7835\n",
      "Epoch 78/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8212 - acc: 0.7221 - val_loss: 0.6867 - val_acc: 0.7872\n",
      "Epoch 79/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8036 - acc: 0.7303 - val_loss: 0.6860 - val_acc: 0.7872\n",
      "Epoch 80/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.8097 - acc: 0.7266 - val_loss: 0.6850 - val_acc: 0.7961\n",
      "Epoch 81/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8166 - acc: 0.7284 - val_loss: 0.6839 - val_acc: 0.7894\n",
      "Epoch 82/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8002 - acc: 0.7318 - val_loss: 0.6835 - val_acc: 0.7961\n",
      "Epoch 83/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8146 - acc: 0.7392 - val_loss: 0.6774 - val_acc: 0.7976\n",
      "Epoch 84/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8059 - acc: 0.7247 - val_loss: 0.6834 - val_acc: 0.7879\n",
      "Epoch 85/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7983 - acc: 0.7295 - val_loss: 0.6818 - val_acc: 0.7917\n",
      "\n",
      "Epoch 00085: loss improved from 0.81412 to 0.79828, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-0-000085-0.798285-0.791667.hdf5\n",
      "Epoch 86/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8100 - acc: 0.7273 - val_loss: 0.6767 - val_acc: 0.7946\n",
      "Epoch 87/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7972 - acc: 0.7266 - val_loss: 0.6770 - val_acc: 0.7924\n",
      "Epoch 88/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8059 - acc: 0.7385 - val_loss: 0.6786 - val_acc: 0.7865\n",
      "Epoch 89/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7841 - acc: 0.7355 - val_loss: 0.6744 - val_acc: 0.7917\n",
      "\n",
      "Epoch 00089: loss improved from 0.79828 to 0.78413, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-0-000089-0.784133-0.791667.hdf5\n",
      "Epoch 90/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8045 - acc: 0.7333 - val_loss: 0.6756 - val_acc: 0.7917\n",
      "Epoch 91/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8051 - acc: 0.7221 - val_loss: 0.6759 - val_acc: 0.7887\n",
      "Epoch 92/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8002 - acc: 0.7232 - val_loss: 0.6741 - val_acc: 0.7887\n",
      "Epoch 93/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8179 - acc: 0.7191 - val_loss: 0.6745 - val_acc: 0.7887\n",
      "Epoch 94/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7839 - acc: 0.7344 - val_loss: 0.6760 - val_acc: 0.7917\n",
      "Epoch 95/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7828 - acc: 0.7347 - val_loss: 0.6733 - val_acc: 0.7909\n",
      "Epoch 96/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7712 - acc: 0.7333 - val_loss: 0.6706 - val_acc: 0.7879\n",
      "Epoch 97/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7789 - acc: 0.7359 - val_loss: 0.6682 - val_acc: 0.7924\n",
      "\n",
      "Epoch 00097: loss improved from 0.78413 to 0.77892, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-0-000097-0.778925-0.792411.hdf5\n",
      "Epoch 98/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7994 - acc: 0.7277 - val_loss: 0.6642 - val_acc: 0.7946\n",
      "Epoch 99/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7855 - acc: 0.7269 - val_loss: 0.6675 - val_acc: 0.7961\n",
      "Epoch 100/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7895 - acc: 0.7266 - val_loss: 0.6669 - val_acc: 0.7924\n",
      "\n",
      "Epoch 00100: saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/0-000100-0.789529-0.792411.hdf5\n",
      "Epoch 101/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7972 - acc: 0.7340 - val_loss: 0.6658 - val_acc: 0.7932\n",
      "Epoch 102/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8008 - acc: 0.7329 - val_loss: 0.6662 - val_acc: 0.7909\n",
      "Epoch 103/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7941 - acc: 0.7228 - val_loss: 0.6670 - val_acc: 0.7917\n",
      "Epoch 104/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7730 - acc: 0.7400 - val_loss: 0.6654 - val_acc: 0.7939\n",
      "Epoch 105/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8016 - acc: 0.7247 - val_loss: 0.6634 - val_acc: 0.7917\n",
      "Epoch 106/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7830 - acc: 0.7366 - val_loss: 0.6650 - val_acc: 0.7894\n",
      "Epoch 107/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7835 - acc: 0.7299 - val_loss: 0.6641 - val_acc: 0.7894\n",
      "Epoch 108/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7788 - acc: 0.7351 - val_loss: 0.6628 - val_acc: 0.7946\n",
      "Epoch 109/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7847 - acc: 0.7269 - val_loss: 0.6606 - val_acc: 0.7924\n",
      "Epoch 110/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7845 - acc: 0.7318 - val_loss: 0.6640 - val_acc: 0.7924\n",
      "Epoch 111/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7736 - acc: 0.7333 - val_loss: 0.6621 - val_acc: 0.7932\n",
      "Epoch 112/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7799 - acc: 0.7277 - val_loss: 0.6622 - val_acc: 0.7909\n",
      "Epoch 113/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7731 - acc: 0.7329 - val_loss: 0.6592 - val_acc: 0.7939\n",
      "Epoch 114/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7721 - acc: 0.7336 - val_loss: 0.6587 - val_acc: 0.7961\n",
      "Epoch 115/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7652 - acc: 0.7437 - val_loss: 0.6586 - val_acc: 0.7917\n",
      "Epoch 116/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7691 - acc: 0.7329 - val_loss: 0.6586 - val_acc: 0.7939\n",
      "Epoch 117/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7743 - acc: 0.7359 - val_loss: 0.6579 - val_acc: 0.7939\n",
      "Epoch 118/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7728 - acc: 0.7333 - val_loss: 0.6572 - val_acc: 0.7946\n",
      "Epoch 119/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7749 - acc: 0.7303 - val_loss: 0.6566 - val_acc: 0.7961\n",
      "Epoch 120/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7664 - acc: 0.7388 - val_loss: 0.6566 - val_acc: 0.7954\n",
      "Epoch 121/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7872 - acc: 0.7336 - val_loss: 0.6591 - val_acc: 0.7946\n",
      "Epoch 122/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7766 - acc: 0.7292 - val_loss: 0.6547 - val_acc: 0.7961\n",
      "Epoch 123/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7761 - acc: 0.7329 - val_loss: 0.6569 - val_acc: 0.7961\n",
      "Epoch 124/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7668 - acc: 0.7299 - val_loss: 0.6603 - val_acc: 0.7917\n",
      "Epoch 125/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7711 - acc: 0.7333 - val_loss: 0.6535 - val_acc: 0.7954\n",
      "Epoch 126/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7597 - acc: 0.7362 - val_loss: 0.6553 - val_acc: 0.7939\n",
      "Epoch 127/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7675 - acc: 0.7347 - val_loss: 0.6528 - val_acc: 0.7946\n",
      "Epoch 128/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7810 - acc: 0.7281 - val_loss: 0.6552 - val_acc: 0.7976\n",
      "Epoch 129/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7583 - acc: 0.7347 - val_loss: 0.6506 - val_acc: 0.7984\n",
      "Epoch 130/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7735 - acc: 0.7400 - val_loss: 0.6536 - val_acc: 0.7976\n",
      "Epoch 131/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7762 - acc: 0.7359 - val_loss: 0.6551 - val_acc: 0.7939\n",
      "Epoch 132/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7586 - acc: 0.7422 - val_loss: 0.6547 - val_acc: 0.7939\n",
      "Epoch 133/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7527 - acc: 0.7463 - val_loss: 0.6509 - val_acc: 0.7969\n",
      "Epoch 134/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7519 - acc: 0.7437 - val_loss: 0.6532 - val_acc: 0.7932\n",
      "Epoch 135/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7638 - acc: 0.7340 - val_loss: 0.6516 - val_acc: 0.7969\n",
      "Epoch 136/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7586 - acc: 0.7385 - val_loss: 0.6506 - val_acc: 0.7939\n",
      "Epoch 137/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7607 - acc: 0.7403 - val_loss: 0.6512 - val_acc: 0.7969\n",
      "Epoch 138/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7509 - acc: 0.7336 - val_loss: 0.6512 - val_acc: 0.7954\n",
      "Epoch 139/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7531 - acc: 0.7374 - val_loss: 0.6523 - val_acc: 0.7946\n",
      "Epoch 140/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7705 - acc: 0.7292 - val_loss: 0.6510 - val_acc: 0.7976\n",
      "Epoch 141/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7568 - acc: 0.7403 - val_loss: 0.6496 - val_acc: 0.7954\n",
      "Epoch 142/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7561 - acc: 0.7396 - val_loss: 0.6504 - val_acc: 0.7976\n",
      "Epoch 143/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7669 - acc: 0.7329 - val_loss: 0.6492 - val_acc: 0.7961\n",
      "Epoch 144/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7586 - acc: 0.7377 - val_loss: 0.6500 - val_acc: 0.7939\n",
      "Epoch 145/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7703 - acc: 0.7325 - val_loss: 0.6489 - val_acc: 0.7946\n",
      "Epoch 146/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7652 - acc: 0.7370 - val_loss: 0.6483 - val_acc: 0.7917\n",
      "Epoch 147/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7505 - acc: 0.7444 - val_loss: 0.6475 - val_acc: 0.7946\n",
      "Epoch 148/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7547 - acc: 0.7351 - val_loss: 0.6491 - val_acc: 0.7984\n",
      "Epoch 149/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7681 - acc: 0.7366 - val_loss: 0.6490 - val_acc: 0.7932\n",
      "Epoch 150/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7576 - acc: 0.7295 - val_loss: 0.6469 - val_acc: 0.7932\n",
      "Epoch 151/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7571 - acc: 0.7310 - val_loss: 0.6474 - val_acc: 0.7954\n",
      "Epoch 152/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7549 - acc: 0.7355 - val_loss: 0.6486 - val_acc: 0.7909\n",
      "Epoch 153/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7630 - acc: 0.7299 - val_loss: 0.6471 - val_acc: 0.7909\n",
      "Epoch 154/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7531 - acc: 0.7422 - val_loss: 0.6453 - val_acc: 0.7954\n",
      "Epoch 155/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7275 - acc: 0.7467 - val_loss: 0.6453 - val_acc: 0.7954\n",
      "Epoch 156/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7460 - acc: 0.7429 - val_loss: 0.6443 - val_acc: 0.7954\n",
      "Epoch 157/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7570 - acc: 0.7392 - val_loss: 0.6470 - val_acc: 0.7932\n",
      "Epoch 158/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7495 - acc: 0.7414 - val_loss: 0.6458 - val_acc: 0.7932\n",
      "Epoch 159/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7532 - acc: 0.7407 - val_loss: 0.6456 - val_acc: 0.7939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7434 - acc: 0.7440 - val_loss: 0.6414 - val_acc: 0.7961\n",
      "Epoch 161/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7475 - acc: 0.7455 - val_loss: 0.6397 - val_acc: 0.7961\n",
      "Epoch 162/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7657 - acc: 0.7388 - val_loss: 0.6459 - val_acc: 0.7954\n",
      "Epoch 163/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7396 - acc: 0.7493 - val_loss: 0.6455 - val_acc: 0.7961\n",
      "Epoch 164/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7459 - acc: 0.7385 - val_loss: 0.6426 - val_acc: 0.7954\n",
      "Epoch 165/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7553 - acc: 0.7433 - val_loss: 0.6438 - val_acc: 0.7954\n",
      "\n",
      "Epoch 00165: loss improved from inf to 0.75528, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-0-000165-0.755282-0.795387.hdf5\n",
      "Epoch 166/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7564 - acc: 0.7377 - val_loss: 0.6446 - val_acc: 0.7939\n",
      "Epoch 167/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7481 - acc: 0.7422 - val_loss: 0.6451 - val_acc: 0.7924\n",
      "Epoch 168/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7432 - acc: 0.7448 - val_loss: 0.6427 - val_acc: 0.7954\n",
      "Epoch 169/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7477 - acc: 0.7407 - val_loss: 0.6426 - val_acc: 0.7946\n",
      "\n",
      "Epoch 00169: loss improved from 0.75528 to 0.74772, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-0-000169-0.747724-0.794643.hdf5\n",
      "Epoch 170/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7431 - acc: 0.7426 - val_loss: 0.6394 - val_acc: 0.7932\n",
      "Epoch 171/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7567 - acc: 0.7362 - val_loss: 0.6409 - val_acc: 0.7954\n",
      "Epoch 172/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7486 - acc: 0.7467 - val_loss: 0.6425 - val_acc: 0.7961\n",
      "Epoch 173/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7414 - acc: 0.7362 - val_loss: 0.6410 - val_acc: 0.7946\n",
      "\n",
      "Epoch 00173: loss improved from 0.74772 to 0.74136, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-0-000173-0.741357-0.794643.hdf5\n",
      "Epoch 174/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7503 - acc: 0.7336 - val_loss: 0.6403 - val_acc: 0.7954\n",
      "Epoch 175/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7546 - acc: 0.7325 - val_loss: 0.6405 - val_acc: 0.7946\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 176/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7417 - acc: 0.7388 - val_loss: 0.6416 - val_acc: 0.7946\n",
      "Epoch 177/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7526 - acc: 0.7388 - val_loss: 0.6393 - val_acc: 0.7969\n",
      "Epoch 178/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7587 - acc: 0.7377 - val_loss: 0.6404 - val_acc: 0.7946\n",
      "Epoch 179/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7394 - acc: 0.7414 - val_loss: 0.6411 - val_acc: 0.7946\n",
      "Epoch 180/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7429 - acc: 0.7407 - val_loss: 0.6394 - val_acc: 0.7946\n",
      "Epoch 181/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7410 - acc: 0.7500 - val_loss: 0.6386 - val_acc: 0.7961\n",
      "\n",
      "Epoch 00181: loss improved from 0.74136 to 0.74102, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-0-000181-0.741021-0.796131.hdf5\n",
      "Epoch 182/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7460 - acc: 0.7403 - val_loss: 0.6384 - val_acc: 0.7961\n",
      "Epoch 183/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7493 - acc: 0.7396 - val_loss: 0.6394 - val_acc: 0.7961\n",
      "Epoch 184/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7478 - acc: 0.7385 - val_loss: 0.6374 - val_acc: 0.7961\n",
      "Epoch 185/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7345 - acc: 0.7470 - val_loss: 0.6396 - val_acc: 0.7969\n",
      "\n",
      "Epoch 00185: loss improved from 0.74102 to 0.73446, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-0-000185-0.734465-0.796875.hdf5\n",
      "Epoch 186/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7379 - acc: 0.7418 - val_loss: 0.6380 - val_acc: 0.7969\n",
      "Epoch 187/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7391 - acc: 0.7411 - val_loss: 0.6384 - val_acc: 0.7969\n",
      "Epoch 188/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7362 - acc: 0.7374 - val_loss: 0.6406 - val_acc: 0.7969\n",
      "Epoch 189/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7531 - acc: 0.7340 - val_loss: 0.6409 - val_acc: 0.7954\n",
      "Epoch 190/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7509 - acc: 0.7429 - val_loss: 0.6398 - val_acc: 0.7976\n",
      "Epoch 191/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7303 - acc: 0.7411 - val_loss: 0.6403 - val_acc: 0.7969\n",
      "Epoch 192/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7538 - acc: 0.7351 - val_loss: 0.6405 - val_acc: 0.7961\n",
      "Epoch 193/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7473 - acc: 0.7329 - val_loss: 0.6405 - val_acc: 0.7969\n",
      "Epoch 194/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7481 - acc: 0.7355 - val_loss: 0.6396 - val_acc: 0.7961\n",
      "Epoch 195/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7402 - acc: 0.7463 - val_loss: 0.6404 - val_acc: 0.7961\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 196/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7526 - acc: 0.7396 - val_loss: 0.6407 - val_acc: 0.7969\n",
      "Epoch 197/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7490 - acc: 0.7381 - val_loss: 0.6385 - val_acc: 0.7976\n",
      "Epoch 198/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7494 - acc: 0.7448 - val_loss: 0.6380 - val_acc: 0.7984\n",
      "Epoch 199/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7349 - acc: 0.7388 - val_loss: 0.6401 - val_acc: 0.7961\n",
      "Epoch 200/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7484 - acc: 0.7422 - val_loss: 0.6366 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00200: saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/0-000200-0.748441-0.798363.hdf5\n",
      "Epoch 201/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7427 - acc: 0.7407 - val_loss: 0.6403 - val_acc: 0.7961\n",
      "Epoch 202/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7546 - acc: 0.7310 - val_loss: 0.6367 - val_acc: 0.7976\n",
      "Epoch 203/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7460 - acc: 0.7225 - val_loss: 0.6379 - val_acc: 0.7984\n",
      "Epoch 204/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7323 - acc: 0.7422 - val_loss: 0.6389 - val_acc: 0.7976\n",
      "Epoch 205/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7363 - acc: 0.7381 - val_loss: 0.6399 - val_acc: 0.7969\n",
      "Epoch 206/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7415 - acc: 0.7519 - val_loss: 0.6404 - val_acc: 0.7969\n",
      "Epoch 207/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7227 - acc: 0.7552 - val_loss: 0.6374 - val_acc: 0.7976\n",
      "Epoch 208/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7308 - acc: 0.7429 - val_loss: 0.6379 - val_acc: 0.7984\n",
      "Epoch 209/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7391 - acc: 0.7418 - val_loss: 0.6261 - val_acc: 0.7991\n",
      "Epoch 210/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7535 - acc: 0.7437 - val_loss: 0.6395 - val_acc: 0.7976\n",
      "Epoch 211/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7347 - acc: 0.7422 - val_loss: 0.6380 - val_acc: 0.7976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 212/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7424 - acc: 0.7414 - val_loss: 0.6381 - val_acc: 0.7976\n",
      "Epoch 213/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7373 - acc: 0.7467 - val_loss: 0.6403 - val_acc: 0.7961\n",
      "Epoch 214/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7446 - acc: 0.7474 - val_loss: 0.6388 - val_acc: 0.7976\n",
      "Epoch 215/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7732 - acc: 0.7299 - val_loss: 0.6397 - val_acc: 0.7969\n",
      "Epoch 216/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7491 - acc: 0.7288 - val_loss: 0.6384 - val_acc: 0.7984\n",
      "Epoch 217/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7399 - acc: 0.7388 - val_loss: 0.6372 - val_acc: 0.7976\n",
      "Epoch 218/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7348 - acc: 0.7455 - val_loss: 0.6392 - val_acc: 0.7961\n",
      "Epoch 219/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7418 - acc: 0.7440 - val_loss: 0.6378 - val_acc: 0.7969\n",
      "Epoch 220/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7604 - acc: 0.7374 - val_loss: 0.6382 - val_acc: 0.7961\n",
      "Epoch 221/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7410 - acc: 0.7418 - val_loss: 0.6378 - val_acc: 0.7976\n",
      "Epoch 222/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7432 - acc: 0.7467 - val_loss: 0.6392 - val_acc: 0.7961\n",
      "Epoch 223/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7293 - acc: 0.7470 - val_loss: 0.6371 - val_acc: 0.7991\n",
      "Epoch 224/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7339 - acc: 0.7493 - val_loss: 0.6396 - val_acc: 0.7961\n",
      "Epoch 225/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7459 - acc: 0.7474 - val_loss: 0.6383 - val_acc: 0.7969\n",
      "Epoch 226/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7471 - acc: 0.7340 - val_loss: 0.6392 - val_acc: 0.7969\n",
      "Epoch 227/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7435 - acc: 0.7433 - val_loss: 0.6385 - val_acc: 0.7976\n",
      "\n",
      "Epoch 00227: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 228/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7325 - acc: 0.7459 - val_loss: 0.6374 - val_acc: 0.7984\n",
      "Epoch 229/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7325 - acc: 0.7504 - val_loss: 0.6398 - val_acc: 0.7969\n",
      "Epoch 230/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7428 - acc: 0.7440 - val_loss: 0.6368 - val_acc: 0.7984\n",
      "Epoch 231/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7464 - acc: 0.7411 - val_loss: 0.6394 - val_acc: 0.7969\n",
      "Epoch 232/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7434 - acc: 0.7392 - val_loss: 0.6347 - val_acc: 0.7991\n",
      "Epoch 233/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7431 - acc: 0.7374 - val_loss: 0.6394 - val_acc: 0.7961\n",
      "Epoch 234/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7473 - acc: 0.7437 - val_loss: 0.6372 - val_acc: 0.7976\n",
      "Epoch 235/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7517 - acc: 0.7359 - val_loss: 0.6367 - val_acc: 0.7976\n",
      "Epoch 236/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7427 - acc: 0.7407 - val_loss: 0.6372 - val_acc: 0.7976\n",
      "Epoch 237/1000\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.7410 - acc: 0.7422 - val_loss: 0.6366 - val_acc: 0.7976\n",
      "Epoch 238/1000\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.7331 - acc: 0.7381 - val_loss: 0.6389 - val_acc: 0.7976\n",
      "Epoch 239/1000\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.7413 - acc: 0.7351 - val_loss: 0.6375 - val_acc: 0.7969\n",
      "Epoch 240/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7374 - acc: 0.7392 - val_loss: 0.6371 - val_acc: 0.7969\n",
      "Epoch 241/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7414 - acc: 0.7429 - val_loss: 0.6356 - val_acc: 0.7984\n",
      "Epoch 242/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7483 - acc: 0.7325 - val_loss: 0.6387 - val_acc: 0.7969\n",
      "Epoch 243/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7388 - acc: 0.7489 - val_loss: 0.6378 - val_acc: 0.7969\n",
      "Epoch 244/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7291 - acc: 0.7448 - val_loss: 0.6378 - val_acc: 0.7969\n",
      "Epoch 245/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7368 - acc: 0.7381 - val_loss: 0.6388 - val_acc: 0.7969\n",
      "Epoch 246/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7479 - acc: 0.7388 - val_loss: 0.6396 - val_acc: 0.7961\n",
      "Epoch 247/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7352 - acc: 0.7426 - val_loss: 0.6388 - val_acc: 0.7969\n",
      "Epoch 248/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7343 - acc: 0.7444 - val_loss: 0.6397 - val_acc: 0.7961\n",
      "Epoch 249/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7481 - acc: 0.7440 - val_loss: 0.6355 - val_acc: 0.7991\n",
      "Epoch 250/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7429 - acc: 0.7422 - val_loss: 0.6381 - val_acc: 0.7976\n",
      "Epoch 251/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7550 - acc: 0.7310 - val_loss: 0.6386 - val_acc: 0.7969\n",
      "Epoch 252/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7399 - acc: 0.7437 - val_loss: 0.6388 - val_acc: 0.7976\n",
      "Epoch 253/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7359 - acc: 0.7407 - val_loss: 0.6397 - val_acc: 0.7969\n",
      "Epoch 254/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7538 - acc: 0.7400 - val_loss: 0.6393 - val_acc: 0.7969\n",
      "Epoch 255/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7375 - acc: 0.7500 - val_loss: 0.6391 - val_acc: 0.7969\n",
      "Epoch 256/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7428 - acc: 0.7385 - val_loss: 0.6389 - val_acc: 0.7969\n",
      "Epoch 257/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7502 - acc: 0.7422 - val_loss: 0.6379 - val_acc: 0.7976\n",
      "Epoch 258/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7508 - acc: 0.7422 - val_loss: 0.6346 - val_acc: 0.7991\n",
      "Epoch 259/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7250 - acc: 0.7407 - val_loss: 0.6369 - val_acc: 0.7984\n",
      "Epoch 260/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7375 - acc: 0.7511 - val_loss: 0.6384 - val_acc: 0.7976\n",
      "Epoch 261/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7495 - acc: 0.7362 - val_loss: 0.6382 - val_acc: 0.7976\n",
      "Epoch 262/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7339 - acc: 0.7414 - val_loss: 0.6381 - val_acc: 0.7976\n",
      "Epoch 263/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7425 - acc: 0.7470 - val_loss: 0.6384 - val_acc: 0.7976\n",
      "Epoch 264/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7282 - acc: 0.7440 - val_loss: 0.6387 - val_acc: 0.7976\n",
      "Epoch 265/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7405 - acc: 0.7414 - val_loss: 0.6390 - val_acc: 0.7969\n",
      "\n",
      "Epoch 00265: loss improved from inf to 0.74053, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-0-000265-0.740534-0.796875.hdf5\n",
      "Epoch 266/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7220 - acc: 0.7459 - val_loss: 0.6396 - val_acc: 0.7969\n",
      "Epoch 267/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7342 - acc: 0.7392 - val_loss: 0.6384 - val_acc: 0.7976\n",
      "Epoch 268/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7458 - acc: 0.7381 - val_loss: 0.6394 - val_acc: 0.7969\n",
      "Epoch 269/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7549 - acc: 0.7433 - val_loss: 0.6382 - val_acc: 0.7984\n",
      "Epoch 270/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7424 - acc: 0.7381 - val_loss: 0.6385 - val_acc: 0.7976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7377 - acc: 0.7426 - val_loss: 0.6357 - val_acc: 0.7984\n",
      "Epoch 272/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7363 - acc: 0.7429 - val_loss: 0.6387 - val_acc: 0.7976\n",
      "Epoch 273/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7353 - acc: 0.7485 - val_loss: 0.6388 - val_acc: 0.7976\n",
      "\n",
      "Epoch 00273: loss improved from 0.74053 to 0.73535, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-0-000273-0.735348-0.797619.hdf5\n",
      "Epoch 274/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7398 - acc: 0.7374 - val_loss: 0.6386 - val_acc: 0.7976\n",
      "Epoch 275/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7542 - acc: 0.7359 - val_loss: 0.6399 - val_acc: 0.7969\n",
      "Epoch 276/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7382 - acc: 0.7400 - val_loss: 0.6392 - val_acc: 0.7976\n",
      "Epoch 277/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7372 - acc: 0.7403 - val_loss: 0.6395 - val_acc: 0.7969\n",
      "Epoch 278/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7468 - acc: 0.7340 - val_loss: 0.6381 - val_acc: 0.7976\n",
      "Epoch 279/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7558 - acc: 0.7362 - val_loss: 0.6386 - val_acc: 0.7976\n",
      "Epoch 280/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7344 - acc: 0.7433 - val_loss: 0.6390 - val_acc: 0.7969\n",
      "Epoch 281/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7409 - acc: 0.7414 - val_loss: 0.6380 - val_acc: 0.7976\n",
      "Epoch 282/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7515 - acc: 0.7347 - val_loss: 0.6349 - val_acc: 0.7984\n",
      "Epoch 283/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7531 - acc: 0.7411 - val_loss: 0.6394 - val_acc: 0.7969\n",
      "Epoch 284/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7372 - acc: 0.7381 - val_loss: 0.6388 - val_acc: 0.7969\n",
      "Epoch 285/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7405 - acc: 0.7374 - val_loss: 0.6340 - val_acc: 0.7976\n",
      "Epoch 286/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7438 - acc: 0.7411 - val_loss: 0.6388 - val_acc: 0.7969\n",
      "Epoch 287/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7554 - acc: 0.7374 - val_loss: 0.6392 - val_acc: 0.7969\n",
      "Epoch 288/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7511 - acc: 0.7347 - val_loss: 0.6361 - val_acc: 0.7976\n",
      "Epoch 289/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7423 - acc: 0.7414 - val_loss: 0.6380 - val_acc: 0.7976\n",
      "Epoch 290/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7276 - acc: 0.7426 - val_loss: 0.6376 - val_acc: 0.7976\n",
      "Epoch 291/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7210 - acc: 0.7452 - val_loss: 0.6380 - val_acc: 0.7969\n",
      "Epoch 292/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7524 - acc: 0.7321 - val_loss: 0.6371 - val_acc: 0.7976\n",
      "Epoch 293/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7464 - acc: 0.7370 - val_loss: 0.6389 - val_acc: 0.7976\n",
      "Epoch 294/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7422 - acc: 0.7403 - val_loss: 0.6395 - val_acc: 0.7969\n",
      "Epoch 295/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7446 - acc: 0.7426 - val_loss: 0.6381 - val_acc: 0.7976\n",
      "Epoch 296/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7407 - acc: 0.7385 - val_loss: 0.6374 - val_acc: 0.7976\n",
      "Epoch 297/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7463 - acc: 0.7355 - val_loss: 0.6365 - val_acc: 0.7984\n",
      "Epoch 298/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7495 - acc: 0.7418 - val_loss: 0.6395 - val_acc: 0.7969\n",
      "Epoch 299/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7315 - acc: 0.7414 - val_loss: 0.6389 - val_acc: 0.7976\n",
      "Epoch 300/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7509 - acc: 0.7385 - val_loss: 0.6367 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00300: saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/0-000300-0.750916-0.798363.hdf5\n",
      "Epoch 301/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7424 - acc: 0.7407 - val_loss: 0.6381 - val_acc: 0.7976\n",
      "Epoch 302/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7479 - acc: 0.7374 - val_loss: 0.6361 - val_acc: 0.7976\n",
      "Epoch 303/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7433 - acc: 0.7478 - val_loss: 0.6396 - val_acc: 0.7969\n",
      "Epoch 304/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7318 - acc: 0.7455 - val_loss: 0.6345 - val_acc: 0.7991\n",
      "Epoch 305/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7416 - acc: 0.7429 - val_loss: 0.6361 - val_acc: 0.7984\n",
      "Epoch 306/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7288 - acc: 0.7485 - val_loss: 0.6356 - val_acc: 0.7976\n",
      "Epoch 307/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7514 - acc: 0.7381 - val_loss: 0.6374 - val_acc: 0.7976\n",
      "Epoch 308/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7415 - acc: 0.7481 - val_loss: 0.6389 - val_acc: 0.7976\n",
      "Epoch 309/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7475 - acc: 0.7359 - val_loss: 0.6375 - val_acc: 0.7976\n",
      "Epoch 310/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7497 - acc: 0.7381 - val_loss: 0.6395 - val_acc: 0.7969\n",
      "Epoch 311/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7477 - acc: 0.7414 - val_loss: 0.6378 - val_acc: 0.7976\n",
      "Epoch 312/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7422 - acc: 0.7467 - val_loss: 0.6357 - val_acc: 0.7991\n",
      "Epoch 313/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7376 - acc: 0.7429 - val_loss: 0.6376 - val_acc: 0.7976\n",
      "Epoch 314/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7431 - acc: 0.7400 - val_loss: 0.6397 - val_acc: 0.7969\n",
      "Epoch 315/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7223 - acc: 0.7485 - val_loss: 0.6360 - val_acc: 0.7984\n",
      "Epoch 316/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7551 - acc: 0.7396 - val_loss: 0.6382 - val_acc: 0.7969\n",
      "Epoch 317/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7468 - acc: 0.7422 - val_loss: 0.6378 - val_acc: 0.7976\n",
      "Epoch 318/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7360 - acc: 0.7452 - val_loss: 0.6387 - val_acc: 0.7969\n",
      "Epoch 319/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7346 - acc: 0.7522 - val_loss: 0.6369 - val_acc: 0.7984\n",
      "Epoch 320/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7326 - acc: 0.7433 - val_loss: 0.6365 - val_acc: 0.7984\n",
      "Epoch 321/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7470 - acc: 0.7388 - val_loss: 0.6384 - val_acc: 0.7969\n",
      "Epoch 322/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7401 - acc: 0.7374 - val_loss: 0.6366 - val_acc: 0.7976\n",
      "Epoch 323/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7511 - acc: 0.7433 - val_loss: 0.6373 - val_acc: 0.7984\n",
      "Epoch 324/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7493 - acc: 0.7426 - val_loss: 0.6366 - val_acc: 0.7991\n",
      "Epoch 325/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7398 - acc: 0.7362 - val_loss: 0.6368 - val_acc: 0.7976\n",
      "Epoch 326/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7345 - acc: 0.7418 - val_loss: 0.6381 - val_acc: 0.7976\n",
      "Epoch 327/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7355 - acc: 0.7500 - val_loss: 0.6379 - val_acc: 0.7976\n",
      "Epoch 328/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7439 - acc: 0.7381 - val_loss: 0.6370 - val_acc: 0.7984\n",
      "Epoch 329/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7446 - acc: 0.7422 - val_loss: 0.6387 - val_acc: 0.7969\n",
      "Epoch 330/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7423 - acc: 0.7455 - val_loss: 0.6389 - val_acc: 0.7969\n",
      "Epoch 331/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7477 - acc: 0.7366 - val_loss: 0.6394 - val_acc: 0.7969\n",
      "Epoch 332/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7550 - acc: 0.7396 - val_loss: 0.6387 - val_acc: 0.7976\n",
      "Epoch 333/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7506 - acc: 0.7385 - val_loss: 0.6390 - val_acc: 0.7969\n",
      "Epoch 334/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7519 - acc: 0.7333 - val_loss: 0.6375 - val_acc: 0.7976\n",
      "Epoch 335/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7364 - acc: 0.7452 - val_loss: 0.6378 - val_acc: 0.7976\n",
      "Epoch 336/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7487 - acc: 0.7366 - val_loss: 0.6378 - val_acc: 0.7976\n",
      "Epoch 337/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7395 - acc: 0.7426 - val_loss: 0.6374 - val_acc: 0.7976\n",
      "Epoch 338/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7516 - acc: 0.7351 - val_loss: 0.6361 - val_acc: 0.7984\n",
      "Epoch 339/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7394 - acc: 0.7455 - val_loss: 0.6375 - val_acc: 0.7984\n",
      "Epoch 340/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7336 - acc: 0.7433 - val_loss: 0.6379 - val_acc: 0.7976\n",
      "Epoch 341/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7433 - acc: 0.7407 - val_loss: 0.6362 - val_acc: 0.7984\n",
      "Epoch 342/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7511 - acc: 0.7388 - val_loss: 0.6352 - val_acc: 0.7984\n",
      "Epoch 343/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7293 - acc: 0.7478 - val_loss: 0.6367 - val_acc: 0.7984\n",
      "Epoch 344/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7367 - acc: 0.7374 - val_loss: 0.6387 - val_acc: 0.7969\n",
      "Epoch 345/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7428 - acc: 0.7489 - val_loss: 0.6339 - val_acc: 0.7976\n",
      "Epoch 346/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7370 - acc: 0.7370 - val_loss: 0.6388 - val_acc: 0.7969\n",
      "Epoch 347/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7369 - acc: 0.7362 - val_loss: 0.6386 - val_acc: 0.7969\n",
      "Epoch 348/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7385 - acc: 0.7459 - val_loss: 0.6375 - val_acc: 0.7976\n",
      "Epoch 349/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7483 - acc: 0.7433 - val_loss: 0.6384 - val_acc: 0.7976\n",
      "Epoch 350/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7527 - acc: 0.7440 - val_loss: 0.6384 - val_acc: 0.7976\n",
      "Epoch 351/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7540 - acc: 0.7407 - val_loss: 0.6323 - val_acc: 0.7999\n",
      "Epoch 352/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7380 - acc: 0.7403 - val_loss: 0.6386 - val_acc: 0.7969\n",
      "Epoch 353/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7395 - acc: 0.7463 - val_loss: 0.6377 - val_acc: 0.7976\n",
      "Epoch 354/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7456 - acc: 0.7374 - val_loss: 0.6382 - val_acc: 0.7976\n",
      "Epoch 355/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7441 - acc: 0.7470 - val_loss: 0.6391 - val_acc: 0.7969\n",
      "Epoch 356/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7377 - acc: 0.7418 - val_loss: 0.6328 - val_acc: 0.7991\n",
      "Epoch 357/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7347 - acc: 0.7418 - val_loss: 0.6383 - val_acc: 0.7976\n",
      "Epoch 358/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7334 - acc: 0.7374 - val_loss: 0.6384 - val_acc: 0.7976\n",
      "Epoch 359/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7469 - acc: 0.7403 - val_loss: 0.6359 - val_acc: 0.7991\n",
      "Epoch 360/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7366 - acc: 0.7437 - val_loss: 0.6371 - val_acc: 0.7976\n",
      "Epoch 361/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7486 - acc: 0.7400 - val_loss: 0.6391 - val_acc: 0.7969\n",
      "Epoch 362/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7462 - acc: 0.7381 - val_loss: 0.6369 - val_acc: 0.7984\n",
      "Epoch 363/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7414 - acc: 0.7414 - val_loss: 0.6392 - val_acc: 0.7969\n",
      "Epoch 364/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7423 - acc: 0.7377 - val_loss: 0.6390 - val_acc: 0.7969\n",
      "Epoch 365/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7432 - acc: 0.7426 - val_loss: 0.6385 - val_acc: 0.7969\n",
      "\n",
      "Epoch 00365: loss improved from inf to 0.74321, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-0-000365-0.743207-0.796875.hdf5\n",
      "Epoch 366/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7403 - acc: 0.7429 - val_loss: 0.6379 - val_acc: 0.7976\n",
      "Epoch 367/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7336 - acc: 0.7452 - val_loss: 0.6390 - val_acc: 0.7969\n",
      "Epoch 368/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7460 - acc: 0.7470 - val_loss: 0.6357 - val_acc: 0.7984\n",
      "Epoch 369/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7442 - acc: 0.7396 - val_loss: 0.6388 - val_acc: 0.7969\n",
      "Epoch 370/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7308 - acc: 0.7507 - val_loss: 0.6312 - val_acc: 0.7991\n",
      "Epoch 371/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7354 - acc: 0.7448 - val_loss: 0.6342 - val_acc: 0.7984\n",
      "Epoch 372/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7435 - acc: 0.7407 - val_loss: 0.6341 - val_acc: 0.7984\n",
      "Epoch 373/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7463 - acc: 0.7388 - val_loss: 0.6381 - val_acc: 0.7969\n",
      "Epoch 374/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7552 - acc: 0.7400 - val_loss: 0.6394 - val_acc: 0.7961\n",
      "Epoch 375/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7513 - acc: 0.7433 - val_loss: 0.6372 - val_acc: 0.7976\n",
      "Epoch 376/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7524 - acc: 0.7329 - val_loss: 0.6351 - val_acc: 0.7984\n",
      "Epoch 377/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7454 - acc: 0.7400 - val_loss: 0.6387 - val_acc: 0.7969\n",
      "Epoch 378/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7536 - acc: 0.7359 - val_loss: 0.6381 - val_acc: 0.7969\n",
      "Epoch 379/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7398 - acc: 0.7444 - val_loss: 0.6380 - val_acc: 0.7976\n",
      "Epoch 380/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7388 - acc: 0.7433 - val_loss: 0.6376 - val_acc: 0.7961\n",
      "Epoch 381/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7558 - acc: 0.7377 - val_loss: 0.6394 - val_acc: 0.7961\n",
      "Epoch 382/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7373 - acc: 0.7444 - val_loss: 0.6391 - val_acc: 0.7961\n",
      "Epoch 383/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7401 - acc: 0.7470 - val_loss: 0.6389 - val_acc: 0.7969\n",
      "Epoch 384/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7381 - acc: 0.7422 - val_loss: 0.6391 - val_acc: 0.7969\n",
      "Epoch 385/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7489 - acc: 0.7437 - val_loss: 0.6388 - val_acc: 0.7969\n",
      "Epoch 386/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7471 - acc: 0.7437 - val_loss: 0.6363 - val_acc: 0.7991\n",
      "Epoch 387/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7185 - acc: 0.7500 - val_loss: 0.6391 - val_acc: 0.7969\n",
      "Epoch 388/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7419 - acc: 0.7448 - val_loss: 0.6391 - val_acc: 0.7969\n",
      "Epoch 389/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7460 - acc: 0.7388 - val_loss: 0.6385 - val_acc: 0.7976\n",
      "Epoch 390/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7485 - acc: 0.7411 - val_loss: 0.6378 - val_acc: 0.7976\n",
      "Epoch 391/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7423 - acc: 0.7388 - val_loss: 0.6389 - val_acc: 0.7969\n",
      "Epoch 392/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7359 - acc: 0.7422 - val_loss: 0.6388 - val_acc: 0.7969\n",
      "Epoch 393/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7489 - acc: 0.7422 - val_loss: 0.6377 - val_acc: 0.7976\n",
      "Epoch 394/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7381 - acc: 0.7418 - val_loss: 0.6387 - val_acc: 0.7969\n",
      "Epoch 395/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7398 - acc: 0.7429 - val_loss: 0.6375 - val_acc: 0.7984\n",
      "Epoch 396/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7393 - acc: 0.7340 - val_loss: 0.6395 - val_acc: 0.7969\n",
      "Epoch 397/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7553 - acc: 0.7321 - val_loss: 0.6384 - val_acc: 0.7976\n",
      "Epoch 398/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7219 - acc: 0.7586 - val_loss: 0.6386 - val_acc: 0.7976\n",
      "Epoch 399/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7286 - acc: 0.7530 - val_loss: 0.6389 - val_acc: 0.7969\n",
      "Epoch 400/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7391 - acc: 0.7507 - val_loss: 0.6373 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00400: saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/0-000400-0.739128-0.798363.hdf5\n",
      "Epoch 401/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7515 - acc: 0.7325 - val_loss: 0.6371 - val_acc: 0.7984\n",
      "Epoch 402/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7185 - acc: 0.7493 - val_loss: 0.6369 - val_acc: 0.7984\n",
      "Epoch 403/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7461 - acc: 0.7429 - val_loss: 0.6353 - val_acc: 0.7984\n",
      "Epoch 404/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7368 - acc: 0.7329 - val_loss: 0.6382 - val_acc: 0.7976\n",
      "Epoch 405/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7309 - acc: 0.7429 - val_loss: 0.6369 - val_acc: 0.7984\n",
      "Epoch 406/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7571 - acc: 0.7351 - val_loss: 0.6392 - val_acc: 0.7969\n",
      "Epoch 407/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7466 - acc: 0.7366 - val_loss: 0.6385 - val_acc: 0.7969\n",
      "Epoch 408/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7389 - acc: 0.7467 - val_loss: 0.6381 - val_acc: 0.7969\n",
      "Epoch 409/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7328 - acc: 0.7429 - val_loss: 0.6370 - val_acc: 0.7984\n",
      "Epoch 410/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7427 - acc: 0.7347 - val_loss: 0.6388 - val_acc: 0.7969\n",
      "Epoch 411/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7448 - acc: 0.7414 - val_loss: 0.6383 - val_acc: 0.7976\n",
      "Epoch 412/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7388 - acc: 0.7400 - val_loss: 0.6378 - val_acc: 0.7969\n",
      "Epoch 413/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7490 - acc: 0.7351 - val_loss: 0.6395 - val_acc: 0.7969\n",
      "Epoch 414/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7573 - acc: 0.7344 - val_loss: 0.6373 - val_acc: 0.7984\n",
      "Epoch 415/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7407 - acc: 0.7396 - val_loss: 0.6366 - val_acc: 0.7976\n",
      "Epoch 416/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7485 - acc: 0.7407 - val_loss: 0.6376 - val_acc: 0.7984\n",
      "Epoch 417/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7384 - acc: 0.7440 - val_loss: 0.6362 - val_acc: 0.7984\n",
      "Epoch 418/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7322 - acc: 0.7452 - val_loss: 0.6350 - val_acc: 0.7984\n",
      "Epoch 419/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7529 - acc: 0.7385 - val_loss: 0.6392 - val_acc: 0.7969\n",
      "Epoch 420/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7482 - acc: 0.7433 - val_loss: 0.6365 - val_acc: 0.7984\n",
      "Epoch 421/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7513 - acc: 0.7325 - val_loss: 0.6363 - val_acc: 0.7984\n",
      "Epoch 422/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.7597 - acc: 0.7407 - val_loss: 0.6390 - val_acc: 0.7969\n",
      "Epoch 423/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7569 - acc: 0.7374 - val_loss: 0.6353 - val_acc: 0.7984\n",
      "Epoch 424/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7383 - acc: 0.7370 - val_loss: 0.6383 - val_acc: 0.7976\n",
      "Epoch 425/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7311 - acc: 0.7403 - val_loss: 0.6390 - val_acc: 0.7969\n",
      "Epoch 426/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7241 - acc: 0.7500 - val_loss: 0.6374 - val_acc: 0.7984\n",
      "Epoch 427/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7379 - acc: 0.7433 - val_loss: 0.6369 - val_acc: 0.7984\n",
      "Epoch 428/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.7417 - acc: 0.7478 - val_loss: 0.6382 - val_acc: 0.7976\n",
      "Epoch 429/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7510 - acc: 0.7340 - val_loss: 0.6384 - val_acc: 0.7969\n",
      "Epoch 430/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7330 - acc: 0.7426 - val_loss: 0.6361 - val_acc: 0.7984\n",
      "Epoch 431/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7263 - acc: 0.7470 - val_loss: 0.6386 - val_acc: 0.7969\n",
      "Epoch 432/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7443 - acc: 0.7448 - val_loss: 0.6393 - val_acc: 0.7969\n",
      "Epoch 433/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7453 - acc: 0.7396 - val_loss: 0.6391 - val_acc: 0.7969\n",
      "Epoch 434/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7420 - acc: 0.7433 - val_loss: 0.6386 - val_acc: 0.7969\n",
      "Epoch 435/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7435 - acc: 0.7459 - val_loss: 0.6373 - val_acc: 0.7984\n",
      "Epoch 436/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7534 - acc: 0.7347 - val_loss: 0.6389 - val_acc: 0.7969\n",
      "Epoch 437/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7513 - acc: 0.7370 - val_loss: 0.6358 - val_acc: 0.7984\n",
      "Epoch 438/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7512 - acc: 0.7359 - val_loss: 0.6377 - val_acc: 0.7976\n",
      "Epoch 439/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7400 - acc: 0.7433 - val_loss: 0.6381 - val_acc: 0.7969\n",
      "Epoch 440/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7475 - acc: 0.7374 - val_loss: 0.6366 - val_acc: 0.7984\n",
      "Epoch 441/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7524 - acc: 0.7418 - val_loss: 0.6387 - val_acc: 0.7969\n",
      "Epoch 442/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7326 - acc: 0.7426 - val_loss: 0.6386 - val_acc: 0.7976\n",
      "Epoch 443/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7365 - acc: 0.7444 - val_loss: 0.6380 - val_acc: 0.7976\n",
      "Epoch 444/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7291 - acc: 0.7418 - val_loss: 0.6373 - val_acc: 0.7976\n",
      "Epoch 445/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7300 - acc: 0.7493 - val_loss: 0.6390 - val_acc: 0.7969\n",
      "Epoch 446/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7268 - acc: 0.7467 - val_loss: 0.6371 - val_acc: 0.7984\n",
      "Epoch 447/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7533 - acc: 0.7429 - val_loss: 0.6379 - val_acc: 0.7976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 448/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7439 - acc: 0.7388 - val_loss: 0.6388 - val_acc: 0.7969\n",
      "Epoch 449/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7372 - acc: 0.7463 - val_loss: 0.6374 - val_acc: 0.7976\n",
      "Epoch 450/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7374 - acc: 0.7411 - val_loss: 0.6392 - val_acc: 0.7969\n",
      "Epoch 451/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7302 - acc: 0.7429 - val_loss: 0.6344 - val_acc: 0.7976\n",
      "Epoch 452/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7333 - acc: 0.7470 - val_loss: 0.6383 - val_acc: 0.7969\n",
      "Epoch 453/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7500 - acc: 0.7388 - val_loss: 0.6372 - val_acc: 0.7976\n",
      "Epoch 454/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7451 - acc: 0.7418 - val_loss: 0.6367 - val_acc: 0.7976\n",
      "Epoch 455/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7446 - acc: 0.7377 - val_loss: 0.6337 - val_acc: 0.7976\n",
      "Epoch 456/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7432 - acc: 0.7470 - val_loss: 0.6395 - val_acc: 0.7969\n",
      "Epoch 457/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7475 - acc: 0.7474 - val_loss: 0.6386 - val_acc: 0.7976\n",
      "Epoch 458/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7351 - acc: 0.7511 - val_loss: 0.6354 - val_acc: 0.7984\n",
      "Epoch 459/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7460 - acc: 0.7385 - val_loss: 0.6387 - val_acc: 0.7969\n",
      "Epoch 460/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7428 - acc: 0.7400 - val_loss: 0.6391 - val_acc: 0.7969\n",
      "Epoch 461/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7361 - acc: 0.7403 - val_loss: 0.6387 - val_acc: 0.7969\n",
      "Epoch 462/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7478 - acc: 0.7433 - val_loss: 0.6393 - val_acc: 0.7969\n",
      "Epoch 463/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7316 - acc: 0.7541 - val_loss: 0.6387 - val_acc: 0.7969\n",
      "Epoch 464/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7312 - acc: 0.7433 - val_loss: 0.6386 - val_acc: 0.7969\n",
      "Epoch 465/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7411 - acc: 0.7370 - val_loss: 0.6371 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00465: loss improved from inf to 0.74108, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-0-000465-0.741083-0.798363.hdf5\n",
      "Epoch 466/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7324 - acc: 0.7392 - val_loss: 0.6332 - val_acc: 0.7976\n",
      "Epoch 467/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7404 - acc: 0.7418 - val_loss: 0.6375 - val_acc: 0.7976\n",
      "Epoch 468/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7336 - acc: 0.7455 - val_loss: 0.6365 - val_acc: 0.7984\n",
      "Epoch 469/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7230 - acc: 0.7448 - val_loss: 0.6363 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00469: loss improved from 0.74108 to 0.72304, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-0-000469-0.723036-0.798363.hdf5\n",
      "Epoch 470/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7512 - acc: 0.7463 - val_loss: 0.6384 - val_acc: 0.7969\n",
      "Epoch 471/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7409 - acc: 0.7429 - val_loss: 0.6389 - val_acc: 0.7969\n",
      "Epoch 472/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7398 - acc: 0.7414 - val_loss: 0.6396 - val_acc: 0.7969\n",
      "Epoch 473/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7440 - acc: 0.7336 - val_loss: 0.6389 - val_acc: 0.7969\n",
      "Epoch 474/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7451 - acc: 0.7392 - val_loss: 0.6354 - val_acc: 0.7976\n",
      "Epoch 475/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7544 - acc: 0.7414 - val_loss: 0.6360 - val_acc: 0.7984\n",
      "Epoch 476/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7375 - acc: 0.7351 - val_loss: 0.6369 - val_acc: 0.7976\n",
      "Epoch 477/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7485 - acc: 0.7392 - val_loss: 0.6382 - val_acc: 0.7976\n",
      "Epoch 478/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7529 - acc: 0.7303 - val_loss: 0.6379 - val_acc: 0.7969\n",
      "Epoch 479/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7432 - acc: 0.7407 - val_loss: 0.6372 - val_acc: 0.7976\n",
      "Epoch 480/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7279 - acc: 0.7429 - val_loss: 0.6385 - val_acc: 0.7976\n",
      "Epoch 481/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7333 - acc: 0.7433 - val_loss: 0.6373 - val_acc: 0.7976\n",
      "Epoch 482/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7382 - acc: 0.7411 - val_loss: 0.6395 - val_acc: 0.7969\n",
      "Epoch 483/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7332 - acc: 0.7370 - val_loss: 0.6377 - val_acc: 0.7976\n",
      "Epoch 484/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7528 - acc: 0.7351 - val_loss: 0.6369 - val_acc: 0.7976\n",
      "Epoch 485/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7412 - acc: 0.7370 - val_loss: 0.6384 - val_acc: 0.7976\n",
      "Epoch 486/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7462 - acc: 0.7396 - val_loss: 0.6354 - val_acc: 0.7984\n",
      "Epoch 487/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7388 - acc: 0.7418 - val_loss: 0.6388 - val_acc: 0.7969\n",
      "Epoch 488/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7422 - acc: 0.7452 - val_loss: 0.6390 - val_acc: 0.7969\n",
      "Epoch 489/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7483 - acc: 0.7437 - val_loss: 0.6362 - val_acc: 0.7976\n",
      "Epoch 490/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7424 - acc: 0.7355 - val_loss: 0.6370 - val_acc: 0.7976\n",
      "Epoch 491/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7496 - acc: 0.7426 - val_loss: 0.6374 - val_acc: 0.7976\n",
      "Epoch 492/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7385 - acc: 0.7370 - val_loss: 0.6369 - val_acc: 0.7984\n",
      "Epoch 493/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7312 - acc: 0.7452 - val_loss: 0.6385 - val_acc: 0.7976\n",
      "Epoch 494/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7314 - acc: 0.7511 - val_loss: 0.6357 - val_acc: 0.7991\n",
      "Epoch 495/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7333 - acc: 0.7347 - val_loss: 0.6359 - val_acc: 0.7976\n",
      "Epoch 496/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7446 - acc: 0.7374 - val_loss: 0.6364 - val_acc: 0.7984\n",
      "Epoch 497/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7349 - acc: 0.7478 - val_loss: 0.6374 - val_acc: 0.7976\n",
      "Epoch 498/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7308 - acc: 0.7407 - val_loss: 0.6387 - val_acc: 0.7969\n",
      "Epoch 499/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7284 - acc: 0.7470 - val_loss: 0.6356 - val_acc: 0.7976\n",
      "Epoch 500/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7523 - acc: 0.7396 - val_loss: 0.6368 - val_acc: 0.7976\n",
      "\n",
      "Epoch 00500: saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/0-000500-0.752262-0.797619.hdf5\n",
      "Epoch 501/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7348 - acc: 0.7463 - val_loss: 0.6385 - val_acc: 0.7969\n",
      "Epoch 502/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7340 - acc: 0.7374 - val_loss: 0.6390 - val_acc: 0.7969\n",
      "Epoch 503/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7336 - acc: 0.7478 - val_loss: 0.6355 - val_acc: 0.7984\n",
      "Epoch 504/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7373 - acc: 0.7470 - val_loss: 0.6381 - val_acc: 0.7976\n",
      "Epoch 505/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7459 - acc: 0.7414 - val_loss: 0.6377 - val_acc: 0.7976\n",
      "Epoch 506/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7285 - acc: 0.7507 - val_loss: 0.6391 - val_acc: 0.7969\n",
      "Epoch 507/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7442 - acc: 0.7392 - val_loss: 0.6370 - val_acc: 0.7976\n",
      "Epoch 508/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7336 - acc: 0.7455 - val_loss: 0.6380 - val_acc: 0.7976\n",
      "Epoch 509/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7299 - acc: 0.7463 - val_loss: 0.6359 - val_acc: 0.7984\n",
      "Epoch 510/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7275 - acc: 0.7437 - val_loss: 0.6391 - val_acc: 0.7969\n",
      "Epoch 511/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7566 - acc: 0.7284 - val_loss: 0.6369 - val_acc: 0.7976\n",
      "Epoch 512/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7480 - acc: 0.7455 - val_loss: 0.6378 - val_acc: 0.7976\n",
      "Epoch 513/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7420 - acc: 0.7351 - val_loss: 0.6381 - val_acc: 0.7976\n",
      "Epoch 514/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7407 - acc: 0.7407 - val_loss: 0.6368 - val_acc: 0.7984\n",
      "Epoch 515/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7243 - acc: 0.7429 - val_loss: 0.6368 - val_acc: 0.7984\n",
      "Epoch 516/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7470 - acc: 0.7310 - val_loss: 0.6389 - val_acc: 0.7969\n",
      "Epoch 517/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7251 - acc: 0.7426 - val_loss: 0.6392 - val_acc: 0.7969\n",
      "Epoch 518/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7466 - acc: 0.7411 - val_loss: 0.6376 - val_acc: 0.7976\n",
      "Epoch 519/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7434 - acc: 0.7407 - val_loss: 0.6383 - val_acc: 0.7976\n",
      "Epoch 520/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7456 - acc: 0.7407 - val_loss: 0.6368 - val_acc: 0.7976\n",
      "Epoch 521/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7437 - acc: 0.7392 - val_loss: 0.6366 - val_acc: 0.7984\n",
      "Epoch 522/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7515 - acc: 0.7359 - val_loss: 0.6383 - val_acc: 0.7969\n",
      "Epoch 523/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7353 - acc: 0.7396 - val_loss: 0.6373 - val_acc: 0.7976\n",
      "Epoch 524/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7538 - acc: 0.7359 - val_loss: 0.6361 - val_acc: 0.7976\n",
      "Epoch 525/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7216 - acc: 0.7489 - val_loss: 0.6358 - val_acc: 0.7984\n",
      "Epoch 526/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7374 - acc: 0.7392 - val_loss: 0.6375 - val_acc: 0.7984\n",
      "Epoch 527/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7292 - acc: 0.7470 - val_loss: 0.6391 - val_acc: 0.7969\n",
      "Epoch 528/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7357 - acc: 0.7459 - val_loss: 0.6378 - val_acc: 0.7976\n",
      "Epoch 529/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7416 - acc: 0.7448 - val_loss: 0.6377 - val_acc: 0.7984\n",
      "Epoch 530/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7389 - acc: 0.7374 - val_loss: 0.6388 - val_acc: 0.7969\n",
      "Epoch 531/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7507 - acc: 0.7392 - val_loss: 0.6367 - val_acc: 0.7976\n",
      "Epoch 532/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7429 - acc: 0.7478 - val_loss: 0.6374 - val_acc: 0.7976\n",
      "Epoch 533/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7209 - acc: 0.7440 - val_loss: 0.6376 - val_acc: 0.7976\n",
      "Epoch 534/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7229 - acc: 0.7504 - val_loss: 0.6382 - val_acc: 0.7969\n",
      "Epoch 535/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7414 - acc: 0.7411 - val_loss: 0.6374 - val_acc: 0.7976\n",
      "Epoch 536/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7433 - acc: 0.7422 - val_loss: 0.6386 - val_acc: 0.7969\n",
      "Epoch 537/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7297 - acc: 0.7452 - val_loss: 0.6385 - val_acc: 0.7976\n",
      "Epoch 538/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7472 - acc: 0.7388 - val_loss: 0.6387 - val_acc: 0.7969\n",
      "Epoch 539/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7462 - acc: 0.7362 - val_loss: 0.6379 - val_acc: 0.7976\n",
      "Epoch 540/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7393 - acc: 0.7452 - val_loss: 0.6366 - val_acc: 0.7984\n",
      "Epoch 541/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7395 - acc: 0.7452 - val_loss: 0.6337 - val_acc: 0.7984\n",
      "Epoch 542/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7354 - acc: 0.7414 - val_loss: 0.6371 - val_acc: 0.7976\n",
      "Epoch 543/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7463 - acc: 0.7325 - val_loss: 0.6380 - val_acc: 0.7969\n",
      "Epoch 544/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7334 - acc: 0.7444 - val_loss: 0.6388 - val_acc: 0.7976\n",
      "Epoch 545/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7325 - acc: 0.7407 - val_loss: 0.6383 - val_acc: 0.7969\n",
      "Epoch 546/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7432 - acc: 0.7433 - val_loss: 0.6386 - val_acc: 0.7969\n",
      "Epoch 547/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7494 - acc: 0.7370 - val_loss: 0.6385 - val_acc: 0.7976\n",
      "Epoch 548/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7388 - acc: 0.7459 - val_loss: 0.6357 - val_acc: 0.7976\n",
      "Epoch 549/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7534 - acc: 0.7329 - val_loss: 0.6364 - val_acc: 0.7984\n",
      "Epoch 550/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7441 - acc: 0.7407 - val_loss: 0.6371 - val_acc: 0.7976\n",
      "Epoch 551/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7590 - acc: 0.7366 - val_loss: 0.6390 - val_acc: 0.7969\n",
      "Epoch 552/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7461 - acc: 0.7385 - val_loss: 0.6389 - val_acc: 0.7969\n",
      "Epoch 553/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7320 - acc: 0.7459 - val_loss: 0.6353 - val_acc: 0.7984\n",
      "Epoch 554/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7397 - acc: 0.7396 - val_loss: 0.6363 - val_acc: 0.7984\n",
      "Epoch 555/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7446 - acc: 0.7459 - val_loss: 0.6376 - val_acc: 0.7976\n",
      "Epoch 556/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7433 - acc: 0.7392 - val_loss: 0.6388 - val_acc: 0.7969\n",
      "Epoch 557/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7406 - acc: 0.7448 - val_loss: 0.6369 - val_acc: 0.7976\n",
      "Epoch 558/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7326 - acc: 0.7426 - val_loss: 0.6344 - val_acc: 0.7984\n",
      "Epoch 559/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7340 - acc: 0.7403 - val_loss: 0.6350 - val_acc: 0.7984\n",
      "Epoch 560/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7349 - acc: 0.7374 - val_loss: 0.6378 - val_acc: 0.7976\n",
      "Epoch 561/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7317 - acc: 0.7437 - val_loss: 0.6355 - val_acc: 0.7976\n",
      "Epoch 562/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7345 - acc: 0.7407 - val_loss: 0.6375 - val_acc: 0.7976\n",
      "Epoch 563/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7455 - acc: 0.7422 - val_loss: 0.6392 - val_acc: 0.7969\n",
      "Epoch 564/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7550 - acc: 0.7440 - val_loss: 0.6366 - val_acc: 0.7976\n",
      "Epoch 565/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7344 - acc: 0.7418 - val_loss: 0.6368 - val_acc: 0.7984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00565: loss improved from inf to 0.73437, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-0-000565-0.734374-0.798363.hdf5\n",
      "Epoch 566/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7534 - acc: 0.7385 - val_loss: 0.6361 - val_acc: 0.7976\n",
      "Epoch 567/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7469 - acc: 0.7526 - val_loss: 0.6376 - val_acc: 0.7976\n",
      "Epoch 568/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7459 - acc: 0.7355 - val_loss: 0.6322 - val_acc: 0.7991\n",
      "Epoch 569/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7359 - acc: 0.7377 - val_loss: 0.6361 - val_acc: 0.7984\n",
      "Epoch 570/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7451 - acc: 0.7336 - val_loss: 0.6391 - val_acc: 0.7969\n",
      "Epoch 571/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7361 - acc: 0.7437 - val_loss: 0.6391 - val_acc: 0.7969\n",
      "Epoch 572/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7169 - acc: 0.7422 - val_loss: 0.6379 - val_acc: 0.7976\n",
      "Epoch 573/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7598 - acc: 0.7336 - val_loss: 0.6368 - val_acc: 0.7984\n",
      "Epoch 574/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7354 - acc: 0.7422 - val_loss: 0.6385 - val_acc: 0.7969\n",
      "Epoch 575/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7531 - acc: 0.7411 - val_loss: 0.6385 - val_acc: 0.7976\n",
      "Epoch 576/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7383 - acc: 0.7400 - val_loss: 0.6348 - val_acc: 0.7991\n",
      "Epoch 577/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7370 - acc: 0.7433 - val_loss: 0.6370 - val_acc: 0.7976\n",
      "Epoch 578/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7348 - acc: 0.7418 - val_loss: 0.6339 - val_acc: 0.7991\n",
      "Epoch 579/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7430 - acc: 0.7388 - val_loss: 0.6359 - val_acc: 0.7976\n",
      "Epoch 580/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7279 - acc: 0.7489 - val_loss: 0.6387 - val_acc: 0.7969\n",
      "Epoch 581/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7287 - acc: 0.7433 - val_loss: 0.6369 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00581: loss improved from 0.73437 to 0.72870, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-0-000581-0.728701-0.798363.hdf5\n",
      "Epoch 582/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7402 - acc: 0.7366 - val_loss: 0.6388 - val_acc: 0.7969\n",
      "Epoch 583/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7298 - acc: 0.7452 - val_loss: 0.6381 - val_acc: 0.7976\n",
      "Epoch 584/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7422 - acc: 0.7433 - val_loss: 0.6380 - val_acc: 0.7976\n",
      "Epoch 585/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7376 - acc: 0.7426 - val_loss: 0.6368 - val_acc: 0.7984\n",
      "Epoch 586/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7393 - acc: 0.7440 - val_loss: 0.6384 - val_acc: 0.7969\n",
      "Epoch 587/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7359 - acc: 0.7411 - val_loss: 0.6381 - val_acc: 0.7976\n",
      "Epoch 588/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7339 - acc: 0.7485 - val_loss: 0.6368 - val_acc: 0.7984\n",
      "Epoch 589/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7467 - acc: 0.7467 - val_loss: 0.6362 - val_acc: 0.7976\n",
      "Epoch 590/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7385 - acc: 0.7478 - val_loss: 0.6289 - val_acc: 0.7984\n",
      "Epoch 591/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7421 - acc: 0.7452 - val_loss: 0.6387 - val_acc: 0.7969\n",
      "Epoch 592/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7267 - acc: 0.7414 - val_loss: 0.6390 - val_acc: 0.7969\n",
      "Epoch 593/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7293 - acc: 0.7440 - val_loss: 0.6372 - val_acc: 0.7976\n",
      "Epoch 594/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7459 - acc: 0.7433 - val_loss: 0.6383 - val_acc: 0.7969\n",
      "Epoch 595/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7408 - acc: 0.7433 - val_loss: 0.6376 - val_acc: 0.7976\n",
      "Epoch 596/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7426 - acc: 0.7489 - val_loss: 0.6313 - val_acc: 0.7984\n",
      "Epoch 597/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7503 - acc: 0.7396 - val_loss: 0.6370 - val_acc: 0.7984\n",
      "Epoch 598/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7451 - acc: 0.7426 - val_loss: 0.6382 - val_acc: 0.7976\n",
      "Epoch 599/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7371 - acc: 0.7548 - val_loss: 0.6380 - val_acc: 0.7969\n",
      "Epoch 600/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7412 - acc: 0.7407 - val_loss: 0.6382 - val_acc: 0.7969\n",
      "\n",
      "Epoch 00600: saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/0-000600-0.741210-0.796875.hdf5\n",
      "Epoch 601/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7397 - acc: 0.7392 - val_loss: 0.6356 - val_acc: 0.7984\n",
      "Epoch 602/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7408 - acc: 0.7370 - val_loss: 0.6387 - val_acc: 0.7969\n",
      "Epoch 603/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7400 - acc: 0.7385 - val_loss: 0.6371 - val_acc: 0.7976\n",
      "Epoch 604/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7484 - acc: 0.7463 - val_loss: 0.6390 - val_acc: 0.7969\n",
      "Epoch 605/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7190 - acc: 0.7485 - val_loss: 0.6379 - val_acc: 0.7976\n",
      "Epoch 606/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7398 - acc: 0.7418 - val_loss: 0.6365 - val_acc: 0.7984\n",
      "Epoch 607/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7275 - acc: 0.7437 - val_loss: 0.6377 - val_acc: 0.7976\n",
      "Epoch 608/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7404 - acc: 0.7381 - val_loss: 0.6304 - val_acc: 0.7991\n",
      "Epoch 609/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7345 - acc: 0.7422 - val_loss: 0.6380 - val_acc: 0.7976\n",
      "Epoch 610/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7244 - acc: 0.7418 - val_loss: 0.6383 - val_acc: 0.7969\n",
      "Epoch 611/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7467 - acc: 0.7318 - val_loss: 0.6352 - val_acc: 0.7984\n",
      "Epoch 612/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7434 - acc: 0.7414 - val_loss: 0.6382 - val_acc: 0.7976\n",
      "Epoch 613/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7508 - acc: 0.7426 - val_loss: 0.6386 - val_acc: 0.7969\n",
      "Epoch 614/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7381 - acc: 0.7485 - val_loss: 0.6378 - val_acc: 0.7976\n",
      "Epoch 615/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7611 - acc: 0.7321 - val_loss: 0.6345 - val_acc: 0.7984\n",
      "Epoch 616/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7478 - acc: 0.7366 - val_loss: 0.6363 - val_acc: 0.7976\n",
      "Epoch 617/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7280 - acc: 0.7429 - val_loss: 0.6385 - val_acc: 0.7969\n",
      "Epoch 618/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7420 - acc: 0.7403 - val_loss: 0.6370 - val_acc: 0.7984\n",
      "Epoch 619/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7338 - acc: 0.7385 - val_loss: 0.6362 - val_acc: 0.7984\n",
      "Epoch 620/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7395 - acc: 0.7329 - val_loss: 0.6379 - val_acc: 0.7969\n",
      "Epoch 621/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7330 - acc: 0.7422 - val_loss: 0.6388 - val_acc: 0.7969\n",
      "Epoch 622/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7386 - acc: 0.7470 - val_loss: 0.6383 - val_acc: 0.7969\n",
      "Epoch 623/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7457 - acc: 0.7414 - val_loss: 0.6386 - val_acc: 0.7969\n",
      "Epoch 624/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7501 - acc: 0.7440 - val_loss: 0.6357 - val_acc: 0.7976\n",
      "Epoch 625/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7206 - acc: 0.7489 - val_loss: 0.6348 - val_acc: 0.7991\n",
      "Epoch 626/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7485 - acc: 0.7433 - val_loss: 0.6374 - val_acc: 0.7976\n",
      "Epoch 627/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7363 - acc: 0.7433 - val_loss: 0.6374 - val_acc: 0.7976\n",
      "Epoch 628/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7451 - acc: 0.7347 - val_loss: 0.6347 - val_acc: 0.7976\n",
      "Epoch 629/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7398 - acc: 0.7459 - val_loss: 0.6392 - val_acc: 0.7969\n",
      "Epoch 630/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7347 - acc: 0.7448 - val_loss: 0.6378 - val_acc: 0.7976\n",
      "Epoch 631/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7438 - acc: 0.7388 - val_loss: 0.6372 - val_acc: 0.7976\n",
      "Epoch 632/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7422 - acc: 0.7414 - val_loss: 0.6378 - val_acc: 0.7984\n",
      "Epoch 633/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7459 - acc: 0.7504 - val_loss: 0.6380 - val_acc: 0.7976\n",
      "Epoch 634/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7406 - acc: 0.7433 - val_loss: 0.6375 - val_acc: 0.7969\n",
      "Epoch 635/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7416 - acc: 0.7437 - val_loss: 0.6381 - val_acc: 0.7969\n",
      "Epoch 636/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7633 - acc: 0.7347 - val_loss: 0.6374 - val_acc: 0.7976\n",
      "Epoch 637/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7366 - acc: 0.7411 - val_loss: 0.6393 - val_acc: 0.7969\n",
      "Epoch 638/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7449 - acc: 0.7426 - val_loss: 0.6366 - val_acc: 0.7976\n",
      "Epoch 639/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7503 - acc: 0.7400 - val_loss: 0.6371 - val_acc: 0.7976\n",
      "Epoch 640/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7276 - acc: 0.7481 - val_loss: 0.6383 - val_acc: 0.7969\n",
      "Epoch 641/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7495 - acc: 0.7377 - val_loss: 0.6381 - val_acc: 0.7976\n",
      "Epoch 642/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7436 - acc: 0.7396 - val_loss: 0.6354 - val_acc: 0.7984\n",
      "Epoch 643/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7363 - acc: 0.7414 - val_loss: 0.6379 - val_acc: 0.7969\n",
      "Epoch 644/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7434 - acc: 0.7507 - val_loss: 0.6385 - val_acc: 0.7969\n",
      "Epoch 645/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7310 - acc: 0.7362 - val_loss: 0.6248 - val_acc: 0.7984\n",
      "Epoch 646/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7299 - acc: 0.7548 - val_loss: 0.6390 - val_acc: 0.7969\n",
      "Epoch 647/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7365 - acc: 0.7444 - val_loss: 0.6376 - val_acc: 0.7976\n",
      "Epoch 648/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7563 - acc: 0.7370 - val_loss: 0.6371 - val_acc: 0.7976\n",
      "Epoch 649/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7441 - acc: 0.7351 - val_loss: 0.6344 - val_acc: 0.7991\n",
      "Epoch 650/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7235 - acc: 0.7493 - val_loss: 0.6370 - val_acc: 0.7976\n",
      "Epoch 651/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7346 - acc: 0.7474 - val_loss: 0.6372 - val_acc: 0.7976\n",
      "Epoch 652/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7433 - acc: 0.7452 - val_loss: 0.6385 - val_acc: 0.7969\n",
      "Epoch 653/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7504 - acc: 0.7377 - val_loss: 0.6334 - val_acc: 0.7991\n",
      "Epoch 654/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7447 - acc: 0.7437 - val_loss: 0.6361 - val_acc: 0.7984\n",
      "Epoch 655/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7508 - acc: 0.7340 - val_loss: 0.6368 - val_acc: 0.7976\n",
      "Epoch 656/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7381 - acc: 0.7452 - val_loss: 0.6381 - val_acc: 0.7976\n",
      "Epoch 657/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7454 - acc: 0.7385 - val_loss: 0.6371 - val_acc: 0.7976\n",
      "Epoch 658/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7354 - acc: 0.7444 - val_loss: 0.6391 - val_acc: 0.7969\n",
      "Epoch 659/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7517 - acc: 0.7418 - val_loss: 0.6363 - val_acc: 0.7984\n",
      "Epoch 660/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7389 - acc: 0.7411 - val_loss: 0.6339 - val_acc: 0.7976\n",
      "Epoch 661/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7431 - acc: 0.7400 - val_loss: 0.6387 - val_acc: 0.7969\n",
      "Epoch 662/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7433 - acc: 0.7407 - val_loss: 0.6340 - val_acc: 0.7984\n",
      "Epoch 663/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7515 - acc: 0.7452 - val_loss: 0.6385 - val_acc: 0.7969\n",
      "Epoch 664/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7502 - acc: 0.7333 - val_loss: 0.6363 - val_acc: 0.7976\n",
      "Epoch 665/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7419 - acc: 0.7403 - val_loss: 0.6359 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00665: loss improved from inf to 0.74192, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-0-000665-0.741917-0.798363.hdf5\n",
      "Epoch 666/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7441 - acc: 0.7377 - val_loss: 0.6360 - val_acc: 0.7991\n",
      "Epoch 667/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7475 - acc: 0.7396 - val_loss: 0.6367 - val_acc: 0.7976\n",
      "Epoch 668/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7454 - acc: 0.7400 - val_loss: 0.6366 - val_acc: 0.7991\n",
      "Epoch 669/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7462 - acc: 0.7418 - val_loss: 0.6389 - val_acc: 0.7969\n",
      "Epoch 670/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7353 - acc: 0.7444 - val_loss: 0.6373 - val_acc: 0.7976\n",
      "Epoch 671/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7440 - acc: 0.7377 - val_loss: 0.6377 - val_acc: 0.7976\n",
      "Epoch 672/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7426 - acc: 0.7422 - val_loss: 0.6339 - val_acc: 0.7984\n",
      "Epoch 673/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.7438 - acc: 0.7366 - val_loss: 0.6358 - val_acc: 0.7984\n",
      "Epoch 674/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7361 - acc: 0.7407 - val_loss: 0.6386 - val_acc: 0.7969\n",
      "Epoch 675/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7479 - acc: 0.7411 - val_loss: 0.6366 - val_acc: 0.7984\n",
      "Epoch 676/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7362 - acc: 0.7411 - val_loss: 0.6368 - val_acc: 0.7976\n",
      "Epoch 677/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7252 - acc: 0.7485 - val_loss: 0.6369 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00677: loss improved from 0.74192 to 0.72516, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-0-000677-0.725157-0.798363.hdf5\n",
      "Epoch 678/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7455 - acc: 0.7414 - val_loss: 0.6369 - val_acc: 0.7984\n",
      "Epoch 679/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7321 - acc: 0.7414 - val_loss: 0.6347 - val_acc: 0.7984\n",
      "Epoch 680/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7426 - acc: 0.7448 - val_loss: 0.6384 - val_acc: 0.7969\n",
      "Epoch 681/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7494 - acc: 0.7444 - val_loss: 0.6362 - val_acc: 0.7976\n",
      "Epoch 682/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7584 - acc: 0.7347 - val_loss: 0.6386 - val_acc: 0.7969\n",
      "Epoch 683/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7479 - acc: 0.7351 - val_loss: 0.6378 - val_acc: 0.7969\n",
      "Epoch 684/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7335 - acc: 0.7485 - val_loss: 0.6382 - val_acc: 0.7976\n",
      "Epoch 685/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7397 - acc: 0.7403 - val_loss: 0.6382 - val_acc: 0.7976\n",
      "Epoch 686/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7378 - acc: 0.7448 - val_loss: 0.6381 - val_acc: 0.7976\n",
      "Epoch 687/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7534 - acc: 0.7340 - val_loss: 0.6375 - val_acc: 0.7976\n",
      "Epoch 688/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7436 - acc: 0.7392 - val_loss: 0.6372 - val_acc: 0.7976\n",
      "Epoch 689/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7425 - acc: 0.7496 - val_loss: 0.6279 - val_acc: 0.7984\n",
      "Epoch 690/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7389 - acc: 0.7400 - val_loss: 0.6357 - val_acc: 0.7976\n",
      "Epoch 691/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7339 - acc: 0.7433 - val_loss: 0.6331 - val_acc: 0.7984\n",
      "Epoch 692/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7337 - acc: 0.7500 - val_loss: 0.6351 - val_acc: 0.7976\n",
      "Epoch 693/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7262 - acc: 0.7463 - val_loss: 0.6385 - val_acc: 0.7976\n",
      "Epoch 694/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7361 - acc: 0.7396 - val_loss: 0.6375 - val_acc: 0.7976\n",
      "Epoch 695/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7357 - acc: 0.7437 - val_loss: 0.6369 - val_acc: 0.7976\n",
      "Epoch 696/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7435 - acc: 0.7362 - val_loss: 0.6390 - val_acc: 0.7969\n",
      "Epoch 697/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7439 - acc: 0.7459 - val_loss: 0.6375 - val_acc: 0.7976\n",
      "Epoch 698/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7264 - acc: 0.7437 - val_loss: 0.6393 - val_acc: 0.7969\n",
      "Epoch 699/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7338 - acc: 0.7418 - val_loss: 0.6386 - val_acc: 0.7969\n",
      "Epoch 700/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7511 - acc: 0.7344 - val_loss: 0.6376 - val_acc: 0.7976\n",
      "\n",
      "Epoch 00700: saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/0-000700-0.751106-0.797619.hdf5\n",
      "Epoch 701/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7464 - acc: 0.7333 - val_loss: 0.6375 - val_acc: 0.7976\n",
      "Epoch 702/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7353 - acc: 0.7452 - val_loss: 0.6377 - val_acc: 0.7976\n",
      "Epoch 703/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7459 - acc: 0.7362 - val_loss: 0.6352 - val_acc: 0.7991\n",
      "Epoch 704/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7326 - acc: 0.7519 - val_loss: 0.6366 - val_acc: 0.7984\n",
      "Epoch 705/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7328 - acc: 0.7467 - val_loss: 0.6360 - val_acc: 0.7984\n",
      "Epoch 706/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7431 - acc: 0.7377 - val_loss: 0.6382 - val_acc: 0.7969\n",
      "Epoch 707/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7518 - acc: 0.7414 - val_loss: 0.6359 - val_acc: 0.7976\n",
      "Epoch 708/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7242 - acc: 0.7526 - val_loss: 0.6345 - val_acc: 0.7999\n",
      "Epoch 709/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7282 - acc: 0.7396 - val_loss: 0.6359 - val_acc: 0.7984\n",
      "Epoch 710/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7397 - acc: 0.7448 - val_loss: 0.6362 - val_acc: 0.7984\n",
      "Epoch 711/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7459 - acc: 0.7359 - val_loss: 0.6390 - val_acc: 0.7969\n",
      "Epoch 712/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7303 - acc: 0.7403 - val_loss: 0.6366 - val_acc: 0.7969\n",
      "Epoch 713/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7393 - acc: 0.7400 - val_loss: 0.6368 - val_acc: 0.7976\n",
      "Epoch 714/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7383 - acc: 0.7418 - val_loss: 0.6356 - val_acc: 0.7976\n",
      "Epoch 715/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7427 - acc: 0.7459 - val_loss: 0.6362 - val_acc: 0.7969\n",
      "Epoch 716/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7483 - acc: 0.7437 - val_loss: 0.6390 - val_acc: 0.7969\n",
      "Epoch 717/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7507 - acc: 0.7344 - val_loss: 0.6385 - val_acc: 0.7969\n",
      "Epoch 718/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7415 - acc: 0.7474 - val_loss: 0.6372 - val_acc: 0.7976\n",
      "Epoch 719/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7343 - acc: 0.7407 - val_loss: 0.6387 - val_acc: 0.7969\n",
      "Epoch 720/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7437 - acc: 0.7426 - val_loss: 0.6351 - val_acc: 0.7976\n",
      "Epoch 721/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7117 - acc: 0.7515 - val_loss: 0.6355 - val_acc: 0.7991\n",
      "Epoch 722/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7471 - acc: 0.7329 - val_loss: 0.6387 - val_acc: 0.7969\n",
      "Epoch 723/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7529 - acc: 0.7396 - val_loss: 0.6380 - val_acc: 0.7969\n",
      "Epoch 724/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7529 - acc: 0.7347 - val_loss: 0.6383 - val_acc: 0.7969\n",
      "Epoch 725/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7383 - acc: 0.7448 - val_loss: 0.6378 - val_acc: 0.7976\n",
      "Epoch 726/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7375 - acc: 0.7448 - val_loss: 0.6359 - val_acc: 0.7984\n",
      "Epoch 727/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7389 - acc: 0.7414 - val_loss: 0.6390 - val_acc: 0.7969\n",
      "Epoch 728/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7516 - acc: 0.7448 - val_loss: 0.6363 - val_acc: 0.7984\n",
      "Epoch 729/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7359 - acc: 0.7426 - val_loss: 0.6380 - val_acc: 0.7976\n",
      "Epoch 730/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7440 - acc: 0.7407 - val_loss: 0.6383 - val_acc: 0.7969\n",
      "Epoch 731/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7375 - acc: 0.7470 - val_loss: 0.6360 - val_acc: 0.7976\n",
      "Epoch 732/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7303 - acc: 0.7485 - val_loss: 0.6380 - val_acc: 0.7969\n",
      "Epoch 733/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.7496 - acc: 0.7463 - val_loss: 0.6388 - val_acc: 0.7969\n",
      "Epoch 734/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7371 - acc: 0.7362 - val_loss: 0.6364 - val_acc: 0.7976\n",
      "Epoch 735/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7306 - acc: 0.7344 - val_loss: 0.6366 - val_acc: 0.7984\n",
      "Epoch 736/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7490 - acc: 0.7385 - val_loss: 0.6342 - val_acc: 0.7984\n",
      "Epoch 737/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7325 - acc: 0.7426 - val_loss: 0.6374 - val_acc: 0.7969\n",
      "Epoch 738/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7399 - acc: 0.7444 - val_loss: 0.6377 - val_acc: 0.7969\n",
      "Epoch 739/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7444 - acc: 0.7429 - val_loss: 0.6387 - val_acc: 0.7961\n",
      "Epoch 740/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7436 - acc: 0.7414 - val_loss: 0.6367 - val_acc: 0.7969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 741/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7533 - acc: 0.7448 - val_loss: 0.6380 - val_acc: 0.7969\n",
      "Epoch 742/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7274 - acc: 0.7470 - val_loss: 0.6374 - val_acc: 0.7969\n",
      "Epoch 743/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7483 - acc: 0.7485 - val_loss: 0.6372 - val_acc: 0.7969\n",
      "Epoch 744/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7516 - acc: 0.7385 - val_loss: 0.6373 - val_acc: 0.7969\n",
      "Epoch 745/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7392 - acc: 0.7470 - val_loss: 0.6379 - val_acc: 0.7969\n",
      "Epoch 746/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7462 - acc: 0.7463 - val_loss: 0.6363 - val_acc: 0.7969\n",
      "Epoch 747/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7477 - acc: 0.7467 - val_loss: 0.6363 - val_acc: 0.7984\n",
      "Epoch 748/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.7344 - acc: 0.7440 - val_loss: 0.6341 - val_acc: 0.7991\n",
      "Epoch 749/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7426 - acc: 0.7392 - val_loss: 0.6382 - val_acc: 0.7976\n",
      "Epoch 750/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7460 - acc: 0.7370 - val_loss: 0.6337 - val_acc: 0.7991\n",
      "Epoch 751/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7496 - acc: 0.7426 - val_loss: 0.6365 - val_acc: 0.7984\n",
      "Epoch 752/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.7452 - acc: 0.7362 - val_loss: 0.6374 - val_acc: 0.7976\n",
      "Epoch 753/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7463 - acc: 0.7418 - val_loss: 0.6374 - val_acc: 0.7984\n",
      "Epoch 754/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7317 - acc: 0.7437 - val_loss: 0.6365 - val_acc: 0.7984\n",
      "Epoch 755/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7546 - acc: 0.7396 - val_loss: 0.6373 - val_acc: 0.7976\n",
      "Epoch 756/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7379 - acc: 0.7440 - val_loss: 0.6334 - val_acc: 0.7991\n",
      "Epoch 757/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7485 - acc: 0.7388 - val_loss: 0.6384 - val_acc: 0.7969\n",
      "Epoch 758/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7456 - acc: 0.7403 - val_loss: 0.6346 - val_acc: 0.7984\n",
      "Epoch 759/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7447 - acc: 0.7336 - val_loss: 0.6358 - val_acc: 0.7991\n",
      "Epoch 760/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7467 - acc: 0.7318 - val_loss: 0.6374 - val_acc: 0.7976\n",
      "Epoch 761/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7433 - acc: 0.7392 - val_loss: 0.6379 - val_acc: 0.7976\n",
      "Epoch 762/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7340 - acc: 0.7522 - val_loss: 0.6368 - val_acc: 0.7976\n",
      "Epoch 763/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7473 - acc: 0.7303 - val_loss: 0.6355 - val_acc: 0.7984\n",
      "Epoch 764/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7518 - acc: 0.7336 - val_loss: 0.6372 - val_acc: 0.7976\n",
      "Epoch 765/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7463 - acc: 0.7362 - val_loss: 0.6360 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00765: loss improved from inf to 0.74633, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-0-000765-0.746334-0.798363.hdf5\n",
      "Epoch 766/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7378 - acc: 0.7433 - val_loss: 0.6377 - val_acc: 0.7976\n",
      "Epoch 767/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7389 - acc: 0.7385 - val_loss: 0.6384 - val_acc: 0.7969\n",
      "Epoch 768/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7436 - acc: 0.7381 - val_loss: 0.6375 - val_acc: 0.7976\n",
      "Epoch 769/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7388 - acc: 0.7459 - val_loss: 0.6331 - val_acc: 0.7991\n",
      "\n",
      "Epoch 00769: loss improved from 0.74633 to 0.73876, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-0-000769-0.738763-0.799107.hdf5\n",
      "Epoch 770/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7357 - acc: 0.7433 - val_loss: 0.6341 - val_acc: 0.7976\n",
      "Epoch 771/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7473 - acc: 0.7463 - val_loss: 0.6369 - val_acc: 0.7976\n",
      "Epoch 772/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7366 - acc: 0.7496 - val_loss: 0.6378 - val_acc: 0.7976\n",
      "Epoch 773/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7363 - acc: 0.7411 - val_loss: 0.6368 - val_acc: 0.7976\n",
      "\n",
      "Epoch 00773: loss improved from 0.73876 to 0.73626, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-0-000773-0.736262-0.797619.hdf5\n",
      "Epoch 774/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7283 - acc: 0.7496 - val_loss: 0.6373 - val_acc: 0.7969\n",
      "Epoch 775/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7396 - acc: 0.7351 - val_loss: 0.6383 - val_acc: 0.7969\n",
      "Epoch 776/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7535 - acc: 0.7314 - val_loss: 0.6392 - val_acc: 0.7969\n",
      "Epoch 777/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7241 - acc: 0.7474 - val_loss: 0.6370 - val_acc: 0.7976\n",
      "\n",
      "Epoch 00777: loss improved from 0.73626 to 0.72407, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-0-000777-0.724065-0.797619.hdf5\n",
      "Epoch 778/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7477 - acc: 0.7381 - val_loss: 0.6358 - val_acc: 0.7984\n",
      "Epoch 779/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7445 - acc: 0.7448 - val_loss: 0.6378 - val_acc: 0.7976\n",
      "Epoch 780/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7456 - acc: 0.7359 - val_loss: 0.6376 - val_acc: 0.7976\n",
      "Epoch 781/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7428 - acc: 0.7359 - val_loss: 0.6349 - val_acc: 0.7984\n",
      "Epoch 782/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7534 - acc: 0.7414 - val_loss: 0.6345 - val_acc: 0.7984\n",
      "Epoch 783/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7530 - acc: 0.7414 - val_loss: 0.6361 - val_acc: 0.7984\n",
      "Epoch 784/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7432 - acc: 0.7381 - val_loss: 0.6364 - val_acc: 0.7984\n",
      "Epoch 785/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7429 - acc: 0.7429 - val_loss: 0.6385 - val_acc: 0.7969\n",
      "Epoch 786/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7393 - acc: 0.7388 - val_loss: 0.6388 - val_acc: 0.7969\n",
      "Epoch 787/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7370 - acc: 0.7340 - val_loss: 0.6365 - val_acc: 0.7969\n",
      "Epoch 788/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7442 - acc: 0.7381 - val_loss: 0.6376 - val_acc: 0.7976\n",
      "Epoch 789/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7507 - acc: 0.7295 - val_loss: 0.6368 - val_acc: 0.7976\n",
      "Epoch 790/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7273 - acc: 0.7448 - val_loss: 0.6388 - val_acc: 0.7961\n",
      "Epoch 791/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7377 - acc: 0.7411 - val_loss: 0.6349 - val_acc: 0.7976\n",
      "Epoch 792/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7300 - acc: 0.7374 - val_loss: 0.6369 - val_acc: 0.7969\n",
      "Epoch 793/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7440 - acc: 0.7370 - val_loss: 0.6379 - val_acc: 0.7969\n",
      "Epoch 794/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7422 - acc: 0.7407 - val_loss: 0.6370 - val_acc: 0.7976\n",
      "Epoch 795/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7479 - acc: 0.7355 - val_loss: 0.6379 - val_acc: 0.7961\n",
      "Epoch 796/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7504 - acc: 0.7362 - val_loss: 0.6373 - val_acc: 0.7969\n",
      "Epoch 797/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7310 - acc: 0.7485 - val_loss: 0.6375 - val_acc: 0.7969\n",
      "Epoch 798/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7326 - acc: 0.7414 - val_loss: 0.6385 - val_acc: 0.7961\n",
      "Epoch 799/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7487 - acc: 0.7359 - val_loss: 0.6370 - val_acc: 0.7969\n",
      "Epoch 800/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7256 - acc: 0.7459 - val_loss: 0.6360 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00800: saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/0-000800-0.725564-0.798363.hdf5\n",
      "Epoch 801/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7366 - acc: 0.7418 - val_loss: 0.6387 - val_acc: 0.7969\n",
      "Epoch 802/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7267 - acc: 0.7548 - val_loss: 0.6363 - val_acc: 0.7984\n",
      "Epoch 803/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7264 - acc: 0.7429 - val_loss: 0.6389 - val_acc: 0.7969\n",
      "Epoch 804/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7234 - acc: 0.7437 - val_loss: 0.6378 - val_acc: 0.7976\n",
      "Epoch 805/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7414 - acc: 0.7422 - val_loss: 0.6377 - val_acc: 0.7969\n",
      "Epoch 806/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7453 - acc: 0.7366 - val_loss: 0.6382 - val_acc: 0.7961\n",
      "Epoch 807/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7482 - acc: 0.7422 - val_loss: 0.6390 - val_acc: 0.7961\n",
      "Epoch 808/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7606 - acc: 0.7440 - val_loss: 0.6387 - val_acc: 0.7969\n",
      "Epoch 809/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7314 - acc: 0.7552 - val_loss: 0.6355 - val_acc: 0.7984\n",
      "Epoch 810/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7385 - acc: 0.7463 - val_loss: 0.6373 - val_acc: 0.7961\n",
      "Epoch 811/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7368 - acc: 0.7318 - val_loss: 0.6365 - val_acc: 0.7969\n",
      "Epoch 812/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7455 - acc: 0.7392 - val_loss: 0.6357 - val_acc: 0.7976\n",
      "Epoch 813/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7443 - acc: 0.7414 - val_loss: 0.6358 - val_acc: 0.7976\n",
      "Epoch 814/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7530 - acc: 0.7381 - val_loss: 0.6373 - val_acc: 0.7976\n",
      "Epoch 815/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7372 - acc: 0.7459 - val_loss: 0.6382 - val_acc: 0.7969\n",
      "Epoch 816/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7436 - acc: 0.7437 - val_loss: 0.6349 - val_acc: 0.7976\n",
      "Epoch 817/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7390 - acc: 0.7418 - val_loss: 0.6364 - val_acc: 0.7976\n",
      "Epoch 818/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7605 - acc: 0.7385 - val_loss: 0.6372 - val_acc: 0.7969\n",
      "Epoch 819/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7483 - acc: 0.7444 - val_loss: 0.6365 - val_acc: 0.7969\n",
      "Epoch 820/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7278 - acc: 0.7448 - val_loss: 0.6380 - val_acc: 0.7961\n",
      "Epoch 821/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7435 - acc: 0.7403 - val_loss: 0.6350 - val_acc: 0.7976\n",
      "Epoch 822/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7371 - acc: 0.7400 - val_loss: 0.6385 - val_acc: 0.7961\n",
      "Epoch 823/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7494 - acc: 0.7325 - val_loss: 0.6374 - val_acc: 0.7969\n",
      "Epoch 824/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7360 - acc: 0.7470 - val_loss: 0.6373 - val_acc: 0.7961\n",
      "Epoch 825/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7313 - acc: 0.7414 - val_loss: 0.6373 - val_acc: 0.7976\n",
      "Epoch 826/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7398 - acc: 0.7374 - val_loss: 0.6344 - val_acc: 0.7976\n",
      "Epoch 827/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7232 - acc: 0.7467 - val_loss: 0.6375 - val_acc: 0.7969\n",
      "Epoch 828/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7456 - acc: 0.7418 - val_loss: 0.6367 - val_acc: 0.7969\n",
      "Epoch 829/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7504 - acc: 0.7400 - val_loss: 0.6361 - val_acc: 0.7969\n",
      "Epoch 830/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7336 - acc: 0.7414 - val_loss: 0.6373 - val_acc: 0.7969\n",
      "Epoch 831/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7427 - acc: 0.7351 - val_loss: 0.6382 - val_acc: 0.7969\n",
      "Epoch 832/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7548 - acc: 0.7333 - val_loss: 0.6352 - val_acc: 0.7969\n",
      "Epoch 833/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7372 - acc: 0.7426 - val_loss: 0.6382 - val_acc: 0.7961\n",
      "Epoch 834/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7408 - acc: 0.7396 - val_loss: 0.6369 - val_acc: 0.7984\n",
      "Epoch 835/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7427 - acc: 0.7381 - val_loss: 0.6388 - val_acc: 0.7961\n",
      "Epoch 836/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7400 - acc: 0.7448 - val_loss: 0.6383 - val_acc: 0.7961\n",
      "Epoch 837/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7303 - acc: 0.7507 - val_loss: 0.6382 - val_acc: 0.7961\n",
      "Epoch 838/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7439 - acc: 0.7440 - val_loss: 0.6338 - val_acc: 0.7984\n",
      "Epoch 839/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7377 - acc: 0.7396 - val_loss: 0.6367 - val_acc: 0.7976\n",
      "Epoch 840/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7380 - acc: 0.7426 - val_loss: 0.6386 - val_acc: 0.7961\n",
      "Epoch 841/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.7509 - acc: 0.7355 - val_loss: 0.6322 - val_acc: 0.7984\n",
      "Epoch 842/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7441 - acc: 0.7359 - val_loss: 0.6296 - val_acc: 0.7969\n",
      "Epoch 843/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7307 - acc: 0.7470 - val_loss: 0.6378 - val_acc: 0.7961\n",
      "Epoch 844/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7238 - acc: 0.7388 - val_loss: 0.6359 - val_acc: 0.7969\n",
      "Epoch 845/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7411 - acc: 0.7429 - val_loss: 0.6375 - val_acc: 0.7969\n",
      "Epoch 846/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7448 - acc: 0.7400 - val_loss: 0.6316 - val_acc: 0.7969\n",
      "Epoch 847/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7462 - acc: 0.7381 - val_loss: 0.6382 - val_acc: 0.7961\n",
      "Epoch 848/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7433 - acc: 0.7366 - val_loss: 0.6384 - val_acc: 0.7961\n",
      "Epoch 849/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7386 - acc: 0.7418 - val_loss: 0.6360 - val_acc: 0.7976\n",
      "Epoch 850/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7557 - acc: 0.7422 - val_loss: 0.6374 - val_acc: 0.7969\n",
      "Epoch 851/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7367 - acc: 0.7429 - val_loss: 0.6372 - val_acc: 0.7969\n",
      "Epoch 852/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7578 - acc: 0.7403 - val_loss: 0.6366 - val_acc: 0.7976\n",
      "Epoch 853/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7389 - acc: 0.7519 - val_loss: 0.6381 - val_acc: 0.7969\n",
      "Epoch 854/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7382 - acc: 0.7370 - val_loss: 0.6386 - val_acc: 0.7961\n",
      "Epoch 855/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7376 - acc: 0.7429 - val_loss: 0.6377 - val_acc: 0.7969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7494 - acc: 0.7344 - val_loss: 0.6353 - val_acc: 0.7976\n",
      "Epoch 857/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7412 - acc: 0.7437 - val_loss: 0.6366 - val_acc: 0.7969\n",
      "Epoch 858/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7442 - acc: 0.7277 - val_loss: 0.6378 - val_acc: 0.7969\n",
      "Epoch 859/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7453 - acc: 0.7388 - val_loss: 0.6363 - val_acc: 0.7969\n",
      "Epoch 860/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7276 - acc: 0.7381 - val_loss: 0.6391 - val_acc: 0.7961\n",
      "Epoch 861/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7399 - acc: 0.7500 - val_loss: 0.6378 - val_acc: 0.7969\n",
      "Epoch 862/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7290 - acc: 0.7493 - val_loss: 0.6337 - val_acc: 0.7969\n",
      "Epoch 863/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7326 - acc: 0.7478 - val_loss: 0.6381 - val_acc: 0.7961\n",
      "Epoch 864/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7330 - acc: 0.7429 - val_loss: 0.6346 - val_acc: 0.7976\n",
      "Epoch 865/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7252 - acc: 0.7504 - val_loss: 0.6373 - val_acc: 0.7969\n",
      "\n",
      "Epoch 00865: loss improved from inf to 0.72519, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-0-000865-0.725195-0.796875.hdf5\n",
      "Epoch 866/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7347 - acc: 0.7370 - val_loss: 0.6352 - val_acc: 0.7976\n",
      "Epoch 867/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7245 - acc: 0.7507 - val_loss: 0.6375 - val_acc: 0.7969\n",
      "Epoch 868/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7348 - acc: 0.7400 - val_loss: 0.6389 - val_acc: 0.7961\n",
      "Epoch 869/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7251 - acc: 0.7511 - val_loss: 0.6331 - val_acc: 0.7976\n",
      "\n",
      "Epoch 00869: loss improved from 0.72519 to 0.72515, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-0-000869-0.725147-0.797619.hdf5\n",
      "Epoch 870/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7423 - acc: 0.7400 - val_loss: 0.6368 - val_acc: 0.7969\n",
      "Epoch 871/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7455 - acc: 0.7374 - val_loss: 0.6374 - val_acc: 0.7969\n",
      "Epoch 872/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7516 - acc: 0.7414 - val_loss: 0.6375 - val_acc: 0.7969\n",
      "Epoch 873/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7458 - acc: 0.7429 - val_loss: 0.6366 - val_acc: 0.7969\n",
      "Epoch 874/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7364 - acc: 0.7429 - val_loss: 0.6372 - val_acc: 0.7969\n",
      "Epoch 875/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7389 - acc: 0.7493 - val_loss: 0.6364 - val_acc: 0.7969\n",
      "Epoch 876/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7324 - acc: 0.7452 - val_loss: 0.6375 - val_acc: 0.7969\n",
      "Epoch 877/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7304 - acc: 0.7448 - val_loss: 0.6361 - val_acc: 0.7976\n",
      "Epoch 878/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7434 - acc: 0.7440 - val_loss: 0.6378 - val_acc: 0.7969\n",
      "Epoch 879/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7370 - acc: 0.7429 - val_loss: 0.6377 - val_acc: 0.7969\n",
      "Epoch 880/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7283 - acc: 0.7533 - val_loss: 0.6358 - val_acc: 0.7976\n",
      "Epoch 881/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7346 - acc: 0.7374 - val_loss: 0.6369 - val_acc: 0.7969\n",
      "Epoch 882/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7385 - acc: 0.7481 - val_loss: 0.6384 - val_acc: 0.7961\n",
      "Epoch 883/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7366 - acc: 0.7400 - val_loss: 0.6354 - val_acc: 0.7976\n",
      "Epoch 884/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7324 - acc: 0.7463 - val_loss: 0.6363 - val_acc: 0.7976\n",
      "Epoch 885/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7345 - acc: 0.7478 - val_loss: 0.6364 - val_acc: 0.7976\n",
      "Epoch 886/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7427 - acc: 0.7418 - val_loss: 0.6379 - val_acc: 0.7961\n",
      "Epoch 887/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7417 - acc: 0.7444 - val_loss: 0.6379 - val_acc: 0.7969\n",
      "Epoch 888/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7383 - acc: 0.7440 - val_loss: 0.6379 - val_acc: 0.7969\n",
      "Epoch 889/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7525 - acc: 0.7385 - val_loss: 0.6376 - val_acc: 0.7961\n",
      "Epoch 890/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7432 - acc: 0.7414 - val_loss: 0.6382 - val_acc: 0.7961\n",
      "Epoch 891/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7574 - acc: 0.7314 - val_loss: 0.6356 - val_acc: 0.7976\n",
      "Epoch 892/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7445 - acc: 0.7407 - val_loss: 0.6366 - val_acc: 0.7976\n",
      "Epoch 893/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7281 - acc: 0.7496 - val_loss: 0.6377 - val_acc: 0.7961\n",
      "Epoch 894/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7517 - acc: 0.7403 - val_loss: 0.6373 - val_acc: 0.7969\n",
      "Epoch 895/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7399 - acc: 0.7459 - val_loss: 0.6385 - val_acc: 0.7961\n",
      "Epoch 896/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7515 - acc: 0.7411 - val_loss: 0.6342 - val_acc: 0.7976\n",
      "Epoch 897/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7429 - acc: 0.7437 - val_loss: 0.6384 - val_acc: 0.7961\n",
      "Epoch 898/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7354 - acc: 0.7403 - val_loss: 0.6381 - val_acc: 0.7961\n",
      "Epoch 899/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7461 - acc: 0.7403 - val_loss: 0.6381 - val_acc: 0.7961\n",
      "Epoch 900/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7317 - acc: 0.7463 - val_loss: 0.6359 - val_acc: 0.7969\n",
      "\n",
      "Epoch 00900: saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/0-000900-0.731722-0.796875.hdf5\n",
      "Epoch 901/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7420 - acc: 0.7377 - val_loss: 0.6375 - val_acc: 0.7961\n",
      "Epoch 902/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7250 - acc: 0.7571 - val_loss: 0.6375 - val_acc: 0.7969\n",
      "Epoch 903/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7505 - acc: 0.7481 - val_loss: 0.6377 - val_acc: 0.7969\n",
      "Epoch 904/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7474 - acc: 0.7388 - val_loss: 0.6383 - val_acc: 0.7961\n",
      "Epoch 905/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7389 - acc: 0.7437 - val_loss: 0.6375 - val_acc: 0.7969\n",
      "Epoch 906/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7490 - acc: 0.7318 - val_loss: 0.6360 - val_acc: 0.7976\n",
      "Epoch 907/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7572 - acc: 0.7396 - val_loss: 0.6376 - val_acc: 0.7969\n",
      "Epoch 908/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7340 - acc: 0.7478 - val_loss: 0.6367 - val_acc: 0.7976\n",
      "Epoch 909/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7412 - acc: 0.7407 - val_loss: 0.6350 - val_acc: 0.7984\n",
      "Epoch 910/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7369 - acc: 0.7411 - val_loss: 0.6371 - val_acc: 0.7976\n",
      "Epoch 911/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7500 - acc: 0.7396 - val_loss: 0.6379 - val_acc: 0.7961\n",
      "Epoch 912/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7278 - acc: 0.7481 - val_loss: 0.6384 - val_acc: 0.7961\n",
      "Epoch 913/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7507 - acc: 0.7295 - val_loss: 0.6348 - val_acc: 0.7976\n",
      "Epoch 914/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7467 - acc: 0.7426 - val_loss: 0.6355 - val_acc: 0.7969\n",
      "Epoch 915/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7415 - acc: 0.7481 - val_loss: 0.6321 - val_acc: 0.7984\n",
      "Epoch 916/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7384 - acc: 0.7396 - val_loss: 0.6372 - val_acc: 0.7961\n",
      "Epoch 917/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.7406 - acc: 0.7411 - val_loss: 0.6363 - val_acc: 0.7969\n",
      "Epoch 918/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7463 - acc: 0.7426 - val_loss: 0.6361 - val_acc: 0.7976\n",
      "Epoch 919/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7444 - acc: 0.7307 - val_loss: 0.6361 - val_acc: 0.7969\n",
      "Epoch 920/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7423 - acc: 0.7388 - val_loss: 0.6376 - val_acc: 0.7969\n",
      "Epoch 921/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7373 - acc: 0.7437 - val_loss: 0.6378 - val_acc: 0.7969\n",
      "Epoch 00921: early stopping\n",
      "ModelCheckpoint 已经保存到 ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/0-final.hdf5\n",
      "Create subdir directory: ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/log...\n",
      "save in: ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/log/20220201_2000_64_1_3_1.csv\n",
      "time: 0:24:02 s\n",
      "time: 1442.0 s\n",
      "average 1.442000 s\n",
      "0 epoch finished\n",
      "--------------------   best   --------------------\n",
      "no_activities: 10\n",
      "\n",
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1349/1349 [==============================] - 2s 2ms/step\n",
      "0-milan:\tacc: 79.76%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 4, 0, 0, 4, 0, 0, 0, 0, 4, 0, 4, 0, 0, 7, 0, 0, 0, 0, 0, 7, 2, 2, 2, 2, 2, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 0, 9, 9, 9, 0, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 7, 9, 9, 9, 9, 7, 9, 0, 9, 9, 9, 0, 9, 9, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 0, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 0, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 0, 7, 7, 7, 0, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 0, 7, 7, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 0, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 9, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 7, 0, 0, 0, 7, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 7, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 7, 0, 0, 9, 9, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 5, 4, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 7, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 7, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 4, 4, 0, 4, 4, 4, 4, 0, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 0, 0, 4, 4, 0, 0, 4, 4, 0, 0, 4, 0, 4, 4, 0, 4, 0, 4, 4, 0, 7, 4, 4, 4, 0, 0, 4, 0, 4, 4, 0, 4, 0, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 0, 0, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 9, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.775068  0.918138  0.840558       623\n",
      "         Work   0.000000  0.000000  0.000000        26\n",
      "Take_medicine   1.000000  0.950000  0.974359        20\n",
      "        Sleep   0.000000  0.000000  0.000000        32\n",
      "        Relax   0.793814  0.538462  0.641667       143\n",
      "   Leave_Home   0.888889  0.901408  0.895105        71\n",
      "          Eat   0.000000  0.000000  0.000000         7\n",
      "         Cook   0.837563  0.891892  0.863874       185\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        30\n",
      "      Bathing   0.792035  0.844340  0.817352       212\n",
      "\n",
      "     accuracy                       0.797628      1349\n",
      "    macro avg   0.508737  0.504424  0.503291      1349\n",
      " weighted avg   0.743035  0.797628  0.764686      1349\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  30   0   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0  19   6   0]\n",
      " [  0   0   0   0   0   2   0   5   0   0]\n",
      " [  0   0   0  19   1   0   0   0   0   0]\n",
      " [  0   0   0   0 179   2   0  31   0   0]\n",
      " [  0   0   0   0   1 165   1  17   1   0]\n",
      " [  0   0   0   0   0   1  64   4   2   0]\n",
      " [  0   0   0   0   9  24   7 572  11   0]\n",
      " [  0   0   0   0   0   2   0  64  77   0]\n",
      " [  0   0   0   0   6   0   0  26   0   0]]\n",
      "--------------------   final   --------------------\n",
      "no_activities: 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1349/1349 [==============================] - 2s 2ms/step\n",
      "0-milan:\tacc: 79.69%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 4, 0, 0, 4, 0, 0, 0, 0, 4, 0, 4, 0, 0, 7, 0, 0, 0, 0, 0, 7, 2, 2, 2, 2, 2, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 0, 9, 9, 9, 0, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 7, 9, 9, 9, 9, 7, 9, 0, 9, 9, 9, 0, 9, 9, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 0, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 0, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 0, 7, 7, 7, 0, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 0, 7, 7, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 0, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 9, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 7, 0, 0, 0, 7, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 7, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 7, 0, 0, 9, 9, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 5, 4, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 7, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 7, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 4, 4, 0, 4, 4, 4, 4, 0, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 0, 0, 4, 4, 0, 0, 4, 4, 0, 0, 4, 0, 4, 4, 0, 4, 0, 4, 4, 0, 7, 4, 4, 4, 0, 0, 4, 0, 4, 4, 0, 4, 0, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 0, 0, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 9, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.774019  0.918138  0.839941       623\n",
      "         Work   0.000000  0.000000  0.000000        26\n",
      "Take_medicine   1.000000  0.950000  0.974359        20\n",
      "        Sleep   0.000000  0.000000  0.000000        32\n",
      "        Relax   0.793814  0.538462  0.641667       143\n",
      "   Leave_Home   0.888889  0.901408  0.895105        71\n",
      "          Eat   0.000000  0.000000  0.000000         7\n",
      "         Cook   0.837563  0.891892  0.863874       185\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        30\n",
      "      Bathing   0.791111  0.839623  0.814645       212\n",
      "\n",
      "     accuracy                       0.796887      1349\n",
      "    macro avg   0.508540  0.503952  0.502959      1349\n",
      " weighted avg   0.742406  0.796887  0.763975      1349\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  30   0   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0  19   6   0]\n",
      " [  0   0   0   0   0   2   0   5   0   0]\n",
      " [  0   0   0  19   1   0   0   0   0   0]\n",
      " [  0   0   0   0 178   2   0  32   0   0]\n",
      " [  0   0   0   0   1 165   1  17   1   0]\n",
      " [  0   0   0   0   0   1  64   4   2   0]\n",
      " [  0   0   0   0   9  24   7 572  11   0]\n",
      " [  0   0   0   0   0   2   0  64  77   0]\n",
      " [  0   0   0   0   6   0   0  26   0   0]]\n",
      "no_activities: 10\n",
      "\n",
      "Begin training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "42/42 [==============================] - 4s 104ms/step - loss: 1.8529 - acc: 0.4096 - val_loss: 1.3870 - val_acc: 0.5394\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.3235 - acc: 0.5703 - val_loss: 1.0990 - val_acc: 0.6369\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.1923 - acc: 0.6101 - val_loss: 0.9984 - val_acc: 0.7024\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.1094 - acc: 0.6369 - val_loss: 0.9480 - val_acc: 0.7076\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.0616 - acc: 0.6592 - val_loss: 0.8997 - val_acc: 0.7366\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.0348 - acc: 0.6823 - val_loss: 0.8754 - val_acc: 0.7426\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9811 - acc: 0.6987 - val_loss: 0.8496 - val_acc: 0.7507\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.9650 - acc: 0.6990 - val_loss: 0.8228 - val_acc: 0.7493\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9557 - acc: 0.6912 - val_loss: 0.8153 - val_acc: 0.7597\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9324 - acc: 0.7191 - val_loss: 0.8023 - val_acc: 0.7455\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8997 - acc: 0.7228 - val_loss: 0.7900 - val_acc: 0.7537\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9105 - acc: 0.7121 - val_loss: 0.7754 - val_acc: 0.7634\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.9064 - acc: 0.7083 - val_loss: 0.7738 - val_acc: 0.7641\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8893 - acc: 0.7173 - val_loss: 0.7648 - val_acc: 0.7597\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8889 - acc: 0.7158 - val_loss: 0.7619 - val_acc: 0.7626\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8825 - acc: 0.7176 - val_loss: 0.7549 - val_acc: 0.7664\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.8742 - acc: 0.7173 - val_loss: 0.7496 - val_acc: 0.7656\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.8772 - acc: 0.7143 - val_loss: 0.7449 - val_acc: 0.7634\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8720 - acc: 0.7176 - val_loss: 0.7396 - val_acc: 0.7560\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8576 - acc: 0.7277 - val_loss: 0.7357 - val_acc: 0.7574\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8410 - acc: 0.7318 - val_loss: 0.7353 - val_acc: 0.7530\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8495 - acc: 0.7176 - val_loss: 0.7297 - val_acc: 0.7597\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.8512 - acc: 0.7165 - val_loss: 0.7298 - val_acc: 0.7574\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8407 - acc: 0.7221 - val_loss: 0.7233 - val_acc: 0.7626\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8325 - acc: 0.7299 - val_loss: 0.7251 - val_acc: 0.7589\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8267 - acc: 0.7269 - val_loss: 0.7205 - val_acc: 0.7567\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8113 - acc: 0.7347 - val_loss: 0.7160 - val_acc: 0.7649\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8338 - acc: 0.7277 - val_loss: 0.7121 - val_acc: 0.7560\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8224 - acc: 0.7307 - val_loss: 0.7086 - val_acc: 0.7589\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8279 - acc: 0.7359 - val_loss: 0.7124 - val_acc: 0.7522\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8043 - acc: 0.7411 - val_loss: 0.7096 - val_acc: 0.7515\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8228 - acc: 0.7202 - val_loss: 0.7064 - val_acc: 0.7552\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8071 - acc: 0.7303 - val_loss: 0.7057 - val_acc: 0.7619\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.8136 - acc: 0.7314 - val_loss: 0.7027 - val_acc: 0.7567\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8111 - acc: 0.7269 - val_loss: 0.7031 - val_acc: 0.7574\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8046 - acc: 0.7273 - val_loss: 0.6996 - val_acc: 0.7560\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8273 - acc: 0.7325 - val_loss: 0.6949 - val_acc: 0.7641\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7968 - acc: 0.7329 - val_loss: 0.6971 - val_acc: 0.7634\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7984 - acc: 0.7266 - val_loss: 0.6911 - val_acc: 0.7626\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7890 - acc: 0.7422 - val_loss: 0.6906 - val_acc: 0.7626\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8102 - acc: 0.7247 - val_loss: 0.6911 - val_acc: 0.7574\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8114 - acc: 0.7225 - val_loss: 0.6884 - val_acc: 0.7604\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7724 - acc: 0.7400 - val_loss: 0.6899 - val_acc: 0.7574\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7954 - acc: 0.7374 - val_loss: 0.6892 - val_acc: 0.7552\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7952 - acc: 0.7281 - val_loss: 0.6840 - val_acc: 0.7619\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7812 - acc: 0.7392 - val_loss: 0.6848 - val_acc: 0.7560\n",
      "Epoch 47/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7810 - acc: 0.7359 - val_loss: 0.6838 - val_acc: 0.7612\n",
      "Epoch 48/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7760 - acc: 0.7318 - val_loss: 0.6791 - val_acc: 0.7597\n",
      "Epoch 49/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7940 - acc: 0.7303 - val_loss: 0.6819 - val_acc: 0.7619\n",
      "Epoch 50/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7751 - acc: 0.7444 - val_loss: 0.6819 - val_acc: 0.7545\n",
      "Epoch 51/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7858 - acc: 0.7388 - val_loss: 0.6813 - val_acc: 0.7589\n",
      "Epoch 52/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7930 - acc: 0.7307 - val_loss: 0.6820 - val_acc: 0.7567\n",
      "Epoch 53/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7689 - acc: 0.7374 - val_loss: 0.6795 - val_acc: 0.7582\n",
      "Epoch 54/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7896 - acc: 0.7359 - val_loss: 0.6757 - val_acc: 0.7649\n",
      "Epoch 55/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7687 - acc: 0.7414 - val_loss: 0.6788 - val_acc: 0.7574\n",
      "Epoch 56/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7984 - acc: 0.7325 - val_loss: 0.6773 - val_acc: 0.7589\n",
      "Epoch 57/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7671 - acc: 0.7340 - val_loss: 0.6759 - val_acc: 0.7589\n",
      "Epoch 58/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7836 - acc: 0.7303 - val_loss: 0.6746 - val_acc: 0.7582\n",
      "Epoch 59/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7664 - acc: 0.7366 - val_loss: 0.6728 - val_acc: 0.7604\n",
      "Epoch 60/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7657 - acc: 0.7355 - val_loss: 0.6706 - val_acc: 0.7619\n",
      "Epoch 61/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7593 - acc: 0.7493 - val_loss: 0.6698 - val_acc: 0.7589\n",
      "Epoch 62/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7727 - acc: 0.7288 - val_loss: 0.6633 - val_acc: 0.7604\n",
      "Epoch 63/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7807 - acc: 0.7366 - val_loss: 0.6718 - val_acc: 0.7589\n",
      "Epoch 64/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7676 - acc: 0.7388 - val_loss: 0.6713 - val_acc: 0.7604\n",
      "Epoch 65/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7761 - acc: 0.7388 - val_loss: 0.6716 - val_acc: 0.7612\n",
      "\n",
      "Epoch 00065: loss improved from inf to 0.77612, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-1-000065-0.776124-0.761161.hdf5\n",
      "Epoch 66/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7663 - acc: 0.7344 - val_loss: 0.6673 - val_acc: 0.7664\n",
      "Epoch 67/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7722 - acc: 0.7340 - val_loss: 0.6652 - val_acc: 0.7619\n",
      "Epoch 68/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7504 - acc: 0.7493 - val_loss: 0.6688 - val_acc: 0.7582\n",
      "Epoch 69/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7821 - acc: 0.7362 - val_loss: 0.6685 - val_acc: 0.7589\n",
      "Epoch 70/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7669 - acc: 0.7385 - val_loss: 0.6656 - val_acc: 0.7619\n",
      "Epoch 71/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7619 - acc: 0.7362 - val_loss: 0.6668 - val_acc: 0.7664\n",
      "Epoch 72/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7490 - acc: 0.7455 - val_loss: 0.6633 - val_acc: 0.7626\n",
      "Epoch 73/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7524 - acc: 0.7478 - val_loss: 0.6622 - val_acc: 0.7582\n",
      "\n",
      "Epoch 00073: loss improved from 0.77612 to 0.75242, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-1-000073-0.752420-0.758185.hdf5\n",
      "Epoch 74/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7604 - acc: 0.7374 - val_loss: 0.6647 - val_acc: 0.7626\n",
      "Epoch 75/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7568 - acc: 0.7340 - val_loss: 0.6631 - val_acc: 0.7626\n",
      "Epoch 76/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7487 - acc: 0.7429 - val_loss: 0.6636 - val_acc: 0.7597\n",
      "Epoch 77/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7583 - acc: 0.7481 - val_loss: 0.6598 - val_acc: 0.7619\n",
      "Epoch 78/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7451 - acc: 0.7437 - val_loss: 0.6607 - val_acc: 0.7582\n",
      "Epoch 79/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7480 - acc: 0.7444 - val_loss: 0.6631 - val_acc: 0.7567\n",
      "Epoch 80/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7607 - acc: 0.7452 - val_loss: 0.6608 - val_acc: 0.7597\n",
      "Epoch 81/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7352 - acc: 0.7429 - val_loss: 0.6585 - val_acc: 0.7604\n",
      "\n",
      "Epoch 00081: loss improved from 0.75242 to 0.73516, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-1-000081-0.735159-0.760417.hdf5\n",
      "Epoch 82/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7470 - acc: 0.7388 - val_loss: 0.6592 - val_acc: 0.7574\n",
      "Epoch 83/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7475 - acc: 0.7470 - val_loss: 0.6594 - val_acc: 0.7612\n",
      "Epoch 84/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7616 - acc: 0.7426 - val_loss: 0.6602 - val_acc: 0.7597\n",
      "Epoch 85/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7438 - acc: 0.7429 - val_loss: 0.6580 - val_acc: 0.7604\n",
      "Epoch 86/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7528 - acc: 0.7526 - val_loss: 0.6535 - val_acc: 0.7589\n",
      "Epoch 87/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7452 - acc: 0.7511 - val_loss: 0.6608 - val_acc: 0.7582\n",
      "Epoch 88/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7432 - acc: 0.7526 - val_loss: 0.6594 - val_acc: 0.7589\n",
      "Epoch 89/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7558 - acc: 0.7418 - val_loss: 0.6557 - val_acc: 0.7589\n",
      "Epoch 90/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7468 - acc: 0.7437 - val_loss: 0.6556 - val_acc: 0.7649\n",
      "Epoch 91/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7499 - acc: 0.7385 - val_loss: 0.6576 - val_acc: 0.7574\n",
      "Epoch 92/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7409 - acc: 0.7522 - val_loss: 0.6573 - val_acc: 0.7582\n",
      "Epoch 93/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7534 - acc: 0.7418 - val_loss: 0.6575 - val_acc: 0.7560\n",
      "Epoch 94/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7373 - acc: 0.7556 - val_loss: 0.6527 - val_acc: 0.7619\n",
      "Epoch 95/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7394 - acc: 0.7426 - val_loss: 0.6572 - val_acc: 0.7597\n",
      "Epoch 96/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7414 - acc: 0.7515 - val_loss: 0.6574 - val_acc: 0.7589\n",
      "Epoch 97/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7478 - acc: 0.7437 - val_loss: 0.6573 - val_acc: 0.7597\n",
      "Epoch 98/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7488 - acc: 0.7433 - val_loss: 0.6569 - val_acc: 0.7574\n",
      "Epoch 99/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7315 - acc: 0.7522 - val_loss: 0.6548 - val_acc: 0.7582\n",
      "Epoch 100/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7474 - acc: 0.7467 - val_loss: 0.6527 - val_acc: 0.7589\n",
      "\n",
      "Epoch 00100: saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/1-000100-0.747393-0.758929.hdf5\n",
      "Epoch 101/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7334 - acc: 0.7478 - val_loss: 0.6534 - val_acc: 0.7612\n",
      "Epoch 102/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7293 - acc: 0.7507 - val_loss: 0.6532 - val_acc: 0.7597\n",
      "Epoch 103/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7284 - acc: 0.7567 - val_loss: 0.6532 - val_acc: 0.7597\n",
      "Epoch 104/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7271 - acc: 0.7545 - val_loss: 0.6527 - val_acc: 0.7612\n",
      "Epoch 105/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7437 - acc: 0.7526 - val_loss: 0.6537 - val_acc: 0.7597\n",
      "Epoch 106/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7305 - acc: 0.7530 - val_loss: 0.6517 - val_acc: 0.7582\n",
      "Epoch 107/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7276 - acc: 0.7556 - val_loss: 0.6482 - val_acc: 0.7597\n",
      "Epoch 108/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7177 - acc: 0.7578 - val_loss: 0.6525 - val_acc: 0.7619\n",
      "Epoch 109/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7161 - acc: 0.7623 - val_loss: 0.6516 - val_acc: 0.7612\n",
      "Epoch 110/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7228 - acc: 0.7634 - val_loss: 0.6514 - val_acc: 0.7634\n",
      "Epoch 111/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7373 - acc: 0.7507 - val_loss: 0.6517 - val_acc: 0.7664\n",
      "Epoch 112/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7121 - acc: 0.7638 - val_loss: 0.6512 - val_acc: 0.7679\n",
      "Epoch 113/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7401 - acc: 0.7541 - val_loss: 0.6518 - val_acc: 0.7679\n",
      "Epoch 114/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7225 - acc: 0.7467 - val_loss: 0.6518 - val_acc: 0.7701\n",
      "Epoch 115/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7337 - acc: 0.7511 - val_loss: 0.6511 - val_acc: 0.7671\n",
      "Epoch 116/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7289 - acc: 0.7548 - val_loss: 0.6500 - val_acc: 0.7701\n",
      "Epoch 117/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7296 - acc: 0.7552 - val_loss: 0.6505 - val_acc: 0.7671\n",
      "Epoch 118/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7271 - acc: 0.7545 - val_loss: 0.6493 - val_acc: 0.7679\n",
      "Epoch 119/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7196 - acc: 0.7511 - val_loss: 0.6494 - val_acc: 0.7649\n",
      "Epoch 120/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7230 - acc: 0.7578 - val_loss: 0.6408 - val_acc: 0.7693\n",
      "Epoch 121/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7227 - acc: 0.7537 - val_loss: 0.6469 - val_acc: 0.7679\n",
      "Epoch 122/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7160 - acc: 0.7600 - val_loss: 0.6454 - val_acc: 0.7679\n",
      "Epoch 123/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7412 - acc: 0.7496 - val_loss: 0.6482 - val_acc: 0.7701\n",
      "Epoch 124/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7298 - acc: 0.7511 - val_loss: 0.6460 - val_acc: 0.7679\n",
      "Epoch 125/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7188 - acc: 0.7530 - val_loss: 0.6427 - val_acc: 0.7671\n",
      "Epoch 126/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7094 - acc: 0.7574 - val_loss: 0.6462 - val_acc: 0.7708\n",
      "Epoch 127/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7208 - acc: 0.7515 - val_loss: 0.6433 - val_acc: 0.7693\n",
      "Epoch 128/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7182 - acc: 0.7608 - val_loss: 0.6457 - val_acc: 0.7723\n",
      "Epoch 129/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7326 - acc: 0.7545 - val_loss: 0.6438 - val_acc: 0.7716\n",
      "Epoch 130/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7198 - acc: 0.7548 - val_loss: 0.6432 - val_acc: 0.7686\n",
      "Epoch 131/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7071 - acc: 0.7604 - val_loss: 0.6461 - val_acc: 0.7671\n",
      "Epoch 132/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7061 - acc: 0.7507 - val_loss: 0.6459 - val_acc: 0.7701\n",
      "Epoch 133/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7231 - acc: 0.7496 - val_loss: 0.6449 - val_acc: 0.7693\n",
      "Epoch 134/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.7264 - acc: 0.7504 - val_loss: 0.6462 - val_acc: 0.7671\n",
      "Epoch 135/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7207 - acc: 0.7567 - val_loss: 0.6458 - val_acc: 0.7656\n",
      "Epoch 136/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7062 - acc: 0.7548 - val_loss: 0.6446 - val_acc: 0.7708\n",
      "Epoch 137/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7059 - acc: 0.7641 - val_loss: 0.6437 - val_acc: 0.7716\n",
      "Epoch 138/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7092 - acc: 0.7582 - val_loss: 0.6432 - val_acc: 0.7738\n",
      "Epoch 139/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7172 - acc: 0.7578 - val_loss: 0.6452 - val_acc: 0.7656\n",
      "Epoch 140/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7226 - acc: 0.7556 - val_loss: 0.6391 - val_acc: 0.7671\n",
      "Epoch 141/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7333 - acc: 0.7500 - val_loss: 0.6428 - val_acc: 0.7671\n",
      "Epoch 142/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7110 - acc: 0.7500 - val_loss: 0.6416 - val_acc: 0.7708\n",
      "Epoch 143/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7084 - acc: 0.7615 - val_loss: 0.6428 - val_acc: 0.7656\n",
      "Epoch 144/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7228 - acc: 0.7548 - val_loss: 0.6418 - val_acc: 0.7686\n",
      "Epoch 145/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7164 - acc: 0.7533 - val_loss: 0.6421 - val_acc: 0.7656\n",
      "Epoch 146/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7094 - acc: 0.7656 - val_loss: 0.6413 - val_acc: 0.7716\n",
      "Epoch 147/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7039 - acc: 0.7574 - val_loss: 0.6427 - val_acc: 0.7723\n",
      "Epoch 148/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7191 - acc: 0.7545 - val_loss: 0.6395 - val_acc: 0.7693\n",
      "Epoch 149/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7087 - acc: 0.7593 - val_loss: 0.6417 - val_acc: 0.7701\n",
      "Epoch 150/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7240 - acc: 0.7493 - val_loss: 0.6406 - val_acc: 0.7716\n",
      "Epoch 151/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7256 - acc: 0.7500 - val_loss: 0.6414 - val_acc: 0.7701\n",
      "Epoch 152/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7194 - acc: 0.7541 - val_loss: 0.6412 - val_acc: 0.7693\n",
      "Epoch 153/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7165 - acc: 0.7552 - val_loss: 0.6384 - val_acc: 0.7708\n",
      "Epoch 154/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7106 - acc: 0.7653 - val_loss: 0.6396 - val_acc: 0.7693\n",
      "Epoch 155/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7190 - acc: 0.7608 - val_loss: 0.6396 - val_acc: 0.7686\n",
      "Epoch 156/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6988 - acc: 0.7556 - val_loss: 0.6385 - val_acc: 0.7723\n",
      "Epoch 157/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7034 - acc: 0.7615 - val_loss: 0.6408 - val_acc: 0.7731\n",
      "Epoch 158/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6981 - acc: 0.7530 - val_loss: 0.6396 - val_acc: 0.7708\n",
      "Epoch 159/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7079 - acc: 0.7604 - val_loss: 0.6384 - val_acc: 0.7701\n",
      "Epoch 160/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7035 - acc: 0.7582 - val_loss: 0.6383 - val_acc: 0.7679\n",
      "Epoch 161/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6986 - acc: 0.7589 - val_loss: 0.6392 - val_acc: 0.7693\n",
      "Epoch 162/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7154 - acc: 0.7600 - val_loss: 0.6368 - val_acc: 0.7686\n",
      "Epoch 163/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6816 - acc: 0.7608 - val_loss: 0.6371 - val_acc: 0.7693\n",
      "Epoch 164/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6963 - acc: 0.7600 - val_loss: 0.6369 - val_acc: 0.7701\n",
      "Epoch 165/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7141 - acc: 0.7537 - val_loss: 0.6376 - val_acc: 0.7693\n",
      "\n",
      "Epoch 00165: loss improved from inf to 0.71409, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-1-000165-0.714093-0.769345.hdf5\n",
      "Epoch 166/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6976 - acc: 0.7586 - val_loss: 0.6349 - val_acc: 0.7716\n",
      "Epoch 167/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7042 - acc: 0.7615 - val_loss: 0.6356 - val_acc: 0.7686\n",
      "Epoch 168/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7009 - acc: 0.7619 - val_loss: 0.6332 - val_acc: 0.7738\n",
      "Epoch 169/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6945 - acc: 0.7656 - val_loss: 0.6364 - val_acc: 0.7708\n",
      "\n",
      "Epoch 00169: loss improved from 0.71409 to 0.69449, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-1-000169-0.694489-0.770833.hdf5\n",
      "Epoch 170/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6879 - acc: 0.7634 - val_loss: 0.6319 - val_acc: 0.7731\n",
      "Epoch 171/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7139 - acc: 0.7589 - val_loss: 0.6349 - val_acc: 0.7723\n",
      "Epoch 172/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7028 - acc: 0.7667 - val_loss: 0.6342 - val_acc: 0.7708\n",
      "Epoch 173/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6923 - acc: 0.7608 - val_loss: 0.6344 - val_acc: 0.7723\n",
      "\n",
      "Epoch 00173: loss improved from 0.69449 to 0.69232, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-1-000173-0.692316-0.772321.hdf5\n",
      "Epoch 174/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6918 - acc: 0.7671 - val_loss: 0.6353 - val_acc: 0.7723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7150 - acc: 0.7571 - val_loss: 0.6349 - val_acc: 0.7701\n",
      "Epoch 176/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7175 - acc: 0.7560 - val_loss: 0.6365 - val_acc: 0.7693\n",
      "Epoch 177/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6926 - acc: 0.7641 - val_loss: 0.6366 - val_acc: 0.7679\n",
      "Epoch 178/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6868 - acc: 0.7623 - val_loss: 0.6358 - val_acc: 0.7708\n",
      "Epoch 179/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6993 - acc: 0.7612 - val_loss: 0.6347 - val_acc: 0.7701\n",
      "Epoch 180/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6920 - acc: 0.7593 - val_loss: 0.6346 - val_acc: 0.7701\n",
      "Epoch 181/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7104 - acc: 0.7500 - val_loss: 0.6347 - val_acc: 0.7708\n",
      "Epoch 182/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6908 - acc: 0.7623 - val_loss: 0.6347 - val_acc: 0.7716\n",
      "Epoch 183/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7128 - acc: 0.7545 - val_loss: 0.6354 - val_acc: 0.7716\n",
      "\n",
      "Epoch 00183: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 184/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7078 - acc: 0.7571 - val_loss: 0.6357 - val_acc: 0.7716\n",
      "Epoch 185/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6970 - acc: 0.7560 - val_loss: 0.6355 - val_acc: 0.7701\n",
      "Epoch 186/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6883 - acc: 0.7641 - val_loss: 0.6308 - val_acc: 0.7731\n",
      "Epoch 187/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7035 - acc: 0.7593 - val_loss: 0.6333 - val_acc: 0.7701\n",
      "Epoch 188/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7139 - acc: 0.7593 - val_loss: 0.6344 - val_acc: 0.7708\n",
      "Epoch 189/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7081 - acc: 0.7612 - val_loss: 0.6316 - val_acc: 0.7708\n",
      "Epoch 190/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6863 - acc: 0.7612 - val_loss: 0.6342 - val_acc: 0.7708\n",
      "Epoch 191/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6912 - acc: 0.7630 - val_loss: 0.6340 - val_acc: 0.7701\n",
      "Epoch 192/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7014 - acc: 0.7671 - val_loss: 0.6349 - val_acc: 0.7693\n",
      "Epoch 193/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6914 - acc: 0.7626 - val_loss: 0.6354 - val_acc: 0.7701\n",
      "\n",
      "Epoch 00193: loss improved from 0.69232 to 0.69137, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-1-000193-0.691368-0.770089.hdf5\n",
      "Epoch 194/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7048 - acc: 0.7630 - val_loss: 0.6332 - val_acc: 0.7708\n",
      "Epoch 195/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6853 - acc: 0.7667 - val_loss: 0.6329 - val_acc: 0.7701\n",
      "Epoch 196/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6982 - acc: 0.7686 - val_loss: 0.6341 - val_acc: 0.7708\n",
      "Epoch 197/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7064 - acc: 0.7619 - val_loss: 0.6303 - val_acc: 0.7708\n",
      "Epoch 198/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7021 - acc: 0.7604 - val_loss: 0.6344 - val_acc: 0.7723\n",
      "Epoch 199/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7055 - acc: 0.7600 - val_loss: 0.6341 - val_acc: 0.7701\n",
      "Epoch 200/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7170 - acc: 0.7493 - val_loss: 0.6339 - val_acc: 0.7708\n",
      "\n",
      "Epoch 00200: saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/1-000200-0.716967-0.770833.hdf5\n",
      "Epoch 201/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6978 - acc: 0.7630 - val_loss: 0.6344 - val_acc: 0.7693\n",
      "Epoch 202/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7049 - acc: 0.7634 - val_loss: 0.6348 - val_acc: 0.7693\n",
      "Epoch 203/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7053 - acc: 0.7608 - val_loss: 0.6348 - val_acc: 0.7686\n",
      "\n",
      "Epoch 00203: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 204/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6961 - acc: 0.7586 - val_loss: 0.6350 - val_acc: 0.7686\n",
      "Epoch 205/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7029 - acc: 0.7656 - val_loss: 0.6313 - val_acc: 0.7693\n",
      "Epoch 206/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6855 - acc: 0.7731 - val_loss: 0.6346 - val_acc: 0.7686\n",
      "Epoch 207/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6900 - acc: 0.7615 - val_loss: 0.6332 - val_acc: 0.7701\n",
      "Epoch 208/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7106 - acc: 0.7485 - val_loss: 0.6340 - val_acc: 0.7693\n",
      "Epoch 209/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7058 - acc: 0.7578 - val_loss: 0.6347 - val_acc: 0.7686\n",
      "Epoch 210/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7074 - acc: 0.7597 - val_loss: 0.6331 - val_acc: 0.7693\n",
      "Epoch 211/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6915 - acc: 0.7630 - val_loss: 0.6329 - val_acc: 0.7701\n",
      "Epoch 212/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6990 - acc: 0.7645 - val_loss: 0.6336 - val_acc: 0.7693\n",
      "Epoch 213/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6975 - acc: 0.7626 - val_loss: 0.6330 - val_acc: 0.7693\n",
      "Epoch 214/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6934 - acc: 0.7578 - val_loss: 0.6332 - val_acc: 0.7701\n",
      "Epoch 215/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6997 - acc: 0.7556 - val_loss: 0.6347 - val_acc: 0.7686\n",
      "Epoch 216/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6944 - acc: 0.7571 - val_loss: 0.6353 - val_acc: 0.7686\n",
      "Epoch 217/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7069 - acc: 0.7548 - val_loss: 0.6347 - val_acc: 0.7686\n",
      "Epoch 218/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7070 - acc: 0.7571 - val_loss: 0.6333 - val_acc: 0.7693\n",
      "Epoch 219/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7034 - acc: 0.7578 - val_loss: 0.6353 - val_acc: 0.7686\n",
      "Epoch 220/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7076 - acc: 0.7545 - val_loss: 0.6321 - val_acc: 0.7701\n",
      "Epoch 221/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7132 - acc: 0.7586 - val_loss: 0.6344 - val_acc: 0.7686\n",
      "Epoch 222/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7053 - acc: 0.7589 - val_loss: 0.6351 - val_acc: 0.7686\n",
      "Epoch 223/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6905 - acc: 0.7656 - val_loss: 0.6350 - val_acc: 0.7686\n",
      "\n",
      "Epoch 00223: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 224/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7021 - acc: 0.7690 - val_loss: 0.6308 - val_acc: 0.7708\n",
      "Epoch 225/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7107 - acc: 0.7526 - val_loss: 0.6342 - val_acc: 0.7693\n",
      "Epoch 226/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6910 - acc: 0.7612 - val_loss: 0.6353 - val_acc: 0.7686\n",
      "Epoch 227/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7098 - acc: 0.7507 - val_loss: 0.6329 - val_acc: 0.7686\n",
      "Epoch 228/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6935 - acc: 0.7612 - val_loss: 0.6338 - val_acc: 0.7693\n",
      "Epoch 229/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6886 - acc: 0.7701 - val_loss: 0.6321 - val_acc: 0.7693\n",
      "Epoch 230/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7030 - acc: 0.7593 - val_loss: 0.6340 - val_acc: 0.7693\n",
      "Epoch 231/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6970 - acc: 0.7697 - val_loss: 0.6351 - val_acc: 0.7686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6992 - acc: 0.7567 - val_loss: 0.6330 - val_acc: 0.7693\n",
      "Epoch 233/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6926 - acc: 0.7600 - val_loss: 0.6328 - val_acc: 0.7701\n",
      "Epoch 234/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6967 - acc: 0.7563 - val_loss: 0.6321 - val_acc: 0.7708\n",
      "Epoch 235/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7123 - acc: 0.7593 - val_loss: 0.6341 - val_acc: 0.7686\n",
      "Epoch 236/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7042 - acc: 0.7548 - val_loss: 0.6337 - val_acc: 0.7693\n",
      "Epoch 237/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7014 - acc: 0.7493 - val_loss: 0.6350 - val_acc: 0.7686\n",
      "Epoch 238/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7087 - acc: 0.7589 - val_loss: 0.6340 - val_acc: 0.7693\n",
      "Epoch 239/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7042 - acc: 0.7578 - val_loss: 0.6351 - val_acc: 0.7686\n",
      "Epoch 240/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7078 - acc: 0.7578 - val_loss: 0.6338 - val_acc: 0.7693\n",
      "Epoch 241/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7079 - acc: 0.7522 - val_loss: 0.6313 - val_acc: 0.7693\n",
      "Epoch 242/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7104 - acc: 0.7586 - val_loss: 0.6334 - val_acc: 0.7693\n",
      "Epoch 243/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7034 - acc: 0.7589 - val_loss: 0.6338 - val_acc: 0.7693\n",
      "Epoch 244/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7071 - acc: 0.7619 - val_loss: 0.6314 - val_acc: 0.7701\n",
      "Epoch 245/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7030 - acc: 0.7608 - val_loss: 0.6341 - val_acc: 0.7686\n",
      "Epoch 246/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7076 - acc: 0.7548 - val_loss: 0.6347 - val_acc: 0.7686\n",
      "Epoch 247/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6905 - acc: 0.7574 - val_loss: 0.6345 - val_acc: 0.7686\n",
      "Epoch 248/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7105 - acc: 0.7548 - val_loss: 0.6332 - val_acc: 0.7693\n",
      "Epoch 249/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7157 - acc: 0.7567 - val_loss: 0.6337 - val_acc: 0.7693\n",
      "Epoch 250/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6832 - acc: 0.7623 - val_loss: 0.6314 - val_acc: 0.7701\n",
      "Epoch 251/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6960 - acc: 0.7600 - val_loss: 0.6347 - val_acc: 0.7693\n",
      "Epoch 252/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6972 - acc: 0.7612 - val_loss: 0.6300 - val_acc: 0.7693\n",
      "Epoch 253/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7037 - acc: 0.7533 - val_loss: 0.6339 - val_acc: 0.7693\n",
      "Epoch 254/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6988 - acc: 0.7500 - val_loss: 0.6332 - val_acc: 0.7701\n",
      "Epoch 255/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6924 - acc: 0.7693 - val_loss: 0.6344 - val_acc: 0.7686\n",
      "Epoch 256/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7042 - acc: 0.7619 - val_loss: 0.6329 - val_acc: 0.7701\n",
      "Epoch 257/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7074 - acc: 0.7586 - val_loss: 0.6349 - val_acc: 0.7686\n",
      "Epoch 258/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6984 - acc: 0.7578 - val_loss: 0.6339 - val_acc: 0.7693\n",
      "Epoch 259/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7081 - acc: 0.7604 - val_loss: 0.6328 - val_acc: 0.7693\n",
      "Epoch 260/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7017 - acc: 0.7582 - val_loss: 0.6346 - val_acc: 0.7693\n",
      "Epoch 261/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6888 - acc: 0.7615 - val_loss: 0.6335 - val_acc: 0.7693\n",
      "Epoch 262/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6901 - acc: 0.7612 - val_loss: 0.6346 - val_acc: 0.7686\n",
      "Epoch 263/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6876 - acc: 0.7615 - val_loss: 0.6351 - val_acc: 0.7686\n",
      "Epoch 264/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6901 - acc: 0.7626 - val_loss: 0.6256 - val_acc: 0.7701\n",
      "Epoch 265/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6887 - acc: 0.7653 - val_loss: 0.6332 - val_acc: 0.7693\n",
      "\n",
      "Epoch 00265: loss improved from inf to 0.68870, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-1-000265-0.688702-0.769345.hdf5\n",
      "Epoch 266/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6958 - acc: 0.7623 - val_loss: 0.6350 - val_acc: 0.7686\n",
      "Epoch 267/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6878 - acc: 0.7697 - val_loss: 0.6329 - val_acc: 0.7693\n",
      "Epoch 268/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6872 - acc: 0.7638 - val_loss: 0.6344 - val_acc: 0.7686\n",
      "Epoch 269/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6915 - acc: 0.7615 - val_loss: 0.6343 - val_acc: 0.7693\n",
      "Epoch 270/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6945 - acc: 0.7600 - val_loss: 0.6305 - val_acc: 0.7708\n",
      "Epoch 271/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7011 - acc: 0.7533 - val_loss: 0.6336 - val_acc: 0.7693\n",
      "Epoch 272/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7023 - acc: 0.7645 - val_loss: 0.6349 - val_acc: 0.7686\n",
      "Epoch 273/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6986 - acc: 0.7604 - val_loss: 0.6296 - val_acc: 0.7708\n",
      "Epoch 274/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6734 - acc: 0.7608 - val_loss: 0.6321 - val_acc: 0.7701\n",
      "Epoch 275/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7105 - acc: 0.7522 - val_loss: 0.6331 - val_acc: 0.7701\n",
      "Epoch 276/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7221 - acc: 0.7597 - val_loss: 0.6333 - val_acc: 0.7693\n",
      "Epoch 277/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7063 - acc: 0.7634 - val_loss: 0.6343 - val_acc: 0.7686\n",
      "Epoch 278/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7067 - acc: 0.7615 - val_loss: 0.6338 - val_acc: 0.7693\n",
      "Epoch 279/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7087 - acc: 0.7548 - val_loss: 0.6335 - val_acc: 0.7693\n",
      "Epoch 280/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.6923 - acc: 0.7716 - val_loss: 0.6343 - val_acc: 0.7686\n",
      "Epoch 281/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6940 - acc: 0.7682 - val_loss: 0.6302 - val_acc: 0.7708\n",
      "Epoch 282/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6852 - acc: 0.7679 - val_loss: 0.6342 - val_acc: 0.7686\n",
      "Epoch 283/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6923 - acc: 0.7604 - val_loss: 0.6350 - val_acc: 0.7686\n",
      "Epoch 284/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7069 - acc: 0.7582 - val_loss: 0.6341 - val_acc: 0.7693\n",
      "Epoch 285/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6954 - acc: 0.7586 - val_loss: 0.6346 - val_acc: 0.7686\n",
      "Epoch 286/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6965 - acc: 0.7589 - val_loss: 0.6336 - val_acc: 0.7693\n",
      "Epoch 287/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6954 - acc: 0.7619 - val_loss: 0.6342 - val_acc: 0.7693\n",
      "Epoch 288/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6960 - acc: 0.7630 - val_loss: 0.6318 - val_acc: 0.7701\n",
      "Epoch 289/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6810 - acc: 0.7656 - val_loss: 0.6291 - val_acc: 0.7708\n",
      "\n",
      "Epoch 00289: loss improved from 0.68870 to 0.68103, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-1-000289-0.681029-0.770833.hdf5\n",
      "Epoch 290/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6992 - acc: 0.7548 - val_loss: 0.6348 - val_acc: 0.7686\n",
      "Epoch 291/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7097 - acc: 0.7656 - val_loss: 0.6325 - val_acc: 0.7701\n",
      "Epoch 292/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7039 - acc: 0.7574 - val_loss: 0.6315 - val_acc: 0.7701\n",
      "Epoch 293/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6949 - acc: 0.7615 - val_loss: 0.6340 - val_acc: 0.7686\n",
      "Epoch 294/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7071 - acc: 0.7582 - val_loss: 0.6309 - val_acc: 0.7701\n",
      "Epoch 295/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6866 - acc: 0.7626 - val_loss: 0.6332 - val_acc: 0.7693\n",
      "Epoch 296/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6948 - acc: 0.7563 - val_loss: 0.6345 - val_acc: 0.7686\n",
      "Epoch 297/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6880 - acc: 0.7574 - val_loss: 0.6338 - val_acc: 0.7693\n",
      "Epoch 298/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6944 - acc: 0.7626 - val_loss: 0.6317 - val_acc: 0.7701\n",
      "Epoch 299/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6933 - acc: 0.7567 - val_loss: 0.6338 - val_acc: 0.7693\n",
      "Epoch 300/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6989 - acc: 0.7634 - val_loss: 0.6311 - val_acc: 0.7693\n",
      "\n",
      "Epoch 00300: saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/1-000300-0.698896-0.769345.hdf5\n",
      "Epoch 301/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6981 - acc: 0.7641 - val_loss: 0.6340 - val_acc: 0.7693\n",
      "Epoch 302/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6950 - acc: 0.7623 - val_loss: 0.6352 - val_acc: 0.7686\n",
      "Epoch 303/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6854 - acc: 0.7615 - val_loss: 0.6344 - val_acc: 0.7686\n",
      "Epoch 304/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6741 - acc: 0.7664 - val_loss: 0.6333 - val_acc: 0.7693\n",
      "Epoch 305/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6860 - acc: 0.7664 - val_loss: 0.6326 - val_acc: 0.7693\n",
      "Epoch 306/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6898 - acc: 0.7541 - val_loss: 0.6351 - val_acc: 0.7686\n",
      "Epoch 307/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6875 - acc: 0.7656 - val_loss: 0.6334 - val_acc: 0.7693\n",
      "Epoch 308/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7040 - acc: 0.7571 - val_loss: 0.6337 - val_acc: 0.7693\n",
      "Epoch 309/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6863 - acc: 0.7727 - val_loss: 0.6345 - val_acc: 0.7686\n",
      "Epoch 310/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7027 - acc: 0.7653 - val_loss: 0.6327 - val_acc: 0.7693\n",
      "Epoch 311/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7000 - acc: 0.7638 - val_loss: 0.6327 - val_acc: 0.7693\n",
      "Epoch 312/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6950 - acc: 0.7597 - val_loss: 0.6322 - val_acc: 0.7701\n",
      "Epoch 313/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7088 - acc: 0.7489 - val_loss: 0.6333 - val_acc: 0.7693\n",
      "Epoch 314/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7135 - acc: 0.7545 - val_loss: 0.6345 - val_acc: 0.7686\n",
      "Epoch 315/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6964 - acc: 0.7552 - val_loss: 0.6345 - val_acc: 0.7686\n",
      "Epoch 316/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6897 - acc: 0.7664 - val_loss: 0.6350 - val_acc: 0.7686\n",
      "Epoch 317/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6937 - acc: 0.7649 - val_loss: 0.6332 - val_acc: 0.7693\n",
      "Epoch 318/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6869 - acc: 0.7671 - val_loss: 0.6306 - val_acc: 0.7708\n",
      "Epoch 319/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6858 - acc: 0.7660 - val_loss: 0.6328 - val_acc: 0.7701\n",
      "Epoch 320/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7015 - acc: 0.7560 - val_loss: 0.6333 - val_acc: 0.7701\n",
      "Epoch 321/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7003 - acc: 0.7675 - val_loss: 0.6329 - val_acc: 0.7693\n",
      "Epoch 322/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6963 - acc: 0.7641 - val_loss: 0.6342 - val_acc: 0.7693\n",
      "Epoch 323/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7022 - acc: 0.7530 - val_loss: 0.6338 - val_acc: 0.7693\n",
      "Epoch 324/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6942 - acc: 0.7612 - val_loss: 0.6322 - val_acc: 0.7693\n",
      "Epoch 325/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6891 - acc: 0.7697 - val_loss: 0.6349 - val_acc: 0.7686\n",
      "Epoch 326/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7066 - acc: 0.7630 - val_loss: 0.6347 - val_acc: 0.7686\n",
      "Epoch 327/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7033 - acc: 0.7623 - val_loss: 0.6310 - val_acc: 0.7693\n",
      "Epoch 328/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6984 - acc: 0.7604 - val_loss: 0.6328 - val_acc: 0.7701\n",
      "Epoch 329/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6866 - acc: 0.7664 - val_loss: 0.6339 - val_acc: 0.7686\n",
      "Epoch 330/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6988 - acc: 0.7600 - val_loss: 0.6343 - val_acc: 0.7686\n",
      "Epoch 331/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7105 - acc: 0.7615 - val_loss: 0.6348 - val_acc: 0.7686\n",
      "Epoch 332/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6949 - acc: 0.7671 - val_loss: 0.6348 - val_acc: 0.7686\n",
      "Epoch 333/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6945 - acc: 0.7608 - val_loss: 0.6345 - val_acc: 0.7686\n",
      "Epoch 334/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6931 - acc: 0.7716 - val_loss: 0.6322 - val_acc: 0.7701\n",
      "Epoch 335/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6975 - acc: 0.7586 - val_loss: 0.6339 - val_acc: 0.7693\n",
      "Epoch 336/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7025 - acc: 0.7593 - val_loss: 0.6316 - val_acc: 0.7701\n",
      "Epoch 337/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6785 - acc: 0.7746 - val_loss: 0.6333 - val_acc: 0.7693\n",
      "Epoch 338/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7127 - acc: 0.7545 - val_loss: 0.6334 - val_acc: 0.7693\n",
      "Epoch 339/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6864 - acc: 0.7641 - val_loss: 0.6341 - val_acc: 0.7686\n",
      "Epoch 340/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6926 - acc: 0.7634 - val_loss: 0.6328 - val_acc: 0.7693\n",
      "Epoch 341/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6964 - acc: 0.7533 - val_loss: 0.6322 - val_acc: 0.7701\n",
      "Epoch 342/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6985 - acc: 0.7626 - val_loss: 0.6328 - val_acc: 0.7693\n",
      "Epoch 343/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7086 - acc: 0.7541 - val_loss: 0.6336 - val_acc: 0.7693\n",
      "Epoch 344/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7047 - acc: 0.7630 - val_loss: 0.6302 - val_acc: 0.7701\n",
      "Epoch 345/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7059 - acc: 0.7582 - val_loss: 0.6344 - val_acc: 0.7686\n",
      "Epoch 346/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6933 - acc: 0.7515 - val_loss: 0.6334 - val_acc: 0.7693\n",
      "Epoch 347/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7167 - acc: 0.7481 - val_loss: 0.6338 - val_acc: 0.7686\n",
      "Epoch 348/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7037 - acc: 0.7560 - val_loss: 0.6346 - val_acc: 0.7686\n",
      "Epoch 349/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6886 - acc: 0.7653 - val_loss: 0.6336 - val_acc: 0.7693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6928 - acc: 0.7604 - val_loss: 0.6319 - val_acc: 0.7701\n",
      "Epoch 351/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6867 - acc: 0.7630 - val_loss: 0.6322 - val_acc: 0.7693\n",
      "Epoch 352/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6874 - acc: 0.7664 - val_loss: 0.6329 - val_acc: 0.7701\n",
      "Epoch 353/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7061 - acc: 0.7533 - val_loss: 0.6342 - val_acc: 0.7686\n",
      "Epoch 354/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6933 - acc: 0.7604 - val_loss: 0.6344 - val_acc: 0.7686\n",
      "Epoch 355/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6817 - acc: 0.7667 - val_loss: 0.6335 - val_acc: 0.7701\n",
      "Epoch 356/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6966 - acc: 0.7653 - val_loss: 0.6344 - val_acc: 0.7686\n",
      "Epoch 357/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6911 - acc: 0.7634 - val_loss: 0.6331 - val_acc: 0.7693\n",
      "Epoch 358/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7022 - acc: 0.7597 - val_loss: 0.6306 - val_acc: 0.7708\n",
      "Epoch 359/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6952 - acc: 0.7615 - val_loss: 0.6305 - val_acc: 0.7701\n",
      "Epoch 360/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6981 - acc: 0.7623 - val_loss: 0.6347 - val_acc: 0.7686\n",
      "Epoch 361/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7008 - acc: 0.7589 - val_loss: 0.6345 - val_acc: 0.7686\n",
      "Epoch 362/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7044 - acc: 0.7634 - val_loss: 0.6337 - val_acc: 0.7693\n",
      "Epoch 363/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6942 - acc: 0.7582 - val_loss: 0.6343 - val_acc: 0.7686\n",
      "Epoch 364/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6961 - acc: 0.7552 - val_loss: 0.6336 - val_acc: 0.7693\n",
      "Epoch 365/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6999 - acc: 0.7507 - val_loss: 0.6329 - val_acc: 0.7693\n",
      "\n",
      "Epoch 00365: loss improved from inf to 0.69985, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-1-000365-0.699853-0.769345.hdf5\n",
      "Epoch 366/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7027 - acc: 0.7619 - val_loss: 0.6334 - val_acc: 0.7693\n",
      "Epoch 367/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6804 - acc: 0.7645 - val_loss: 0.6300 - val_acc: 0.7701\n",
      "Epoch 368/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7009 - acc: 0.7593 - val_loss: 0.6349 - val_acc: 0.7686\n",
      "Epoch 369/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6977 - acc: 0.7537 - val_loss: 0.6349 - val_acc: 0.7686\n",
      "\n",
      "Epoch 00369: loss improved from 0.69985 to 0.69767, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-1-000369-0.697665-0.768601.hdf5\n",
      "Epoch 370/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7004 - acc: 0.7638 - val_loss: 0.6329 - val_acc: 0.7701\n",
      "Epoch 371/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6999 - acc: 0.7615 - val_loss: 0.6347 - val_acc: 0.7686\n",
      "Epoch 372/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6908 - acc: 0.7671 - val_loss: 0.6317 - val_acc: 0.7693\n",
      "Epoch 373/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7015 - acc: 0.7560 - val_loss: 0.6317 - val_acc: 0.7701\n",
      "Epoch 374/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7007 - acc: 0.7578 - val_loss: 0.6344 - val_acc: 0.7686\n",
      "Epoch 375/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6885 - acc: 0.7656 - val_loss: 0.6334 - val_acc: 0.7693\n",
      "Epoch 376/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7015 - acc: 0.7586 - val_loss: 0.6334 - val_acc: 0.7693\n",
      "Epoch 377/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6998 - acc: 0.7586 - val_loss: 0.6344 - val_acc: 0.7686\n",
      "Epoch 378/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6847 - acc: 0.7612 - val_loss: 0.6339 - val_acc: 0.7686\n",
      "Epoch 379/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6967 - acc: 0.7645 - val_loss: 0.6256 - val_acc: 0.7708\n",
      "Epoch 380/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7120 - acc: 0.7589 - val_loss: 0.6347 - val_acc: 0.7686\n",
      "Epoch 381/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6982 - acc: 0.7574 - val_loss: 0.6325 - val_acc: 0.7701\n",
      "Epoch 382/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6953 - acc: 0.7586 - val_loss: 0.6329 - val_acc: 0.7693\n",
      "Epoch 383/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7132 - acc: 0.7608 - val_loss: 0.6348 - val_acc: 0.7686\n",
      "Epoch 384/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6889 - acc: 0.7660 - val_loss: 0.6336 - val_acc: 0.7693\n",
      "Epoch 385/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6954 - acc: 0.7600 - val_loss: 0.6338 - val_acc: 0.7693\n",
      "\n",
      "Epoch 00385: loss improved from 0.69767 to 0.69544, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-1-000385-0.695441-0.769345.hdf5\n",
      "Epoch 386/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7147 - acc: 0.7519 - val_loss: 0.6340 - val_acc: 0.7686\n",
      "Epoch 387/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7116 - acc: 0.7530 - val_loss: 0.6336 - val_acc: 0.7693\n",
      "Epoch 388/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6939 - acc: 0.7634 - val_loss: 0.6334 - val_acc: 0.7693\n",
      "Epoch 389/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6956 - acc: 0.7619 - val_loss: 0.6346 - val_acc: 0.7686\n",
      "Epoch 390/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6995 - acc: 0.7604 - val_loss: 0.6293 - val_acc: 0.7701\n",
      "Epoch 391/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6907 - acc: 0.7623 - val_loss: 0.6346 - val_acc: 0.7686\n",
      "Epoch 392/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6946 - acc: 0.7630 - val_loss: 0.6341 - val_acc: 0.7686\n",
      "Epoch 393/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7141 - acc: 0.7493 - val_loss: 0.6327 - val_acc: 0.7701\n",
      "Epoch 394/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7039 - acc: 0.7638 - val_loss: 0.6343 - val_acc: 0.7686\n",
      "Epoch 395/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7048 - acc: 0.7604 - val_loss: 0.6337 - val_acc: 0.7693\n",
      "Epoch 396/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6938 - acc: 0.7600 - val_loss: 0.6323 - val_acc: 0.7701\n",
      "Epoch 397/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6968 - acc: 0.7623 - val_loss: 0.6346 - val_acc: 0.7686\n",
      "Epoch 398/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6935 - acc: 0.7641 - val_loss: 0.6336 - val_acc: 0.7686\n",
      "Epoch 399/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6829 - acc: 0.7641 - val_loss: 0.6330 - val_acc: 0.7693\n",
      "Epoch 400/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6913 - acc: 0.7604 - val_loss: 0.6333 - val_acc: 0.7693\n",
      "\n",
      "Epoch 00400: saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/1-000400-0.691291-0.769345.hdf5\n",
      "Epoch 401/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6957 - acc: 0.7686 - val_loss: 0.6316 - val_acc: 0.7693\n",
      "Epoch 402/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6846 - acc: 0.7690 - val_loss: 0.6321 - val_acc: 0.7693\n",
      "Epoch 403/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6951 - acc: 0.7589 - val_loss: 0.6324 - val_acc: 0.7701\n",
      "Epoch 404/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6832 - acc: 0.7630 - val_loss: 0.6347 - val_acc: 0.7686\n",
      "Epoch 405/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7023 - acc: 0.7593 - val_loss: 0.6329 - val_acc: 0.7693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 406/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7058 - acc: 0.7604 - val_loss: 0.6331 - val_acc: 0.7701\n",
      "Epoch 407/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7014 - acc: 0.7604 - val_loss: 0.6329 - val_acc: 0.7693\n",
      "Epoch 408/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6855 - acc: 0.7712 - val_loss: 0.6325 - val_acc: 0.7693\n",
      "Epoch 409/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6941 - acc: 0.7649 - val_loss: 0.6308 - val_acc: 0.7701\n",
      "Epoch 410/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6993 - acc: 0.7586 - val_loss: 0.6335 - val_acc: 0.7693\n",
      "Epoch 411/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6935 - acc: 0.7522 - val_loss: 0.6325 - val_acc: 0.7693\n",
      "Epoch 412/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6926 - acc: 0.7656 - val_loss: 0.6346 - val_acc: 0.7686\n",
      "Epoch 413/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7063 - acc: 0.7626 - val_loss: 0.6316 - val_acc: 0.7693\n",
      "Epoch 414/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6958 - acc: 0.7634 - val_loss: 0.6333 - val_acc: 0.7693\n",
      "Epoch 415/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6783 - acc: 0.7593 - val_loss: 0.6347 - val_acc: 0.7686\n",
      "Epoch 416/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6980 - acc: 0.7574 - val_loss: 0.6318 - val_acc: 0.7693\n",
      "Epoch 417/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6834 - acc: 0.7645 - val_loss: 0.6334 - val_acc: 0.7693\n",
      "Epoch 418/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7025 - acc: 0.7563 - val_loss: 0.6304 - val_acc: 0.7701\n",
      "Epoch 419/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7068 - acc: 0.7582 - val_loss: 0.6342 - val_acc: 0.7686\n",
      "Epoch 420/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6831 - acc: 0.7612 - val_loss: 0.6346 - val_acc: 0.7686\n",
      "Epoch 421/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6943 - acc: 0.7537 - val_loss: 0.6338 - val_acc: 0.7686\n",
      "Epoch 422/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6844 - acc: 0.7697 - val_loss: 0.6342 - val_acc: 0.7686\n",
      "Epoch 423/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6936 - acc: 0.7600 - val_loss: 0.6282 - val_acc: 0.7708\n",
      "Epoch 424/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6970 - acc: 0.7630 - val_loss: 0.6345 - val_acc: 0.7686\n",
      "Epoch 425/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6889 - acc: 0.7634 - val_loss: 0.6338 - val_acc: 0.7693\n",
      "Epoch 426/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6976 - acc: 0.7608 - val_loss: 0.6324 - val_acc: 0.7693\n",
      "Epoch 427/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6998 - acc: 0.7660 - val_loss: 0.6311 - val_acc: 0.7701\n",
      "Epoch 428/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7049 - acc: 0.7537 - val_loss: 0.6335 - val_acc: 0.7686\n",
      "Epoch 429/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6852 - acc: 0.7686 - val_loss: 0.6318 - val_acc: 0.7701\n",
      "Epoch 430/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7045 - acc: 0.7645 - val_loss: 0.6331 - val_acc: 0.7693\n",
      "Epoch 431/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6875 - acc: 0.7626 - val_loss: 0.6342 - val_acc: 0.7693\n",
      "Epoch 432/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6879 - acc: 0.7593 - val_loss: 0.6344 - val_acc: 0.7686\n",
      "Epoch 433/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6908 - acc: 0.7586 - val_loss: 0.6311 - val_acc: 0.7701\n",
      "Epoch 434/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7053 - acc: 0.7563 - val_loss: 0.6347 - val_acc: 0.7686\n",
      "Epoch 435/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7051 - acc: 0.7533 - val_loss: 0.6346 - val_acc: 0.7686\n",
      "Epoch 436/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7016 - acc: 0.7600 - val_loss: 0.6318 - val_acc: 0.7701\n",
      "Epoch 437/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6968 - acc: 0.7630 - val_loss: 0.6340 - val_acc: 0.7686\n",
      "Epoch 438/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7030 - acc: 0.7560 - val_loss: 0.6343 - val_acc: 0.7686\n",
      "Epoch 439/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6787 - acc: 0.7794 - val_loss: 0.6346 - val_acc: 0.7686\n",
      "Epoch 440/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6959 - acc: 0.7571 - val_loss: 0.6339 - val_acc: 0.7686\n",
      "Epoch 441/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6963 - acc: 0.7641 - val_loss: 0.6293 - val_acc: 0.7701\n",
      "Epoch 442/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7159 - acc: 0.7556 - val_loss: 0.6341 - val_acc: 0.7686\n",
      "Epoch 443/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6868 - acc: 0.7667 - val_loss: 0.6321 - val_acc: 0.7693\n",
      "Epoch 444/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6872 - acc: 0.7645 - val_loss: 0.6327 - val_acc: 0.7693\n",
      "Epoch 445/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6968 - acc: 0.7608 - val_loss: 0.6326 - val_acc: 0.7693\n",
      "Epoch 446/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6847 - acc: 0.7600 - val_loss: 0.6339 - val_acc: 0.7693\n",
      "Epoch 447/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7082 - acc: 0.7600 - val_loss: 0.6345 - val_acc: 0.7686\n",
      "Epoch 448/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7036 - acc: 0.7541 - val_loss: 0.6333 - val_acc: 0.7693\n",
      "Epoch 449/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6980 - acc: 0.7545 - val_loss: 0.6281 - val_acc: 0.7716\n",
      "Epoch 450/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6976 - acc: 0.7641 - val_loss: 0.6345 - val_acc: 0.7686\n",
      "Epoch 451/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7054 - acc: 0.7533 - val_loss: 0.6344 - val_acc: 0.7686\n",
      "Epoch 452/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6932 - acc: 0.7641 - val_loss: 0.6302 - val_acc: 0.7701\n",
      "Epoch 453/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7126 - acc: 0.7597 - val_loss: 0.6342 - val_acc: 0.7686\n",
      "Epoch 454/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7032 - acc: 0.7600 - val_loss: 0.6346 - val_acc: 0.7686\n",
      "Epoch 455/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7012 - acc: 0.7574 - val_loss: 0.6330 - val_acc: 0.7693\n",
      "Epoch 456/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7026 - acc: 0.7634 - val_loss: 0.6324 - val_acc: 0.7701\n",
      "Epoch 457/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6703 - acc: 0.7615 - val_loss: 0.6339 - val_acc: 0.7686\n",
      "Epoch 458/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6940 - acc: 0.7653 - val_loss: 0.6333 - val_acc: 0.7693\n",
      "Epoch 459/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6821 - acc: 0.7772 - val_loss: 0.6337 - val_acc: 0.7693\n",
      "Epoch 460/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6958 - acc: 0.7634 - val_loss: 0.6346 - val_acc: 0.7686\n",
      "Epoch 461/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7034 - acc: 0.7582 - val_loss: 0.6339 - val_acc: 0.7693\n",
      "Epoch 462/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6939 - acc: 0.7671 - val_loss: 0.6342 - val_acc: 0.7693\n",
      "Epoch 463/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6934 - acc: 0.7645 - val_loss: 0.6321 - val_acc: 0.7693\n",
      "Epoch 464/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6873 - acc: 0.7623 - val_loss: 0.6330 - val_acc: 0.7701\n",
      "Epoch 465/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6874 - acc: 0.7615 - val_loss: 0.6343 - val_acc: 0.7686\n",
      "\n",
      "Epoch 00465: loss improved from inf to 0.68744, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-1-000465-0.687444-0.768601.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 466/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7025 - acc: 0.7723 - val_loss: 0.6315 - val_acc: 0.7701\n",
      "Epoch 467/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7000 - acc: 0.7664 - val_loss: 0.6338 - val_acc: 0.7693\n",
      "Epoch 468/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6933 - acc: 0.7660 - val_loss: 0.6275 - val_acc: 0.7693\n",
      "Epoch 469/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6893 - acc: 0.7638 - val_loss: 0.6338 - val_acc: 0.7693\n",
      "Epoch 470/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6968 - acc: 0.7582 - val_loss: 0.6305 - val_acc: 0.7701\n",
      "Epoch 471/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6931 - acc: 0.7656 - val_loss: 0.6342 - val_acc: 0.7686\n",
      "Epoch 472/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6976 - acc: 0.7586 - val_loss: 0.6320 - val_acc: 0.7708\n",
      "Epoch 473/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6906 - acc: 0.7630 - val_loss: 0.6344 - val_acc: 0.7686\n",
      "Epoch 474/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7027 - acc: 0.7519 - val_loss: 0.6329 - val_acc: 0.7701\n",
      "Epoch 475/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6991 - acc: 0.7578 - val_loss: 0.6341 - val_acc: 0.7686\n",
      "Epoch 476/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6958 - acc: 0.7597 - val_loss: 0.6335 - val_acc: 0.7679\n",
      "Epoch 477/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6963 - acc: 0.7626 - val_loss: 0.6343 - val_acc: 0.7679\n",
      "Epoch 478/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6953 - acc: 0.7649 - val_loss: 0.6345 - val_acc: 0.7679\n",
      "Epoch 479/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6897 - acc: 0.7679 - val_loss: 0.6333 - val_acc: 0.7686\n",
      "Epoch 480/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7117 - acc: 0.7507 - val_loss: 0.6340 - val_acc: 0.7686\n",
      "Epoch 481/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6933 - acc: 0.7623 - val_loss: 0.6335 - val_acc: 0.7686\n",
      "Epoch 482/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6896 - acc: 0.7593 - val_loss: 0.6331 - val_acc: 0.7701\n",
      "Epoch 483/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7084 - acc: 0.7560 - val_loss: 0.6322 - val_acc: 0.7701\n",
      "Epoch 484/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6837 - acc: 0.7675 - val_loss: 0.6345 - val_acc: 0.7686\n",
      "Epoch 485/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6937 - acc: 0.7641 - val_loss: 0.6337 - val_acc: 0.7693\n",
      "Epoch 486/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6992 - acc: 0.7612 - val_loss: 0.6346 - val_acc: 0.7686\n",
      "Epoch 487/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7085 - acc: 0.7604 - val_loss: 0.6328 - val_acc: 0.7701\n",
      "Epoch 488/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6795 - acc: 0.7708 - val_loss: 0.6348 - val_acc: 0.7686\n",
      "Epoch 489/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6965 - acc: 0.7556 - val_loss: 0.6316 - val_acc: 0.7701\n",
      "Epoch 490/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6999 - acc: 0.7563 - val_loss: 0.6326 - val_acc: 0.7701\n",
      "Epoch 491/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7009 - acc: 0.7600 - val_loss: 0.6329 - val_acc: 0.7701\n",
      "Epoch 492/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6891 - acc: 0.7582 - val_loss: 0.6324 - val_acc: 0.7701\n",
      "Epoch 493/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7097 - acc: 0.7552 - val_loss: 0.6342 - val_acc: 0.7686\n",
      "Epoch 494/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6947 - acc: 0.7586 - val_loss: 0.6342 - val_acc: 0.7686\n",
      "Epoch 495/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6915 - acc: 0.7634 - val_loss: 0.6334 - val_acc: 0.7693\n",
      "Epoch 496/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6833 - acc: 0.7656 - val_loss: 0.6319 - val_acc: 0.7701\n",
      "Epoch 497/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6989 - acc: 0.7556 - val_loss: 0.6331 - val_acc: 0.7686\n",
      "Epoch 498/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7007 - acc: 0.7589 - val_loss: 0.6346 - val_acc: 0.7686\n",
      "Epoch 499/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6875 - acc: 0.7619 - val_loss: 0.6334 - val_acc: 0.7693\n",
      "Epoch 500/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6978 - acc: 0.7552 - val_loss: 0.6313 - val_acc: 0.7693\n",
      "\n",
      "Epoch 00500: saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/1-000500-0.697819-0.769345.hdf5\n",
      "Epoch 501/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6864 - acc: 0.7615 - val_loss: 0.6331 - val_acc: 0.7693\n",
      "Epoch 502/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6953 - acc: 0.7645 - val_loss: 0.6340 - val_acc: 0.7686\n",
      "Epoch 503/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7011 - acc: 0.7619 - val_loss: 0.6345 - val_acc: 0.7686\n",
      "Epoch 504/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6966 - acc: 0.7582 - val_loss: 0.6343 - val_acc: 0.7686\n",
      "Epoch 505/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6982 - acc: 0.7608 - val_loss: 0.6318 - val_acc: 0.7701\n",
      "Epoch 506/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6877 - acc: 0.7727 - val_loss: 0.6314 - val_acc: 0.7693\n",
      "Epoch 507/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6978 - acc: 0.7574 - val_loss: 0.6276 - val_acc: 0.7708\n",
      "Epoch 508/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6869 - acc: 0.7708 - val_loss: 0.6327 - val_acc: 0.7693\n",
      "Epoch 509/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6992 - acc: 0.7604 - val_loss: 0.6315 - val_acc: 0.7693\n",
      "Epoch 510/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6957 - acc: 0.7693 - val_loss: 0.6310 - val_acc: 0.7701\n",
      "Epoch 511/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6892 - acc: 0.7734 - val_loss: 0.6328 - val_acc: 0.7693\n",
      "Epoch 512/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6933 - acc: 0.7612 - val_loss: 0.6343 - val_acc: 0.7686\n",
      "Epoch 513/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7080 - acc: 0.7604 - val_loss: 0.6343 - val_acc: 0.7686\n",
      "Epoch 514/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6905 - acc: 0.7571 - val_loss: 0.6342 - val_acc: 0.7693\n",
      "Epoch 515/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7012 - acc: 0.7586 - val_loss: 0.6340 - val_acc: 0.7693\n",
      "Epoch 516/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7044 - acc: 0.7560 - val_loss: 0.6336 - val_acc: 0.7693\n",
      "Epoch 517/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6914 - acc: 0.7682 - val_loss: 0.6321 - val_acc: 0.7701\n",
      "Epoch 518/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6878 - acc: 0.7574 - val_loss: 0.6344 - val_acc: 0.7686\n",
      "Epoch 519/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6892 - acc: 0.7664 - val_loss: 0.6343 - val_acc: 0.7686\n",
      "Epoch 520/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7183 - acc: 0.7537 - val_loss: 0.6337 - val_acc: 0.7693\n",
      "Epoch 521/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6876 - acc: 0.7697 - val_loss: 0.6333 - val_acc: 0.7693\n",
      "Epoch 522/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6916 - acc: 0.7593 - val_loss: 0.6339 - val_acc: 0.7693\n",
      "Epoch 523/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6862 - acc: 0.7634 - val_loss: 0.6326 - val_acc: 0.7701\n",
      "Epoch 524/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7034 - acc: 0.7619 - val_loss: 0.6329 - val_acc: 0.7693\n",
      "Epoch 525/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7133 - acc: 0.7600 - val_loss: 0.6324 - val_acc: 0.7693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 526/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7042 - acc: 0.7608 - val_loss: 0.6340 - val_acc: 0.7686\n",
      "Epoch 527/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7100 - acc: 0.7571 - val_loss: 0.6345 - val_acc: 0.7686\n",
      "Epoch 528/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6962 - acc: 0.7641 - val_loss: 0.6343 - val_acc: 0.7686\n",
      "Epoch 529/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7019 - acc: 0.7615 - val_loss: 0.6326 - val_acc: 0.7693\n",
      "Epoch 530/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7063 - acc: 0.7571 - val_loss: 0.6340 - val_acc: 0.7693\n",
      "Epoch 531/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6957 - acc: 0.7597 - val_loss: 0.6340 - val_acc: 0.7686\n",
      "Epoch 532/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6981 - acc: 0.7593 - val_loss: 0.6335 - val_acc: 0.7693\n",
      "Epoch 533/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6944 - acc: 0.7567 - val_loss: 0.6331 - val_acc: 0.7693\n",
      "Epoch 534/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6930 - acc: 0.7645 - val_loss: 0.6336 - val_acc: 0.7693\n",
      "Epoch 535/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6919 - acc: 0.7705 - val_loss: 0.6341 - val_acc: 0.7686\n",
      "Epoch 536/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6972 - acc: 0.7533 - val_loss: 0.6314 - val_acc: 0.7693\n",
      "Epoch 537/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6961 - acc: 0.7630 - val_loss: 0.6325 - val_acc: 0.7693\n",
      "Epoch 538/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6820 - acc: 0.7664 - val_loss: 0.6305 - val_acc: 0.7693\n",
      "Epoch 539/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6978 - acc: 0.7608 - val_loss: 0.6341 - val_acc: 0.7693\n",
      "Epoch 540/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6998 - acc: 0.7615 - val_loss: 0.6338 - val_acc: 0.7686\n",
      "Epoch 541/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7014 - acc: 0.7623 - val_loss: 0.6344 - val_acc: 0.7686\n",
      "Epoch 542/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6895 - acc: 0.7634 - val_loss: 0.6347 - val_acc: 0.7686\n",
      "Epoch 543/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7075 - acc: 0.7556 - val_loss: 0.6337 - val_acc: 0.7693\n",
      "Epoch 544/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6883 - acc: 0.7716 - val_loss: 0.6348 - val_acc: 0.7686\n",
      "Epoch 545/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6863 - acc: 0.7623 - val_loss: 0.6338 - val_acc: 0.7693\n",
      "Epoch 546/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7056 - acc: 0.7589 - val_loss: 0.6329 - val_acc: 0.7693\n",
      "Epoch 547/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6968 - acc: 0.7500 - val_loss: 0.6339 - val_acc: 0.7686\n",
      "Epoch 548/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7052 - acc: 0.7560 - val_loss: 0.6338 - val_acc: 0.7693\n",
      "Epoch 549/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6819 - acc: 0.7667 - val_loss: 0.6332 - val_acc: 0.7701\n",
      "Epoch 550/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7082 - acc: 0.7548 - val_loss: 0.6344 - val_acc: 0.7686\n",
      "Epoch 551/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6889 - acc: 0.7634 - val_loss: 0.6322 - val_acc: 0.7701\n",
      "Epoch 552/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6981 - acc: 0.7615 - val_loss: 0.6322 - val_acc: 0.7701\n",
      "Epoch 553/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7005 - acc: 0.7653 - val_loss: 0.6341 - val_acc: 0.7686\n",
      "Epoch 554/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6989 - acc: 0.7548 - val_loss: 0.6341 - val_acc: 0.7686\n",
      "Epoch 555/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6931 - acc: 0.7615 - val_loss: 0.6315 - val_acc: 0.7701\n",
      "Epoch 556/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6933 - acc: 0.7660 - val_loss: 0.6345 - val_acc: 0.7686\n",
      "Epoch 557/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6979 - acc: 0.7619 - val_loss: 0.6319 - val_acc: 0.7693\n",
      "Epoch 558/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6842 - acc: 0.7649 - val_loss: 0.6332 - val_acc: 0.7693\n",
      "Epoch 559/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6936 - acc: 0.7604 - val_loss: 0.6343 - val_acc: 0.7686\n",
      "Epoch 560/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7114 - acc: 0.7578 - val_loss: 0.6331 - val_acc: 0.7693\n",
      "Epoch 561/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6981 - acc: 0.7641 - val_loss: 0.6335 - val_acc: 0.7693\n",
      "Epoch 562/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6917 - acc: 0.7586 - val_loss: 0.6346 - val_acc: 0.7686\n",
      "Epoch 563/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6888 - acc: 0.7634 - val_loss: 0.6334 - val_acc: 0.7693\n",
      "Epoch 564/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6841 - acc: 0.7626 - val_loss: 0.6342 - val_acc: 0.7686\n",
      "Epoch 565/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6764 - acc: 0.7612 - val_loss: 0.6254 - val_acc: 0.7701\n",
      "\n",
      "Epoch 00565: loss improved from inf to 0.67641, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-1-000565-0.676406-0.770089.hdf5\n",
      "Epoch 566/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7073 - acc: 0.7586 - val_loss: 0.6338 - val_acc: 0.7686\n",
      "Epoch 567/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6908 - acc: 0.7600 - val_loss: 0.6344 - val_acc: 0.7686\n",
      "Epoch 568/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6966 - acc: 0.7593 - val_loss: 0.6344 - val_acc: 0.7686\n",
      "Epoch 569/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7065 - acc: 0.7567 - val_loss: 0.6342 - val_acc: 0.7686\n",
      "Epoch 570/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6920 - acc: 0.7623 - val_loss: 0.6318 - val_acc: 0.7693\n",
      "Epoch 571/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7082 - acc: 0.7526 - val_loss: 0.6327 - val_acc: 0.7693\n",
      "Epoch 572/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6888 - acc: 0.7679 - val_loss: 0.6345 - val_acc: 0.7686\n",
      "Epoch 573/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6985 - acc: 0.7582 - val_loss: 0.6344 - val_acc: 0.7686\n",
      "Epoch 574/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6955 - acc: 0.7589 - val_loss: 0.6327 - val_acc: 0.7686\n",
      "Epoch 575/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6947 - acc: 0.7664 - val_loss: 0.6325 - val_acc: 0.7701\n",
      "Epoch 576/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7060 - acc: 0.7519 - val_loss: 0.6325 - val_acc: 0.7693\n",
      "Epoch 577/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6965 - acc: 0.7664 - val_loss: 0.6344 - val_acc: 0.7686\n",
      "Epoch 578/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6984 - acc: 0.7545 - val_loss: 0.6306 - val_acc: 0.7701\n",
      "Epoch 579/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6960 - acc: 0.7589 - val_loss: 0.6326 - val_acc: 0.7701\n",
      "Epoch 580/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7101 - acc: 0.7541 - val_loss: 0.6337 - val_acc: 0.7693\n",
      "Epoch 581/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7213 - acc: 0.7530 - val_loss: 0.6338 - val_acc: 0.7693\n",
      "Epoch 582/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6871 - acc: 0.7649 - val_loss: 0.6329 - val_acc: 0.7701\n",
      "Epoch 583/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6995 - acc: 0.7556 - val_loss: 0.6323 - val_acc: 0.7693\n",
      "Epoch 584/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6757 - acc: 0.7671 - val_loss: 0.6331 - val_acc: 0.7693\n",
      "Epoch 585/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7008 - acc: 0.7582 - val_loss: 0.6342 - val_acc: 0.7686\n",
      "Epoch 586/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6849 - acc: 0.7679 - val_loss: 0.6309 - val_acc: 0.7693\n",
      "Epoch 587/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6921 - acc: 0.7604 - val_loss: 0.6305 - val_acc: 0.7701\n",
      "Epoch 588/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6992 - acc: 0.7589 - val_loss: 0.6334 - val_acc: 0.7693\n",
      "Epoch 589/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7001 - acc: 0.7589 - val_loss: 0.6344 - val_acc: 0.7686\n",
      "Epoch 590/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6965 - acc: 0.7556 - val_loss: 0.6338 - val_acc: 0.7686\n",
      "Epoch 591/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6839 - acc: 0.7597 - val_loss: 0.6321 - val_acc: 0.7693\n",
      "Epoch 592/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7008 - acc: 0.7634 - val_loss: 0.6346 - val_acc: 0.7686\n",
      "Epoch 593/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6960 - acc: 0.7686 - val_loss: 0.6318 - val_acc: 0.7701\n",
      "Epoch 594/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.6879 - acc: 0.7701 - val_loss: 0.6329 - val_acc: 0.7693\n",
      "Epoch 595/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6986 - acc: 0.7675 - val_loss: 0.6329 - val_acc: 0.7693\n",
      "Epoch 596/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6966 - acc: 0.7589 - val_loss: 0.6323 - val_acc: 0.7693\n",
      "Epoch 597/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6923 - acc: 0.7615 - val_loss: 0.6322 - val_acc: 0.7693\n",
      "Epoch 598/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7059 - acc: 0.7578 - val_loss: 0.6332 - val_acc: 0.7693\n",
      "Epoch 599/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6955 - acc: 0.7560 - val_loss: 0.6346 - val_acc: 0.7686\n",
      "Epoch 600/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.6897 - acc: 0.7578 - val_loss: 0.6323 - val_acc: 0.7693\n",
      "\n",
      "Epoch 00600: saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/1-000600-0.689720-0.769345.hdf5\n",
      "Epoch 601/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7019 - acc: 0.7608 - val_loss: 0.6342 - val_acc: 0.7686\n",
      "Epoch 602/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6917 - acc: 0.7552 - val_loss: 0.6340 - val_acc: 0.7686\n",
      "Epoch 603/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6910 - acc: 0.7626 - val_loss: 0.6299 - val_acc: 0.7708\n",
      "Epoch 604/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6882 - acc: 0.7693 - val_loss: 0.6345 - val_acc: 0.7686\n",
      "Epoch 605/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7037 - acc: 0.7645 - val_loss: 0.6346 - val_acc: 0.7686\n",
      "Epoch 606/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6842 - acc: 0.7675 - val_loss: 0.6310 - val_acc: 0.7701\n",
      "Epoch 607/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7014 - acc: 0.7582 - val_loss: 0.6329 - val_acc: 0.7693\n",
      "Epoch 608/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6880 - acc: 0.7664 - val_loss: 0.6326 - val_acc: 0.7693\n",
      "Epoch 609/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6958 - acc: 0.7552 - val_loss: 0.6348 - val_acc: 0.7686\n",
      "Epoch 610/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7027 - acc: 0.7608 - val_loss: 0.6325 - val_acc: 0.7701\n",
      "Epoch 611/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6993 - acc: 0.7645 - val_loss: 0.6319 - val_acc: 0.7701\n",
      "Epoch 612/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7135 - acc: 0.7574 - val_loss: 0.6336 - val_acc: 0.7686\n",
      "Epoch 613/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6920 - acc: 0.7641 - val_loss: 0.6344 - val_acc: 0.7686\n",
      "Epoch 614/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6868 - acc: 0.7664 - val_loss: 0.6333 - val_acc: 0.7693\n",
      "Epoch 615/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6958 - acc: 0.7641 - val_loss: 0.6321 - val_acc: 0.7693\n",
      "Epoch 616/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6969 - acc: 0.7641 - val_loss: 0.6308 - val_acc: 0.7701\n",
      "Epoch 617/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7041 - acc: 0.7545 - val_loss: 0.6338 - val_acc: 0.7686\n",
      "Epoch 618/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7028 - acc: 0.7548 - val_loss: 0.6335 - val_acc: 0.7693\n",
      "Epoch 619/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6876 - acc: 0.7630 - val_loss: 0.6332 - val_acc: 0.7686\n",
      "Epoch 620/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6950 - acc: 0.7656 - val_loss: 0.6329 - val_acc: 0.7686\n",
      "Epoch 621/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7101 - acc: 0.7619 - val_loss: 0.6347 - val_acc: 0.7679\n",
      "Epoch 622/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6965 - acc: 0.7634 - val_loss: 0.6346 - val_acc: 0.7679\n",
      "Epoch 623/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6931 - acc: 0.7597 - val_loss: 0.6337 - val_acc: 0.7679\n",
      "Epoch 624/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6928 - acc: 0.7653 - val_loss: 0.6321 - val_acc: 0.7693\n",
      "Epoch 625/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7033 - acc: 0.7593 - val_loss: 0.6343 - val_acc: 0.7679\n",
      "Epoch 626/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6948 - acc: 0.7630 - val_loss: 0.6336 - val_acc: 0.7686\n",
      "Epoch 627/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6796 - acc: 0.7693 - val_loss: 0.6343 - val_acc: 0.7679\n",
      "Epoch 628/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7024 - acc: 0.7533 - val_loss: 0.6338 - val_acc: 0.7679\n",
      "Epoch 629/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7053 - acc: 0.7563 - val_loss: 0.6335 - val_acc: 0.7679\n",
      "Epoch 630/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6955 - acc: 0.7634 - val_loss: 0.6322 - val_acc: 0.7686\n",
      "Epoch 631/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6839 - acc: 0.7634 - val_loss: 0.6333 - val_acc: 0.7686\n",
      "Epoch 632/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7120 - acc: 0.7522 - val_loss: 0.6335 - val_acc: 0.7686\n",
      "Epoch 633/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7145 - acc: 0.7578 - val_loss: 0.6330 - val_acc: 0.7686\n",
      "Epoch 634/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6918 - acc: 0.7600 - val_loss: 0.6332 - val_acc: 0.7686\n",
      "Epoch 635/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7069 - acc: 0.7675 - val_loss: 0.6336 - val_acc: 0.7679\n",
      "Epoch 636/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7029 - acc: 0.7563 - val_loss: 0.6316 - val_acc: 0.7686\n",
      "Epoch 637/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6964 - acc: 0.7626 - val_loss: 0.6343 - val_acc: 0.7679\n",
      "Epoch 638/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7004 - acc: 0.7597 - val_loss: 0.6321 - val_acc: 0.7686\n",
      "Epoch 639/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7010 - acc: 0.7619 - val_loss: 0.6341 - val_acc: 0.7679\n",
      "Epoch 640/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6854 - acc: 0.7649 - val_loss: 0.6342 - val_acc: 0.7679\n",
      "Epoch 641/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6927 - acc: 0.7615 - val_loss: 0.6305 - val_acc: 0.7686\n",
      "Epoch 642/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6977 - acc: 0.7615 - val_loss: 0.6314 - val_acc: 0.7693\n",
      "Epoch 643/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6860 - acc: 0.7619 - val_loss: 0.6310 - val_acc: 0.7686\n",
      "Epoch 644/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7028 - acc: 0.7597 - val_loss: 0.6330 - val_acc: 0.7686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 645/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6817 - acc: 0.7705 - val_loss: 0.6319 - val_acc: 0.7686\n",
      "Epoch 646/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6863 - acc: 0.7593 - val_loss: 0.6305 - val_acc: 0.7693\n",
      "Epoch 647/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6977 - acc: 0.7641 - val_loss: 0.6338 - val_acc: 0.7679\n",
      "Epoch 648/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7035 - acc: 0.7630 - val_loss: 0.6336 - val_acc: 0.7679\n",
      "Epoch 649/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7064 - acc: 0.7496 - val_loss: 0.6325 - val_acc: 0.7693\n",
      "Epoch 650/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6952 - acc: 0.7537 - val_loss: 0.6299 - val_acc: 0.7693\n",
      "Epoch 651/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6988 - acc: 0.7578 - val_loss: 0.6335 - val_acc: 0.7686\n",
      "Epoch 652/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6920 - acc: 0.7604 - val_loss: 0.6334 - val_acc: 0.7679\n",
      "Epoch 653/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6976 - acc: 0.7578 - val_loss: 0.6328 - val_acc: 0.7686\n",
      "Epoch 654/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7021 - acc: 0.7548 - val_loss: 0.6322 - val_acc: 0.7693\n",
      "Epoch 655/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6975 - acc: 0.7645 - val_loss: 0.6328 - val_acc: 0.7693\n",
      "Epoch 656/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6871 - acc: 0.7567 - val_loss: 0.6329 - val_acc: 0.7686\n",
      "Epoch 657/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6890 - acc: 0.7693 - val_loss: 0.6335 - val_acc: 0.7686\n",
      "Epoch 00657: early stopping\n",
      "ModelCheckpoint 已经保存到 ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/1-final.hdf5\n",
      "save in: ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/log/20220201_2000_64_1_3_1.csv\n",
      "time: 0:17:26 s\n",
      "time: 1046.0 s\n",
      "average 1.046000 s\n",
      "1 epoch finished\n",
      "--------------------   best   --------------------\n",
      "no_activities: 10\n",
      "\n",
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1348/1348 [==============================] - 2s 2ms/step\n",
      "1-milan:\tacc: 76.93%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 0, 0, 0, 0, 9, 0, 1, 0, 0, 4, 1, 0, 4, 4, 0, 4, 1, 4, 0, 0, 0, 4, 0, 0, 7, 7, 7, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 7, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 5, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 4, 9, 9, 9, 9, 0, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 7, 4, 7, 7, 7, 7, 7, 0, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 0, 7, 0, 0, 0, 7, 0, 7, 7, 0, 0, 7, 7, 7, 7, 0, 7, 7, 0, 0, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 0, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 0, 0, 0, 0, 9, 7, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 9, 7, 0, 0, 0, 9, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 7, 7, 7, 7, 7, 2, 2, 9, 2, 7, 2, 2, 0, 0, 0, 0, 1, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 5, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 9, 0, 0, 0, 0, 4, 0, 9, 9, 4, 0, 7, 0, 7, 4, 7, 0, 0, 9, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 4, 4, 0, 0, 0, 0, 9, 0, 0, 0, 0, 7, 0, 0, 0, 9, 0, 0, 0, 9, 0, 4, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7, 7, 0, 0, 0, 0, 0, 0, 4, 4, 0, 4, 0, 0, 0, 5, 0, 0, 0, 4, 0, 9, 7, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 0, 0, 4, 4, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 4, 9, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 4, 0, 0, 0, 0, 0, 9, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 7, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 0, 7, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 7, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7, 0, 0, 0, 0, 7, 0, 0, 0, 7, 4, 4, 0, 0, 0, 0, 0, 7, 4, 4, 4, 4, 4, 4, 0, 4, 7, 4, 4, 4, 4, 4, 0, 0, 4, 4, 4, 4, 4, 0, 7, 4, 0, 4, 4, 0, 4, 0, 4, 0, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 7, 4, 4, 0, 4, 0, 7, 0, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 0, 4, 4, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 0, 4, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 0, 0, 9, 0, 0, 0, 0, 0, 0, 9, 0, 9, 9, 0, 0, 0, 0, 0, 4, 4, 0, 4, 0, 0, 0, 4, 0, 0, 7, 0, 4, 0, 4, 0, 4, 0, 4, 7, 4, 4, 0, 4, 0, 0, 0, 0, 4, 4, 4, 0, 0, 0, 4, 0, 4, 0, 0, 0]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.786350  0.850722  0.817271       623\n",
      "         Work   0.600000  0.120000  0.200000        25\n",
      "Take_medicine   1.000000  0.500000  0.666667        20\n",
      "        Sleep   0.000000  0.000000  0.000000        32\n",
      "        Relax   0.696721  0.598592  0.643939       142\n",
      "   Leave_Home   0.916667  0.916667  0.916667        72\n",
      "          Eat   0.000000  0.000000  0.000000         8\n",
      "         Cook   0.709524  0.809783  0.756345       184\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        30\n",
      "      Bathing   0.760784  0.915094  0.830835       212\n",
      "\n",
      "     accuracy                       0.769288      1348\n",
      "    macro avg   0.547005  0.471086  0.483172      1348\n",
      " weighted avg   0.728241  0.769288  0.742015      1348\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  29   0   0   1   0   0]\n",
      " [  0   3   0   0   1   1   0  14   6   0]\n",
      " [  0   0   0   0   0   3   0   5   0   0]\n",
      " [  0   0   0  10   2   8   0   0   0   0]\n",
      " [  0   0   0   0 194   1   1  15   1   0]\n",
      " [  0   0   0   0   0 149   0  34   1   0]\n",
      " [  0   0   0   0   0   2  66   4   0   0]\n",
      " [  0   2   0   0  21  36   5 530  29   0]\n",
      " [  0   0   0   0   0  10   0  47  85   0]\n",
      " [  0   0   0   0   8   0   0  24   0   0]]\n",
      "--------------------   final   --------------------\n",
      "no_activities: 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1348/1348 [==============================] - 2s 2ms/step\n",
      "1-milan:\tacc: 76.85%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 0, 0, 0, 0, 9, 0, 1, 0, 0, 4, 1, 0, 4, 4, 0, 4, 1, 4, 0, 0, 0, 4, 4, 0, 7, 7, 7, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 7, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 5, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 4, 9, 9, 9, 9, 0, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 7, 4, 7, 7, 7, 7, 7, 0, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 0, 7, 0, 0, 0, 7, 0, 7, 7, 0, 0, 7, 7, 7, 7, 0, 7, 7, 0, 0, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 0, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 0, 0, 0, 0, 9, 7, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 9, 7, 0, 0, 0, 9, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 7, 7, 7, 7, 7, 2, 2, 9, 2, 7, 2, 2, 0, 0, 0, 0, 1, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 5, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 9, 0, 0, 0, 0, 4, 0, 9, 9, 4, 0, 7, 0, 7, 4, 7, 0, 0, 9, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 4, 4, 0, 0, 0, 0, 9, 0, 0, 0, 0, 7, 0, 0, 0, 9, 0, 0, 0, 9, 0, 4, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7, 7, 0, 0, 0, 0, 0, 0, 4, 4, 0, 4, 0, 0, 0, 5, 0, 0, 0, 4, 0, 9, 7, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 0, 0, 4, 4, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 4, 9, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 4, 0, 0, 0, 0, 0, 9, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 7, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 0, 7, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 4, 0, 0, 7, 0, 0, 7, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7, 0, 0, 0, 0, 7, 0, 0, 0, 7, 4, 4, 0, 0, 0, 0, 0, 7, 4, 4, 4, 4, 4, 4, 0, 4, 7, 4, 4, 4, 4, 4, 0, 0, 4, 4, 4, 4, 4, 0, 7, 4, 0, 4, 4, 0, 4, 0, 4, 0, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 7, 4, 4, 0, 4, 0, 7, 0, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 0, 4, 4, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 0, 4, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 0, 0, 9, 0, 0, 0, 0, 0, 0, 9, 0, 9, 9, 0, 0, 0, 0, 0, 4, 4, 0, 4, 0, 0, 0, 4, 0, 0, 7, 0, 4, 0, 4, 0, 4, 0, 4, 7, 4, 4, 0, 4, 0, 0, 0, 0, 4, 4, 4, 0, 0, 0, 4, 0, 4, 0, 0, 0]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.787202  0.849117  0.816988       623\n",
      "         Work   0.600000  0.120000  0.200000        25\n",
      "Take_medicine   1.000000  0.500000  0.666667        20\n",
      "        Sleep   0.000000  0.000000  0.000000        32\n",
      "        Relax   0.685484  0.598592  0.639098       142\n",
      "   Leave_Home   0.916667  0.916667  0.916667        72\n",
      "          Eat   0.000000  0.000000  0.000000         8\n",
      "         Cook   0.709524  0.809783  0.756345       184\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        30\n",
      "      Bathing   0.760784  0.915094  0.830835       212\n",
      "\n",
      "     accuracy                       0.768546      1348\n",
      "    macro avg   0.545966  0.470925  0.482660      1348\n",
      " weighted avg   0.727451  0.768546  0.741375      1348\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  29   0   0   1   0   0]\n",
      " [  0   3   0   0   1   1   0  13   7   0]\n",
      " [  0   0   0   0   0   3   0   5   0   0]\n",
      " [  0   0   0  10   2   8   0   0   0   0]\n",
      " [  0   0   0   0 194   1   1  15   1   0]\n",
      " [  0   0   0   0   0 149   0  34   1   0]\n",
      " [  0   0   0   0   0   2  66   4   0   0]\n",
      " [  0   2   0   0  21  36   5 529  30   0]\n",
      " [  0   0   0   0   0  10   0  47  85   0]\n",
      " [  0   0   0   0   8   0   0  24   0   0]]\n",
      "no_activities: 10\n",
      "\n",
      "Begin training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "42/42 [==============================] - 5s 109ms/step - loss: 1.9022 - acc: 0.4554 - val_loss: 1.5059 - val_acc: 0.6086\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 1.4230 - acc: 0.6176 - val_loss: 1.2852 - val_acc: 0.6481\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.2548 - acc: 0.6354 - val_loss: 1.1433 - val_acc: 0.6510\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 1.1577 - acc: 0.6473 - val_loss: 1.0743 - val_acc: 0.6443\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 1s 36ms/step - loss: 1.1237 - acc: 0.6462 - val_loss: 1.0226 - val_acc: 0.6577\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0958 - acc: 0.6462 - val_loss: 0.9951 - val_acc: 0.6600\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.0484 - acc: 0.6592 - val_loss: 0.9628 - val_acc: 0.6637\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0203 - acc: 0.6607 - val_loss: 0.9416 - val_acc: 0.6659\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0104 - acc: 0.6577 - val_loss: 0.9204 - val_acc: 0.6644\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9907 - acc: 0.6722 - val_loss: 0.9059 - val_acc: 0.6615\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.9712 - acc: 0.6696 - val_loss: 0.8797 - val_acc: 0.6719\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9610 - acc: 0.6808 - val_loss: 0.8726 - val_acc: 0.6964\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.9422 - acc: 0.7005 - val_loss: 0.8564 - val_acc: 0.7121\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9487 - acc: 0.6864 - val_loss: 0.8452 - val_acc: 0.7121\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9136 - acc: 0.7016 - val_loss: 0.8323 - val_acc: 0.7240\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.9099 - acc: 0.7039 - val_loss: 0.8146 - val_acc: 0.7336\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8913 - acc: 0.7161 - val_loss: 0.8084 - val_acc: 0.7336\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.8846 - acc: 0.7228 - val_loss: 0.7980 - val_acc: 0.7448\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.8757 - acc: 0.7158 - val_loss: 0.7914 - val_acc: 0.7403\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8731 - acc: 0.7180 - val_loss: 0.7778 - val_acc: 0.7463\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8798 - acc: 0.7191 - val_loss: 0.7804 - val_acc: 0.7381\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8658 - acc: 0.7225 - val_loss: 0.7628 - val_acc: 0.7515\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8607 - acc: 0.7284 - val_loss: 0.7586 - val_acc: 0.7582\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8526 - acc: 0.7307 - val_loss: 0.7559 - val_acc: 0.7574\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8457 - acc: 0.7158 - val_loss: 0.7500 - val_acc: 0.7500\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8432 - acc: 0.7314 - val_loss: 0.7518 - val_acc: 0.7515\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8376 - acc: 0.7232 - val_loss: 0.7430 - val_acc: 0.7493\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8264 - acc: 0.7225 - val_loss: 0.7402 - val_acc: 0.7507\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8368 - acc: 0.7318 - val_loss: 0.7403 - val_acc: 0.7574\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8114 - acc: 0.7340 - val_loss: 0.7261 - val_acc: 0.7560\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.8302 - acc: 0.7344 - val_loss: 0.7329 - val_acc: 0.7574\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8100 - acc: 0.7340 - val_loss: 0.7288 - val_acc: 0.7522\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8273 - acc: 0.7303 - val_loss: 0.7244 - val_acc: 0.7560\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7994 - acc: 0.7333 - val_loss: 0.7151 - val_acc: 0.7604\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8284 - acc: 0.7292 - val_loss: 0.7132 - val_acc: 0.7612\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.8013 - acc: 0.7336 - val_loss: 0.7189 - val_acc: 0.7567\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8104 - acc: 0.7284 - val_loss: 0.7143 - val_acc: 0.7582\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8148 - acc: 0.7254 - val_loss: 0.7135 - val_acc: 0.7589\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7865 - acc: 0.7426 - val_loss: 0.7080 - val_acc: 0.7582\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7952 - acc: 0.7347 - val_loss: 0.7047 - val_acc: 0.7597\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.8111 - acc: 0.7359 - val_loss: 0.7023 - val_acc: 0.7582\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7834 - acc: 0.7374 - val_loss: 0.7003 - val_acc: 0.7582\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7973 - acc: 0.7310 - val_loss: 0.6974 - val_acc: 0.7597\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.8142 - acc: 0.7284 - val_loss: 0.7013 - val_acc: 0.7567\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7905 - acc: 0.7355 - val_loss: 0.6974 - val_acc: 0.7604\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7915 - acc: 0.7325 - val_loss: 0.6961 - val_acc: 0.7567\n",
      "Epoch 47/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7832 - acc: 0.7321 - val_loss: 0.6924 - val_acc: 0.7589\n",
      "Epoch 48/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7910 - acc: 0.7321 - val_loss: 0.6947 - val_acc: 0.7619\n",
      "Epoch 49/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7825 - acc: 0.7392 - val_loss: 0.6915 - val_acc: 0.7597\n",
      "Epoch 50/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7887 - acc: 0.7370 - val_loss: 0.6952 - val_acc: 0.7567\n",
      "Epoch 51/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7810 - acc: 0.7440 - val_loss: 0.6893 - val_acc: 0.7589\n",
      "Epoch 52/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7717 - acc: 0.7414 - val_loss: 0.6889 - val_acc: 0.7582\n",
      "Epoch 53/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7745 - acc: 0.7467 - val_loss: 0.6813 - val_acc: 0.7597\n",
      "Epoch 54/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7587 - acc: 0.7493 - val_loss: 0.6810 - val_acc: 0.7612\n",
      "Epoch 55/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7784 - acc: 0.7463 - val_loss: 0.6811 - val_acc: 0.7641\n",
      "Epoch 56/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7810 - acc: 0.7333 - val_loss: 0.6813 - val_acc: 0.7589\n",
      "Epoch 57/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.7614 - acc: 0.7407 - val_loss: 0.6817 - val_acc: 0.7619\n",
      "Epoch 58/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7683 - acc: 0.7414 - val_loss: 0.6780 - val_acc: 0.7626\n",
      "Epoch 59/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7607 - acc: 0.7400 - val_loss: 0.6821 - val_acc: 0.7619\n",
      "Epoch 60/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7648 - acc: 0.7455 - val_loss: 0.6775 - val_acc: 0.7582\n",
      "Epoch 61/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.7628 - acc: 0.7351 - val_loss: 0.6777 - val_acc: 0.7626\n",
      "Epoch 62/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7551 - acc: 0.7515 - val_loss: 0.6748 - val_acc: 0.7612\n",
      "Epoch 63/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7544 - acc: 0.7444 - val_loss: 0.6732 - val_acc: 0.7604\n",
      "Epoch 64/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7492 - acc: 0.7422 - val_loss: 0.6668 - val_acc: 0.7671\n",
      "Epoch 65/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7462 - acc: 0.7504 - val_loss: 0.6762 - val_acc: 0.7597\n",
      "\n",
      "Epoch 00065: loss improved from inf to 0.74617, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-2-000065-0.746173-0.759673.hdf5\n",
      "Epoch 66/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7492 - acc: 0.7414 - val_loss: 0.6701 - val_acc: 0.7597\n",
      "Epoch 67/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7499 - acc: 0.7455 - val_loss: 0.6708 - val_acc: 0.7626\n",
      "Epoch 68/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7518 - acc: 0.7545 - val_loss: 0.6669 - val_acc: 0.7634\n",
      "Epoch 69/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7410 - acc: 0.7493 - val_loss: 0.6677 - val_acc: 0.7619\n",
      "\n",
      "Epoch 00069: loss improved from 0.74617 to 0.74095, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-2-000069-0.740954-0.761905.hdf5\n",
      "Epoch 70/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7361 - acc: 0.7470 - val_loss: 0.6688 - val_acc: 0.7626\n",
      "Epoch 71/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7535 - acc: 0.7478 - val_loss: 0.6693 - val_acc: 0.7634\n",
      "Epoch 72/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7420 - acc: 0.7470 - val_loss: 0.6697 - val_acc: 0.7619\n",
      "Epoch 73/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7504 - acc: 0.7414 - val_loss: 0.6653 - val_acc: 0.7664\n",
      "Epoch 74/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7485 - acc: 0.7470 - val_loss: 0.6616 - val_acc: 0.7634\n",
      "Epoch 75/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7417 - acc: 0.7485 - val_loss: 0.6641 - val_acc: 0.7664\n",
      "Epoch 76/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7289 - acc: 0.7541 - val_loss: 0.6639 - val_acc: 0.7656\n",
      "Epoch 77/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7517 - acc: 0.7414 - val_loss: 0.6671 - val_acc: 0.7649\n",
      "Epoch 78/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7397 - acc: 0.7493 - val_loss: 0.6630 - val_acc: 0.7612\n",
      "Epoch 79/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7533 - acc: 0.7500 - val_loss: 0.6606 - val_acc: 0.7626\n",
      "Epoch 80/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7302 - acc: 0.7493 - val_loss: 0.6588 - val_acc: 0.7664\n",
      "Epoch 81/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7403 - acc: 0.7452 - val_loss: 0.6615 - val_acc: 0.7641\n",
      "\n",
      "Epoch 00081: loss improved from 0.74095 to 0.74032, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-2-000081-0.740323-0.764137.hdf5\n",
      "Epoch 82/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7443 - acc: 0.7519 - val_loss: 0.6619 - val_acc: 0.7656\n",
      "Epoch 83/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7240 - acc: 0.7567 - val_loss: 0.6588 - val_acc: 0.7641\n",
      "Epoch 84/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7395 - acc: 0.7493 - val_loss: 0.6569 - val_acc: 0.7656\n",
      "Epoch 85/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7412 - acc: 0.7481 - val_loss: 0.6584 - val_acc: 0.7679\n",
      "Epoch 86/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7314 - acc: 0.7511 - val_loss: 0.6570 - val_acc: 0.7664\n",
      "Epoch 87/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7250 - acc: 0.7586 - val_loss: 0.6554 - val_acc: 0.7641\n",
      "Epoch 88/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7321 - acc: 0.7533 - val_loss: 0.6556 - val_acc: 0.7641\n",
      "Epoch 89/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7261 - acc: 0.7537 - val_loss: 0.6523 - val_acc: 0.7626\n",
      "\n",
      "Epoch 00089: loss improved from 0.74032 to 0.72611, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-2-000089-0.726109-0.762649.hdf5\n",
      "Epoch 90/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7345 - acc: 0.7474 - val_loss: 0.6523 - val_acc: 0.7641\n",
      "Epoch 91/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7228 - acc: 0.7522 - val_loss: 0.6536 - val_acc: 0.7649\n",
      "Epoch 92/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7295 - acc: 0.7533 - val_loss: 0.6540 - val_acc: 0.7641\n",
      "Epoch 93/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7235 - acc: 0.7560 - val_loss: 0.6536 - val_acc: 0.7693\n",
      "\n",
      "Epoch 00093: loss improved from 0.72611 to 0.72348, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-2-000093-0.723484-0.769345.hdf5\n",
      "Epoch 94/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7186 - acc: 0.7645 - val_loss: 0.6505 - val_acc: 0.7679\n",
      "Epoch 95/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7290 - acc: 0.7481 - val_loss: 0.6561 - val_acc: 0.7649\n",
      "Epoch 96/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7138 - acc: 0.7541 - val_loss: 0.6557 - val_acc: 0.7626\n",
      "Epoch 97/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7178 - acc: 0.7533 - val_loss: 0.6549 - val_acc: 0.7612\n",
      "\n",
      "Epoch 00097: loss improved from 0.72348 to 0.71780, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-2-000097-0.717799-0.761161.hdf5\n",
      "Epoch 98/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7121 - acc: 0.7578 - val_loss: 0.6515 - val_acc: 0.7626\n",
      "Epoch 99/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7212 - acc: 0.7574 - val_loss: 0.6498 - val_acc: 0.7656\n",
      "Epoch 100/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7233 - acc: 0.7500 - val_loss: 0.6510 - val_acc: 0.7664\n",
      "\n",
      "Epoch 00100: saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/2-000100-0.723271-0.766369.hdf5\n",
      "Epoch 101/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7119 - acc: 0.7560 - val_loss: 0.6524 - val_acc: 0.7634\n",
      "Epoch 102/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7124 - acc: 0.7604 - val_loss: 0.6503 - val_acc: 0.7693\n",
      "Epoch 103/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7171 - acc: 0.7619 - val_loss: 0.6494 - val_acc: 0.7693\n",
      "Epoch 104/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7125 - acc: 0.7600 - val_loss: 0.6498 - val_acc: 0.7641\n",
      "Epoch 105/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7292 - acc: 0.7485 - val_loss: 0.6495 - val_acc: 0.7641\n",
      "Epoch 106/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7284 - acc: 0.7511 - val_loss: 0.6472 - val_acc: 0.7656\n",
      "Epoch 107/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7110 - acc: 0.7645 - val_loss: 0.6486 - val_acc: 0.7634\n",
      "Epoch 108/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7312 - acc: 0.7604 - val_loss: 0.6487 - val_acc: 0.7612\n",
      "Epoch 109/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.7190 - acc: 0.7537 - val_loss: 0.6463 - val_acc: 0.7656\n",
      "Epoch 110/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7049 - acc: 0.7552 - val_loss: 0.6483 - val_acc: 0.7641\n",
      "Epoch 111/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7263 - acc: 0.7511 - val_loss: 0.6476 - val_acc: 0.7649\n",
      "Epoch 112/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7204 - acc: 0.7478 - val_loss: 0.6478 - val_acc: 0.7708\n",
      "Epoch 113/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7350 - acc: 0.7493 - val_loss: 0.6470 - val_acc: 0.7693\n",
      "Epoch 114/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7170 - acc: 0.7548 - val_loss: 0.6468 - val_acc: 0.7679\n",
      "Epoch 115/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7111 - acc: 0.7526 - val_loss: 0.6425 - val_acc: 0.7693\n",
      "Epoch 116/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7313 - acc: 0.7507 - val_loss: 0.6479 - val_acc: 0.7686\n",
      "Epoch 117/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7120 - acc: 0.7567 - val_loss: 0.6399 - val_acc: 0.7693\n",
      "Epoch 118/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7144 - acc: 0.7578 - val_loss: 0.6425 - val_acc: 0.7783\n",
      "Epoch 119/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7124 - acc: 0.7560 - val_loss: 0.6422 - val_acc: 0.7753\n",
      "Epoch 120/1000\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.7005 - acc: 0.7619 - val_loss: 0.6453 - val_acc: 0.7626\n",
      "Epoch 121/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7087 - acc: 0.7537 - val_loss: 0.6412 - val_acc: 0.7671\n",
      "Epoch 122/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7161 - acc: 0.7511 - val_loss: 0.6407 - val_acc: 0.7738\n",
      "Epoch 123/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.7080 - acc: 0.7530 - val_loss: 0.6425 - val_acc: 0.7716\n",
      "Epoch 124/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7226 - acc: 0.7526 - val_loss: 0.6439 - val_acc: 0.7723\n",
      "Epoch 125/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7236 - acc: 0.7556 - val_loss: 0.6426 - val_acc: 0.7738\n",
      "Epoch 126/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7122 - acc: 0.7612 - val_loss: 0.6429 - val_acc: 0.7746\n",
      "Epoch 127/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7223 - acc: 0.7504 - val_loss: 0.6413 - val_acc: 0.7768\n",
      "Epoch 128/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7001 - acc: 0.7623 - val_loss: 0.6424 - val_acc: 0.7768\n",
      "Epoch 129/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6937 - acc: 0.7641 - val_loss: 0.6411 - val_acc: 0.7723\n",
      "Epoch 130/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7082 - acc: 0.7604 - val_loss: 0.6392 - val_acc: 0.7798\n",
      "Epoch 131/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7092 - acc: 0.7604 - val_loss: 0.6410 - val_acc: 0.7820\n",
      "Epoch 132/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6951 - acc: 0.7660 - val_loss: 0.6409 - val_acc: 0.7805\n",
      "Epoch 133/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6994 - acc: 0.7671 - val_loss: 0.6378 - val_acc: 0.7775\n",
      "Epoch 134/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6929 - acc: 0.7682 - val_loss: 0.6377 - val_acc: 0.7746\n",
      "Epoch 135/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6986 - acc: 0.7653 - val_loss: 0.6381 - val_acc: 0.7760\n",
      "Epoch 136/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7052 - acc: 0.7641 - val_loss: 0.6405 - val_acc: 0.7768\n",
      "Epoch 137/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6897 - acc: 0.7671 - val_loss: 0.6384 - val_acc: 0.7820\n",
      "Epoch 138/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7186 - acc: 0.7533 - val_loss: 0.6304 - val_acc: 0.7827\n",
      "Epoch 139/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7098 - acc: 0.7522 - val_loss: 0.6403 - val_acc: 0.7760\n",
      "Epoch 140/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7042 - acc: 0.7519 - val_loss: 0.6399 - val_acc: 0.7760\n",
      "Epoch 141/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6932 - acc: 0.7619 - val_loss: 0.6389 - val_acc: 0.7760\n",
      "Epoch 142/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6933 - acc: 0.7679 - val_loss: 0.6382 - val_acc: 0.7768\n",
      "Epoch 143/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7123 - acc: 0.7582 - val_loss: 0.6411 - val_acc: 0.7805\n",
      "Epoch 144/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7121 - acc: 0.7638 - val_loss: 0.6427 - val_acc: 0.7760\n",
      "Epoch 145/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6890 - acc: 0.7638 - val_loss: 0.6381 - val_acc: 0.7753\n",
      "Epoch 146/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6927 - acc: 0.7589 - val_loss: 0.6406 - val_acc: 0.7768\n",
      "Epoch 147/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7108 - acc: 0.7522 - val_loss: 0.6390 - val_acc: 0.7775\n",
      "Epoch 148/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7024 - acc: 0.7571 - val_loss: 0.6388 - val_acc: 0.7783\n",
      "Epoch 149/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7043 - acc: 0.7552 - val_loss: 0.6344 - val_acc: 0.7798\n",
      "Epoch 150/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6987 - acc: 0.7582 - val_loss: 0.6362 - val_acc: 0.7768\n",
      "Epoch 151/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7037 - acc: 0.7533 - val_loss: 0.6381 - val_acc: 0.7820\n",
      "Epoch 152/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7008 - acc: 0.7560 - val_loss: 0.6395 - val_acc: 0.7798\n",
      "Epoch 153/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6955 - acc: 0.7589 - val_loss: 0.6396 - val_acc: 0.7775\n",
      "Epoch 154/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6934 - acc: 0.7593 - val_loss: 0.6398 - val_acc: 0.7753\n",
      "Epoch 155/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6899 - acc: 0.7626 - val_loss: 0.6367 - val_acc: 0.7842\n",
      "Epoch 156/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6939 - acc: 0.7612 - val_loss: 0.6371 - val_acc: 0.7827\n",
      "Epoch 157/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7000 - acc: 0.7560 - val_loss: 0.6354 - val_acc: 0.7820\n",
      "Epoch 158/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7015 - acc: 0.7560 - val_loss: 0.6374 - val_acc: 0.7775\n",
      "Epoch 159/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6915 - acc: 0.7638 - val_loss: 0.6358 - val_acc: 0.7753\n",
      "Epoch 160/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6895 - acc: 0.7701 - val_loss: 0.6333 - val_acc: 0.7798\n",
      "Epoch 161/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6933 - acc: 0.7630 - val_loss: 0.6364 - val_acc: 0.7812\n",
      "Epoch 162/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6954 - acc: 0.7604 - val_loss: 0.6344 - val_acc: 0.7820\n",
      "Epoch 163/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6936 - acc: 0.7667 - val_loss: 0.6362 - val_acc: 0.7820\n",
      "Epoch 164/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6955 - acc: 0.7619 - val_loss: 0.6341 - val_acc: 0.7827\n",
      "Epoch 165/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.6819 - acc: 0.7719 - val_loss: 0.6342 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00165: loss improved from inf to 0.68186, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-2-000165-0.681857-0.785714.hdf5\n",
      "Epoch 166/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6887 - acc: 0.7667 - val_loss: 0.6348 - val_acc: 0.7842\n",
      "Epoch 167/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6965 - acc: 0.7597 - val_loss: 0.6345 - val_acc: 0.7842\n",
      "Epoch 168/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6929 - acc: 0.7600 - val_loss: 0.6337 - val_acc: 0.7872\n",
      "Epoch 169/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6813 - acc: 0.7671 - val_loss: 0.6355 - val_acc: 0.7775\n",
      "\n",
      "Epoch 00169: loss improved from 0.68186 to 0.68133, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-2-000169-0.681333-0.777530.hdf5\n",
      "Epoch 170/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6950 - acc: 0.7649 - val_loss: 0.6327 - val_acc: 0.7850\n",
      "Epoch 171/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6860 - acc: 0.7738 - val_loss: 0.6353 - val_acc: 0.7835\n",
      "Epoch 172/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6917 - acc: 0.7600 - val_loss: 0.6349 - val_acc: 0.7790\n",
      "Epoch 173/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6742 - acc: 0.7708 - val_loss: 0.6335 - val_acc: 0.7835\n",
      "\n",
      "Epoch 00173: loss improved from 0.68133 to 0.67419, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-2-000173-0.674185-0.783482.hdf5\n",
      "Epoch 174/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6872 - acc: 0.7593 - val_loss: 0.6348 - val_acc: 0.7850\n",
      "Epoch 175/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6824 - acc: 0.7638 - val_loss: 0.6317 - val_acc: 0.7835\n",
      "Epoch 176/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6789 - acc: 0.7582 - val_loss: 0.6304 - val_acc: 0.7835\n",
      "Epoch 177/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.7022 - acc: 0.7537 - val_loss: 0.6339 - val_acc: 0.7842\n",
      "Epoch 178/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6841 - acc: 0.7708 - val_loss: 0.6334 - val_acc: 0.7835\n",
      "Epoch 179/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7036 - acc: 0.7586 - val_loss: 0.6331 - val_acc: 0.7835\n",
      "Epoch 180/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7011 - acc: 0.7589 - val_loss: 0.6349 - val_acc: 0.7827\n",
      "Epoch 181/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6873 - acc: 0.7615 - val_loss: 0.6347 - val_acc: 0.7842\n",
      "Epoch 182/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7018 - acc: 0.7578 - val_loss: 0.6306 - val_acc: 0.7827\n",
      "Epoch 183/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6942 - acc: 0.7641 - val_loss: 0.6344 - val_acc: 0.7835\n",
      "Epoch 184/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6963 - acc: 0.7608 - val_loss: 0.6327 - val_acc: 0.7812\n",
      "Epoch 185/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.6892 - acc: 0.7660 - val_loss: 0.6328 - val_acc: 0.7820\n",
      "Epoch 186/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6863 - acc: 0.7589 - val_loss: 0.6340 - val_acc: 0.7746\n",
      "Epoch 187/1000\n",
      "42/42 [==============================] - 1s 35ms/step - loss: 0.6664 - acc: 0.7723 - val_loss: 0.6293 - val_acc: 0.7835\n",
      "Epoch 188/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6774 - acc: 0.7645 - val_loss: 0.6285 - val_acc: 0.7827\n",
      "Epoch 189/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.6655 - acc: 0.7753 - val_loss: 0.6303 - val_acc: 0.7842\n",
      "\n",
      "Epoch 00189: loss improved from 0.67419 to 0.66550, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-2-000189-0.665501-0.784226.hdf5\n",
      "Epoch 190/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6845 - acc: 0.7623 - val_loss: 0.6300 - val_acc: 0.7835\n",
      "Epoch 191/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6767 - acc: 0.7600 - val_loss: 0.6310 - val_acc: 0.7783\n",
      "Epoch 192/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.6842 - acc: 0.7686 - val_loss: 0.6298 - val_acc: 0.7835\n",
      "Epoch 193/1000\n",
      "42/42 [==============================] - 1s 34ms/step - loss: 0.6851 - acc: 0.7656 - val_loss: 0.6272 - val_acc: 0.7850\n",
      "Epoch 194/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6797 - acc: 0.7608 - val_loss: 0.6311 - val_acc: 0.7850\n",
      "Epoch 195/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6869 - acc: 0.7600 - val_loss: 0.6273 - val_acc: 0.7850\n",
      "Epoch 196/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6946 - acc: 0.7604 - val_loss: 0.6254 - val_acc: 0.7835\n",
      "Epoch 197/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6879 - acc: 0.7645 - val_loss: 0.6324 - val_acc: 0.7798\n",
      "Epoch 198/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6831 - acc: 0.7679 - val_loss: 0.6292 - val_acc: 0.7835\n",
      "Epoch 199/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6708 - acc: 0.7664 - val_loss: 0.6280 - val_acc: 0.7835\n",
      "Epoch 200/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6941 - acc: 0.7653 - val_loss: 0.6266 - val_acc: 0.7842\n",
      "\n",
      "Epoch 00200: saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/2-000200-0.694054-0.784226.hdf5\n",
      "Epoch 201/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6793 - acc: 0.7667 - val_loss: 0.6296 - val_acc: 0.7820\n",
      "Epoch 202/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6791 - acc: 0.7697 - val_loss: 0.6289 - val_acc: 0.7798\n",
      "Epoch 203/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6799 - acc: 0.7645 - val_loss: 0.6287 - val_acc: 0.7850\n",
      "Epoch 204/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6822 - acc: 0.7686 - val_loss: 0.6270 - val_acc: 0.7850\n",
      "Epoch 205/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6775 - acc: 0.7682 - val_loss: 0.6268 - val_acc: 0.7820\n",
      "Epoch 206/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6926 - acc: 0.7660 - val_loss: 0.6265 - val_acc: 0.7850\n",
      "Epoch 207/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6691 - acc: 0.7705 - val_loss: 0.6277 - val_acc: 0.7820\n",
      "Epoch 208/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6917 - acc: 0.7626 - val_loss: 0.6279 - val_acc: 0.7820\n",
      "Epoch 209/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6764 - acc: 0.7645 - val_loss: 0.6289 - val_acc: 0.7798\n",
      "\n",
      "Epoch 00209: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 210/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6837 - acc: 0.7612 - val_loss: 0.6272 - val_acc: 0.7835\n",
      "Epoch 211/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6709 - acc: 0.7734 - val_loss: 0.6262 - val_acc: 0.7857\n",
      "Epoch 212/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6772 - acc: 0.7641 - val_loss: 0.6269 - val_acc: 0.7842\n",
      "Epoch 213/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6688 - acc: 0.7682 - val_loss: 0.6262 - val_acc: 0.7857\n",
      "Epoch 214/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6786 - acc: 0.7630 - val_loss: 0.6282 - val_acc: 0.7842\n",
      "Epoch 215/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6741 - acc: 0.7686 - val_loss: 0.6266 - val_acc: 0.7842\n",
      "Epoch 216/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6850 - acc: 0.7623 - val_loss: 0.6253 - val_acc: 0.7850\n",
      "Epoch 217/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6727 - acc: 0.7686 - val_loss: 0.6265 - val_acc: 0.7842\n",
      "Epoch 218/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6798 - acc: 0.7634 - val_loss: 0.6277 - val_acc: 0.7842\n",
      "Epoch 219/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6568 - acc: 0.7719 - val_loss: 0.6280 - val_acc: 0.7842\n",
      "Epoch 220/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6891 - acc: 0.7615 - val_loss: 0.6262 - val_acc: 0.7842\n",
      "Epoch 221/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6833 - acc: 0.7638 - val_loss: 0.6238 - val_acc: 0.7850\n",
      "Epoch 222/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6908 - acc: 0.7645 - val_loss: 0.6276 - val_acc: 0.7850\n",
      "Epoch 223/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6763 - acc: 0.7675 - val_loss: 0.6268 - val_acc: 0.7842\n",
      "Epoch 224/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6742 - acc: 0.7731 - val_loss: 0.6217 - val_acc: 0.7850\n",
      "Epoch 225/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6876 - acc: 0.7615 - val_loss: 0.6247 - val_acc: 0.7857\n",
      "Epoch 226/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6722 - acc: 0.7630 - val_loss: 0.6266 - val_acc: 0.7857\n",
      "Epoch 227/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6719 - acc: 0.7656 - val_loss: 0.6254 - val_acc: 0.7850\n",
      "Epoch 228/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6840 - acc: 0.7671 - val_loss: 0.6265 - val_acc: 0.7842\n",
      "Epoch 229/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6853 - acc: 0.7619 - val_loss: 0.6276 - val_acc: 0.7827\n",
      "Epoch 230/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6968 - acc: 0.7578 - val_loss: 0.6245 - val_acc: 0.7850\n",
      "Epoch 231/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6606 - acc: 0.7664 - val_loss: 0.6268 - val_acc: 0.7850\n",
      "Epoch 232/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6844 - acc: 0.7571 - val_loss: 0.6271 - val_acc: 0.7850\n",
      "Epoch 233/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6645 - acc: 0.7783 - val_loss: 0.6260 - val_acc: 0.7850\n",
      "Epoch 234/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6779 - acc: 0.7586 - val_loss: 0.6258 - val_acc: 0.7835\n",
      "Epoch 235/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6664 - acc: 0.7626 - val_loss: 0.6273 - val_acc: 0.7842\n",
      "Epoch 236/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6793 - acc: 0.7645 - val_loss: 0.6271 - val_acc: 0.7835\n",
      "Epoch 237/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6813 - acc: 0.7667 - val_loss: 0.6282 - val_acc: 0.7835\n",
      "Epoch 238/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6732 - acc: 0.7671 - val_loss: 0.6274 - val_acc: 0.7842\n",
      "Epoch 239/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6825 - acc: 0.7671 - val_loss: 0.6268 - val_acc: 0.7842\n",
      "\n",
      "Epoch 00239: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 240/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6886 - acc: 0.7645 - val_loss: 0.6260 - val_acc: 0.7842\n",
      "Epoch 241/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6867 - acc: 0.7664 - val_loss: 0.6261 - val_acc: 0.7842\n",
      "Epoch 242/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6702 - acc: 0.7675 - val_loss: 0.6277 - val_acc: 0.7835\n",
      "Epoch 243/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6830 - acc: 0.7649 - val_loss: 0.6251 - val_acc: 0.7842\n",
      "Epoch 244/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6918 - acc: 0.7593 - val_loss: 0.6279 - val_acc: 0.7835\n",
      "Epoch 245/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6690 - acc: 0.7682 - val_loss: 0.6258 - val_acc: 0.7850\n",
      "Epoch 246/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6730 - acc: 0.7675 - val_loss: 0.6276 - val_acc: 0.7835\n",
      "Epoch 247/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6869 - acc: 0.7634 - val_loss: 0.6269 - val_acc: 0.7850\n",
      "Epoch 248/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6914 - acc: 0.7608 - val_loss: 0.6273 - val_acc: 0.7842\n",
      "Epoch 249/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6690 - acc: 0.7641 - val_loss: 0.6279 - val_acc: 0.7842\n",
      "Epoch 250/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6670 - acc: 0.7671 - val_loss: 0.6281 - val_acc: 0.7842\n",
      "Epoch 251/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6658 - acc: 0.7645 - val_loss: 0.6267 - val_acc: 0.7842\n",
      "Epoch 252/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6765 - acc: 0.7656 - val_loss: 0.6265 - val_acc: 0.7850\n",
      "Epoch 253/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6757 - acc: 0.7645 - val_loss: 0.6268 - val_acc: 0.7842\n",
      "Epoch 254/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6824 - acc: 0.7623 - val_loss: 0.6229 - val_acc: 0.7857\n",
      "Epoch 255/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6774 - acc: 0.7690 - val_loss: 0.6214 - val_acc: 0.7857\n",
      "Epoch 256/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6797 - acc: 0.7686 - val_loss: 0.6279 - val_acc: 0.7835\n",
      "Epoch 257/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6574 - acc: 0.7794 - val_loss: 0.6274 - val_acc: 0.7842\n",
      "Epoch 258/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6711 - acc: 0.7768 - val_loss: 0.6272 - val_acc: 0.7835\n",
      "Epoch 259/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6629 - acc: 0.7708 - val_loss: 0.6267 - val_acc: 0.7835\n",
      "\n",
      "Epoch 00259: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 260/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6797 - acc: 0.7653 - val_loss: 0.6275 - val_acc: 0.7835\n",
      "Epoch 261/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6837 - acc: 0.7600 - val_loss: 0.6253 - val_acc: 0.7842\n",
      "Epoch 262/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6919 - acc: 0.7548 - val_loss: 0.6278 - val_acc: 0.7835\n",
      "Epoch 263/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6799 - acc: 0.7649 - val_loss: 0.6266 - val_acc: 0.7842\n",
      "Epoch 264/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6581 - acc: 0.7738 - val_loss: 0.6270 - val_acc: 0.7835\n",
      "Epoch 265/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6678 - acc: 0.7667 - val_loss: 0.6276 - val_acc: 0.7835\n",
      "\n",
      "Epoch 00265: loss improved from inf to 0.66776, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-2-000265-0.667756-0.783482.hdf5\n",
      "Epoch 266/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6732 - acc: 0.7708 - val_loss: 0.6277 - val_acc: 0.7835\n",
      "Epoch 267/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6706 - acc: 0.7783 - val_loss: 0.6270 - val_acc: 0.7842\n",
      "Epoch 268/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6832 - acc: 0.7653 - val_loss: 0.6254 - val_acc: 0.7842\n",
      "Epoch 269/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6821 - acc: 0.7638 - val_loss: 0.6241 - val_acc: 0.7842\n",
      "Epoch 270/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6737 - acc: 0.7623 - val_loss: 0.6250 - val_acc: 0.7850\n",
      "Epoch 271/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6692 - acc: 0.7731 - val_loss: 0.6259 - val_acc: 0.7842\n",
      "Epoch 272/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6710 - acc: 0.7626 - val_loss: 0.6254 - val_acc: 0.7842\n",
      "Epoch 273/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6687 - acc: 0.7682 - val_loss: 0.6241 - val_acc: 0.7850\n",
      "Epoch 274/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6712 - acc: 0.7656 - val_loss: 0.6263 - val_acc: 0.7835\n",
      "Epoch 275/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6713 - acc: 0.7671 - val_loss: 0.6272 - val_acc: 0.7835\n",
      "Epoch 276/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6812 - acc: 0.7682 - val_loss: 0.6273 - val_acc: 0.7835\n",
      "Epoch 277/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6731 - acc: 0.7675 - val_loss: 0.6276 - val_acc: 0.7842\n",
      "Epoch 278/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6818 - acc: 0.7589 - val_loss: 0.6273 - val_acc: 0.7842\n",
      "Epoch 279/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6988 - acc: 0.7630 - val_loss: 0.6256 - val_acc: 0.7850\n",
      "Epoch 280/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6799 - acc: 0.7693 - val_loss: 0.6264 - val_acc: 0.7850\n",
      "Epoch 281/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6767 - acc: 0.7712 - val_loss: 0.6271 - val_acc: 0.7842\n",
      "Epoch 282/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6763 - acc: 0.7600 - val_loss: 0.6265 - val_acc: 0.7850\n",
      "Epoch 283/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6739 - acc: 0.7656 - val_loss: 0.6245 - val_acc: 0.7850\n",
      "Epoch 284/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6770 - acc: 0.7660 - val_loss: 0.6234 - val_acc: 0.7857\n",
      "Epoch 285/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6721 - acc: 0.7712 - val_loss: 0.6252 - val_acc: 0.7842\n",
      "Epoch 286/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6878 - acc: 0.7638 - val_loss: 0.6262 - val_acc: 0.7850\n",
      "Epoch 287/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6665 - acc: 0.7697 - val_loss: 0.6273 - val_acc: 0.7835\n",
      "Epoch 288/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6730 - acc: 0.7731 - val_loss: 0.6274 - val_acc: 0.7835\n",
      "Epoch 289/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6773 - acc: 0.7705 - val_loss: 0.6278 - val_acc: 0.7835\n",
      "Epoch 290/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6874 - acc: 0.7630 - val_loss: 0.6277 - val_acc: 0.7835\n",
      "Epoch 291/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6694 - acc: 0.7716 - val_loss: 0.6253 - val_acc: 0.7835\n",
      "Epoch 292/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6600 - acc: 0.7723 - val_loss: 0.6277 - val_acc: 0.7827\n",
      "Epoch 293/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6810 - acc: 0.7686 - val_loss: 0.6205 - val_acc: 0.7842\n",
      "Epoch 294/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6682 - acc: 0.7671 - val_loss: 0.6249 - val_acc: 0.7850\n",
      "Epoch 295/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6832 - acc: 0.7630 - val_loss: 0.6247 - val_acc: 0.7835\n",
      "Epoch 296/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6867 - acc: 0.7623 - val_loss: 0.6274 - val_acc: 0.7827\n",
      "Epoch 297/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6945 - acc: 0.7582 - val_loss: 0.6252 - val_acc: 0.7850\n",
      "Epoch 298/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6704 - acc: 0.7723 - val_loss: 0.6268 - val_acc: 0.7835\n",
      "Epoch 299/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6571 - acc: 0.7738 - val_loss: 0.6278 - val_acc: 0.7835\n",
      "Epoch 300/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6745 - acc: 0.7664 - val_loss: 0.6261 - val_acc: 0.7842\n",
      "\n",
      "Epoch 00300: saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/2-000300-0.674515-0.784226.hdf5\n",
      "Epoch 301/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6749 - acc: 0.7734 - val_loss: 0.6273 - val_acc: 0.7835\n",
      "Epoch 302/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6706 - acc: 0.7712 - val_loss: 0.6265 - val_acc: 0.7842\n",
      "Epoch 303/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6776 - acc: 0.7749 - val_loss: 0.6278 - val_acc: 0.7835\n",
      "Epoch 304/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6912 - acc: 0.7675 - val_loss: 0.6241 - val_acc: 0.7850\n",
      "Epoch 305/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6690 - acc: 0.7723 - val_loss: 0.6271 - val_acc: 0.7827\n",
      "Epoch 306/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6752 - acc: 0.7682 - val_loss: 0.6241 - val_acc: 0.7842\n",
      "Epoch 307/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6691 - acc: 0.7719 - val_loss: 0.6277 - val_acc: 0.7827\n",
      "Epoch 308/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6850 - acc: 0.7660 - val_loss: 0.6265 - val_acc: 0.7827\n",
      "Epoch 309/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6760 - acc: 0.7723 - val_loss: 0.6266 - val_acc: 0.7835\n",
      "Epoch 310/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6708 - acc: 0.7705 - val_loss: 0.6265 - val_acc: 0.7835\n",
      "Epoch 311/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6771 - acc: 0.7664 - val_loss: 0.6265 - val_acc: 0.7835\n",
      "Epoch 312/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6807 - acc: 0.7664 - val_loss: 0.6266 - val_acc: 0.7827\n",
      "Epoch 313/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6801 - acc: 0.7705 - val_loss: 0.6259 - val_acc: 0.7842\n",
      "Epoch 314/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6689 - acc: 0.7738 - val_loss: 0.6261 - val_acc: 0.7842\n",
      "Epoch 315/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6754 - acc: 0.7660 - val_loss: 0.6276 - val_acc: 0.7827\n",
      "Epoch 316/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6576 - acc: 0.7712 - val_loss: 0.6271 - val_acc: 0.7827\n",
      "Epoch 317/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6807 - acc: 0.7679 - val_loss: 0.6278 - val_acc: 0.7827\n",
      "Epoch 318/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6683 - acc: 0.7738 - val_loss: 0.6160 - val_acc: 0.7842\n",
      "Epoch 319/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6788 - acc: 0.7738 - val_loss: 0.6271 - val_acc: 0.7827\n",
      "Epoch 320/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6710 - acc: 0.7701 - val_loss: 0.6260 - val_acc: 0.7835\n",
      "Epoch 321/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6960 - acc: 0.7623 - val_loss: 0.6247 - val_acc: 0.7842\n",
      "Epoch 322/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6623 - acc: 0.7716 - val_loss: 0.6272 - val_acc: 0.7827\n",
      "Epoch 323/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6771 - acc: 0.7671 - val_loss: 0.6274 - val_acc: 0.7827\n",
      "Epoch 324/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6963 - acc: 0.7519 - val_loss: 0.6277 - val_acc: 0.7827\n",
      "Epoch 325/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6842 - acc: 0.7623 - val_loss: 0.6263 - val_acc: 0.7835\n",
      "Epoch 326/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6689 - acc: 0.7742 - val_loss: 0.6266 - val_acc: 0.7835\n",
      "Epoch 327/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6778 - acc: 0.7638 - val_loss: 0.6276 - val_acc: 0.7827\n",
      "Epoch 328/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6844 - acc: 0.7675 - val_loss: 0.6265 - val_acc: 0.7835\n",
      "Epoch 329/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6814 - acc: 0.7641 - val_loss: 0.6252 - val_acc: 0.7842\n",
      "Epoch 330/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6699 - acc: 0.7697 - val_loss: 0.6250 - val_acc: 0.7835\n",
      "Epoch 331/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6758 - acc: 0.7667 - val_loss: 0.6266 - val_acc: 0.7842\n",
      "Epoch 332/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6685 - acc: 0.7634 - val_loss: 0.6245 - val_acc: 0.7850\n",
      "Epoch 333/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6729 - acc: 0.7656 - val_loss: 0.6257 - val_acc: 0.7850\n",
      "Epoch 334/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6804 - acc: 0.7630 - val_loss: 0.6277 - val_acc: 0.7835\n",
      "Epoch 335/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6717 - acc: 0.7757 - val_loss: 0.6261 - val_acc: 0.7842\n",
      "Epoch 336/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6820 - acc: 0.7664 - val_loss: 0.6257 - val_acc: 0.7842\n",
      "Epoch 337/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6771 - acc: 0.7623 - val_loss: 0.6258 - val_acc: 0.7835\n",
      "Epoch 338/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6823 - acc: 0.7630 - val_loss: 0.6268 - val_acc: 0.7842\n",
      "Epoch 339/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6698 - acc: 0.7693 - val_loss: 0.6277 - val_acc: 0.7835\n",
      "Epoch 340/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6634 - acc: 0.7693 - val_loss: 0.6260 - val_acc: 0.7842\n",
      "Epoch 341/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6890 - acc: 0.7705 - val_loss: 0.6248 - val_acc: 0.7842\n",
      "Epoch 342/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6860 - acc: 0.7660 - val_loss: 0.6275 - val_acc: 0.7835\n",
      "Epoch 343/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.6782 - acc: 0.7723 - val_loss: 0.6254 - val_acc: 0.7850\n",
      "Epoch 344/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6756 - acc: 0.7615 - val_loss: 0.6271 - val_acc: 0.7835\n",
      "Epoch 345/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6646 - acc: 0.7701 - val_loss: 0.6256 - val_acc: 0.7842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 346/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6787 - acc: 0.7660 - val_loss: 0.6275 - val_acc: 0.7835\n",
      "Epoch 347/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.7004 - acc: 0.7533 - val_loss: 0.6264 - val_acc: 0.7842\n",
      "Epoch 348/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6775 - acc: 0.7693 - val_loss: 0.6255 - val_acc: 0.7842\n",
      "Epoch 349/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6863 - acc: 0.7634 - val_loss: 0.6253 - val_acc: 0.7835\n",
      "Epoch 350/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6765 - acc: 0.7623 - val_loss: 0.6269 - val_acc: 0.7827\n",
      "Epoch 351/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6811 - acc: 0.7638 - val_loss: 0.6264 - val_acc: 0.7835\n",
      "Epoch 352/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6719 - acc: 0.7731 - val_loss: 0.6256 - val_acc: 0.7835\n",
      "Epoch 353/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6710 - acc: 0.7593 - val_loss: 0.6255 - val_acc: 0.7835\n",
      "Epoch 354/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6748 - acc: 0.7567 - val_loss: 0.6267 - val_acc: 0.7827\n",
      "Epoch 355/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6694 - acc: 0.7615 - val_loss: 0.6263 - val_acc: 0.7835\n",
      "Epoch 356/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6765 - acc: 0.7697 - val_loss: 0.6275 - val_acc: 0.7827\n",
      "Epoch 357/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6694 - acc: 0.7660 - val_loss: 0.6261 - val_acc: 0.7835\n",
      "Epoch 358/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6569 - acc: 0.7734 - val_loss: 0.6252 - val_acc: 0.7835\n",
      "Epoch 359/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6737 - acc: 0.7738 - val_loss: 0.6272 - val_acc: 0.7835\n",
      "Epoch 360/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6699 - acc: 0.7772 - val_loss: 0.6275 - val_acc: 0.7827\n",
      "Epoch 361/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6883 - acc: 0.7589 - val_loss: 0.6239 - val_acc: 0.7842\n",
      "Epoch 362/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6718 - acc: 0.7645 - val_loss: 0.6272 - val_acc: 0.7827\n",
      "Epoch 363/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6740 - acc: 0.7671 - val_loss: 0.6222 - val_acc: 0.7842\n",
      "Epoch 364/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6628 - acc: 0.7690 - val_loss: 0.6277 - val_acc: 0.7827\n",
      "Epoch 365/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6740 - acc: 0.7679 - val_loss: 0.6276 - val_acc: 0.7835\n",
      "\n",
      "Epoch 00365: loss improved from inf to 0.67400, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-2-000365-0.674001-0.783482.hdf5\n",
      "Epoch 366/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6663 - acc: 0.7731 - val_loss: 0.6277 - val_acc: 0.7835\n",
      "Epoch 367/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6611 - acc: 0.7731 - val_loss: 0.6271 - val_acc: 0.7835\n",
      "Epoch 368/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6690 - acc: 0.7690 - val_loss: 0.6265 - val_acc: 0.7842\n",
      "Epoch 369/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6564 - acc: 0.7712 - val_loss: 0.6230 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00369: loss improved from 0.67400 to 0.65642, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-2-000369-0.656420-0.785714.hdf5\n",
      "Epoch 370/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6885 - acc: 0.7671 - val_loss: 0.6269 - val_acc: 0.7835\n",
      "Epoch 371/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6765 - acc: 0.7634 - val_loss: 0.6268 - val_acc: 0.7842\n",
      "Epoch 372/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6848 - acc: 0.7623 - val_loss: 0.6262 - val_acc: 0.7842\n",
      "Epoch 373/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6724 - acc: 0.7645 - val_loss: 0.6252 - val_acc: 0.7842\n",
      "Epoch 374/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6816 - acc: 0.7675 - val_loss: 0.6269 - val_acc: 0.7842\n",
      "Epoch 375/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6703 - acc: 0.7679 - val_loss: 0.6278 - val_acc: 0.7835\n",
      "Epoch 376/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6759 - acc: 0.7679 - val_loss: 0.6256 - val_acc: 0.7842\n",
      "Epoch 377/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6593 - acc: 0.7708 - val_loss: 0.6253 - val_acc: 0.7842\n",
      "Epoch 378/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6733 - acc: 0.7775 - val_loss: 0.6267 - val_acc: 0.7842\n",
      "Epoch 379/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6702 - acc: 0.7600 - val_loss: 0.6243 - val_acc: 0.7850\n",
      "Epoch 380/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6773 - acc: 0.7612 - val_loss: 0.6268 - val_acc: 0.7835\n",
      "Epoch 381/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6568 - acc: 0.7679 - val_loss: 0.6277 - val_acc: 0.7835\n",
      "Epoch 382/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6746 - acc: 0.7682 - val_loss: 0.6244 - val_acc: 0.7850\n",
      "Epoch 383/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6692 - acc: 0.7615 - val_loss: 0.6266 - val_acc: 0.7835\n",
      "Epoch 384/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6864 - acc: 0.7612 - val_loss: 0.6273 - val_acc: 0.7835\n",
      "Epoch 385/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6859 - acc: 0.7600 - val_loss: 0.6255 - val_acc: 0.7850\n",
      "Epoch 386/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6794 - acc: 0.7630 - val_loss: 0.6274 - val_acc: 0.7835\n",
      "Epoch 387/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6664 - acc: 0.7731 - val_loss: 0.6255 - val_acc: 0.7842\n",
      "Epoch 388/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6571 - acc: 0.7693 - val_loss: 0.6277 - val_acc: 0.7835\n",
      "Epoch 389/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6683 - acc: 0.7690 - val_loss: 0.6272 - val_acc: 0.7835\n",
      "Epoch 390/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6731 - acc: 0.7653 - val_loss: 0.6268 - val_acc: 0.7842\n",
      "Epoch 391/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6641 - acc: 0.7656 - val_loss: 0.6256 - val_acc: 0.7842\n",
      "Epoch 392/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6646 - acc: 0.7675 - val_loss: 0.6238 - val_acc: 0.7850\n",
      "Epoch 393/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6732 - acc: 0.7705 - val_loss: 0.6276 - val_acc: 0.7835\n",
      "Epoch 394/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6793 - acc: 0.7619 - val_loss: 0.6262 - val_acc: 0.7842\n",
      "Epoch 395/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6762 - acc: 0.7604 - val_loss: 0.6245 - val_acc: 0.7842\n",
      "Epoch 396/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6783 - acc: 0.7626 - val_loss: 0.6260 - val_acc: 0.7842\n",
      "Epoch 397/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6860 - acc: 0.7645 - val_loss: 0.6271 - val_acc: 0.7835\n",
      "Epoch 398/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6861 - acc: 0.7693 - val_loss: 0.6272 - val_acc: 0.7835\n",
      "Epoch 399/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6848 - acc: 0.7630 - val_loss: 0.6271 - val_acc: 0.7835\n",
      "Epoch 400/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6752 - acc: 0.7757 - val_loss: 0.6266 - val_acc: 0.7842\n",
      "\n",
      "Epoch 00400: saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/2-000400-0.675234-0.784226.hdf5\n",
      "Epoch 401/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6679 - acc: 0.7697 - val_loss: 0.6263 - val_acc: 0.7842\n",
      "Epoch 402/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6702 - acc: 0.7671 - val_loss: 0.6250 - val_acc: 0.7850\n",
      "Epoch 403/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6629 - acc: 0.7645 - val_loss: 0.6278 - val_acc: 0.7835\n",
      "Epoch 404/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6694 - acc: 0.7731 - val_loss: 0.6261 - val_acc: 0.7835\n",
      "Epoch 405/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6856 - acc: 0.7682 - val_loss: 0.6262 - val_acc: 0.7842\n",
      "Epoch 406/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6662 - acc: 0.7660 - val_loss: 0.6271 - val_acc: 0.7835\n",
      "Epoch 407/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6798 - acc: 0.7705 - val_loss: 0.6251 - val_acc: 0.7842\n",
      "Epoch 408/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6837 - acc: 0.7593 - val_loss: 0.6262 - val_acc: 0.7842\n",
      "Epoch 409/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6841 - acc: 0.7597 - val_loss: 0.6264 - val_acc: 0.7842\n",
      "Epoch 410/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6876 - acc: 0.7619 - val_loss: 0.6260 - val_acc: 0.7842\n",
      "Epoch 411/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6759 - acc: 0.7686 - val_loss: 0.6243 - val_acc: 0.7842\n",
      "Epoch 412/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6674 - acc: 0.7645 - val_loss: 0.6268 - val_acc: 0.7842\n",
      "Epoch 413/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6756 - acc: 0.7671 - val_loss: 0.6262 - val_acc: 0.7842\n",
      "Epoch 414/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6633 - acc: 0.7768 - val_loss: 0.6251 - val_acc: 0.7842\n",
      "Epoch 415/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6834 - acc: 0.7615 - val_loss: 0.6250 - val_acc: 0.7850\n",
      "Epoch 416/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6858 - acc: 0.7675 - val_loss: 0.6265 - val_acc: 0.7842\n",
      "Epoch 417/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6734 - acc: 0.7690 - val_loss: 0.6279 - val_acc: 0.7835\n",
      "Epoch 418/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6687 - acc: 0.7667 - val_loss: 0.6269 - val_acc: 0.7835\n",
      "Epoch 419/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6699 - acc: 0.7675 - val_loss: 0.6267 - val_acc: 0.7835\n",
      "Epoch 420/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6936 - acc: 0.7600 - val_loss: 0.6255 - val_acc: 0.7842\n",
      "Epoch 421/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6862 - acc: 0.7586 - val_loss: 0.6258 - val_acc: 0.7842\n",
      "Epoch 422/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6670 - acc: 0.7664 - val_loss: 0.6252 - val_acc: 0.7842\n",
      "Epoch 423/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6663 - acc: 0.7712 - val_loss: 0.6253 - val_acc: 0.7842\n",
      "Epoch 424/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6724 - acc: 0.7649 - val_loss: 0.6262 - val_acc: 0.7842\n",
      "Epoch 425/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6663 - acc: 0.7716 - val_loss: 0.6265 - val_acc: 0.7842\n",
      "Epoch 426/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6775 - acc: 0.7664 - val_loss: 0.6275 - val_acc: 0.7835\n",
      "Epoch 427/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6651 - acc: 0.7708 - val_loss: 0.6238 - val_acc: 0.7850\n",
      "Epoch 428/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6806 - acc: 0.7623 - val_loss: 0.6252 - val_acc: 0.7842\n",
      "Epoch 429/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6811 - acc: 0.7660 - val_loss: 0.6250 - val_acc: 0.7850\n",
      "Epoch 430/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6984 - acc: 0.7560 - val_loss: 0.6250 - val_acc: 0.7842\n",
      "Epoch 431/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6861 - acc: 0.7638 - val_loss: 0.6260 - val_acc: 0.7842\n",
      "Epoch 432/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6964 - acc: 0.7530 - val_loss: 0.6253 - val_acc: 0.7850\n",
      "Epoch 433/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6645 - acc: 0.7731 - val_loss: 0.6241 - val_acc: 0.7850\n",
      "Epoch 434/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6720 - acc: 0.7686 - val_loss: 0.6272 - val_acc: 0.7835\n",
      "Epoch 435/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6739 - acc: 0.7615 - val_loss: 0.6243 - val_acc: 0.7842\n",
      "Epoch 436/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6770 - acc: 0.7671 - val_loss: 0.6277 - val_acc: 0.7835\n",
      "Epoch 437/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6866 - acc: 0.7574 - val_loss: 0.6276 - val_acc: 0.7835\n",
      "Epoch 438/1000\n",
      "42/42 [==============================] - 2s 39ms/step - loss: 0.6689 - acc: 0.7660 - val_loss: 0.6273 - val_acc: 0.7835\n",
      "Epoch 439/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6671 - acc: 0.7634 - val_loss: 0.6256 - val_acc: 0.7842\n",
      "Epoch 440/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6739 - acc: 0.7653 - val_loss: 0.6266 - val_acc: 0.7835\n",
      "Epoch 441/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6760 - acc: 0.7600 - val_loss: 0.6268 - val_acc: 0.7835\n",
      "Epoch 442/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6720 - acc: 0.7675 - val_loss: 0.6258 - val_acc: 0.7842\n",
      "Epoch 443/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6890 - acc: 0.7626 - val_loss: 0.6257 - val_acc: 0.7842\n",
      "Epoch 444/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6761 - acc: 0.7641 - val_loss: 0.6252 - val_acc: 0.7842\n",
      "Epoch 445/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6723 - acc: 0.7667 - val_loss: 0.6266 - val_acc: 0.7835\n",
      "Epoch 446/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6549 - acc: 0.7742 - val_loss: 0.6269 - val_acc: 0.7835\n",
      "Epoch 447/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6781 - acc: 0.7727 - val_loss: 0.6268 - val_acc: 0.7835\n",
      "Epoch 448/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6866 - acc: 0.7589 - val_loss: 0.6267 - val_acc: 0.7835\n",
      "Epoch 449/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6733 - acc: 0.7653 - val_loss: 0.6240 - val_acc: 0.7850\n",
      "Epoch 450/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6722 - acc: 0.7705 - val_loss: 0.6261 - val_acc: 0.7842\n",
      "Epoch 451/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6642 - acc: 0.7671 - val_loss: 0.6273 - val_acc: 0.7835\n",
      "Epoch 452/1000\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 0.6888 - acc: 0.7649 - val_loss: 0.6251 - val_acc: 0.7842\n",
      "Epoch 453/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6821 - acc: 0.7641 - val_loss: 0.6265 - val_acc: 0.7835\n",
      "Epoch 454/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6794 - acc: 0.7608 - val_loss: 0.6271 - val_acc: 0.7842\n",
      "Epoch 455/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6775 - acc: 0.7682 - val_loss: 0.6267 - val_acc: 0.7835\n",
      "Epoch 456/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6659 - acc: 0.7708 - val_loss: 0.6259 - val_acc: 0.7842\n",
      "Epoch 457/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6683 - acc: 0.7656 - val_loss: 0.6262 - val_acc: 0.7842\n",
      "Epoch 458/1000\n",
      "42/42 [==============================] - 2s 38ms/step - loss: 0.6675 - acc: 0.7675 - val_loss: 0.6276 - val_acc: 0.7835\n",
      "Epoch 459/1000\n",
      "42/42 [==============================] - 2s 36ms/step - loss: 0.6651 - acc: 0.7701 - val_loss: 0.6244 - val_acc: 0.7850\n",
      "Epoch 460/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6561 - acc: 0.7742 - val_loss: 0.6269 - val_acc: 0.7842\n",
      "Epoch 461/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6927 - acc: 0.7615 - val_loss: 0.6267 - val_acc: 0.7835\n",
      "Epoch 462/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6922 - acc: 0.7608 - val_loss: 0.6270 - val_acc: 0.7835\n",
      "Epoch 463/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6923 - acc: 0.7649 - val_loss: 0.6265 - val_acc: 0.7842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 464/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6778 - acc: 0.7693 - val_loss: 0.6258 - val_acc: 0.7842\n",
      "Epoch 465/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6806 - acc: 0.7641 - val_loss: 0.6217 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00465: loss improved from inf to 0.68059, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-2-000465-0.680587-0.785714.hdf5\n",
      "Epoch 466/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6772 - acc: 0.7682 - val_loss: 0.6244 - val_acc: 0.7850\n",
      "Epoch 467/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6779 - acc: 0.7626 - val_loss: 0.6271 - val_acc: 0.7835\n",
      "Epoch 468/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6720 - acc: 0.7690 - val_loss: 0.6245 - val_acc: 0.7842\n",
      "Epoch 469/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6811 - acc: 0.7716 - val_loss: 0.6275 - val_acc: 0.7835\n",
      "Epoch 470/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6819 - acc: 0.7653 - val_loss: 0.6259 - val_acc: 0.7842\n",
      "Epoch 471/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6738 - acc: 0.7645 - val_loss: 0.6273 - val_acc: 0.7835\n",
      "Epoch 472/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6932 - acc: 0.7671 - val_loss: 0.6257 - val_acc: 0.7842\n",
      "Epoch 473/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6761 - acc: 0.7675 - val_loss: 0.6258 - val_acc: 0.7842\n",
      "\n",
      "Epoch 00473: loss improved from 0.68059 to 0.67610, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-2-000473-0.676104-0.784226.hdf5\n",
      "Epoch 474/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6748 - acc: 0.7716 - val_loss: 0.6273 - val_acc: 0.7835\n",
      "Epoch 475/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6767 - acc: 0.7626 - val_loss: 0.6267 - val_acc: 0.7842\n",
      "Epoch 476/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6811 - acc: 0.7682 - val_loss: 0.6270 - val_acc: 0.7835\n",
      "Epoch 477/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6793 - acc: 0.7600 - val_loss: 0.6263 - val_acc: 0.7842\n",
      "Epoch 478/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6772 - acc: 0.7727 - val_loss: 0.6255 - val_acc: 0.7850\n",
      "Epoch 479/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6782 - acc: 0.7656 - val_loss: 0.6245 - val_acc: 0.7850\n",
      "Epoch 480/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6792 - acc: 0.7664 - val_loss: 0.6275 - val_acc: 0.7835\n",
      "Epoch 481/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6561 - acc: 0.7708 - val_loss: 0.6241 - val_acc: 0.7842\n",
      "\n",
      "Epoch 00481: loss improved from 0.67610 to 0.65614, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-2-000481-0.656145-0.784226.hdf5\n",
      "Epoch 482/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6947 - acc: 0.7600 - val_loss: 0.6254 - val_acc: 0.7842\n",
      "Epoch 483/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.6682 - acc: 0.7753 - val_loss: 0.6267 - val_acc: 0.7842\n",
      "Epoch 484/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6561 - acc: 0.7716 - val_loss: 0.6274 - val_acc: 0.7835\n",
      "Epoch 485/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6823 - acc: 0.7649 - val_loss: 0.6258 - val_acc: 0.7842\n",
      "Epoch 486/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6742 - acc: 0.7619 - val_loss: 0.6251 - val_acc: 0.7850\n",
      "Epoch 487/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6724 - acc: 0.7619 - val_loss: 0.6255 - val_acc: 0.7842\n",
      "Epoch 488/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6758 - acc: 0.7664 - val_loss: 0.6243 - val_acc: 0.7850\n",
      "Epoch 489/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6674 - acc: 0.7705 - val_loss: 0.6276 - val_acc: 0.7835\n",
      "Epoch 490/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6950 - acc: 0.7582 - val_loss: 0.6242 - val_acc: 0.7850\n",
      "Epoch 491/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6755 - acc: 0.7686 - val_loss: 0.6233 - val_acc: 0.7857\n",
      "Epoch 492/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6627 - acc: 0.7667 - val_loss: 0.6264 - val_acc: 0.7842\n",
      "Epoch 493/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6698 - acc: 0.7701 - val_loss: 0.6270 - val_acc: 0.7835\n",
      "Epoch 494/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6766 - acc: 0.7641 - val_loss: 0.6243 - val_acc: 0.7842\n",
      "Epoch 495/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6827 - acc: 0.7697 - val_loss: 0.6246 - val_acc: 0.7850\n",
      "Epoch 496/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6642 - acc: 0.7749 - val_loss: 0.6252 - val_acc: 0.7842\n",
      "Epoch 497/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6790 - acc: 0.7589 - val_loss: 0.6263 - val_acc: 0.7842\n",
      "Epoch 498/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6916 - acc: 0.7589 - val_loss: 0.6275 - val_acc: 0.7835\n",
      "Epoch 499/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6760 - acc: 0.7641 - val_loss: 0.6261 - val_acc: 0.7842\n",
      "Epoch 500/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6785 - acc: 0.7686 - val_loss: 0.6245 - val_acc: 0.7850\n",
      "\n",
      "Epoch 00500: saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/2-000500-0.678468-0.784970.hdf5\n",
      "Epoch 501/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6881 - acc: 0.7653 - val_loss: 0.6256 - val_acc: 0.7850\n",
      "Epoch 502/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6758 - acc: 0.7708 - val_loss: 0.6234 - val_acc: 0.7850\n",
      "Epoch 503/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6776 - acc: 0.7701 - val_loss: 0.6251 - val_acc: 0.7842\n",
      "Epoch 504/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6837 - acc: 0.7693 - val_loss: 0.6263 - val_acc: 0.7842\n",
      "Epoch 505/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6837 - acc: 0.7708 - val_loss: 0.6266 - val_acc: 0.7842\n",
      "Epoch 506/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6717 - acc: 0.7731 - val_loss: 0.6270 - val_acc: 0.7835\n",
      "Epoch 507/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6810 - acc: 0.7615 - val_loss: 0.6249 - val_acc: 0.7850\n",
      "Epoch 508/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6686 - acc: 0.7705 - val_loss: 0.6263 - val_acc: 0.7842\n",
      "Epoch 509/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6655 - acc: 0.7731 - val_loss: 0.6267 - val_acc: 0.7842\n",
      "Epoch 510/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6845 - acc: 0.7586 - val_loss: 0.6256 - val_acc: 0.7850\n",
      "Epoch 511/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6735 - acc: 0.7686 - val_loss: 0.6279 - val_acc: 0.7842\n",
      "Epoch 512/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6740 - acc: 0.7623 - val_loss: 0.6260 - val_acc: 0.7850\n",
      "Epoch 513/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6868 - acc: 0.7638 - val_loss: 0.6270 - val_acc: 0.7842\n",
      "Epoch 514/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.7030 - acc: 0.7597 - val_loss: 0.6244 - val_acc: 0.7857\n",
      "Epoch 515/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6732 - acc: 0.7679 - val_loss: 0.6242 - val_acc: 0.7857\n",
      "Epoch 516/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6730 - acc: 0.7671 - val_loss: 0.6248 - val_acc: 0.7857\n",
      "Epoch 517/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.6740 - acc: 0.7638 - val_loss: 0.6258 - val_acc: 0.7857\n",
      "Epoch 518/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6707 - acc: 0.7664 - val_loss: 0.6251 - val_acc: 0.7850\n",
      "Epoch 519/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6831 - acc: 0.7619 - val_loss: 0.6256 - val_acc: 0.7850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 520/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6597 - acc: 0.7686 - val_loss: 0.6265 - val_acc: 0.7850\n",
      "Epoch 521/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6785 - acc: 0.7701 - val_loss: 0.6272 - val_acc: 0.7842\n",
      "Epoch 522/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6738 - acc: 0.7567 - val_loss: 0.6249 - val_acc: 0.7857\n",
      "Epoch 523/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6723 - acc: 0.7708 - val_loss: 0.6268 - val_acc: 0.7842\n",
      "Epoch 524/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6766 - acc: 0.7649 - val_loss: 0.6255 - val_acc: 0.7857\n",
      "Epoch 525/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6737 - acc: 0.7645 - val_loss: 0.6261 - val_acc: 0.7850\n",
      "Epoch 526/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6677 - acc: 0.7664 - val_loss: 0.6278 - val_acc: 0.7842\n",
      "Epoch 527/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6812 - acc: 0.7675 - val_loss: 0.6246 - val_acc: 0.7857\n",
      "Epoch 528/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6838 - acc: 0.7649 - val_loss: 0.6232 - val_acc: 0.7857\n",
      "Epoch 529/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6830 - acc: 0.7675 - val_loss: 0.6255 - val_acc: 0.7850\n",
      "Epoch 530/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6685 - acc: 0.7604 - val_loss: 0.6265 - val_acc: 0.7850\n",
      "Epoch 531/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6827 - acc: 0.7604 - val_loss: 0.6270 - val_acc: 0.7842\n",
      "Epoch 532/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6646 - acc: 0.7790 - val_loss: 0.6266 - val_acc: 0.7850\n",
      "Epoch 533/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6812 - acc: 0.7682 - val_loss: 0.6272 - val_acc: 0.7842\n",
      "Epoch 534/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6783 - acc: 0.7671 - val_loss: 0.6262 - val_acc: 0.7842\n",
      "Epoch 535/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6812 - acc: 0.7679 - val_loss: 0.6265 - val_acc: 0.7850\n",
      "Epoch 536/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6778 - acc: 0.7679 - val_loss: 0.6273 - val_acc: 0.7842\n",
      "Epoch 537/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6762 - acc: 0.7693 - val_loss: 0.6255 - val_acc: 0.7857\n",
      "Epoch 538/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6738 - acc: 0.7656 - val_loss: 0.6228 - val_acc: 0.7857\n",
      "Epoch 539/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6756 - acc: 0.7649 - val_loss: 0.6275 - val_acc: 0.7842\n",
      "Epoch 540/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6793 - acc: 0.7746 - val_loss: 0.6222 - val_acc: 0.7865\n",
      "Epoch 541/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6847 - acc: 0.7630 - val_loss: 0.6249 - val_acc: 0.7857\n",
      "Epoch 542/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6591 - acc: 0.7731 - val_loss: 0.6271 - val_acc: 0.7842\n",
      "Epoch 543/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6642 - acc: 0.7697 - val_loss: 0.6267 - val_acc: 0.7850\n",
      "Epoch 544/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6904 - acc: 0.7626 - val_loss: 0.6269 - val_acc: 0.7850\n",
      "Epoch 545/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6801 - acc: 0.7708 - val_loss: 0.6264 - val_acc: 0.7850\n",
      "Epoch 546/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6836 - acc: 0.7645 - val_loss: 0.6274 - val_acc: 0.7842\n",
      "Epoch 547/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6831 - acc: 0.7574 - val_loss: 0.6255 - val_acc: 0.7850\n",
      "Epoch 548/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6646 - acc: 0.7705 - val_loss: 0.6271 - val_acc: 0.7842\n",
      "Epoch 549/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6744 - acc: 0.7671 - val_loss: 0.6274 - val_acc: 0.7842\n",
      "Epoch 550/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6776 - acc: 0.7675 - val_loss: 0.6270 - val_acc: 0.7842\n",
      "Epoch 551/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6664 - acc: 0.7716 - val_loss: 0.6268 - val_acc: 0.7842\n",
      "Epoch 552/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6904 - acc: 0.7656 - val_loss: 0.6269 - val_acc: 0.7842\n",
      "Epoch 553/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6782 - acc: 0.7716 - val_loss: 0.6215 - val_acc: 0.7857\n",
      "Epoch 554/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6731 - acc: 0.7727 - val_loss: 0.6261 - val_acc: 0.7850\n",
      "Epoch 555/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6686 - acc: 0.7693 - val_loss: 0.6253 - val_acc: 0.7850\n",
      "Epoch 556/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6558 - acc: 0.7760 - val_loss: 0.6266 - val_acc: 0.7842\n",
      "Epoch 557/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6768 - acc: 0.7682 - val_loss: 0.6272 - val_acc: 0.7842\n",
      "Epoch 558/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6582 - acc: 0.7701 - val_loss: 0.6272 - val_acc: 0.7842\n",
      "Epoch 559/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6737 - acc: 0.7686 - val_loss: 0.6259 - val_acc: 0.7850\n",
      "Epoch 560/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6759 - acc: 0.7623 - val_loss: 0.6272 - val_acc: 0.7842\n",
      "Epoch 561/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6615 - acc: 0.7734 - val_loss: 0.6259 - val_acc: 0.7850\n",
      "Epoch 562/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6980 - acc: 0.7593 - val_loss: 0.6274 - val_acc: 0.7842\n",
      "Epoch 563/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6760 - acc: 0.7719 - val_loss: 0.6262 - val_acc: 0.7850\n",
      "Epoch 564/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6646 - acc: 0.7764 - val_loss: 0.6272 - val_acc: 0.7842\n",
      "Epoch 565/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6730 - acc: 0.7641 - val_loss: 0.6274 - val_acc: 0.7842\n",
      "\n",
      "Epoch 00565: loss improved from inf to 0.67295, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-2-000565-0.672954-0.784226.hdf5\n",
      "Epoch 566/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6676 - acc: 0.7731 - val_loss: 0.6274 - val_acc: 0.7842\n",
      "Epoch 567/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6855 - acc: 0.7630 - val_loss: 0.6270 - val_acc: 0.7842\n",
      "Epoch 568/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6710 - acc: 0.7626 - val_loss: 0.6268 - val_acc: 0.7842\n",
      "Epoch 569/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6691 - acc: 0.7716 - val_loss: 0.6267 - val_acc: 0.7842\n",
      "\n",
      "Epoch 00569: loss improved from 0.67295 to 0.66906, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-2-000569-0.669056-0.784226.hdf5\n",
      "Epoch 570/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6900 - acc: 0.7589 - val_loss: 0.6273 - val_acc: 0.7842\n",
      "Epoch 571/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6722 - acc: 0.7626 - val_loss: 0.6262 - val_acc: 0.7850\n",
      "Epoch 572/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6732 - acc: 0.7734 - val_loss: 0.6250 - val_acc: 0.7857\n",
      "Epoch 573/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6806 - acc: 0.7693 - val_loss: 0.6237 - val_acc: 0.7865\n",
      "Epoch 574/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6725 - acc: 0.7675 - val_loss: 0.6246 - val_acc: 0.7865\n",
      "Epoch 575/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6726 - acc: 0.7638 - val_loss: 0.6275 - val_acc: 0.7842\n",
      "Epoch 576/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6731 - acc: 0.7660 - val_loss: 0.6242 - val_acc: 0.7865\n",
      "Epoch 577/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6672 - acc: 0.7686 - val_loss: 0.6261 - val_acc: 0.7850\n",
      "\n",
      "Epoch 00577: loss improved from 0.66906 to 0.66722, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-2-000577-0.667218-0.784970.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 578/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6831 - acc: 0.7660 - val_loss: 0.6275 - val_acc: 0.7842\n",
      "Epoch 579/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6698 - acc: 0.7667 - val_loss: 0.6266 - val_acc: 0.7850\n",
      "Epoch 580/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6675 - acc: 0.7716 - val_loss: 0.6274 - val_acc: 0.7842\n",
      "Epoch 581/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.6586 - acc: 0.7757 - val_loss: 0.6264 - val_acc: 0.7850\n",
      "\n",
      "Epoch 00581: loss improved from 0.66722 to 0.65858, saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/Pbest-2-000581-0.658577-0.784970.hdf5\n",
      "Epoch 582/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.6825 - acc: 0.7626 - val_loss: 0.6244 - val_acc: 0.7857\n",
      "Epoch 583/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6782 - acc: 0.7619 - val_loss: 0.6248 - val_acc: 0.7850\n",
      "Epoch 584/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6860 - acc: 0.7664 - val_loss: 0.6274 - val_acc: 0.7842\n",
      "Epoch 585/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6742 - acc: 0.7634 - val_loss: 0.6272 - val_acc: 0.7842\n",
      "Epoch 586/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6841 - acc: 0.7634 - val_loss: 0.6262 - val_acc: 0.7850\n",
      "Epoch 587/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6881 - acc: 0.7567 - val_loss: 0.6266 - val_acc: 0.7850\n",
      "Epoch 588/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6767 - acc: 0.7667 - val_loss: 0.6266 - val_acc: 0.7842\n",
      "Epoch 589/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6730 - acc: 0.7675 - val_loss: 0.6266 - val_acc: 0.7842\n",
      "Epoch 590/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6734 - acc: 0.7623 - val_loss: 0.6277 - val_acc: 0.7842\n",
      "Epoch 591/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6766 - acc: 0.7682 - val_loss: 0.6261 - val_acc: 0.7850\n",
      "Epoch 592/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.6646 - acc: 0.7727 - val_loss: 0.6274 - val_acc: 0.7842\n",
      "Epoch 593/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6683 - acc: 0.7615 - val_loss: 0.6267 - val_acc: 0.7842\n",
      "Epoch 594/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6808 - acc: 0.7667 - val_loss: 0.6267 - val_acc: 0.7842\n",
      "Epoch 595/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6756 - acc: 0.7626 - val_loss: 0.6264 - val_acc: 0.7850\n",
      "Epoch 596/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6772 - acc: 0.7626 - val_loss: 0.6267 - val_acc: 0.7842\n",
      "Epoch 597/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6836 - acc: 0.7567 - val_loss: 0.6255 - val_acc: 0.7850\n",
      "Epoch 598/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.6830 - acc: 0.7582 - val_loss: 0.6238 - val_acc: 0.7857\n",
      "Epoch 599/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6804 - acc: 0.7686 - val_loss: 0.6268 - val_acc: 0.7850\n",
      "Epoch 600/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6806 - acc: 0.7701 - val_loss: 0.6268 - val_acc: 0.7842\n",
      "\n",
      "Epoch 00600: saving model to ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/2-000600-0.680581-0.784226.hdf5\n",
      "Epoch 601/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6643 - acc: 0.7653 - val_loss: 0.6275 - val_acc: 0.7842\n",
      "Epoch 602/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6790 - acc: 0.7734 - val_loss: 0.6197 - val_acc: 0.7872\n",
      "Epoch 603/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6658 - acc: 0.7697 - val_loss: 0.6239 - val_acc: 0.7857\n",
      "Epoch 604/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6819 - acc: 0.7697 - val_loss: 0.6243 - val_acc: 0.7857\n",
      "Epoch 605/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6874 - acc: 0.7667 - val_loss: 0.6253 - val_acc: 0.7850\n",
      "Epoch 606/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6830 - acc: 0.7664 - val_loss: 0.6253 - val_acc: 0.7850\n",
      "Epoch 607/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6816 - acc: 0.7679 - val_loss: 0.6262 - val_acc: 0.7850\n",
      "Epoch 608/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6572 - acc: 0.7746 - val_loss: 0.6263 - val_acc: 0.7850\n",
      "Epoch 609/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6785 - acc: 0.7653 - val_loss: 0.6237 - val_acc: 0.7857\n",
      "Epoch 610/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6808 - acc: 0.7641 - val_loss: 0.6265 - val_acc: 0.7850\n",
      "Epoch 611/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6782 - acc: 0.7701 - val_loss: 0.6260 - val_acc: 0.7850\n",
      "Epoch 612/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6848 - acc: 0.7608 - val_loss: 0.6253 - val_acc: 0.7850\n",
      "Epoch 613/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6679 - acc: 0.7753 - val_loss: 0.6267 - val_acc: 0.7842\n",
      "Epoch 614/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.6879 - acc: 0.7582 - val_loss: 0.6256 - val_acc: 0.7850\n",
      "Epoch 615/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6836 - acc: 0.7612 - val_loss: 0.6266 - val_acc: 0.7850\n",
      "Epoch 616/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6736 - acc: 0.7679 - val_loss: 0.6268 - val_acc: 0.7850\n",
      "Epoch 617/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.6753 - acc: 0.7667 - val_loss: 0.6266 - val_acc: 0.7850\n",
      "Epoch 618/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6657 - acc: 0.7723 - val_loss: 0.6274 - val_acc: 0.7842\n",
      "Epoch 619/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6893 - acc: 0.7593 - val_loss: 0.6255 - val_acc: 0.7850\n",
      "Epoch 620/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6889 - acc: 0.7604 - val_loss: 0.6243 - val_acc: 0.7857\n",
      "Epoch 621/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6819 - acc: 0.7679 - val_loss: 0.6258 - val_acc: 0.7850\n",
      "Epoch 622/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6790 - acc: 0.7697 - val_loss: 0.6257 - val_acc: 0.7850\n",
      "Epoch 623/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6790 - acc: 0.7682 - val_loss: 0.6226 - val_acc: 0.7857\n",
      "Epoch 624/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.6776 - acc: 0.7563 - val_loss: 0.6268 - val_acc: 0.7850\n",
      "Epoch 625/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6784 - acc: 0.7645 - val_loss: 0.6276 - val_acc: 0.7842\n",
      "Epoch 626/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6683 - acc: 0.7675 - val_loss: 0.6254 - val_acc: 0.7857\n",
      "Epoch 627/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.6750 - acc: 0.7660 - val_loss: 0.6250 - val_acc: 0.7850\n",
      "Epoch 628/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6684 - acc: 0.7712 - val_loss: 0.6252 - val_acc: 0.7850\n",
      "Epoch 629/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6675 - acc: 0.7626 - val_loss: 0.6264 - val_acc: 0.7850\n",
      "Epoch 630/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6733 - acc: 0.7705 - val_loss: 0.6270 - val_acc: 0.7842\n",
      "Epoch 631/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6671 - acc: 0.7679 - val_loss: 0.6258 - val_acc: 0.7850\n",
      "Epoch 632/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6680 - acc: 0.7727 - val_loss: 0.6258 - val_acc: 0.7857\n",
      "Epoch 633/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6798 - acc: 0.7660 - val_loss: 0.6257 - val_acc: 0.7850\n",
      "Epoch 634/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6577 - acc: 0.7705 - val_loss: 0.6263 - val_acc: 0.7842\n",
      "Epoch 635/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.6736 - acc: 0.7597 - val_loss: 0.6271 - val_acc: 0.7842\n",
      "Epoch 636/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 20ms/step - loss: 0.6775 - acc: 0.7671 - val_loss: 0.6266 - val_acc: 0.7842\n",
      "Epoch 637/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6922 - acc: 0.7612 - val_loss: 0.6240 - val_acc: 0.7850\n",
      "Epoch 638/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6605 - acc: 0.7682 - val_loss: 0.6270 - val_acc: 0.7842\n",
      "Epoch 639/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6792 - acc: 0.7667 - val_loss: 0.6229 - val_acc: 0.7857\n",
      "Epoch 640/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6833 - acc: 0.7634 - val_loss: 0.6234 - val_acc: 0.7857\n",
      "Epoch 641/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6703 - acc: 0.7727 - val_loss: 0.6273 - val_acc: 0.7842\n",
      "Epoch 642/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6749 - acc: 0.7649 - val_loss: 0.6253 - val_acc: 0.7850\n",
      "Epoch 643/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6839 - acc: 0.7653 - val_loss: 0.6277 - val_acc: 0.7842\n",
      "Epoch 644/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6681 - acc: 0.7641 - val_loss: 0.6269 - val_acc: 0.7850\n",
      "Epoch 645/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6672 - acc: 0.7664 - val_loss: 0.6261 - val_acc: 0.7850\n",
      "Epoch 646/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6846 - acc: 0.7582 - val_loss: 0.6272 - val_acc: 0.7842\n",
      "Epoch 00646: early stopping\n",
      "ModelCheckpoint 已经保存到 ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/weights/2-final.hdf5\n",
      "save in: ../datasets/casas/results/WCNNR/milan/5/20220201_2000_64_1_3_1/log/20220201_2000_64_1_3_1.csv\n",
      "time: 0:14:58 s\n",
      "time: 898.0 s\n",
      "average 0.898000 s\n",
      "2 epoch finished\n",
      "--------------------   best   --------------------\n",
      "no_activities: 10\n",
      "\n",
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1348/1348 [==============================] - 2s 2ms/step\n",
      "2-milan:\tacc: 78.41%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 0, 0, 0, 4, 4, 4, 0, 0, 0, 0, 0, 4, 4, 4, 0, 0, 4, 4, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 2, 2, 7, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 0, 7, 7, 7, 0, 0, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 0, 0, 7, 7, 7, 7, 7, 7, 7, 0, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 0, 7, 0, 0, 0, 7, 7, 7, 7, 7, 7, 7, 0, 4, 7, 7, 0, 7, 7, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 9, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 2, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 0, 5, 4, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 0, 9, 0, 0, 9, 9, 0, 0, 9, 0, 0, 0, 9, 0, 0, 9, 0, 0, 9, 9, 0, 0, 0, 0, 0, 7, 0, 0, 9, 0, 0, 0, 0, 9, 0, 9, 9, 0, 0, 0, 0, 9, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7, 7, 7, 7, 2, 2, 2, 2, 7, 0, 2, 2, 2, 2, 0, 0, 9, 0, 0, 0, 0, 7, 0, 0, 0, 4, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 9, 0, 0, 7, 0, 0, 7, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7, 0, 7, 0, 7, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 9, 0, 0, 0, 0, 0, 0, 7, 0, 5, 0, 0, 0, 0, 0, 0, 4, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 4, 4, 4, 0, 4, 4, 4, 4, 0, 4, 4, 4, 4, 0, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 0, 4, 0, 0, 4, 4, 0, 4, 4, 4, 4, 0, 4, 9, 4, 4, 7, 0, 0, 0, 4, 0, 4, 4, 0, 0, 4, 4, 0, 4, 4, 4, 0, 4, 0, 4, 4, 9, 0, 4, 0, 0, 4, 0, 4, 4, 0, 0, 4, 4, 0, 4, 0, 4, 4, 4, 4, 0, 0, 4, 4, 4, 0, 7, 4, 4, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 9, 0, 9, 0, 9, 9, 9, 0, 0, 0, 0, 9, 0, 0, 9, 0, 4, 4, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 0, 4, 0, 4, 4, 4, 0, 4, 0, 0, 4, 0, 0, 0]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.778393  0.902087  0.835688       623\n",
      "         Work   0.000000  0.000000  0.000000        26\n",
      "Take_medicine   0.923077  0.600000  0.727273        20\n",
      "        Sleep   0.000000  0.000000  0.000000        32\n",
      "        Relax   0.792079  0.559441  0.655738       143\n",
      "   Leave_Home   0.898551  0.873239  0.885714        71\n",
      "          Eat   0.000000  0.000000  0.000000         7\n",
      "         Cook   0.825137  0.816216  0.820652       185\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        29\n",
      "      Bathing   0.730769  0.896226  0.805085       212\n",
      "\n",
      "     accuracy                       0.784125      1348\n",
      "    macro avg   0.494801  0.464721  0.473015      1348\n",
      " weighted avg   0.732966  0.784125  0.752473      1348\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  28   0   0   1   0   0]\n",
      " [  0   0   0   0   2   1   0  15   8   0]\n",
      " [  0   0   0   0   0   0   0   7   0   0]\n",
      " [  0   0   0  12   0   7   0   1   0   0]\n",
      " [  0   0   0   0 190   0   0  22   0   0]\n",
      " [  0   0   0   1   1 151   0  31   1   0]\n",
      " [  0   0   0   0   0   0  62   6   3   0]\n",
      " [  0   0   0   0  25  20   7 562   9   0]\n",
      " [  0   0   0   0   2   4   0  57  80   0]\n",
      " [  0   0   0   0  12   0   0  20   0   0]]\n",
      "--------------------   final   --------------------\n",
      "no_activities: 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created model and loaded weights from file\n",
      "Begin testing ...\n",
      "1348/1348 [==============================] - 2s 2ms/step\n",
      "2-milan:\tacc: 78.49%\n",
      "Report:\n",
      "********************\n",
      "list(Y[test]: [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "classes: [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 9, 0, 0, 0, 4, 4, 4, 0, 0, 0, 0, 0, 4, 4, 4, 0, 0, 0, 4, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 2, 2, 7, 2, 2, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 0, 7, 7, 7, 0, 0, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 0, 0, 7, 7, 7, 7, 7, 7, 7, 0, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 0, 7, 0, 0, 0, 7, 7, 7, 7, 7, 7, 7, 0, 4, 7, 7, 0, 7, 7, 0, 7, 7, 0, 7, 7, 7, 7, 7, 7, 0, 7, 7, 0, 7, 7, 9, 0, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 2, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 0, 5, 4, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 0, 9, 0, 0, 9, 9, 0, 0, 9, 0, 0, 0, 9, 0, 0, 9, 0, 0, 9, 9, 0, 0, 0, 0, 0, 7, 0, 0, 9, 0, 0, 0, 0, 9, 0, 9, 9, 0, 0, 0, 0, 9, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7, 7, 7, 7, 2, 2, 2, 2, 7, 0, 2, 2, 2, 2, 0, 0, 9, 0, 0, 0, 0, 7, 0, 0, 0, 4, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 9, 0, 0, 7, 0, 0, 7, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7, 0, 7, 0, 7, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 9, 0, 0, 0, 0, 0, 0, 7, 0, 5, 0, 0, 0, 0, 0, 0, 4, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 4, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 4, 4, 4, 0, 4, 4, 4, 4, 0, 4, 4, 4, 4, 0, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 0, 4, 0, 0, 4, 4, 0, 4, 4, 4, 4, 0, 4, 9, 4, 4, 7, 0, 0, 0, 4, 0, 4, 4, 0, 0, 4, 4, 0, 4, 4, 4, 0, 4, 0, 4, 4, 9, 0, 4, 0, 0, 4, 4, 4, 4, 0, 0, 4, 4, 0, 4, 0, 4, 4, 4, 4, 0, 4, 4, 4, 4, 0, 7, 4, 4, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 9, 0, 9, 0, 9, 9, 9, 0, 0, 0, 0, 9, 0, 0, 9, 0, 4, 4, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 4, 0, 0, 0, 0, 7, 0, 0, 4, 0, 4, 4, 4, 0, 4, 0, 0, 4, 0, 0, 0]\n",
      "********************\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Other   0.779167  0.900482  0.835443       623\n",
      "         Work   0.000000  0.000000  0.000000        26\n",
      "Take_medicine   0.923077  0.600000  0.727273        20\n",
      "        Sleep   0.000000  0.000000  0.000000        32\n",
      "        Relax   0.788462  0.573427  0.663968       143\n",
      "   Leave_Home   0.898551  0.873239  0.885714        71\n",
      "          Eat   0.000000  0.000000  0.000000         7\n",
      "         Cook   0.828729  0.810811  0.819672       185\n",
      "Bed_to_toilet   0.000000  0.000000  0.000000        29\n",
      "      Bathing   0.731801  0.900943  0.807611       212\n",
      "\n",
      "     accuracy                       0.784866      1348\n",
      "    macro avg   0.494979  0.465890  0.473968      1348\n",
      " weighted avg   0.733595  0.784866  0.753496      1348\n",
      "\n",
      "Confusion matrix:\n",
      "confusion matrix's labels is: [8, 1, 6, 2, 9, 7, 5, 0, 4, 3]\n",
      "[[  0   0   0   0  28   0   0   1   0   0]\n",
      " [  0   0   0   0   2   1   0  16   7   0]\n",
      " [  0   0   0   0   0   0   0   7   0   0]\n",
      " [  0   0   0  12   0   7   0   1   0   0]\n",
      " [  0   0   0   0 191   0   0  21   0   0]\n",
      " [  0   0   0   1   1 150   0  32   1   0]\n",
      " [  0   0   0   0   0   0  62   6   3   0]\n",
      " [  0   0   0   0  25  19   7 561  11   0]\n",
      " [  0   0   0   0   2   4   0  55  82   0]\n",
      " [  0   0   0   0  12   0   0  20   0   0]]\n",
      "best: current database: milan \t 78.37% (+/- 1.16%)\n",
      "final: current database: milan \t 78.34% (+/- 1.16%)\n",
      "CPU times: user 51min 53s, sys: 2min 14s, total: 54min 7s\n",
      "Wall time: 57min 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/musk/anaconda3/envs/HARedit/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=[8, 1, 6, 2, 9, 7, 5, 0, 4, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dict_config_cus['distance_int'] = '5'\n",
    "train_val(dict_config_cus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "scrolled": true
   },
   "source": [
    "```bash\n",
    "best: current database: milan \t 78.37% (+/- 1.16%)\n",
    "final: current database: milan \t 78.34% (+/- 1.16%)\n",
    "CPU times: user 51min 53s, sys: 2min 14s, total: 54min 7s\n",
    "Wall time: 57min 3s\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[origin](#origin)\n",
    "\n",
    "[C](#constrain)\n",
    "\n",
    "[CS_1](#constrain_1)\n",
    "\n",
    "[CS_2](#constrain_2)\n",
    "\n",
    "[CS_3](#constrain_3)\n",
    "\n",
    "[CS_4](#constrain_4)\n",
    "\n",
    "[CS_5](#constrain_5)\n",
    "\n",
    "[statics](#statics)\n",
    "\n",
    "# <a id='statics'>statics</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>9999</th>\n",
       "      <th>999</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>76.4896</td>\n",
       "      <td>77.3545</td>\n",
       "      <td>94.2645</td>\n",
       "      <td>78.3685</td>\n",
       "      <td>77.3793</td>\n",
       "      <td>77.429</td>\n",
       "      <td>78.3433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.73334</td>\n",
       "      <td>0.628945</td>\n",
       "      <td>0.184676</td>\n",
       "      <td>0.423783</td>\n",
       "      <td>0.791054</td>\n",
       "      <td>0.761299</td>\n",
       "      <td>1.16143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        9999       999         1         2         3         4        5\n",
       "753  76.4896   77.3545   94.2645   78.3685   77.3793    77.429  78.3433\n",
       "std  0.73334  0.628945  0.184676  0.423783  0.791054  0.761299  1.16143"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_config_cus = general.Merge(METHOD_PARAMETER_TEMPLATE, dict_config_cus)\n",
    "general.static_distant(dict_config_cus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_config_cus = general.Merge(METHOD_PARAMETER_TEMPLATE, dict_config_cus)\n",
    "general.static_distant(dict_config_cus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
